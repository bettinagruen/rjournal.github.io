markdown: kramdown
issues:
- issue: accepted
  articles:
  - slug: RJ-2019-001
    title: 'atable: Create Tables for Clinical Trial Reports'
    bibtitle: 'atable: Create Tables for Clinical Trial Reports'
    author: Armin Ströbel
    bibauthor: Armin Ströbel
    abstract: '  Abstract Examining distributions of variables is the first step in
      the analysis of a clinical trial before            more specific modelling can
      begin. Reporting these results to stakeholders of the trial is an essential            part
      of a statistician’s work. The atable package facilitates these steps by offering
      easy-to-use but still            flexible functions.'
    acknowledged: '2018-10-08'
    online: '2019-07-22'
    CRANpkgs:
    - multgee
    - Hmisc
    - knitr
    - xtable
    - flextable
    - settings
    - survival
    - furniture
    - tableone
    - stargazer
    - DescTools
    - margrittr
    - dplyr
    CTV_rev:
    - ReproducibleResearch
    - SocialSciences
    - ClinicalTrials
    - Econometrics
    - MissingData
    - Bayesian
    - ModelDeployment
    - Multivariate
    - OfficialStatistics
    - Survival
    suppl: 2 Kb
    landing: '2019'
  - slug: RJ-2019-002
    title: Connecting R with D3 for dynamic graphics, to explore multivariate data
      with tours
    bibtitle: |-
      Connecting R with D3 for dynamic graphics, to explore
                multivariate data with tours
    author:
    - Michael Kipp
    - Ursula Laa
    - Dianne Cook
    bibauthor: Michael Kipp and Ursula Laa and Dianne Cook
    abstract: '  Abstract The tourr package in R has several algorithms and displays
      for showing multivariate data as            a sequence of low-dimensional projections.
      It can display as a movie but has no capacity for interaction,            such
      as stop/go, change tour type, drop/add variables. The tourrGui package provides
      these sorts            of controls, but the interface is programmed with the
      dated RGtk2 package. This work explores            using custom messages to
      pass data from R to D3 for viewing, using the Shiny framework. This is an            approach
      that can be generally used for creating all sorts of interactive graphics.'
    acknowledged: '2018-04-04'
    online: '2019-07-30'
    CRANpkgs:
    - tourr
    - tourrGui
    - RGtk2
    CTV_rev: Graphics
    landing: '2019'
  - slug: RJ-2019-003
    title: 'dr4pl: A Stable Convergence Algorithm for the 4 Parameter Logistic Model'
    bibtitle: |-
      dr4pl: A Stable Convergence Algorithm for the 4 Parameter
                Logistic Model
    author:
    - Hyowon An
    - Justin T. Landis
    - Aubrey G. Bailey
    - James S. Marron
    - Dirk P. Dittmer
    bibauthor: |-
      Hyowon An and Justin T. Landis and Aubrey G. Bailey and
                James S. Marron and Dirk P. Dittmer
    abstract: '  Abstract The 4 Parameter Logistic (4PL) model has been recognized
      as a major tool to analyze the            relationship between doses and responses
      in pharmacological experiments. A main strength of this            model is
      that each parameter contributes an intuitive meaning enhancing interpretability
      of a fitted            model. However, implementing the 4PL model using conventional
      statistical software often encounters            numerical errors. This paper
      highlights the issue of convergence failure and presents several causes            with
      solutions. These causes include outliers and a non-logistic data shape, so useful
      remedies such            as robust estimation, outlier diagnostics and constrained
      optimization are proposed. These features            are implemented in a new
      R package dr4pl (Dose-Response analysis using the 4 Parameter Logistic            model)
      whose code examples are presented as a separate section. Our R package dr4pl
      is shown to            work well for data sets where the traditional dose-response
      modelling packages drc and nplr fail.'
    acknowledged: '2018-04-04'
    online: '2019-07-30'
    CRANpkgs:
    - dr4pl
    - drc
    - nplr
    CTV_rev: ChemPhys
    suppl: 4.1 Kb
    landing: '2019'
  - slug: RJ-2019-004
    title: 'Time Series Forecasting with KNN in R: the tsfknn Package'
    bibtitle: 'Time Series Forecasting with KNN in R: the tsfknn Package'
    author:
    - Francisco Martínez
    - María P. Frías
    - Francisco Charte
    - Antonio J. Rivera
    bibauthor: |-
      Francisco Martínez and María P. Frías and Francisco Charte
                and Antonio J. Rivera
    abstract: '  Abstract In this paper the tsfknn package for time series forecasting
      using k-nearest neighbor regres           sion is described. This package allows
      users to specify a KNN model and to generate its forecasts.            The user
      can choose among different multi-step ahead strategies and among different functions
      to            aggregate the targets of the nearest neighbors. It is also possible
      to assess the forecast accuracy of the            KNN model.'
    acknowledged: '2018-05-29'
    online: '2019-07-30'
    CRANpkgs:
    - forecast
    - caret
    - nnfor
    - tsfknn
    - forecastHybrid
    - GMDH
    - NTS
    - tsDyn
    - nnet
    - neuralnet
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - MachineLearning
    - Environmetrics
    - HighPerformanceComputing
    - MissingData
    - Multivariate
    - SocialSciences
    suppl: 718 bytes
    landing: '2019'
  - slug: RJ-2019-005
    title: 'rollmatch: An R Package for Rolling Entry Matching'
    bibtitle: 'rollmatch: An R Package for Rolling Entry Matching'
    author:
    - Kasey Jones
    - Rob Chew
    - Allison Witman
    - Yiyan Liu
    bibauthor: Kasey Jones and Rob Chew and Allison Witman and Yiyan Liu
    abstract: '  Abstract The gold standard of experimental research is the randomized
      control trial. However,            interventions are often implemented without
      a randomized control group for practical or ethical            reasons. Propensity
      score matching (PSM) is a popular method for minimizing the effects of a            randomized
      experiment from observational data by matching members of a treatment group
      to similar            candidates that did not receive the intervention. Traditional
      PSM is not designed for studies that enroll            participants on a rolling
      basis and does not provide a solution for interventions in which the baseline            and
      intervention period are undefined in the comparison group. Rolling Entry Matching
      (REM) is a            new matching method that addresses both issues. REM selects
      comparison members who are similar            to intervention members with respect
      to both static (e.g., race) and dynamic (e.g., health conditions)            characteristics.
      This paper will discuss the key components of REM and introduce the rollmatch
      R            package.'
    acknowledged: '2018-05-29'
    online: '2019-07-30'
    CRANpkgs:
    - rollmatch
    - CBPS
    - ipw
    - MatchIt
    - Matching
    - optmatch
    CTV_rev:
    - SocialSciences
    - HighPerformanceComputing
    - MissingData
    - OfficialStatistics
    - Optimization
    suppl: 1.1 Kb
    landing: '2019'
  - slug: RJ-2019-006
    title: 'orthoDr: Semiparametric Dimension Reduction via Orthogonality Constrained
      Optimization'
    bibtitle: |-
      orthoDr: Semiparametric Dimension Reduction via
                Orthogonality Constrained Optimization
    author:
    - Ruoqing Zhu
    - Jiyang Zhang
    - Ruilin Zhao
    - Peng Xu
    - Wenzhuo Zhou
    - Xin Zhang
    bibauthor: |-
      Ruoqing Zhu and Jiyang Zhang and Ruilin Zhao and Peng Xu and
                Wenzhuo Zhou and Xin Zhang
    abstract: '  Abstract orthoDr is a package in R that solves dimension reduction
      problems using orthogonality            constrained optimization approach. The
      package serves as a unified framework for many regression            and survival
      analysis dimension reduction models that utilize semiparametric estimating equations.            The
      main computational machinery of orthoDr is a first-order algorithm developed
      by Wen and            Yin (2012) for optimization within the Stiefel manifold.
      We implement the algorithm through Rcpp            and OpenMP for fast computation.
      In addition, we developed a general-purpose solver for such            constrained
      problems with user-specified objective functions, which works as a drop-in version
      of            optim(). The package also serves as a platform for future methodology
      developments along this line            of work.'
    acknowledged: []
    online: '2019-07-30'
    CRANpkgs:
    - orthoDr
    - Rcpp
    - RcppArmadillo
    - ManifoldOpthm
    CTV_rev:
    - NumericalMathematics
    - HighPerformanceComputing
    suppl: 14.2 Kb
    landing: '2019'
  - slug: RJ-2019-007
    title: 'Modeling regimes with extremes: the bayesdfa package for identifying and
      forecasting common trends and anomalies in multivariate time-series data'
    bibtitle: |-
      Modeling regimes with extremes: the bayesdfa package for
                identifying and forecasting common trends and anomalies in
                multivariate time-series data
    author:
    - Eric J. Ward
    - Sean C. Anderson
    - Luis A. Damiano
    - Mary E. Hunsicker
    - Michael A. Litzow
    bibauthor: |-
      Eric J. Ward and Sean C. Anderson and Luis A. Damiano and
                Mary E. Hunsicker and Michael A. Litzow
    abstract: '  Abstract The bayesdfa package provides a flexible Bayesian modeling
      framework for applying dy           namic factor analysis (DFA) to multivariate
      time-series data as a dimension reduction tool. The core            estimation
      is done with the Stan probabilistic programming language. In addition to being
      one of the            few Bayesian implementations of DFA, novel features of
      this model include (1) optionally modeling            latent process deviations
      as drawn from a Student-t distribution to better model extremes, and (2)            optionally
      including autoregressive and moving-average components in the latent trends.
      Besides            estimation, we provide a series of plotting functions to
      visualize trends, loadings, and model pre           dicted values. A secondary
      analysis for some applications is to identify regimes in latent trends. We            provide
      a flexible Bayesian implementation of a Hidden Markov Model — also written with
      Stan — to            characterize regime shifts in latent processes. We provide
      simulation testing and details on parameter            sensitivities in supplementary
      information.'
    acknowledged: '2018-10-08'
    online: '2019-07-30'
    CRANpkgs:
    - dlm
    - KFAS
    - MARSS
    - tsfa
    - rstan
    - heavy
    - bsts
    - stochvol
    - loo
    - depmixS4
    - HMM
    - msm
    CTV_rev:
    - TimeSeries
    - Bayesian
    - Finance
    - Cluster
    - Distributions
    - Econometrics
    - Multivariate
    - Survival
    landing: '2019'
  - slug: RJ-2019-008
    title: Optimization Routines for Enforcing One-to-One Matches in Record Linkage
      Problems
    bibtitle: |-
      Optimization Routines for Enforcing One-to-One Matches in
                Record Linkage Problems
    author:
    - Diego Moretti
    - Luca Valentino
    - Tiziana Tuoto
    bibauthor: Diego Moretti and Luca Valentino and Tiziana Tuoto
    abstract: '  Abstract Record linkage aims at quickly and accurately identifying
      if two records represent the same            real world entity. In many applications,
      we are interested in restricting the linkage results to "1 to 1"            links,
      that is a single record does not appear more than once in the output. This can
      be dealt with the            transport algorithm. The optimization problem,
      however, grows quadratically in the size of the input,            quickly becoming
      untreatable for cases with a few thousand records. This paper compares different            solutions,
      provided by some R packages for linear programming solvers. The comparison is
      done            in terms of memory usage and execution time. The aim is to overcome
      the current implementation            in the toolkit RELAIS, specifically developed
      for record linkage problems. The results highlight            improvements beyond
      expectations. In fact the tested solutions allow successfully executing the
      "1 to            1" reduction for large size datasets up to the largest sample
      surveys at National Statistical Institutes.'
    acknowledged: '2018-10-26'
    online: '2019-07-30'
    CRANpkgs:
    - lpSolve
    - Rglpk
    - ROI.plugin.clp
    - intpoint
    - slam
    CTV_rev: Optimization
    suppl: 180 bytes
    landing: '2019'
  - slug: RJ-2019-009
    title: 'mixedsde: A Package to Fit Mixed Stochastic Differential Equations'
    bibtitle: |-
      mixedsde: A Package to Fit Mixed Stochastic Differential
                Equations
    author:
    - Charlotte Dion
    - Simone Hermann
    - Adeline Samson
    bibauthor: Charlotte Dion and Simone Hermann and Adeline Samson
    abstract: '  Abstract Stochastic differential equations (SDEs) are useful to model
      continuous stochastic processes.            When (independent) repeated temporal
      data are available, variability between the trajectories can be            modeled
      by introducing random effects in the drift of the SDEs. These models are useful
      to analyze            neuronal data, crack length data, pharmacokinetics, financial
      data, to cite some applications among            other. The R package focuses
      on the estimation of SDEs with linear random effects in the drift. The goal            is
      to estimate the common density of the random effects from repeated discrete
      observations of the            SDE. The package mixedsde proposes three estimation
      methods: a Bayesian parametric, a frequentist            parametric and a frequentist
      nonparametric method. The three procedures are described as well as the            main
      functions of the package. Illustrations are presented on simulated and real
      data.'
    acknowledged: '2017-08-11'
    online: '2019-08-15'
    suppl: 3.3 Kb
    landing: '2019'
  - slug: RJ-2019-010
    title: 'Indoor Positioning and Fingerprinting: The R Package ipft'
    bibtitle: 'Indoor Positioning and Fingerprinting: The R Package ipft'
    author:
    - Emilio Sansano
    - Raúl Montoliu
    - Óscar Belmonte
    - Joaquín Torres-Sospedra
    bibauthor: |-
      Emilio Sansano and Raúl Montoliu and Óscar Belmonte and
                Joaquín Torres-Sospedra
    abstract: '  Abstract Methods based on Received Signal Strength Indicator (RSSI)
      fingerprinting are in the            forefront among several techniques being
      proposed for indoor positioning. This paper introduces            the R package
      ipft, which provides algorithms and utility functions for indoor positioning
      using            fingerprinting techniques. These functions are designed for
      manipulation of RSSI fingerprint data            sets, estimation of positions,
      comparison of the performance of different positioning models, and            graphical
      visualization of data. Well-known machine learning algorithms are implemented
      in this            package to perform analysis and estimations over RSSI data
      sets. The paper provides a description            of these algorithms and functions,
      as well as examples of its use with real data. The ipft package            provides
      a base that we hope to grow into a comprehensive library of fingerprinting-based
      indoor            positioning methodologies.'
    acknowledged: '2018-02-02'
    online: '2019-08-15'
    CRANpkgs:
    - ipft
    - ggplot2
    CTV_rev:
    - Graphics
    - Phylogenetics
    - TeachingStatistics
    suppl: 1.8 Kb
    landing: '2019'
  - slug: RJ-2019-011
    title: 'RobustGaSP: Robust Gaussian Stochastic Process Emulation in R'
    bibtitle: |-
      RobustGaSP: Robust Gaussian Stochastic Process Emulation in
                R
    author:
    - Mengyang Gu
    - Jesus Palomo
    - James O. Berger
    bibauthor: Mengyang Gu and Jesus Palomo and James O. Berger
    abstract: '  Abstract Gaussian stochastic process (GaSP) emulation is a powerful
      tool for approximating compu           tationally intensive computer models.
      However, estimation of parameters in the GaSP emulator is            a challenging
      task. No closed-form estimator is available and many numerical problems arise
      with            standard estimates, e.g., the maximum likelihood estimator.
      In this package, we implement a marginal            posterior mode estimator,
      for special priors and parameterizations. This estimation method that            meets
      the robust parameter estimation criteria was discussed in Gu et al. (2018);
      mathematical reasons            are provided therein to explain why robust parameter
      estimation can greatly improve predictive            performance of the emulator.
      In addition, inert inputs (inputs that almost have no effect on the            variability
      of a function) can be identified from the marginal posterior mode estimation
      at no extra            computational cost. The package also implements the parallel
      partial Gaussian stochastic process            (PP GaSP) emulator (Gu and Berger
      (2016)) for the scenario where the computer model has multiple            outputs
      on, for example, spatial-temporal coordinates. The package can be operated in
      a default mode,            but also allows numerous user specifications, such
      as the capability of specifying trend functions and            noise terms.
      Examples are studied herein to highlight the performance of the package in terms
      of            out-of-sample prediction.'
    acknowledged: []
    online: '2019-08-15'
    CRANpkgs:
    - DiceKriging
    - GPfit
    - mleGP
    - spatial
    - fields
    - RobustGaSP
    - lhs
    - sensitivity
    - nloptr
    CTV_rev:
    - ExperimentalDesign
    - Spatial
    - Distributions
    - Environmetrics
    - Optimization
    - SocialSciences
    suppl: 4.1 Kb
    landing: '2019'
  - slug: RJ-2019-012
    title: 'What''s for dynr: A Package for Linear and Nonlinear Dynamic Modeling
      in R'
    bibtitle: |-
      What's for dynr: A Package for Linear and Nonlinear Dynamic
                Modeling in R
    author:
    - 'Lu Ou+ '
    - 'Michael D. Hunter+ '
    - Sy-Miin Chow
    bibauthor: Lu Ou+ and Michael D. Hunter+ and Sy-Miin Chow
    abstract: '  Abstract Intensive longitudinal data in the behavioral sciences are
      often noisy, multivariate in na           ture, and may involve multiple units
      undergoing regime switches by showing discontinuities in           terspersed
      with continuous dynamics. Despite increasing interest in using linear and nonlinear            differential/difference
      equation models with regime switches, there has been a scarcity of software            packages
      that are fast and freely accessible. We have created an R package called dynr
      that can handle            a broad class of linear and nonlinear discreteand
      continuous-time models, with regime-switching            properties and linear
      Gaussian measurement functions, in C, while maintaining simple and easy-to           learn
      model specification functions in R. We present the mathematical and computational
      bases used            by the dynr R package, and present two illustrative examples
      to demonstrate the unique features of            dynr.'
    acknowledged: '2018-02-02'
    online: '2019-08-15'
    CRANpkgs:
    - dynr
    - dlm
    - KFAS
    - dse
    - OpenMx
    - ctsem
    - depmixS4
    - RHmm
    - MSwM
    - MSBVAR
    - MSGARCH
    - pomp
    - stats
    - Rcpp
    - RcppGSL
    - mice
    CTVs: TimeSeries
    CTV_rev:
    - TimeSeries
    - Finance
    - MissingData
    - Psychometrics
    - Bayesian
    - Cluster
    - DifferentialEquations
    - Environmetrics
    - HighPerformanceComputing
    - Multivariate
    - NumericalMathematics
    - OfficialStatistics
    - SocialSciences
    suppl: 4.2 Kb
    landing: '2019'
  - slug: RJ-2019-016
    title: Identifying and Testing Recursive vs. Interdependent Links in Simultaneous
      Equation Models via the SIRE Package
    bibtitle: |-
      Identifying and Testing Recursive vs. Interdependent Links
                in Simultaneous Equation Models via the SIRE Package
    author:
    - Gianmarco Vacca
    - Maria Grazia Zoia
    bibauthor: Gianmarco Vacca and Maria Grazia Zoia
    abstract: ' Abstract Simultaneous equation models (SEMs) are composed of relations
      which either represent           by Gianmarco Vacca and Maria Grazia Zoia           Package           Equation
      Models via the SIRE           Interdependent Links in Simultaneous           Identifying
      and Testing Recursive vs. Contributed research article                                                                                         1'
    acknowledged: '2018-10-08'
    online: '2019-08-15'
    CRANpkgs:
    - SIRE
    - igraph
    - systemfit
    - Rsolnp
    CTV_rev:
    - Optimization
    - Econometrics
    - gR
    - Graphics
    - Psychometrics
    - Spatial
    suppl: 1.8 Kb
    landing: '2019'
  - slug: RJ-2019-017
    title: 'fclust: An R Package for Fuzzy Clustering'
    bibtitle: 'fclust: An R Package for Fuzzy Clustering'
    author:
    - Maria Brigida Ferraro
    - Paolo Giordani
    - Alessio Serafini
    bibauthor: |-
      Maria Brigida Ferraro and Paolo Giordani and Alessio
                Serafini
    abstract: ' Abstract Fuzzy clustering methods discover fuzzy partitions where
      observations can be softly assigned           to more than one cluster. The
      package fclust is a toolbox for fuzzy clustering in the R programming           language.
      It not only implements the widely used fuzzy k-means (FkM) algorithm, but also
      many FkM           variants. Fuzzy cluster similarity measures, cluster validity
      indices and cluster visualization tools           are also offered. In the current
      version, all the functions are rewritten in the C++ language allowing           their
      application in large-size problems. Moreover, new fuzzy relational clustering
      algorithms for           partitioning qualitative/mixed data are provided together
      with an improved version of the so-called           Gustafson-Kessel algorithm
      to avoid singularity in the cluster covariance matrices. Finally, it is now           possible
      to automatically select the number of clusters by means of the available fuzzy
      cluster validity           indices.'
    acknowledged: '2018-12-01'
    online: '2019-08-15'
    CRANpkgs:
    - fclust
    - cluster
    - clue
    - e1071
    - skmeans
    - vegclust
    - ppclust
    - Rcpp
    - RcppArmadillo
    - smacof
    - MASS
    CTV_rev:
    - Cluster
    - Multivariate
    - Environmetrics
    - NumericalMathematics
    - Psychometrics
    - Distributions
    - Robust
    - Econometrics
    - HighPerformanceComputing
    - MachineLearning
    - NaturalLanguageProcessing
    - Optimization
    - SocialSciences
    - TeachingStatistics
    suppl: 2.5 Kb
    landing: '2019'
  - slug: RJ-2019-018
    title: 'Matching with Clustered Data: the CMatching Package in R'
    bibtitle: 'Matching with Clustered Data: the CMatching Package in R'
    author:
    - Massimo Cannas
    - Bruno Arpino
    bibauthor: Massimo Cannas and Bruno Arpino
    abstract: '  Abstract Matching is a well known technique to balance covariates
      distribution between treated and            control units in non-experimental
      studies. In many fields, clustered data are a very common occurrence            in
      the analysis of observational data and the clustering can add potentially interesting
      information.            Matching algorithms should be adapted to properly exploit
      the hierarchical structure. In this article we            present the CMatching
      package implementing matching algorithms for clustered data. The package            provides
      functions for obtaining a matched dataset along with estimates of most common
      parameters            of interest and model-based standard errors. A propensity
      score matching analysis, relating math            proficiency with homework
      completion for students belonging to different schools (based on the            NELS-88
      data), illustrates in detail the use of the algorithms.'
    acknowledged: '2018-10-26'
    online: '2019-08-15'
    CRANpkgs:
    - CMatching
    - Matching
    - designmatch
    - optmatch
    - MatchIT
    - quickmatch
    - multiwayvcov
    CTV_rev:
    - SocialSciences
    - Econometrics
    - ExperimentalDesign
    - HighPerformanceComputing
    - Optimization
    suppl: 1.9 Kb
    landing: '2019'
  - slug: RJ-2019-019
    title: 'MDFS: MultiDimensional Feature Selection in R'
    bibtitle: 'MDFS: MultiDimensional Feature Selection in R'
    author:
    - Radosław Piliszek
    - Krzysztof Mnich
    - Szymon Migacz
    - Paweł Tabaszewski
    - Andrzej Sułecki
    - Aneta            Polewko-Klim
    - Witold Rudnicki
    bibauthor: |-
      Radosław Piliszek and Krzysztof Mnich and Szymon Migacz and
                Paweł Tabaszewski and Andrzej Sułecki and Aneta Polewko-Klim
                and Witold Rudnicki
    abstract: '  Abstract Identification of informative variables in an information
      system is often performed using            simple one-dimensional filtering
      procedures that discard information about interactions between            variables.
      Such an approach may result in removing some relevant variables from consideration.
      Here            we present an R package MDFS (MultiDimensional Feature Selection)
      that performs identification            of informative variables taking into
      account synergistic interactions between multiple descriptors            and
      the decision variable. MDFS is an implementation of an algorithm based on information
      theory            (Mnich and Rudnicki, 2017). The computational kernel of the
      package is implemented in C++. A            high-performance version implemented
      in CUDA C is also available. The application of MDFS is            demonstrated
      using the well-known Madelon dataset, in which a decision variable is generated
      from            synergistic interactions between descriptor variables. It is
      shown that the application of multidimen           sional analysis results in
      better sensitivity and ranking of importance.'
    acknowledged: '2018-12-01'
    online: '2019-08-16'
    CRANpkgs:
    - MDFS
    - Rfast
    suppl: 1.3 Kb
    landing: '2019'
  - slug: RJ-2019-020
    title: 'Nowcasting: An R Package for Predicting Economic Variables Using Dynamic
      Factor Models'
    bibtitle: |-
      Nowcasting: An R Package for Predicting Economic Variables
                Using Dynamic Factor Models
    author:
    - Serge de Valk
    - Daiane de Mattos
    - Pedro Ferreira
    bibauthor: Serge de Valk and Daiane de Mattos and Pedro Ferreira
    abstract: '  Abstract The nowcasting package provides the tools to make forecasts
      of monthly or quarterly            economic variables using dynamic factor models.
      The objective is to help the user at each step of            the forecasting
      process, starting with the construction of a database, all the way to the interpretation            of
      the forecasts. The dynamic factor model adopted in this package is based on
      the articles from            Giannone et al. (2008) and Banbura et al. (2011).
      Although there exist several other dynamic factor            model packages
      available for R, ours provides an environment to easily forecast economic variables            and
      interpret results.'
    acknowledged: '2018-12-01'
    online: '2019-08-16'
    CRANpkgs: nowcasting
    suppl: 1 Kb
    landing: '2019'
  - slug: RJ-2019-021
    title: 'ConvergenceClubs: A Package for Performing the Phillips and Sul''s Club
      Convergence Clustering Procedure'
    bibtitle: |-
      ConvergenceClubs: A Package for Performing the Phillips and
                Sul's Club Convergence Clustering Procedure
    author:
    - Roberto Sichera
    - Pietro Pizzuto
    bibauthor: Roberto Sichera and Pietro Pizzuto
    abstract: '  Abstract This paper introduces package ConvergenceClubs, which implements
      functions to perform            the Phillips and Sul (2007, 2009) club convergence
      clustering procedure in a simple and reproducible            manner. The approach
      proposed by Phillips and Sul to analyse the convergence patterns of groups            of
      economies is formulated as a nonlinear time varying factor model that allows
      for different time            paths as well as individual heterogeneity. Unlike
      other approaches in which economies are grouped a            priori, it also
      allows the endogenous determination of convergence clubs. The algorithm, usage,
      and            implementation details are discussed.'
    acknowledged:
    - '2018-12-06'
    - '2018-12-07'
    online: '2019-08-16'
    CRANpkgs:
    - ConvergenceClubs
    - mFilter
    CTV_rev: TimeSeries
    suppl: 907 bytes
    landing: '2019'
  - slug: RJ-2019-022
    title: 'SimCorrMix: Simulation of Correlated Data with Multiple Variable Types
      Including Continuous and Count Mixture Distributions'
    bibtitle: |-
      SimCorrMix: Simulation of Correlated Data with Multiple
                Variable Types Including Continuous and Count Mixture
                Distributions
    author:
    - Allison Fialkowski
    - Hemant Tiwari
    bibauthor: Allison Fialkowski and Hemant Tiwari
    abstract: '  Abstract The SimCorrMix package generates correlated continuous (normal,
      non-normal, and mix           ture), binary, ordinal, and count (regular and
      zero-inflated, Poisson and Negative Binomial) variables            that mimic
      real-world data sets. Continuous variables are simulated using either Fleishman’s
      third           order or Headrick’s fifth-order power method transformation.
      Simulation occurs at the component            level for continuous mixture distributions,
      and the target correlation matrix is specified in terms of            correlations
      with components. However, the package contains functions to approximate expected            correlations
      with continuous mixture variables. There are two simulation pathways which calculate            intermediate
      correlations involving count variables differently, increasing accuracy under
      a wide range            of parameters. The package also provides functions to
      calculate cumulants of continuous mixture            distributions, check parameter
      inputs, calculate feasible correlation boundaries, and summarize and            plot
      simulated variables. SimCorrMix is an important addition to existing R simulation
      packages            because it is the first to include continuous mixture and
      zero-inflated count variables in correlated            data sets.'
    acknowledged: '2018-04-04'
    online: '2019-08-16'
    CRANpkgs:
    - AdaptGauss
    - DPP
    - bgmm
    - ClusterR
    - mclust
    - mixture
    - AdMit
    - bimixt
    - bmixture
    - CAMAN
    - flexmix
    - mixdist
    - mixtools
    - nspmix
    - MixtureInf
    - Rmixmod
    - hurdlr
    - zic
    - mixpack
    - distr
    - stats
    - rebmix
    - SimCorrMix
    - SimMultiCorrData
    - GenOrd
    - VGAM
    - Matrix
    - ggplot2
    - mvtnorm
    CTV_rev:
    - Cluster
    - Distributions
    - Multivariate
    - Bayesian
    - Environmetrics
    - Econometrics
    - Psychometrics
    - ExtremeValue
    - Finance
    - Graphics
    - MetaAnalysis
    - NumericalMathematics
    - Phylogenetics
    - Robust
    - SocialSciences
    - Survival
    - TeachingStatistics
    suppl: 5.3 Kb
    landing: '2019'
  - slug: RJ-2019-023
    title: Time-Series Clustering in R Using the dtwclust Package
    bibtitle: Time-Series Clustering in R Using the dtwclust Package
    author: Alexis Sardá-Espinosa
    bibauthor: Alexis Sardá-Espinosa
    abstract: '  Abstract Most clustering strategies have not changed considerably
      since their initial definition. The            common improvements are either
      related to the distance measure used to assess dissimilarity, or            the
      function used to calculate prototypes. Time-series clustering is no exception,
      with the Dynamic            Time Warping distance being particularly popular
      in that context. This distance is computationally            expensive, so many
      related optimizations have been developed over the years. Since no single            clustering
      algorithm can be said to perform best on all datasets, different strategies
      must be tested and            compared, so a common infrastructure can be advantageous.
      In this manuscript, a general overview            of shape-based time-series
      clustering is given, including many specifics related to Dynamic Time            Warping
      and associated techniques. At the same time, a description of the dtwclust package
      for the R            statistical software is provided, showcasing how it can
      be used to evaluate many different time-series            clustering procedures.'
    acknowledged: '2018-04-04'
    online: '2019-08-16'
    CRANpkgs:
    - dtwclust
    - flexclust
    - cluster
    - TSdist
    - TSclust
    - pdc
    - dtw
    - proxy
    - clue
    - foreach
    - RcppParallel
    - doParallel
    CTVs: TimeSeries
    CTV_rev:
    - TimeSeries
    - Cluster
    - Multivariate
    - HighPerformanceComputing
    - Environmetrics
    - Optimization
    - Robust
    suppl: 4.4 Kb
    landing: '2019'
  - slug: RJ-2019-024
    title: 'shadow: R Package for Geometric Shadow Calculations in an Urban Environment'
    bibtitle: |-
      shadow: R Package for Geometric Shadow Calculations in an
                Urban Environment
    author:
    - Michael Dorman
    - Evyatar Erell
    - Adi Vulkan
    - Itai Kloog
    bibauthor: |-
      Michael Dorman and Evyatar Erell and Adi Vulkan and Itai
                Kloog
    abstract: '  Abstract This paper introduces the shadow package for R. The package
      provides functions for shadow           related calculations in the urban environment,
      namely shadow height, shadow footprint and Sky            View Factor (SVF)
      calculations, as well as a wrapper function to estimate solar radiation while
      taking            shadow effects into account. All functions operate on a layer
      of polygons with a height attribute,            also known as “extruded polygons”
      or 2.5D vector data. Such data are associated with accuracy            limitations
      in representing urban environments. However, unlike 3D models, polygonal layers
      of            building outlines along with their height are abundantly available
      and their processing does not            require specialized closed-source 3D
      software. The present package thus brings spatio-temporal            shadow,
      SVF and solar radiation calculation capabilities to the open-source spatial
      analysis workflow            in R. Package functionality is demonstrated using
      small reproducible examples for each function.            Wider potential use
      cases include urban environment applications such as evaluation of micro-climatic            influence
      for urban planning, studying urban climatic comfort and estimating photovoltaic
      energy            production potential.'
    acknowledged: '2018-05-01'
    online: '2019-08-17'
    CRANpkgs:
    - insol
    - shadow
    - sp
    - threejs
    - raster
    - rgeos
    - maptools
    - parallel
    - plot3D
    - sf
    CTVs: Spatial
    CTV_rev:
    - Spatial
    - SpatioTemporal
    suppl: 2.3 Kb
    landing: '2019'
  - slug: RJ-2019-025
    title: Integration of networks and pathways with StarBioTrek package
    bibtitle: |-
      Integration of networks and pathways with StarBioTrek
                package
    author:
    - Claudia Cava
    - Isabella Castiglioni
    bibauthor: Claudia Cava and Isabella Castiglioni
    abstract: '  Abstract High-throughput genomic technologies bring to light a comprehensive
      hallmark of molecular            changes of a disease. It is increasingly evident
      that genes are not isolated from each other and the            identification
      of a gene signature can only partially elucidate the de-regulated biological
      functions in a            disease. The comprehension of how groups of genes
      (pathways) are related to each other (pathway           cross talk) could explain
      biological mechanisms causing diseases. Biological pathways are important            tools
      to identify gene interactions and decrease the large number of genes to be studied
      by partitioning            them into smaller groups. Furthermore, recent scientific
      studies have demonstrated that an integration            of pathways and networks,
      instead of a single component of the pathway or a single network, could            lead
      to a deeper understanding of the pathology.                StarBioTrek is an
      R package for the integration of biological pathways and networks which            provides
      a series of functions to support the user in their analyses. In particular,
      it implements            algorithms to identify pathways cross-talk networks
      and gene network drivers in pathways. It is            available as open source
      and open development software in the Bioconductor platform.'
    acknowledged: '2018-05-01'
    online: '2019-08-17'
    CRANpkgs:
    - XGR
    - qgraph
    - GOplot
    BIOpkgs:
    - NetPathMiner
    - ToPASeq
    - StarBioTrek
    - graphite
    CTV_rev: Psychometrics
    suppl: 1.2 Kb
    landing: '2019'
  - slug: RJ-2019-026
    title: 'ciuupi: An R package for Computing Confidence Intervals that Utilize Uncertain
      Prior Information'
    bibtitle: |-
      ciuupi: An R package for Computing Confidence Intervals that
                Utilize Uncertain Prior Information
    author:
    - Rheanna Mainzer
    - Paul Kabaila
    bibauthor: Rheanna Mainzer and Paul Kabaila
    abstract: '  Abstract We have created the R package ciuupi to compute confidence
      intervals that utilize uncertain            prior information in linear regression.
      Unlike post-model-selection confidence intervals, the confidence            interval
      that utilizes uncertain prior information (CIUUPI) implemented in this package
      has, to an            excellent approximation, coverage probability throughout
      the parameter space that is very close to            the desired minimum coverage
      probability. Furthermore, when the uncertain prior information is            correct,
      the CIUUPI is, on average, shorter than the standard confidence interval constructed
      using            the full linear regression model. In this paper we provide
      motivating examples of scenarios where            the CIUUPI may be used. We
      then give a detailed description of this interval and the numerical            constrained
      optimization method implemented in R to obtain it. Lastly, using a real data
      set as an            illustrative example, we show how to use the functions
      in ciuupi.'
    acknowledged: '2018-05-01'
    online: '2019-08-17'
    CRANpkgs:
    - ciuupi
    - nloptr
    - statmod
    CTV_rev:
    - Distributions
    - NumericalMathematics
    - Optimization
    suppl: 1 Kb
    landing: '2019'
  - slug: RJ-2019-027
    title: 'cvcrand: A package for covariate-constrained randomization and the clustered
      permutation test for cluster randomized trials'
    bibtitle: |-
      cvcrand: A package for covariate-constrained randomization
                and the clustered permutation test for cluster randomized
                trials
    author:
    - Hengshi Yu
    - Fan Li
    - John A. Gallis
    - Elizabeth L. Turner
    bibauthor: |-
      Hengshi Yu and Fan Li and John A. Gallis and Elizabeth L.
                Turner
    abstract: '  Abstract The cluster randomized trial (CRT) is a randomized controlled
      trial in which randomization            is conducted at the cluster level (e.g.
      school or hospital) and outcomes are measured for each            individual
      within a cluster. Often, the number of clusters available to randomize is small
      (≤ 20), which            increases the chance of baseline covariate imbalance
      between comparison arms. Such imbalance is            particularly problematic
      when the covariates are predictive of the outcome because it can threaten            the
      internal validity of the CRT. Pair-matching and stratification are two restricted
      randomization            approaches that are frequently used to ensure balance
      at the design stage. An alternative, less            commonly-used restricted
      randomization approach is covariate-constrained randomization. Covariate           constrained
      randomization quantifies baseline imbalance of cluster-level covariates using
      a balance            metric and randomly selects a randomization scheme from
      those with acceptable balance by the            balance metric. It is able to
      accommodate multiple covariates, both categorical and continuous. To            facilitate
      implementation of covariate-constrained randomization for the design of two-arm
      parallel            CRTs, we have developed the cvcrand R package. In addition,
      cvcrand also implements the clustered            permutation test for analyzing
      continuous and binary outcomes collected from a CRT designed with            covariate-constrained
      randomization. We used a real cluster randomized trial to illustrate the functions            included
      in the package.'
    acknowledged: '2018-05-01'
    online: '2019-08-17'
    CRANpkgs: cvcrand
    suppl: 1.4 Kb
    landing: '2019'
  - slug: RJ-2019-028
    title: 'jomo: A Flexible Package for Two-level Joint Modelling Multiple Imputation'
    bibtitle: |-
      jomo: A Flexible Package for Two-level Joint Modelling
                Multiple Imputation
    author:
    - Matteo Quartagno
    - Simon Grund
    - James Carpenter
    bibauthor: Matteo Quartagno and Simon Grund and James Carpenter
    abstract: '  Abstract Multiple imputation is a tool for parameter estimation and
      inference with partially observed            data, which is used increasingly
      widely in medical and social research. When the data to be imputed            are
      correlated or have a multilevel structure — repeated observations on patients,
      school children            nested in classes within schools within educational
      districts — the imputation model needs to include            this structure.
      Here we introduce our joint modelling package for multiple imputation of multilevel            data,
      jomo, which uses a multivariate normal model fitted by Markov Chain Monte Carlo
      (MCMC).            Compared to previous packages for multilevel imputation,
      e.g. pan, jomo adds the facility to (i) handle            and impute categorical
      variables using a latent normal structure, (ii) impute level-2 variables, and
      (iii)            allow for cluster-specific covariance matrices, including the
      option to give them an inverse-Wishart            distribution at level 2. The
      package uses C routines to speed up the computations and has been            extensively
      validated in simulation studies both by ourselves and others.'
    acknowledged: '2018-05-01'
    online: '2019-08-17'
    CRANpkgs:
    - jomo
    - pan
    - norm
    - cat
    - mix
    - R2MLwiN
    - mitools
    - mice
    - semTools
    - BaBooN
    - mitml
    - Amelia
    - mi
    - lavaan.survey
    - dummies
    - nlme
    CTV_rev:
    - MissingData
    - OfficialStatistics
    - SocialSciences
    - Multivariate
    - Psychometrics
    - Bayesian
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - Spatial
    - SpatioTemporal
    suppl: 1.7 Kb
    landing: '2019'
  - slug: RJ-2019-029
    title: 'ipwErrorY: An R Package for Estimation of Average Treatment Effect with
      Misclassified Binary Outcome'
    bibtitle: |-
      ipwErrorY: An R Package for Estimation of Average Treatment
                Effect with Misclassified Binary Outcome
    author:
    - Di Shu
    - Grace Y. Yi
    bibauthor: Di Shu and Grace Y. Yi
    abstract: '  Abstract It has been well documented that ignoring measurement error
      may result in severely biased            inference results. In recent years,
      there has been limited but increasing research on causal inference            with
      measurement error. In the presence of misclassified binary outcome variable,
      Shu and Yi (2017)            considered the inverse probability weighted estimation
      of the average treatment effect and proposed            valid estimation methods
      to correct for misclassification effects for various settings. To expedite the            application
      of those methods for situations where misclassification in the binary outcome
      variable            is a real concern, we implement correction methods proposed
      by Shu and Yi (2017) and develop            an R package ipwErrorY for general
      users. Simulated datasets are used to illustrate the use of the            developed
      package.'
    acknowledged: '2018-05-29'
    online: '2019-08-17'
    CRANpkgs:
    - ipwErrorY
    - nleqslv
    CTV_rev: NumericalMathematics
    suppl: 1.3 Kb
    landing: '2019'
  - slug: RJ-2019-030
    title: 'optimParallel: An R Package Providing a Parallel Version of the L-BFGS-B
      Optimization Method'
    bibtitle: |-
      optimParallel: An R Package Providing a Parallel Version of
                the L-BFGS-B Optimization Method
    author:
    - Florian Gerber
    - Reinhard Furrer
    bibauthor: Florian Gerber and Reinhard Furrer
    abstract: '  Abstract The R package optimParallel provides a parallel version
      of the L-BFGS-B optimization            method of optim(). The main function
      of the package is optimParallel(), which has the same            usage and output
      as optim(). Using optimParallel() can significantly reduce the optimization
      time,            especially when the evaluation time of the objective function
      is large and no analytical gradient is            available. We introduce the
      R package and illustrate its implementation, which takes advantage of the            lexical
      scoping mechanism of R.'
    acknowledged: '2018-05-29'
    online: '2019-08-17'
    CRANpkgs:
    - lbfgsb3
    - lbfgsb3c
    - optimParallel
    - testthat
    - microbenchmark
    CTVs: Optimization
    CTV_rev: Optimization
    suppl: 2.4 Kb
    landing: '2019'
  - slug: RJ-2019-031
    title: 'swgee: An R Package for Analyzing Longitudinal Data with Response Missingness
      and Covariate Measurement Error'
    bibtitle: |-
      swgee: An R Package for Analyzing Longitudinal Data with
                Response Missingness and Covariate Measurement Error
    author:
    - Juan Xiong
    - Grace Y. Yi
    bibauthor: Juan Xiong and Grace Y. Yi
    abstract: '  Abstract Though longitudinal data often contain missing responses
      and error-prone covariates,            relatively little work has been available
      to simultaneously correct for the effects of response missingness            and
      covariate measurement error on analysis of longitudinal data. Yi (2008) proposed
      a simulation            based marginal method to adjust for the bias induced
      by measurement error in covariates as well            as by missingness in response.
      The proposed method focuses on modeling the marginal mean and            variance
      structures, and the missing at random mechanism is assumed. Furthermore, the
      distribution            of covariates are left unspecified. These features make
      the proposed method applicable to a broad            settings. In this paper,
      we develop an R package, called swgee, which implements the method            proposed
      by Yi (2008). Moreover, our package includes additional implementation steps
      which extend            the setting considered by Yi (2008). To describe the
      use of the package and its main features, we report            simulation studies
      and analyses of a data set arising from the Framingham Heart Study.'
    acknowledged: '2018-07-31'
    online: '2019-08-17'
    CRANpkgs:
    - gee
    - yags
    - wgeesel
    - geepack
    - mvtnorm
    CTV_rev:
    - SocialSciences
    - Distributions
    - Econometrics
    - Finance
    - Multivariate
    suppl: 1.9 Kb
    landing: '2019'
  - slug: RJ-2019-032
    title: 'roahd Package: Robust Analysis of High Dimensional Data'
    bibtitle: 'roahd Package: Robust Analysis of High Dimensional Data'
    author:
    - Francesca Ieva
    - Anna Maria Paganoni
    - Juan Romo
    - Nicholas Tarabelloni
    bibauthor: |-
      Francesca Ieva and Anna Maria Paganoni and Juan Romo and
                Nicholas Tarabelloni
    abstract: ' Abstract The focus of this paper is on the open-source R package roahd
      (RObust Analysis           of High dimensional Data), see Tarabelloni et al.
      (2017). roahd has been developed to gather           recently proposed statistical
      methods that deal with the robust inferential analysis of univariate           and
      multivariate functional data. In particular, efficient methods for outlier detection
      and related           graphical tools, methods to represent and simulate functional
      data, as well as inferential tools for           testing differences and dependency
      among families of curves will be discussed, and the associated           functions
      of the package will be described in details.'
    acknowledged: []
    online: '2019-08-17'
    CRANpkgs: R
    suppl: 1.3 Kb
    landing: '2019'
  - slug: RJ-2019-033
    title: The Landscape of R Packages for Automated Exploratory Data Analysis
    bibtitle: |-
      The Landscape of R Packages for Automated Exploratory Data
                Analysis
    author:
    - Mateusz Staniak
    - Przemysław Biecek
    bibauthor: Mateusz Staniak and Przemysław Biecek
    abstract: '  Abstract The increasing availability of large but noisy data sets
      with a large number of heterogeneous            variables leads to the increasing
      interest in the automation of common tasks for data analysis. The            most
      time-consuming part of this process is the Exploratory Data Analysis, crucial
      for better domain            understanding, data cleaning, data validation,
      and feature engineering.                  There is a growing number of libraries
      that attempt to automate some of the typical Exploratory            Data Analysis
      tasks to make the search for new insights easier and faster. In this paper,
      we present a            systematic review of existing tools for Automated Exploratory
      Data Analysis (autoEDA). We explore            the features of fifteen popular
      R packages to identify the parts of analysis that can be effectively            automated
      with the current tools and to point out new directions for further autoEDA development.'
    acknowledged: []
    online: '2019-08-17'
    CRANpkgs:
    - cranlogs
    - radiant
    - visdat
    - archivist
    - xtable
    - arsenal
    - DataExplorer
    - dataMaid
    - dlookr
    - ExPanDaR
    - explore
    - shiny
    - exploreR
    - funModeling
    - inspectdf
    - RtutoR
    - SmartEDA
    - data.table
    - summarytools
    - knitr
    - ggplot2
    - xray
    - tableone
    - describer
    - skimr
    - prettyR
    - Hmisc
    - ggfortify
    - autoplotly
    - gpairs
    - GGally
    - survminer
    - cr17
    - DALEX
    - iml
    CTV_rev:
    - ReproducibleResearch
    - MissingData
    - TeachingStatistics
    - WebTechnologies
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - Finance
    - Graphics
    - HighPerformanceComputing
    - Multivariate
    - OfficialStatistics
    - Phylogenetics
    - SocialSciences
    - Survival
    suppl: 1.6 Kb
    landing: '2019'
  - slug: RJ-2019-034
    title: 'jomo: A Flexible Package for Two-level Joint Modelling Multiple Imputation'
    bibtitle: |-
      jomo: A Flexible Package for Two-level Joint Modelling
                Multiple Imputation
    author:
    - Matteo Quartagno
    - Simon Grund
    - James Carpenter
    bibauthor: Matteo Quartagno and Simon Grund and James Carpenter
    abstract: '  Abstract Multiple imputation is a tool for parameter estimation and
      inference with partially observed            data, which is used increasingly
      widely in medical and social research. When the data to be imputed            are
      correlated or have a multilevel structure — repeated observations on patients,
      school children            nested in classes within schools within educational
      districts — the imputation model needs to include            this structure.
      Here we introduce our joint modelling package for multiple imputation of multilevel            data,
      jomo, which uses a multivariate normal model fitted by Markov Chain Monte Carlo
      (MCMC).            Compared to previous packages for multilevel imputation,
      e.g. pan, jomo adds the facility to (i) handle            and impute categorical
      variables using a latent normal structure, (ii) impute level-2 variables, and
      (iii)            allow for cluster-specific covariance matrices, including the
      option to give them an inverse-Wishart            distribution at level 2. The
      package uses C routines to speed up the computations and has been            extensively
      validated in simulation studies both by ourselves and others.'
    acknowledged: '2018-08-17'
    online: '2019-08-17'
    CRANpkgs:
    - jomo
    - pan
    - norm
    - cat
    - mix
    - R2MLwiN
    - mitools
    - mice
    - semTools
    - BaBooN
    - mitml
    - Amelia
    - mi
    - lavaan.survey
    - dummies
    - nlme
    CTV_rev:
    - MissingData
    - OfficialStatistics
    - SocialSciences
    - Multivariate
    - Psychometrics
    - Bayesian
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - Spatial
    - SpatioTemporal
    suppl: 1.7 Kb
    landing: '2019'
  - slug: RJ-2019-035
    title: 'BINCOR: An R package for Estimating the Correlation between Two Unevenly
      Spaced Time Series'
    bibtitle: |-
      BINCOR: An R package for Estimating the Correlation between
                Two Unevenly Spaced Time Series
    author:
    - Josue M. Polanco-Martinez
    - Martin A. Medina-Elizalde
    - Maria Fernanda Sanchez Goni
    - Manfred            Mudelsee
    bibauthor: |-
      Josue M. Polanco-Martinez and Martin A. Medina-Elizalde and
                Maria Fernanda Sanchez Goni and Manfred Mudelsee
    abstract: '  Abstract This paper presents a computational program named BINCOR
      (BINned CORrelation) for            estimating the correlation between two unevenly
      spaced time series. This program is also applicable to            the situation
      of two evenly spaced time series not on the same time grid. BINCOR is based
      on a novel            estimation approach proposed by Mudelsee (2010) for estimating
      the correlation between two climate            time series with different timescales.
      The idea is that autocorrelation (e.g. an AR1 process) means            that
      memory enables values obtained on different time points to be correlated. Binned
      correlation            is performed by resampling the time series under study
      into time bins on a regular grid, assigning            the mean values of the
      variable under scrutiny within those bins. We present two examples of our            BINCOR
      package with real data: instrumental and paleoclimatic time series. In both
      applications            BINCOR works properly in detecting well-established
      relationships between the climate records            compared.'
    acknowledged: '2018-02-14'
    online: '2019-08-18'
    CRANpkgs:
    - BINCOR
    - dplR
    - pracma
    - TSdist
    CTV_rev:
    - DifferentialEquations
    - NumericalMathematics
    - TimeSeries
    suppl: 1.2 Kb
    landing: '2019'
  - slug: RJ-2019-036
    title: 'auditor: an R Package for Model-Agnostic Visual Validation and Diagnostics'
    bibtitle: |-
      auditor: an R Package for Model-Agnostic Visual Validation
                and Diagnostics
    author:
    - Alicja Gosiewska
    - Przemysław Biecek
    bibauthor: Alicja Gosiewska and Przemysław Biecek
    abstract: '  Abstract                 Machine learning models have spread to almost
      every area of life. They are successfully applied in            biology, medicine,
      finance, physics, and other fields. With modern software it is easy to train
      even            a complex model that fits the training data and results in high
      accuracy on test set. The problem arises            when models fail confronted
      with the real-world data.                 This paper describes methodology and
      tools for model-agnostic audit. Introduced techniques            facilitate
      assessing and comparing the goodness of fit and performance of models. In addition,
      they            may be used for analysis of the similarity of residuals and
      for identification of outliers and influential            observations. The
      examination is carried out by diagnostic scores and visual verification.                 Presented
      methods were implemented in the auditor package for R. Due to flexible and consistent            grammar,
      it is simple to validate models of any classes.'
    acknowledged: '2018-12-01'
    online: '2019-08-18'
    CRANpkgs: auditor
    suppl: 581 bytes
    landing: '2019'
  - slug: RJ-2019-037
    title: Fixed Point Acceleration in R
    bibtitle: Fixed Point Acceleration in R
    author:
    - Stuart Baumann
    - Margaryta Klymak
    bibauthor: Stuart Baumann and Margaryta Klymak
    abstract: '  Abstract A fixed point problem is one where we seek a vector, X,
      for a function, f, such that f(X) = X.            The solution of many such
      problems can be accelerated by using a fixed point acceleration algorithm.            With
      the release of the FixedPoint package there is now a number of algorithms available
      in R that can            be used for accelerating the finding of a fixed point
      of a function. These algorithms include Newton            acceleration, Aitken
      acceleration and Anderson acceleration as well as epsilon extrapolation methods            and
      minimal polynomial methods. This paper demonstrates the use of fixed point accelerators
      in            solving numerical mathematics problems using the algorithms of
      the FixedPoint package as well as            the squarem method of the SQUAREM
      package.'
    acknowledged: '2018-05-29'
    online: '2019-08-20'
    suppl: 3.5 Kb
    landing: '2019'
  - slug: RJ-2019-038
    title: 'SemiCompRisks: An R Package for the Analysis of Independent and Cluster-correlated
      Semi-competing Risks Data'
    bibtitle: |-
      SemiCompRisks: An R Package for the Analysis of Independent
                and Cluster-correlated Semi-competing Risks Data
    author:
    - Danilo Alvares
    - Sebastien Haneuse
    - Catherine Lee
    - Kyu Ha Lee
    bibauthor: |-
      Danilo Alvares and Sebastien Haneuse and Catherine Lee and
                Kyu Ha Lee
    abstract: '  Abstract Semi-competing risks refer to the setting where primary
      scientific interest lies in estimation            and inference with respect
      to a non-terminal event, the occurrence of which is subject to a terminal            event.
      In this paper, we present the R package SemiCompRisks that provides functions
      to perform            the analysis of independent/clustered semi-competing risks
      data under the illness-death multi-state            model. The package allows
      the user to choose the specification for model components from a range            of
      options giving users substantial flexibility, including: accelerated failure
      time or proportional            hazards regression models; parametric or non-parametric
      specifications for baseline survival functions;            parametric or non-parametric
      specifications for random effects distributions when the data are cluster           correlated;
      and, a Markov or semi-Markov specification for terminal event following non-terminal            event.
      While estimation is mainly performed within the Bayesian paradigm, the package
      also provides            the maximum likelihood estimation for select parametric
      models. The package also includes functions            for univariate survival
      analysis as complementary analysis tools.'
    acknowledged: '2018-05-29'
    online: '2019-08-20'
    suppl: 4.3 Kb
    landing: '2019'
  - slug: RJ-2019-039
    title: 'RSSampling: A Pioneering Package for Ranked Set Sampling '
    bibtitle: 'RSSampling: A Pioneering Package for Ranked Set Sampling'
    author:
    - Busra Sevinc
    - Bekir Cetintav
    - Melek Esemen
    - Selma Gurler
    bibauthor: |-
      Busra Sevinc and Bekir Cetintav and Melek Esemen and Selma
                Gurler
    abstract: '  Abstract Ranked set sampling (RSS) is an advanced data collection
      method when the exact mea           surement of an observation is difficult
      and/or expensive used in a number of research areas, e.g.,            environment,
      bioinformatics, ecology, etc. In this method, random sets are drawn from a population            and
      the units in sets are ranked with a ranking mechanism which is based on a visual
      inspection or a            concomitant variable. Because of the importance of
      working with a good design and easy analysis,            there is a need for
      a software tool which provides sampling designs and statistical inferences based            on
      RSS and its modifications. This paper introduces an R package as a free and
      easy-to-use analysis            tool for both sampling processes and statistical
      inferences based on RSS and its modified versions.            For researchers,
      the RSSampling package provides a sample with RSS, extreme RSS, median RSS,            percentile
      RSS, balanced groups RSS, double versions of RSS, L-RSS, truncation-based RSS,
      and robust            extreme RSS when the judgment rankings are both perfect
      and imperfect. Researchers can also use            this new package to make
      parametric inferences for the population mean and the variance where the            sample
      is obtained via classical RSS. Moreover, this package includes applications
      of the nonparametric            methods which are one sample sign test, Mann-Whitney-Wilcoxon
      test, and Wilcoxon signed-rank test            procedures. The package is available
      as RSSampling on CRAN.'
    acknowledged: '2018-07-26'
    online: '2019-08-20'
    CRANpkgs:
    - NSM3
    - RSSampling
    - stats
    - LearnBayes
    CTV_rev:
    - Bayesian
    - Distributions
    - Survival
    - TeachingStatistics
    suppl: 1.3 Kb
    landing: '2019'
  - slug: RJ-2019-040
    title: 'unival: An FA-based R Package For Assessing Essential Unidimensionality
      Using External Validity Information'
    bibtitle: |-
      unival: An FA-based R Package For Assessing Essential
                Unidimensionality Using External Validity Information
    author:
    - Pere J. Ferrando
    - Urbano Lorenzo-Seva
    - David Navarro-Gonzalez
    bibauthor: |-
      Pere J. Ferrando and Urbano Lorenzo-Seva and David Navarro-
                Gonzalez
    abstract: '  Abstract                The unival package is designed to help researchers
      decide between unidimensional and correlated           factors solutions in
      the factor analysis of psychometric measures. The novelty of the approach is
      its use            of external information, in which multiple factor scores
      and general factor scores are related to relevant            external variables
      or criteria. The unival package’s implementation comes from a series of procedures            put
      forward by Ferrando and Lorenzo-Seva (2019) and new methodological developments
      proposed            in this article. We assess models fitted using unival by
      means of a simulation study extending the            results obtained in the
      original proposal. Its usefulness is also assessed through a real-world data            example.
      Based on these results, we conclude unival is a valuable tool for use in applications
      in which            the dimensionality of an item set is to be assessed.'
    acknowledged: []
    online: '2019-08-20'
    CRANpkgs:
    - unival
    - stats
    - optimbase
    - psych
    - mirt
    CTV_rev:
    - Psychometrics
    - MissingData
    suppl: 449 bytes
    landing: '2019'
