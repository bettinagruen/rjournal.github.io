<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>The R Journal</title>
    <link>https://rjournal-distill.netlify.app/</link>
    <atom:link href="https://rjournal-distill.netlify.app/articles.xml" rel="self" type="application/rss+xml"/>
    <description>Articles published in the R Journal</description>
    <image>
      <title>The R Journal</title>
      <url>https://rjournal-distill.netlify.app/resources/favicon.ico</url>
      <link>https://rjournal-distill.netlify.app/</link>
    </image>
    <generator>Distill</generator>
    <lastBuildDate>Mon, 01 Mar 2021 00:00:00 +0000</lastBuildDate>
    <item>
      <title>stratamatch: Prognostic Score Stratification Using a Pilot Design</title>
      <dc:creator>Rachael C. Aikens</dc:creator>
      <dc:creator>Joseph Rigdon</dc:creator>
      <dc:creator>Justin Lee</dc:creator>
      <dc:creator>Michael Baiocchi</dc:creator>
      <dc:creator>Andrew B. Goldstone</dc:creator>
      <dc:creator>Peter Chiu</dc:creator>
      <dc:creator>Y. Joseph Woo</dc:creator>
      <dc:creator>Jonathan H. Chen</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-063</link>
      <description>stratamatch: Prognostic Score Stratification Using a Pilot Design</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-063</guid>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>BayesSPsurv: An R Package to Estimate Bayesian (Spatial) Split-Population Survival Models</title>
      <dc:creator>Brandon Bolte</dc:creator>
      <dc:creator>Nicolás Schmidt</dc:creator>
      <dc:creator>Sergio Béjar</dc:creator>
      <dc:creator>Nguyen Huynh</dc:creator>
      <dc:creator>Bumba Mukherjee</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-068</link>
      <description>BayesSPsurv: An R Package to Estimate Bayesian (Spatial) Split-Population Survival Models</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-068</guid>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Reproducible Summary Tables with the gtsummary Package</title>
      <dc:creator>Daniel D. Sjoberg</dc:creator>
      <dc:creator>Karissa Whiting</dc:creator>
      <dc:creator>Michael Curry</dc:creator>
      <dc:creator>Jessica A. Lavery</dc:creator>
      <dc:creator>Joseph Larmarange</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-053</link>
      <description>Reproducible Summary Tables with the gtsummary Package</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-053</guid>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Regularized Transformation Models: The tramnet Package</title>
      <dc:creator>Lucas Kook</dc:creator>
      <dc:creator>Torsten Hothorn</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-054</link>
      <description>Regularized Transformation Models: The tramnet Package</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-054</guid>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Automating Reproducible, Collaborative Clinical Trial Document Generation with the \pkg{listdown} Package</title>
      <dc:creator>Michael Kane</dc:creator>
      <dc:creator>Xun Jiang</dc:creator>
      <dc:creator>Simon Urbanek</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-051</link>
      <description>


&lt;style type="text/css"&gt;
d-title h1, d-title p, d-title figure {
  grid-column: page;
}
&lt;/style&gt;
&lt;h1 id="background-and-introduction"&gt;Background and Introduction&lt;/h1&gt;
&lt;p&gt;The conveyance of clinical trial explorations and analysis results from a statistician to a clinical investigator is an often overlooked but critical component to the drug development and clinical research cycle. Graphs, tables, and other analysis artifacts are at the nexus of these collaborations. They facilitate identifying problems and bugs in the data preparation and processing stage, they help to build an intuitive understanding of mechanisms of disease and their treatment, they elucidate prognostic and predictive relationships, they provide insight that results in new hypotheses, and they convince researchers of analyses testing hypotheses.&lt;/p&gt;
&lt;p&gt;Despite their importance, the process of generating these artifacts is usually done in an ad-hoc manner. This is partially because of the nuance and diversity of the hypotheses and scientific questions being interrogated and, to a lesser degree, the variation in clinical data formatting. The usual process usually has a statistician providing a standard set of artifacts, receiving feedback, and providing updates based on feedback. Work performed for one trial is rarely leveraged on others, and as a result, a large amount of work needs to be reproduced for each trial.&lt;/p&gt;
&lt;p&gt;There are two glaring problems with this approach. First, each analysis of a trial requires a substantial amount of error-prone work. While the variation between trials means some work needs to be done for preparation, exploration, and analysis, many aspects of these trials could be better automated resulting in greater efficiency and accuracy. Second, because this work is challenging, it often occupies the majority of the statisticians’ effort. Less time is spent on trial design and analysis, and then this portion is taken up by a clinician who often has less expertise with the statistical aspects of the trial. As a result, the extra effort spent on processing data undermines statisticians’ role as a collaborator and relegates them to service provider. Need tools leveraging existing work to more efficiently provide holistic views on trials will result in less effort and more accurate and comprehensive trial design and analysis.&lt;/p&gt;
&lt;p&gt;The richness of the &lt;span class="citation"&gt;R Core Team (2012)&lt;/span&gt; package ecosystem, particularly with its emphasis on analysis, visualization, reproducibility, and dissemination makes the goal of creating these tools for clinical trials feasible. Generation of tables is supported by packages including  &lt;span class="citation"&gt;(Yoshida and Bartel 2020)&lt;/span&gt;,  &lt;span class="citation"&gt;(Iannone, Cheng, and Schloerke 2020)&lt;/span&gt;,  &lt;span class="citation"&gt;(Sjoberg et al. 2020)&lt;/span&gt;. Visualization is achieved using package including  &lt;span class="citation"&gt;(Wickham 2016)&lt;/span&gt; and  &lt;span class="citation"&gt;(Kassambara, Kosinski, and Biecek 2020)&lt;/span&gt;. We can even provide interactive presentations of data with  &lt;span class="citation"&gt;(Xie, Cheng, and Tan 2020)&lt;/span&gt;,  &lt;span class="citation"&gt;(Sievert 2020)&lt;/span&gt;, and  &lt;span class="citation"&gt;(Hafen and Schloerke 2020)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It should also be realized that work building on these tools for clinical trial data is already in process. The  &lt;span class="citation"&gt;(Harrell Jr 2020)&lt;/span&gt; package provides graphical summaries for clinical trials and has been used in conjunction with  &lt;span class="citation"&gt;(Allaire et al. 2020)&lt;/span&gt; to produce specific trial report types with a specified format.&lt;/p&gt;
&lt;h1 id="using-for-programmatic-collaborative-clinical-trial-document-generation"&gt;Using  for programmatic, collaborative clinical trial document generation&lt;/h1&gt;
&lt;p&gt;The  package &lt;span class="citation"&gt;(Kane, Jiang, and Urbanek 2020)&lt;/span&gt; was recently released to automate the process of generating reproducible (RMarkdown) documents. Objects derived from a summary, exploration, or analysis are stored hierarchically in an R &lt;code&gt;list&lt;/code&gt;, which defines the structure of the document. These objects are referred to as &lt;em&gt;computational components&lt;/em&gt; since they are derived from computation, as opposed to prose, which makes up the &lt;em&gt;narrative components&lt;/em&gt; of a document.&lt;/p&gt;
&lt;p&gt;The computational components capture and structure the objects to be presented. Describing how the objects will be presented and how the document will be rendered is handled through the creation of a &lt;code&gt;listdown&lt;/code&gt; object. The separation between how computational components are created and how they are shown to a user provides two advantages. First, it decouples the data processing and analysis from its exploration and visualization. For compute-intensive analyses, this separation is critical for avoiding redundant computations for small changes in the presentation. It also discourages putting compute-intensive code into RMarkdown documents. Second, it provides the flexibility to quickly change how a computational component is visualized or summarized or even how a document is rendered. This makes transitioning from an interactive .html document to a static .pdf document significantly easier than substituting functions and parameters in an R Markdown document.&lt;/p&gt;
&lt;p&gt;The package has been found to be particularly useful in the reporting and research of clinical trial data. In particular, the package has been used for server collaborations focusing on either the analysis of past trial data to formulate a new trial or in trial monitoring where trial telemetry (enrollment, responses, etc.) is reported, and initial analyses are conveyed to a clinician. The associated presentations require very little context since clinicians often have as good an understanding of the data collected as that of the statistician’s meaning narrative components are not needed. At the same time, a large number of hierarchical, heterogeneous artifacts (tables and multiple types of plots) can be automated where manual creation of RMarkdown documents would be inconvenient and inefficient.&lt;/p&gt;
&lt;p&gt;The rest of this document describes concepts implemented in the  package for automated, reproducible document generation and shows its use with a simplified, synthetic clinical trial data set whose variables are typical of a non-small cell lung cancer trial. The data set comes from the  &lt;span class="citation"&gt;(Kane 2020)&lt;/span&gt; package. As of the time this document was written, the package is under development and is not available on CRAN. However, it can be installed as follows.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;devtools::install_github(&amp;quot;kaneplusplus/forceps&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following section uses the trial data to construct a pipeline for document generation. We note that both the data and the pipeline are simple when compared to most analyses of this type. However, it is sufficient to illustrate accompanying concepts, and both the analyses and concepts translate readily to real-world applications. A final section discusses the use of the package and its current direction.&lt;/p&gt;
&lt;h1 id="constructing-a-pipeline-for-document-generation"&gt;Constructing a pipeline for document generation&lt;/h1&gt;
&lt;p&gt;The process of analyzing data can be described using the classic waterfall model of &lt;span class="citation"&gt;Benington (1983)&lt;/span&gt; where the output (the analysis presentation or service) is dependent on a sequence of tasks that come before it. This dependency structure means that if a problem is detected in a given stage of the production of the analysis, all downstream parts must be rerun to reflect the change. A graphical depiction of the waterfall model, specific to data analyses (clinical or otherwise) is shown in Figure . Note that data exploration and visualization are an integral part of all stages of the production and are often the means for identifying issues and refining analyses.&lt;/p&gt;
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="https://rjournal-distill.netlify.app//articles/RJ-2021-051/waterfall.png" alt="The data analysis waterfall." width="5in" /&gt;
&lt;p class="caption"&gt;
(#fig:waterfall)The data analysis waterfall.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As explained in the previous section, we are going to implement a simple analysis pipeline. The data acquisition and preprocessing steps are handled by importing data sets from the  package and using some of the functions implemented in the package to create a single trial data set, thereby de-emphasizing these components in the pipeline. While these steps are critical, the emphasis of this paper is the incorporation of the  package into the later stages.&lt;/p&gt;
&lt;h2 id="data-acquisision-and-preprocessing"&gt;Data acquisision and preprocessing&lt;/h2&gt;
&lt;p&gt;Data acquisition refers to the portion of the analysis pipeline where the data is retrieved from some managed data store for integration into the pipeline. These data sets may be retrieved as tables from a database, case reports, Analysis Data Model (ADaM) data formatted according to the Clinical Data Interchange Standards Consortium (CDISC) &lt;span class="citation"&gt;(&lt;span&gt;“Clinical Data Interchange Standards Consortium”&lt;/span&gt; 2020)&lt;/span&gt;, Electronic Health Records, or other clinical Real World Data (RWD) formats. These data are then transformed to a format appropriate for analysis.&lt;/p&gt;
&lt;p&gt;In our simple example, this is accomplished by loading data corresponding to trial outcomes, patient adverse events, patient biomarkers, and patient demography and transforming them into a single data set with one row per patient and one variable per column using the  and  &lt;span class="citation"&gt;(Wickham et al. 2020)&lt;/span&gt; packages. The data also includes longitudinal adverse event information, which will is stored as a nested data frame in the &lt;code&gt;ae_long&lt;/code&gt; column of the resulting data set.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(forceps)
library(dplyr)

data(lc_adsl, lc_adverse_events, lc_biomarkers, lc_demography)

lc_trial &amp;lt;- consolidate(
  list(adsl = lc_adsl,
       adverse_events = lc_adverse_events %&amp;gt;% 
         cohort(on = &amp;quot;usubjid&amp;quot;, name = &amp;quot;ae_long&amp;quot;),
       biomarkers = lc_biomarkers,
       demography = lc_demography %&amp;gt;% 
         select(-chemo_stop)
  ),
  on = &amp;quot;usubjid&amp;quot;)

lc_trial&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 558 × 18
   usubjid best_response       pfs_days pfs_censor os_days os_censor
     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1    1003 Stable Disease           101          1     233         1
 2    1005 Complete Response         78          0     184         1
 3    1006 Progressive Disease      253          1     333         1
 4    1009 Partial Response         130          0     643         0
 5    1014 Complete Response         41          1     116         1
 6    1018 Partial Response         194          1     423         1
 7    1023 Stable Disease            49          1     337         1
 8    1025 Stable Disease            95          1     589         1
 9    1030 Complete Response        351          1     688         1
10    1033 Complete Response         33          1     125         1
# … with 548 more rows, and 12 more variables: chemo_stop &amp;lt;chr&amp;gt;,
#   arm &amp;lt;chr&amp;gt;, ae_count &amp;lt;int&amp;gt;, ae_long &amp;lt;list&amp;gt;, egfr_mutation &amp;lt;chr&amp;gt;,
#   smoking &amp;lt;chr&amp;gt;, ecog &amp;lt;chr&amp;gt;, prior_resp &amp;lt;chr&amp;gt;, site_id &amp;lt;int&amp;gt;,
#   sex &amp;lt;chr&amp;gt;, refractory &amp;lt;lgl&amp;gt;, age &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="analysis-defining-and-structuring-the-computational-components"&gt;Analysis defining and structuring the computational components&lt;/h2&gt;
&lt;p&gt;The next step is to define the computational components as a hierarchical, named list of objects that will be presented. These objects are generally derived from the exploratory, descriptive, and analysis stages and are presented as visualizations and tables. This example will focus on the exploratory and descriptive portions. We will start by defining a new function &lt;code&gt;class_and_tag()&lt;/code&gt;, which takes an object and prepends a class designation to the objects along with optionally associating the object with a set of attributes. This extra information will be used later in order to dispatch to the proper functions responsible for presenting the objects in a resulting R Markdown document. If no such information is given, then the object will be presented as it usually would in the document. It should also be noted that &lt;code&gt;class_and_tag()&lt;/code&gt; is provided for convenience here and will be available in subsequent package versions.&lt;/p&gt;
&lt;p&gt;The next step is to define the computational components that will be presented. Our simple example will contain three sections: Outcome Information, Adverse Events, Biomarkers. The Adverse Events and Biomarkers sections will each show summary tables of one of the variables from those data. The Outcome Information section will be composed of two subsections, with the first (Best Response) providing a summary of the best response by the arm and the second (Overall Survival) showing a survival plot by arm of the overall survival. The call to &lt;code&gt;ld_cc_dendro()&lt;/code&gt; at the end of the example provides of dendrogram of the hierarchical structure.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(listdown)

trial_summary &amp;lt;- list(
  `Outcome Information` = list(
    `Best Response` = lc_trial %&amp;gt;% 
      select(best_response, arm) %&amp;gt;% 
      class_and_tag(&amp;quot;summary_table&amp;quot;, by = &amp;quot;arm&amp;quot;),
    `Overall Survival` = lc_trial %&amp;gt;% 
      select(os_days, os_censor, arm) %&amp;gt;% 
      class_and_tag(&amp;quot;survival_plot&amp;quot;, 
                    time = &amp;quot;os_days&amp;quot;, 
                    censor = &amp;quot;os_censor&amp;quot;, 
                    x = &amp;quot;arm&amp;quot;)),
  `Adverse Events` = lc_trial %&amp;gt;%
    select(best_response) %&amp;gt;%
    class_and_tag(&amp;quot;summary_table&amp;quot;),
  `Biomarkers` = list(
    `EGFR` = lc_trial %&amp;gt;%
      select(egfr_mutation) %&amp;gt;%
      class_and_tag(&amp;quot;summary_table&amp;quot;)
  )
)

ld_cc_dendro(trial_summary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
trial_summary
  |-- Outcome Information
   |-- Best Response
   |  o-- object of type(s):summary_table tbl_df tbl data.frame
   o-- Overall Survival
      o-- object of type(s):survival_plot tbl_df tbl data.frame
  |-- Adverse Events
  |  o-- object of type(s):summary_table tbl_df tbl data.frame
  o-- Biomarkers
   o-- EGFR
      o-- object of type(s):summary_table tbl_df tbl data.frame&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="communicating-results"&gt;Communicating results&lt;/h2&gt;
&lt;p&gt;The objects have been constructed and they have been structured. The next step is to define how they will be presented. This is done by creating two functions &lt;code&gt;make_summary&lt;/code&gt; and &lt;code&gt;make_survival_plot&lt;/code&gt;. The former takes a &lt;code&gt;data.frame&lt;/code&gt; and uses the  package to summarize the results. If the &lt;code&gt;data.frame&lt;/code&gt; includes an attribute named &lt;code&gt;by&lt;/code&gt; and denoting a valid variable in the data set, then the summary is created conditionally on that variable. The latter function also takes a &lt;code&gt;data.frame&lt;/code&gt; and uses attributes to denote variables on which a Kaplan-Meier plot can be constructed using the  &lt;span class="citation"&gt;(Terry M. Therneau and Patricia M. Grambsch 2000)&lt;/span&gt; and  packages. The functions are written to a file called &lt;code&gt;decorators.r&lt;/code&gt; and will be used by the R Markdown document to render the final document.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(gtsummary)
library(survival)
library(survminer)
library(dplyr)

make_summary &amp;lt;- function(x) {
  by &amp;lt;- attributes(x)$by
  tbl_summary(x, by = by)
}

make_survival_plot &amp;lt;- function(.x) {
  att &amp;lt;- attributes(.x)
  x &amp;lt;- ifelse(is.null(att$x), &amp;quot;1&amp;quot;, att$x)
  form &amp;lt;- sprintf(&amp;quot;Surv(%s, %s) ~ %s&amp;quot;, att$time, att$censor, x) %&amp;gt;%
    as.formula()
  fit &amp;lt;- surv_fit(form, data = as.data.frame(.x))
  ggsurvplot(fit, data = as.data.frame(.x))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to connect the computational components to the functions that will present them using the &lt;code&gt;listdown()&lt;/code&gt; function. First, the computational components are stored in the &lt;code&gt;trial_summary&lt;/code&gt; object are written to the disk. The resulting R Markdown document will read it in based on the &lt;code&gt;load_cc_expr&lt;/code&gt; argument. Along with reading in the data, initialization in the R Markdown document will include sourcing the &lt;code&gt;decorators.r&lt;/code&gt; file previously written to disk. This is handled with the &lt;code&gt;init_expr&lt;/code&gt; argument. The &lt;code&gt;decorators&lt;/code&gt; argument takes a list where the name specifies the class and the list element corresponds to a function that will present objects of the specified class. For example, &lt;code&gt;summary_table&lt;/code&gt; objects are sent to the &lt;code&gt;make_summary()&lt;/code&gt; function for presentation. This allows us to connect objects to their appropriate function to process and present them. Finally, &lt;code&gt;echo&lt;/code&gt; and &lt;code&gt;message&lt;/code&gt; chunk options are set to &lt;code&gt;FALSE&lt;/code&gt; so that the code and associated messages will not appear in the final rendered document. The last line of code below displays the first 12 lines of R Markdown code chunks as they will appear in the corresponding document.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;saveRDS(trial_summary, &amp;quot;cc.rds&amp;quot;)

ld &amp;lt;- listdown(load_cc_expr = readRDS(&amp;quot;cc.rds&amp;quot;),
               init_expr = source(&amp;quot;decorators.r&amp;quot;),
               decorator = list(summary_table = make_summary,
                                survival_plot = make_survival_plot),
               echo = FALSE,
               message = FALSE)

ld_make_chunks(ld)[1:12]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; [1] &amp;quot;&amp;quot;                                    
 [2] &amp;quot;```{r echo = FALSE, message = FALSE}&amp;quot;
 [3] &amp;quot;source(\&amp;quot;decorators.r\&amp;quot;)&amp;quot;            
 [4] &amp;quot;&amp;quot;                                    
 [5] &amp;quot;cc_list &amp;lt;- readRDS(\&amp;quot;cc.rds\&amp;quot;)&amp;quot;      
 [6] &amp;quot;```&amp;quot;                                 
 [7] &amp;quot;&amp;quot;                                    
 [8] &amp;quot;# Outcome Information&amp;quot;               
 [9] &amp;quot;&amp;quot;                                    
[10] &amp;quot;## Best Response&amp;quot;                    
[11] &amp;quot;&amp;quot;                                    
[12] &amp;quot;```{r echo = FALSE, message = FALSE}&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last step creates the R Markdown header, writes it along with the R code chunks to a file named &lt;code&gt;"simple-data-trial-summary.rmd"&lt;/code&gt; and knits the file with the  package &lt;span class="citation"&gt;(Xie 2020)&lt;/span&gt; to a pdf document, per the &lt;code&gt;output&lt;/code&gt; argument of the &lt;code&gt;ld_rmarkdown_header()&lt;/code&gt; function. &lt;code&gt;md_header&lt;/code&gt; is a &lt;code&gt;yml&lt;/code&gt; object making it easy to control how the document is rendered. The code to generate the document along with the resulting R Markdown and output file constitute a reproducible workflow that can be quickly iterated upon and adapted for different types of explorations, summaries, and analyses.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(knitr)

md_header &amp;lt;- ld_rmarkdown_header(&amp;quot;Fake Data Trial Summary&amp;quot;,
                                 output = &amp;quot;pdf_document&amp;quot;)

ld_write_file(
  rmd_header = as.character(md_header),
  ld = ld_make_chunks(ld),
  file_name = &amp;quot;simple-data-trial-summary.rmd&amp;quot;)

knit(&amp;quot;simple-data-trial-summary.rmd&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="direction"&gt;Direction&lt;/h1&gt;
&lt;p&gt;The  package has been successfully used for collaborations on several clinical trial analyses. The package works particularly well when creating large, navigable sets of summaries and visualizations. Current work focuses on two areas. First is the construction of standard decorators. By packaging decorators and associated functionality, presentations can be made rich as they are developed over time. This standardization also makes it easier to leverage work in configuring chunks so that they can be made more aesthetic by default. In addition, we have been working on abstract and formalize the notion of document composition. In the example presented, the aggregation of the header and R code chunks into a file was sufficient for generating a document. However, the composition of other outputs is also supported. For example, the top-level names of the trial summary could just as easily designate tabs on a web page or other target. The notion of a composer would allow a user to target a greater variety of output types, better suiting the application under consideration and the target audience for the presentation.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id="refs" class="references csl-bib-body hanging-indent"&gt;
&lt;div id="ref-rmarkdown" class="csl-entry"&gt;
Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. &lt;em&gt;Rmarkdown: Dynamic Documents for r&lt;/em&gt;. &lt;a href="https://github.com/rstudio/rmarkdown"&gt;https://github.com/rstudio/rmarkdown&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-benington1983" class="csl-entry"&gt;
Benington, H. D. 1983. &lt;span&gt;“Production of Large Computer Programs.”&lt;/span&gt; &lt;em&gt;Annals of the History of Computing&lt;/em&gt; 5 (4): 350–61. &lt;a href="https://doi.org/10.1109/MAHC.1983.10102"&gt;https://doi.org/10.1109/MAHC.1983.10102&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-CDISC" class="csl-entry"&gt;
&lt;span&gt;“Clinical Data Interchange Standards Consortium.”&lt;/span&gt; 2020. &lt;a href="https://www.cdisc.org/"&gt;https://www.cdisc.org/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-trelliscopejs" class="csl-entry"&gt;
Hafen, Ryan, and Barret Schloerke. 2020. &lt;em&gt;Trelliscopejs: Create Interactive Trelliscope Displays&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=trelliscopejs"&gt;https://CRAN.R-project.org/package=trelliscopejs&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-greport" class="csl-entry"&gt;
Harrell Jr, Frank E. 2020. &lt;em&gt;Greport: Graphical Reporting for Clinical Trials&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=greport"&gt;https://CRAN.R-project.org/package=greport&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-gt" class="csl-entry"&gt;
Iannone, Richard, Joe Cheng, and Barret Schloerke. 2020. &lt;em&gt;Gt: Easily Create Presentation-Ready Display Tables&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=gt"&gt;https://CRAN.R-project.org/package=gt&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-forceps" class="csl-entry"&gt;
Kane, Michael J. 2020. &lt;em&gt;Forceps: A Grammar for Manipulating Clinical Trial Data&lt;/em&gt;. &lt;a href="https://github.com/kaneplusplus/forceps"&gt;https://github.com/kaneplusplus/forceps&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-listdown" class="csl-entry"&gt;
Kane, Michael J., Xun (Tony) Jiang, and Simon Urbanek. 2020. &lt;span&gt;“On the Programmatic Generation of Reproducible Documents.”&lt;/span&gt; &lt;a href="http://arxiv.org/abs/2007.12631"&gt;http://arxiv.org/abs/2007.12631&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-survminer" class="csl-entry"&gt;
Kassambara, Alboukadel, Marcin Kosinski, and Przemyslaw Biecek. 2020. &lt;em&gt;Survminer: Drawing Survival Curves Using ’Ggplot2’&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=survminer"&gt;https://CRAN.R-project.org/package=survminer&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-R" class="csl-entry"&gt;
R Core Team. 2012. &lt;em&gt;R: A Language and Environment for Statistical Computing&lt;/em&gt;. Vienna, Austria: R Foundation for Statistical Computing. &lt;a href="http://www.R-project.org/"&gt;http://www.R-project.org/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-plotly" class="csl-entry"&gt;
Sievert, Carson. 2020. &lt;em&gt;Interactive Web-Based Data Visualization with r, Plotly, and Shiny&lt;/em&gt;. Chapman; Hall/CRC. &lt;a href="https://plotly-r.com"&gt;https://plotly-r.com&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-gtsummary" class="csl-entry"&gt;
Sjoberg, Daniel D., Michael Curry, Margie Hannum, Karissa Whiting, and Emily C. Zabor. 2020. &lt;em&gt;Gtsummary: Presentation-Ready Data Summary and Analytic Result Tables&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=gtsummary"&gt;https://CRAN.R-project.org/package=gtsummary&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-survival" class="csl-entry"&gt;
Terry M. Therneau, and Patricia M. Grambsch. 2000. &lt;em&gt;Modeling Survival Data: Extending the &lt;span&gt;C&lt;/span&gt;ox Model&lt;/em&gt;. New York: Springer.
&lt;/div&gt;
&lt;div id="ref-ggplot2" class="csl-entry"&gt;
Wickham, Hadley. 2016. &lt;em&gt;Ggplot2: Elegant Graphics for Data Analysis&lt;/em&gt;. Springer-Verlag New York. &lt;a href="https://ggplot2.tidyverse.org"&gt;https://ggplot2.tidyverse.org&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-dplyr" class="csl-entry"&gt;
Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2020. &lt;em&gt;Dplyr: A Grammar of Data Manipulation&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=dplyr"&gt;https://CRAN.R-project.org/package=dplyr&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-knitr" class="csl-entry"&gt;
Xie, Yihui. 2020. &lt;em&gt;Knitr: A General-Purpose Package for Dynamic Report Generation in r&lt;/em&gt;. &lt;a href="https://yihui.org/knitr/"&gt;https://yihui.org/knitr/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-DT" class="csl-entry"&gt;
Xie, Yihui, Joe Cheng, and Xianying Tan. 2020. &lt;em&gt;DT: A Wrapper of the JavaScript Library ’DataTables’&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=DT"&gt;https://CRAN.R-project.org/package=DT&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-tableone" class="csl-entry"&gt;
Yoshida, Kazuki, and Alexander Bartel. 2020. &lt;em&gt;Tableone: Create ’Table 1’ to Describe Baseline Characteristics with or Without Propensity Score Weights&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=tableone"&gt;https://CRAN.R-project.org/package=tableone&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;</description>
      <distill:md5>c59fe4f228dbe91cef33fc868a8ecb4e</distill:md5>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-051</guid>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      <media:content url="https://rjournal-distill.netlify.app/articles/RJ-2021-051/waterfall.png" medium="image" type="image/png" width="1260" height="800"/>
    </item>
    <item>
      <title>Towards a Grammar for Processing Clinical Trial Data</title>
      <dc:creator>Michael J. Kane</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-052</link>
      <description>


&lt;style type="text/css"&gt;
d-title h1, d-title p, d-title figure {
  grid-column: page;
}
&lt;/style&gt;
&lt;h1 id="introduction-on-the-use-of-historical-clinical-data"&gt;Introduction: On the use of historical clinical data&lt;/h1&gt;
&lt;p&gt;There are few areas of data science research that provide more promise to improve human quality-of-life and treat a disease than the development of methods and analysis in clinical trials. While adjacent, data-focused areas of biomedicine and health related research have recently seen increased attention, especially the analysis of real-world evidence (RWE) and electronic health records (EHR) in particular, clinical trial data maintains several distinct quality advantages, enumerated here.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Features and measurements are selected for their relevance. Unlike EHR’s or other similar data, variables collected for a clinical trial are included because they are potentially relevant to the disease under consideration or the treatment whose efficacy is being analyzed. This makes the variable selection process considerably easier than that where data collection has not been designed for a targeted analysis of this type.&lt;/li&gt;
&lt;li&gt;Data collection procedures are carefully prescribed. Clinical trial data is uniform in both which variables are collected and how they are collected. This ensures data quality across trial sites ensuring that variables are relatively complete as well as consistent.&lt;/li&gt;
&lt;li&gt;Inclusion/Exclusion criteria define the population. Since RWE studies are observational, the populations they consider are not always well-understood due to bias in the collection process. On the other hand, clinical trial data sets are generally controlled and randomized, with well-documented inclusion and exclusion criteria.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Along with maintaining higher quality clinical trial data is more available and more easily accessible when compared to real-world data sources, which often require affiliations with appropriate research institutions as well as infrastructure and appropriate staff, including data managers, to extract data. By contrast, modern clinical trial data organizations allow users to quickly search and download thousands of trials, including anonymized patient-level information. These data sets tend to include control-arm data, which can be used to understand prognostic disease populations construct historical controls for existing trials. However, some also include treatment data, which can be used to characterize predictive patient subtypes for a given treatment, understand safety profiles for classes of drugs, and aid in the design of new trials. We note that, for oncology, Project Data Sphere &lt;span class="citation"&gt;(&lt;span&gt;“Project Data Sphere: Convener, Collaborator, Catalyst in the Fight Against Cancer”&lt;/span&gt; 2020)&lt;/span&gt; and outside of oncology, Immport &lt;span class="citation"&gt;(&lt;span&gt;“Immport: Bioinformatics for the Future of Immunology”&lt;/span&gt; 2020)&lt;/span&gt; have been invaluable in our own experience by facilitating these types of analyses.&lt;/p&gt;
&lt;h2 id="clinical-trial-analysis-data-sets"&gt;Clinical trial analysis data sets&lt;/h2&gt;
&lt;p&gt;During a clinical trial, patient-level data is collected in case report forms (CRFs). The format and data collected in these forms are prescribed in the trial design. These forms are the basis for the construction of analysis data sets and other documents that will be submitted to governing bodies, including the Food and Drug Association (FDA) and European Medicines Agency (EMA), for approval if the sponsor (party funding the trial) decides it is appropriate. The Clinical Data Interchange Standards Consortium (CDISC) &lt;span class="citation"&gt;(&lt;span&gt;“Clinical Data Interchange Standards Consortium”&lt;/span&gt; 2020)&lt;/span&gt; develops standards dealing with medical research data, including the submission of trial results. Adhering to these standards is necessary for a successful trial submission.&lt;/p&gt;
&lt;p&gt;There are several data sets included with a submission that tend to be useful for analysis. This paper focuses on the Analysis Data Model (ADaM) data, which provides patient-level data, which has been validated and used for data derivation and analysis. An ADaM data set is itself composed of several data sets, including a Subject-Level Analysis Data Set (ADSL) holding analysis and treatment information. Other information, including baseline characteristics, demographic data, visit information, etc., are held in the and Basic Data Structure (BDS) formatted data sets. Finally, adverse events are held in the Analysis Data Sets for Adverse Events (ADAE).&lt;/p&gt;
&lt;h2 id="challenges-to-analyzing-these-data-sets"&gt;Challenges to analyzing these data sets&lt;/h2&gt;
&lt;p&gt;ADaM data for a clinical trial is generally made available as a set of SAS7BDAT &lt;span class="citation"&gt;(M. S. Shotwell et al. 2013)&lt;/span&gt; files. While neither the FDA nor the EMA require this format for submission nor do they requires the use of SAS &lt;span class="citation"&gt;(SAS Institute 2020)&lt;/span&gt; for analysis, there is a heavy bias toward the data format and computing platform. This is partially because they are validated and approved by governing bodies and because a large effort has gone into their use in submissions. Packages like  &lt;span class="citation"&gt;(M. Shotwell 2014)&lt;/span&gt; and, more recently,  &lt;span class="citation"&gt;(Wickham and Miller 2020)&lt;/span&gt; have gone a long way to make these data sets easily accessible to R &lt;span class="citation"&gt;(R Core Team 2012)&lt;/span&gt; users working with clinical trial data.&lt;/p&gt;
&lt;p&gt;Despite the effort that has gone into defining a structure for the data as well as the tools implemented to aid in their analysis, the data sets themselves are not particularly easy to analyze for two reasons. First, the standard is not “tidy” as defined by &lt;span class="citation"&gt;Wickham and others (2014)&lt;/span&gt;. In particular, it is not required that each variable forms a column. In fact, multiple variables may be stored in one column, with another column acting as a key as to which variable’s value is given. This case is often seen in the ADSL data set where a single column may primary and secondary endpoints. For data sets like these, the value variable is held in the Analysis Value (AVAL) if the corresponding variable is numeric, Analysis Value Character (AVALC) if the variable is a string, the Parameter Character Description (PARAMCD) column giving a shorted variable name, and the Parameter column providing a text description of the variable. As an example, consider the &lt;code&gt;adakiep.xpt&lt;/code&gt; data set, which is provided as an example on the CDISC website and whose data is included in the supplementary material.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(readr)

adakiep &amp;lt;- read_csv(&amp;quot;adakiep.csv&amp;quot;) 
adakiep&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 24 × 8
   USUBJID     PARAM      PARAMCD AVALC   ADY ADT        SRCDOM SRCSEQ
   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;date&amp;gt;     &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt;
 1 XYZ-001-001 Death      DEATH   Y        85 2013-11-02 DS          1
 2 XYZ-001-001 Dialysis   DIALYS… Y        80 2013-10-29 PR          2
 3 XYZ-001-001 eGFR 25 P… EGFRDEC N        85 2013-11-02 &amp;lt;NA&amp;gt;       NA
 4 XYZ-001-001 Composite… AKIEP   Y        80 2013-10-29 &amp;lt;NA&amp;gt;       NA
 5 XYZ-001-002 Death      DEATH   Y        82 2015-03-20 DS          1
 6 XYZ-001-002 Dialysis   DIALYS… Y        73 2015-03-11 PR          2
 7 XYZ-001-002 eGFR 25 P… EGFRDEC N        82 2015-03-20 &amp;lt;NA&amp;gt;       NA
 8 XYZ-001-002 Composite… AKIEP   Y        73 2015-03-11 &amp;lt;NA&amp;gt;       NA
 9 XYZ-001-003 Death      DEATH   N        94 2010-10-12 DS          1
10 XYZ-001-003 Dialysis   DIALYS… Y        64 2010-09-12 PR          2
# … with 14 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data set includes minimal information about the trial. However, we can infer that it is from a study focusing on kidney disease. There are four distinct endpoints, death, whether dialysis was needed, whether a 25% decrease in estimated glomerular filtration rate, indicating a decrease in kidney function. For analysis, these data will need to be re-arranged so that each endpoint has it’s own column along with another column per endpoint indicating the trial day where the measurement was taken (from the ADY column).&lt;/p&gt;
&lt;p&gt;The task of transforming these types of data into into appropriate analysis is complicated by the fact that there may be other files with relevant information with similar layout or layouts slightly more complicated if they include longitudinal information, for example. The rest of this paper focuses on shaping these types of data so that they can be quickly understood; they are amenable to many different types of analyses at the individual patient level; and they can be reformatted for an even larger class of analyses through a minimal set of verbs, including cohorting, which is introduced in this paper and is implemented in the  package &lt;span class="citation"&gt;(Kane 2020)&lt;/span&gt;. The package is currently in development and has not been released to CRAN. However, it has been tagged for prerelease on Github and can be installed with the following code.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;devtools::install_github(&amp;quot;kaneplusplus/forceps@v0.0.5&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next section specifies the target data shape, which can be thought of as a restriction on the tidy format. The following section specifies the steps needed to prepare clinical trial data so that it conforms to this restriction and includes an anonymized trial example. The final section provides a roadmap if near-term development as well as directions for enhancements and integration of the larger R ecosystem.&lt;/p&gt;
&lt;h1 id="a-tidy-representation-for-a-consolidated-analysis-data-set"&gt;A tidy representation for a consolidated analysis data set&lt;/h1&gt;
&lt;p&gt;Clinical trial data is collected to be used in an analysis that determines whether or not a treatment for a disease provides a benefit when compared to those receiving either a placebo or the standard of care. “Benefit” is quantified by one or more endpoints, defined before the trial starts (in the &lt;em&gt;design&lt;/em&gt;), which are compared across arms (treatment and placebo) at the conclusion of the trial using a statistical test. These data provide a wealth of information, and their usefulness extends well beyond the scope of the trial. For example, they can also be used to understand prognostic characteristics of the disease-population; they can be used to create a ``historical control’’ for another trial; they can be used to identify patients’ characteristics associated with better outcomes, etc.&lt;/p&gt;
&lt;p&gt;As shown in the previous section, while ADaM-formatted data is structured, the structure does not lend itself to analysis without first performing some data transformations. We propose that the result of these transformations is a single data set with the following characteristics.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Each row corresponds to a single patient.&lt;/li&gt;
&lt;li&gt;A variable with one value per patient should be included as a column variable.&lt;/li&gt;
&lt;li&gt;Longitudinal, time series, or repeated measures data should be stored as an embedded &lt;code&gt;data.frame&lt;/code&gt; per subject.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Data conforming to these characteristics provide several advantages to ADaM data sets. First, they are oriented towards trial analysis. Essentially, trials compare response rates between treatment and control arms. Having those values coded as their own variables in a single data set minimizes the complexity and effort that would otherwise go into extracting data from multiple files, cleaning them and joining them. Second, it minimizes the reshaping effort for other types of analyses. For example, response rates are often analyzed by the site at which patient measurements were taken in order to check for certain types of enrollment heterogeneity. The described patient-centric format can be transformed into a site-centric format by nesting or grouping on a site variable followed by the extraction of site-specific features and analyses, which can then be compared across sites. Transforming between these formats requires a single operation. Likewise, the patient-centric format can be transformed to a patient-longitudinal format by unnesting on the embedded variable holding the relevant longitudinal information. Third and finally, creating a single patient-centric data set minimizes the chance of inconsistent analyses. Primary and secondary analyses often use similar variables and may require similar preprocessing. If these preprocessing steps are performed separately for parallel analyses, then the probability that at least one of them contains an error in these steps is greater than when a validated patient-centric data set is created. It also makes it easier to provide provenance for an analysis if they are dependent on the same preprocessed data.&lt;/p&gt;
&lt;h1 id="processing-adam-data-to-reach-the-tidy-representation"&gt;Processing ADaM data to reach the tidy representation&lt;/h1&gt;
&lt;p&gt;This section provides an example of how to use the functionality provided in the  package, in the order that the operations take place. The data set is provided with the package, and the variable names are taken from several example lung cancer studies. The data set has been significantly reduced in size, and some values and variable names have been preprocessed. This allows the example to remain easy to follow. It also allows us to illustrate the formation of a patient-centric data set in a single pass. In practice, this is often an iterative process, requiring several revisions as bugs are found, and hypotheses change.&lt;/p&gt;
&lt;p&gt;The data sets used are as follows, and the task will be to create a patient-centered data set as described above.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;code&gt;lc_adverse_events&lt;/code&gt; - adverse events longitudinal data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lc_biomarkers&lt;/code&gt; - patient biomarkers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lc_demography&lt;/code&gt; - patient demographic information.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lc_adsl&lt;/code&gt; - response data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="creating-the-data-dictionary"&gt;Creating the data dictionary&lt;/h2&gt;
&lt;p&gt;SAS ADaM formatted data sets generally include extra information about variables, including a short description of each of the variables and possibly formatting information. The  package keeps this as attributes of each of the columns of a &lt;code&gt;tibble&lt;/code&gt; that is read from these files. The  package is capable of extracting this meta-information to create a &lt;code&gt;tibble&lt;/code&gt; that can be used as a data dictionary using the &lt;code&gt;consolidated_describe_data()&lt;/code&gt; function, shown below. In practice, we have found it helpful as a starting for a fuller description of the data and often add columns to further categorize individual variables for analyses.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(forceps)

data(lc_adverse_events)
data(lc_biomarkers)
data(lc_demography)
data(lc_adsl)

consolidated_describe_data(lc_adverse_events,
                           lc_biomarkers,
                           lc_demography,
                           lc_adsl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 27 × 5
   var_name      type      label              format_sas data_source  
   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;              &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;        
 1 usubjid       double    Randomization Code &amp;lt;NA&amp;gt;       lc_adverse_e…
 2 ae            character AE Preferred Term  character  lc_adverse_e…
 3 ae_type       character System Organ Clas… character  lc_adverse_e…
 4 grade         integer   Adverse Event Gra… numeric    lc_adverse_e…
 5 ae_day        double    Days From First D… &amp;lt;NA&amp;gt;       lc_adverse_e…
 6 ae_duration   double    Adverse Event Dur… numeric    lc_adverse_e…
 7 ae_treat      logical   Was the Adverse E… logical    lc_adverse_e…
 8 ae_count      integer   Total Patient Adv… integer    lc_adverse_e…
 9 usubjid       double    Randomization Code &amp;lt;NA&amp;gt;       lc_biomarkers
10 egfr_mutation character EGFR Mutation +ve… character  lc_biomarkers
# … with 17 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="cohorting"&gt;Cohorting&lt;/h2&gt;
&lt;p&gt;The data dictionary (or data description) provides a summary of the variable types and information held by variables in each of the data sets. Some data sets will include repeated, longitudinal, or time series information about individual patients, like &lt;code&gt;lc_adverese_events&lt;/code&gt; in our example. Consolidating data sets like these into a single, patient-centric data set generally involves three distinct operations. The first can be thought of as &lt;code&gt;pivot_wider()&lt;/code&gt; operations that take columns composed of multiple variables and spread them across new columns in the data set. The second takes the data set and &lt;code&gt;nest()&lt;/code&gt;’s the data so that the the resulting data set contains time-varying data embedded in a &lt;code&gt;data.frame&lt;/code&gt; variable and those variables that are repeated appear once per patient in the new variables. This verb, which is referred to as &lt;code&gt;cohort()&lt;/code&gt; in the package, takes the variable to cohort on (the &lt;code&gt;usubjid&lt;/code&gt; in the example below), checks for values that are repeated by the subject identifier (&lt;code&gt;ae_count&lt;/code&gt; in the example below) and those that are not, and handles the nesting appropriately. A final operation may be applied to the patient-level embedded &lt;code&gt;data.frame&lt;/code&gt; objects to extract other features that will be used in subsequent analyses.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(dplyr)

data(lc_adverse_events)

lc_adverse_events %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 6 × 8
  usubjid ae     ae_type    grade ae_day ae_duration ae_treat ae_count
    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;      &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt;       &amp;lt;int&amp;gt;
1    1003 BURNI… NERVOUS S…     1     27           4 FALSE          15
2    1003 CONST… GASTROINT…     2      4           4 TRUE           15
3    1003 DEPRE… PSYCHIATR…     2     66          NA FALSE          15
4    1003 BACK … MUSCULOSK…     2     27          NA TRUE           15
5    1003 DYSUR… RENAL AND…     2      1           3 TRUE           15
6    1003 SKIN … SKIN AND …     1      5          26 FALSE          15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;lc_adverse_events &amp;lt;- lc_adverse_events %&amp;gt;%
  cohort(on = &amp;quot;usubjid&amp;quot;, name = &amp;quot;ae_long&amp;quot;)

lc_adverse_events %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 6 × 3
  usubjid ae_count ae_long          
    &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;           
1    1003       15 &amp;lt;tibble [15 × 6]&amp;gt;
2    1005       19 &amp;lt;tibble [19 × 6]&amp;gt;
3    1006       11 &amp;lt;tibble [11 × 6]&amp;gt;
4    1009       12 &amp;lt;tibble [12 × 6]&amp;gt;
5    1014        5 &amp;lt;tibble [5 × 6]&amp;gt; 
6    1018       10 &amp;lt;tibble [10 × 6]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="identifying-conflicts-and-redundancies"&gt;Identifying conflicts and redundancies&lt;/h2&gt;
&lt;p&gt;After cohorting, each of the data sets is in the specified format, and we are almost ready to combine them. It is important to first check to see if there are variables that are repeated across the individual data sets and detect conflicts. While ADaM data sets &lt;em&gt;should&lt;/em&gt; be free of conflicts and redundancies, we have observed multiple cases where this is not true. In order to identify these issues, the &lt;code&gt;duplicate_vars()&lt;/code&gt; function is provided. The function checks the column names of each of the data sets with those of other column names. The object returned is a named list where the name corresponds to the variable that is repeated. Each list element returns a &lt;code&gt;tibble&lt;/code&gt;, joined by the &lt;code&gt;on&lt;/code&gt; parameter with columns corresponding to the &lt;code&gt;on&lt;/code&gt; variable, the duplicated variable, the data sets where the duplicated variable appears. The example below shows that the &lt;code&gt;chemo_stop&lt;/code&gt; variable appears in the &lt;code&gt;demography&lt;/code&gt; and &lt;code&gt;adsl&lt;/code&gt; data sets. Furthermore, we can see that the values in each of the data sets are different by looking at the correspondence between the &lt;code&gt;demography&lt;/code&gt; and &lt;code&gt;adsl&lt;/code&gt; columns. To fix this and move on, we will remove the variable from the &lt;code&gt;demography&lt;/code&gt; data set.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;data(lc_adsl)
data(lc_biomarkers)
data(lc_demography)
data_list &amp;lt;- list(demography = lc_demography, 
                  biomarkers = lc_biomarkers, 
                  adverse_events = lc_adverse_events, 
                  adsl = lc_adsl)
duplicated_vars(data_list, on = &amp;quot;usubjid&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$chemo_stop
# A tibble: 558 × 4
   usubjid var        demography            adsl                 
     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;                 &amp;lt;chr&amp;gt;                
 1    1003 chemo_stop patient discontinued  adverse events       
 2    1005 chemo_stop treatment ineffective adverse events       
 3    1006 chemo_stop &amp;lt;NA&amp;gt;                  treatment ineffective
 4    1009 chemo_stop treatment ineffective &amp;lt;NA&amp;gt;                 
 5    1014 chemo_stop &amp;lt;NA&amp;gt;                  adverse events       
 6    1018 chemo_stop treatment ineffective treatment ineffective
 7    1023 chemo_stop &amp;lt;NA&amp;gt;                  adverse events       
 8    1025 chemo_stop adverse events        adverse events       
 9    1030 chemo_stop adverse events        adverse events       
10    1033 chemo_stop adverse events        treatment ineffective
# … with 548 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;data_list$demography &amp;lt;- data_list$demography %&amp;gt;% 
  select(-chemo_stop)&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="consolidating"&gt;Consolidating&lt;/h2&gt;
&lt;p&gt;The last step is to consolidate the data sets into a single one. This is accomplished by reducing the &lt;code&gt;data_list&lt;/code&gt; using full joins, along with some extra checking. The &lt;code&gt;consolidate()&lt;/code&gt; function wraps this functionality. The result, conforming to the provided format, which can easily be used in the exploration and analysis stage.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;consolidate(data_list, on = &amp;quot;usubjid&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 558 × 18
   usubjid site_id sex    refractory   age egfr_mutation smoking ecog 
     &amp;lt;dbl&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;lgl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;
 1    1003       1 male   FALSE         51 negative      former… ambu…
 2    1005       4 female TRUE          44 negative      former… ambu…
 3    1006       2 male   TRUE          22 negative      former… ambu…
 4    1009       8 male   FALSE         44 &amp;lt;NA&amp;gt;          unknown ambu…
 5    1014       6 male   TRUE          76 &amp;lt;NA&amp;gt;          former… ambu…
 6    1018      10 female TRUE          35 positive      former… ambu…
 7    1023       6 female TRUE          73 &amp;lt;NA&amp;gt;          former… ambu…
 8    1025       7 male   FALSE         71 &amp;lt;NA&amp;gt;          never … ambu…
 9    1030       5 female TRUE          20 &amp;lt;NA&amp;gt;          unknown ambu…
10    1033       6 female TRUE          55 &amp;lt;NA&amp;gt;          unknown ambu…
# … with 548 more rows, and 10 more variables: prior_resp &amp;lt;chr&amp;gt;,
#   ae_count &amp;lt;int&amp;gt;, ae_long &amp;lt;list&amp;gt;, best_response &amp;lt;chr&amp;gt;,
#   pfs_days &amp;lt;dbl&amp;gt;, pfs_censor &amp;lt;dbl&amp;gt;, os_days &amp;lt;dbl&amp;gt;, os_censor &amp;lt;dbl&amp;gt;,
#   chemo_stop &amp;lt;chr&amp;gt;, arm &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="direction-an-integrated-approach-to-processing-clinical-data"&gt;Direction: An integrated approach to processing clinical data&lt;/h1&gt;
&lt;p&gt;As stated before, the goal of this paper is to help define a path toward a grammar for processing clinical trials by a) defining a format in which we would like to represent data from standardized clinical trial data b) describing a standard set of operations to transform clinical trial data into this format, and c) to identify a set of verbs and other functionality to facilitate data processing of this kind and encourage reproducibility of these steps. Admittedly, this only serves to mitigate the process of preparing these types of data for exploration and analysis. Clinical trial data generally contains many more variables than what was presented, and each of these data sets comes with its own set of “quirks” and other challenges. However, it does serve to make the data preparation better defined and propose a path toward standardization of both the processed data set format as well as the operations to achieve that goal.&lt;/p&gt;
&lt;p&gt;Along with further development towards those ends, there is a plethora of development that can be done to provide an integrated data processing experience. For example, the define.xml file, which appears alongside ADaM data sets, gives better descriptions of the variables as well as the variable values. Tools to integrate these data into the construction of the data dictionary would go a long way towards orienting researchers with the data contained and help them more quickly formulate analyses. Packages like  &lt;span class="citation"&gt;(van der Loo 2020)&lt;/span&gt; could enhance and augment data preprocessing steps by keeping better track of when data are being removed and how they are being manipulated. The artifacts accumulated could then be used by packages such as  &lt;span class="citation"&gt;(Higgins 2020)&lt;/span&gt; to provide consort diagrams of how patients progress through the trial and how data progresses through preprocessing. In the longer term, these advancements can provide better data provenance, more reproducible processing, quicker debugging of problems in the processing stage, and give rise to more effective and convenient tools for summarizing trial data.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id="refs" class="references csl-bib-body hanging-indent"&gt;
&lt;div id="ref-CDISC" class="csl-entry"&gt;
&lt;span&gt;“Clinical Data Interchange Standards Consortium.”&lt;/span&gt; 2020. &lt;a href="https://www.cdisc.org/"&gt;https://www.cdisc.org/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-ggconsort" class="csl-entry"&gt;
Higgins, Peter. 2020. &lt;em&gt;Ggconsort: Creates CONSORT Diagrams for RCTs&lt;/em&gt;. &lt;a href="https://github.com/higgi13425/ggconsort"&gt;https://github.com/higgi13425/ggconsort&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-Immport" class="csl-entry"&gt;
&lt;span&gt;“Immport: Bioinformatics for the Future of Immunology.”&lt;/span&gt; 2020. &lt;a href="https://www.immport.org/home"&gt;https://www.immport.org/home&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-forceps" class="csl-entry"&gt;
Kane, Michael J. 2020. &lt;em&gt;Forceps: A Grammar for Manipulating Clinical Trial Data&lt;/em&gt;. &lt;a href="https://github.com/kaneplusplus/forceps"&gt;https://github.com/kaneplusplus/forceps&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-PDS" class="csl-entry"&gt;
&lt;span&gt;“Project Data Sphere: Convener, Collaborator, Catalyst in the Fight Against Cancer.”&lt;/span&gt; 2020. &lt;a href="https://www.projectdatasphere.org/"&gt;https://www.projectdatasphere.org/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-R" class="csl-entry"&gt;
R Core Team. 2012. &lt;em&gt;R: A Language and Environment for Statistical Computing&lt;/em&gt;. Vienna, Austria: R Foundation for Statistical Computing. &lt;a href="http://www.R-project.org/"&gt;http://www.R-project.org/&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-sas" class="csl-entry"&gt;
SAS Institute. 2020. &lt;em&gt;Base SAS 9.4 Procedures Guide&lt;/em&gt;. SAS Institute.
&lt;/div&gt;
&lt;div id="ref-sasbdat" class="csl-entry"&gt;
Shotwell, Matt. 2014. &lt;em&gt;Sas7bdat: SAS Database Reader (Experimental)&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=sas7bdat"&gt;https://CRAN.R-project.org/package=sas7bdat&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-sas7bdat" class="csl-entry"&gt;
Shotwell, Matthew S, Clint Cummins, SAS7BDAT Header, SAS7BDAT Pages, SAS7BDAT Subheaders, and SAS7BDAT Packed Binary Data. 2013. &lt;span&gt;“Sas7bdat Database Binary Format.”&lt;/span&gt; Abgerufen am.
&lt;/div&gt;
&lt;div id="ref-lumberjack" class="csl-entry"&gt;
van der Loo, MPJ. 2020. &lt;span&gt;“Monitoring Data in r with the Lumberjack Package.”&lt;/span&gt; &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, Accepted for publication. &lt;a href="https://CRAN.R-project.org/package=lumberjack"&gt;https://CRAN.R-project.org/package=lumberjack&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-haven" class="csl-entry"&gt;
Wickham, Hadley, and Evan Miller. 2020. &lt;em&gt;Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files&lt;/em&gt;. &lt;a href="https://CRAN.R-project.org/package=haven"&gt;https://CRAN.R-project.org/package=haven&lt;/a&gt;.
&lt;/div&gt;
&lt;div id="ref-wickham2014" class="csl-entry"&gt;
Wickham, Hadley, and others. 2014. &lt;span&gt;“Tidy Data.”&lt;/span&gt; &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 59 (10): 1–23.
&lt;/div&gt;
&lt;/div&gt;</description>
      <distill:md5>f2caf2d6f79d93591b05c12660087549</distill:md5>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-052</guid>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>krippendorffsalpha: An R Package for Measuring Agreement Using Krippendorff's Alpha Coefficient</title>
      <dc:creator>John Hughes</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-046</link>
      <description>krippendorffsalpha: An R Package for Measuring Agreement Using Krippendorff's Alpha Coefficient</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-046</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Working with CRSP/COMPUSTAT in R: Reproducible Empirical Asset Pricing</title>
      <dc:creator>Majeed Simaan</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-047</link>
      <description>Working with CRSP/COMPUSTAT in R: Reproducible Empirical Asset Pricing</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-047</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Analyzing Dependence between Point Processes in Time Using IndTestPP</title>
      <dc:creator>Ana C. Cebrián</dc:creator>
      <dc:creator>Jesús Asín</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-049</link>
      <description>Analyzing Dependence between Point Processes in Time Using IndTestPP</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-049</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Conversations in Time: Interactive Visualization to Explore Structured Temporal Data</title>
      <dc:creator>Earo Wang</dc:creator>
      <dc:creator>Dianne Cook</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-050</link>
      <description>Conversations in Time: Interactive Visualization to Explore Structured Temporal Data</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-050</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>distr6: R6 Object-Oriented Probability Distributions Interface in R</title>
      <dc:creator>Raphael Sonabend</dc:creator>
      <dc:creator>Franz J. Király</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-055</link>
      <description>distr6: R6 Object-Oriented Probability Distributions Interface in R</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-055</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>gofCopula: Goodness-of-Fit Tests for Copulae</title>
      <dc:creator>Ostap Okhrin</dc:creator>
      <dc:creator>Simon Trimborn</dc:creator>
      <dc:creator>Martin Waltz</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-060</link>
      <description>gofCopula: Goodness-of-Fit Tests for Copulae</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-060</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>ROCnReg: An R Package for Receiver Operating Characteristic Curve Inference With and Without Covariates</title>
      <dc:creator>María Xosé Rodríguez-Álvarez</dc:creator>
      <dc:creator>Vanda Inácio</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-066</link>
      <description>ROCnReg: An R Package for Receiver Operating Characteristic Curve Inference With and Without Covariates</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-066</guid>
      <pubDate>Fri, 30 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>OneStep : Le Cam's One-step Estimation Procedure</title>
      <dc:creator>Alexandre Brouste</dc:creator>
      <dc:creator>Christophe Dutang</dc:creator>
      <dc:creator>Darel Noutsa Mieniedou</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-044</link>
      <description>OneStep : Le Cam's One-step Estimation Procedure</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-044</guid>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The HBV.IANIGLA Hydrological Model</title>
      <dc:creator>Ezequiel Toum</dc:creator>
      <dc:creator>Mariano H. Masiokas</dc:creator>
      <dc:creator>Ricardo Villalba</dc:creator>
      <dc:creator>Pierre Pitte</dc:creator>
      <dc:creator>Lucas Ruiz</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-059</link>
      <description>The HBV.IANIGLA Hydrological Model</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-059</guid>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The R Package smicd: Statistical Methods for Interval-Censored Data</title>
      <dc:creator>Paul Walter</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-045</link>
      <description>The R Package smicd: Statistical Methods for Interval-Censored Data</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-045</guid>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>RLumCarlo: Simulating Cold Light using Monte Carlo Methods</title>
      <dc:creator>Sebastian Kreutzer</dc:creator>
      <dc:creator>Johannes Friedrich</dc:creator>
      <dc:creator>Vasilis Pagonis</dc:creator>
      <dc:creator>Christian Laag</dc:creator>
      <dc:creator>Ena Rajovic</dc:creator>
      <dc:creator>Christoph Schmidt</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-043</link>
      <description>RLumCarlo: Simulating Cold Light using Monte Carlo Methods</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-043</guid>
      <pubDate>Mon, 06 Jul 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>pdynmc: A Package for Estimating Linear Dynamic Panel Data Models Based on Nonlinear Moment Conditions</title>
      <dc:creator>Markus Fritsch</dc:creator>
      <dc:creator>Andrew Adrian Yu Pua</dc:creator>
      <dc:creator>Joachim Schnurbus</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-035</link>
      <description>pdynmc: A Package for Estimating Linear Dynamic Panel Data Models Based on Nonlinear Moment Conditions</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-035</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>DChaos: An R Package for Chaotic Time Series Analysis</title>
      <dc:creator>Julio E. Sandubete</dc:creator>
      <dc:creator>Lorenzo Escot</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-036</link>
      <description>DChaos: An R Package for Chaotic Time Series Analysis</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-036</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>IndexNumber: An R Package for Measuring the Evolution of Magnitudes</title>
      <dc:creator>Alejandro Saavedra-Nieves</dc:creator>
      <dc:creator>Paula Saavedra-Nieves</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-038</link>
      <description>IndexNumber: An R Package for Measuring the Evolution of Magnitudes</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-038</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>ROBustness In Network (robin): an R Package for Comparison and Validation of Communities </title>
      <dc:creator>Valeria Policastro</dc:creator>
      <dc:creator>Dario Righelli</dc:creator>
      <dc:creator>Annamaria Carissimo</dc:creator>
      <dc:creator>Luisa Cutillo</dc:creator>
      <dc:creator>Italia De Feis</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-040</link>
      <description>ROBustness In Network (robin): an R Package for Comparison and Validation of Communities </description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-040</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Finding Optimal Normalizing Transformations via \pkg{bestNormalize}</title>
      <dc:creator>Ryan A. Peterson</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-041</link>
      <description>Finding Optimal Normalizing Transformations via \pkg{bestNormalize}</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-041</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      <media:content url="https://rjournal-distill.netlify.app/articles/RJ-2021-041/figs/orq_vis-1.png" medium="image" type="image/png" width="1344" height="960"/>
    </item>
    <item>
      <title>Package wsbackfit for Smooth Backfitting Estimation of Generalized Structured Models</title>
      <dc:creator>Javier Roca-Pardiñas</dc:creator>
      <dc:creator>María Xosé Rodríguez-Álvarez</dc:creator>
      <dc:creator>Stefan Sperlich</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-042</link>
      <description>Package wsbackfit for Smooth Backfitting Estimation of Generalized Structured Models</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-042</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>garchx: Flexible and Robust GARCH-X Modeling</title>
      <dc:creator>Genaro Sucarrat</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-057</link>
      <description>garchx: Flexible and Robust GARCH-X Modeling</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-057</guid>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Statistical Quality Control with the qcr Package</title>
      <dc:creator>Miguel Flores</dc:creator>
      <dc:creator>Rubén Fernández-Casal</dc:creator>
      <dc:creator>Salvador Naya</dc:creator>
      <dc:creator>Javier Tarrío-Saavedra</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-034</link>
      <description>Statistical Quality Control with the qcr Package</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-034</guid>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Linear Regression with Stationary Errors: the R Package slm</title>
      <dc:creator>Emmanuel Caron</dc:creator>
      <dc:creator>Jérôme Dedecker</dc:creator>
      <dc:creator>Bertrand Michel</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-030</link>
      <description>Linear Regression with Stationary Errors: the R Package slm</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-030</guid>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>clustcurv: An R Package for Determining Groups in Multiple Curves </title>
      <dc:creator>Nora M. Villanueva</dc:creator>
      <dc:creator>Marta Sestelo</dc:creator>
      <dc:creator>Luis Meira-Machado</dc:creator>
      <dc:creator>Javier Roca-Pardiñas</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-032</link>
      <description>clustcurv: An R Package for Determining Groups in Multiple Curves </description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-032</guid>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Benchmarking R packages for Calculation of Persistent Homology</title>
      <dc:creator>Eashwar V. Somasundaram</dc:creator>
      <dc:creator>Shael E. Brown</dc:creator>
      <dc:creator>Adam Litzler</dc:creator>
      <dc:creator>Jacob G. Scott</dc:creator>
      <dc:creator>Raoul R. Wadhwa</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-033</link>
      <description>Benchmarking R packages for Calculation of Persistent Homology</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-033</guid>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Wide-to-tall Data Reshaping Using Regular Expressions and the nc Package</title>
      <dc:creator>Toby Dylan Hocking</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-029</link>
      <description>Wide-to-tall Data Reshaping Using Regular Expressions and the nc Package</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-029</guid>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Unidimensional and Multidimensional Methods for Recurrence Quantification Analysis with crqa</title>
      <dc:creator>Moreno I. Coco</dc:creator>
      <dc:creator>Dan Mønster</dc:creator>
      <dc:creator>Giuseppe Leonardi</dc:creator>
      <dc:creator>Rick Dale</dc:creator>
      <dc:creator>Sebastian Wallot</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-062</link>
      <description>Unidimensional and Multidimensional Methods for Recurrence Quantification Analysis with crqa</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-062</guid>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The bdpar Package: Big Data Pipelining Architecture for R</title>
      <dc:creator>Miguel Ferreiro-Díaz</dc:creator>
      <dc:creator>Tomás R. Cotos-Yáñez</dc:creator>
      <dc:creator>José R. Méndez</dc:creator>
      <dc:creator>David Ruano-Ordás</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-065</link>
      <description>The bdpar Package: Big Data Pipelining Architecture for R</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-065</guid>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>JMcmprsk: An R Package for Joint Modelling of Longitudinal and Survival Data with Competing Risks</title>
      <dc:creator>Hong Wang</dc:creator>
      <dc:creator>Ning Li</dc:creator>
      <dc:creator>Shanpeng Li</dc:creator>
      <dc:creator>Gang Li</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-028</link>
      <description>JMcmprsk: An R Package for Joint Modelling of Longitudinal and Survival Data with Competing Risks</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-028</guid>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>exPrior: An R Package for the Formulation of Ex-Situ Priors</title>
      <dc:creator>Falk Heße</dc:creator>
      <dc:creator>Karina Cucchi</dc:creator>
      <dc:creator>Nura Kawa</dc:creator>
      <dc:creator>Yoram Rubin</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-031</link>
      <description>exPrior: An R Package for the Formulation of Ex-Situ Priors</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-031</guid>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>penPHcure: Variable Selection in Proportional Hazards Cure Model with Time-Varying Covariates</title>
      <dc:creator>Alessandro Beretta</dc:creator>
      <dc:creator>Cédric Heuchenne</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-061</link>
      <description>penPHcure: Variable Selection in Proportional Hazards Cure Model with Time-Varying Covariates</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-061</guid>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>A Method for Deriving Information from Running R Code</title>
      <dc:creator>Mark P.J. van der Loo</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-056</link>
      <description>A Method for Deriving Information from Running R Code</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-056</guid>
      <pubDate>Sun, 20 Oct 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>npcure: An R Package for Nonparametric Inference in Mixture Cure Models</title>
      <dc:creator>Ana López-Cheda</dc:creator>
      <dc:creator>M. Amalia Jácome</dc:creator>
      <dc:creator>Ignacio López-de-Ullibarri</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-027</link>
      <description>npcure: An R Package for Nonparametric Inference in Mixture Cure Models</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-027</guid>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>SEEDCCA: An Integrated R-Package for Canonical Correlation Analysis and Partial Least Squares</title>
      <dc:creator>Bo-Young Kim</dc:creator>
      <dc:creator>Yunju Im</dc:creator>
      <dc:creator>Jae Keun Yoo</dc:creator>
      <link>https://rjournal-distill.netlify.app/articles/RJ-2021-026</link>
      <description>SEEDCCA: An Integrated R-Package for Canonical Correlation Analysis and Partial Least Squares</description>
      <guid>https://rjournal-distill.netlify.app/articles/RJ-2021-026</guid>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
