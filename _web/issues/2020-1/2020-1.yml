issue: 2020-1
year: 2020
volume: 12
num: 1
month: June
bibmonth: jun
articles:
- slug: editorial
  cat: Editorial
  author: Michael J. Kane
  title: Editorial
  bibtitle: Editorial
  bibauthor: Michael J. Kane
  pages:
  - 4
  - 5
- heading: Contributed Research Articles
- slug: RJ-2020-010
  title: 'gk: An R Package for the g-and-k and Generalised g-and-h Distributions'
  bibtitle: |-
    gk: An R Package for the g-and-k and Generalised g-and-h
              Distributions
  author: Dennis Prangle
  bibauthor: Dennis Prangle
  abstract: '  Abstract The g-and-k and (generalised) g-and-h distributions are flexible
    univariate distributions            which can model highly skewed or heavy tailed
    data through only four parameters: location and            scale, and two shape
    parameters influencing the skewness and kurtosis. These distributions have            the
    unusual property that they are defined through their quantile function (inverse
    cumulative            distribution function) and their density is unavailable
    in closed form, which makes parameter inference            complicated. This paper
    presents the gk R package to work with these distributions. It provides the            usual
    distribution functions and several algorithms for inference of independent identically
    distributed            data, including the finite difference stochastic approximation
    method, which has not been used before            for this problem.'
  acknowledged: '2017-06-22'
  online: '2020-09-10'
  CRANpkgs:
  - gk
  - microbenchmark
  - abc
  - EasyABC
  - Ecdat
  CTV_rev:
  - Bayesian
  - Distributions
  - Econometrics
  - TimeSeries
  landing: '2020'
  pages:
  - 7
  - 20
- slug: RJ-2020-016
  title: 'NlinTS: An R Package For Causality Detection in Time Series'
  bibtitle: 'NlinTS: An R Package For Causality Detection in Time Series'
  author: Youssef Hmamouche
  bibauthor: Youssef Hmamouche
  abstract: '  Abstract The causality is an important concept that is widely studied
    in the literature, and has several            applications, especially when modelling
    dependencies within complex data, such as multivariate            time series.
    In this article, we present a theoretical description of methods from the NlinTS
    package,            and we focus on causality measures. The package contains the
    classical Granger causality test. To            handle non-linear time series,
    we propose an extension of this test using an artificial neural network.            The
    package includes an implementation of the Transfer entropy, which is also considered
    as a non           linear causality measure based on information theory. For discrete
    variables, we use the classical            Shannon Transfer entropy, while for
    continuous variables, we adopt the k-nearest neighbors approach            to
    estimate it.'
  acknowledged: '2018-02-02'
  online: '2020-09-10'
  CRANpkgs:
  - NlinTS
  - vars
  - lmtest
  - RTransferEntropy
  - timeSeries
  - Rcpp
  CTV_rev:
  - TimeSeries
  - Finance
  - Econometrics
  - HighPerformanceComputing
  - MissingData
  - NumericalMathematics
  - SocialSciences
  landing: '2020'
  pages:
  - 21
  - 31
- slug: RJ-2020-001
  title: 'Mapping Smoothed Spatial Effect Estimates from Individual-Level Data: MapGAM '
  bibtitle: |-
    Mapping Smoothed Spatial Effect Estimates from Individual-
              Level Data: MapGAM
  author:
  - Lu Bai
  - Daniel L. Gillen
  - Scott M. Bartell
  - Verónica M. Vieira
  bibauthor: |-
    Lu Bai and Daniel L. Gillen and Scott M. Bartell and
              Verónica M. Vieira
  abstract: '  Abstract We introduce and illustrate the utility of MapGAM, a user-friendly
    R package that provides            a unified framework for estimating, predicting
    and drawing inference on covariate-adjusted spatial            effects using individual-level
    data. The package also facilitates visualization of spatial effects via            automated
    mapping procedures. MapGAM estimates covariate-adjusted spatial associations with            a
    univariate or survival outcome using generalized additive models that include
    a non-parametric            bivariate smooth term of geolocation parameters. Estimation
    and mapping methods are implemented            for continuous, discrete, and right-censored
    survival data. In the current manuscript, we summarize            the methodology
    implemented in MapGAM and illustrate the package using two example simulated            datasets:
    the first considering a case-control study design from the state of Massachusetts
    and the            second considering right-censored survival data from California.'
  acknowledged: '2018-04-04'
  online: '2020-03-31'
  CRANpkgs: MapGAM
  suppl: 1.7 Kb
  landing: '2020'
  pages:
  - 32
  - 48
- slug: RJ-2020-002
  title: 'mudfold: An R Package for Nonparametric IRT Modelling of Unfolding Processes'
  bibtitle: |-
    mudfold: An R Package for Nonparametric IRT Modelling of
              Unfolding Processes
  author:
  - Spyros E. Balafas
  - Wim P. Krijnen
  - Wendy J. Post
  - Ernst C. Wit
  bibauthor: |-
    Spyros E. Balafas and Wim P. Krijnen and Wendy J. Post and
              Ernst C. Wit
  abstract: '  Abstract Item response theory (IRT) models for unfolding processes
    use the responses of individuals            to attitudinal tests or questionnaires
    in order to infer item and person parameters located on a latent            continuum.
    Parametric models in this class use parametric functions to model the response
    process,            which in practice can be restrictive. MUDFOLD (Multiple UniDimensional
    unFOLDing) can be used            to obtain estimates of person and item ranks
    without imposing strict parametric assumptions on the            item response
    functions (IRFs). This paper describes the implementation of the MUDFOLD method            for
    binary preferential-choice data in the R package mudfold. The latter incorporates
    estimation,            visualization, and simulation methods in order to provide
    R users with utilities for nonparametric            analysis of attitudinal questionnaire
    data. After a brief introduction in IRT, we provide the method           ological
    framework implemented in the package. A description of the available functions
    is followed            by practical examples and suggestions on how this method
    can be used even outside the field of            psychometrics.'
  acknowledged: '2018-12-11'
  online: '2020-03-31'
  CRANpkgs:
  - mudfold
  - GGUM
  - mirt
  - mokken
  - boot
  - mice
  - gtools
  - glmnet
  - mgcv
  - zoo
  - reshape2
  - ggplot2
  - smacof
  CTVs: Psychometrics
  CTV_rev:
  - Psychometrics
  - Econometrics
  - MissingData
  - SocialSciences
  - Environmetrics
  - Survival
  - TimeSeries
  - Bayesian
  - Finance
  - Graphics
  - MachineLearning
  - Multivariate
  - OfficialStatistics
  - Optimization
  - Phylogenetics
  - TeachingStatistics
  suppl: 2.4 Kb
  landing: '2020'
  pages:
  - 49
  - 75
- slug: RJ-2020-021
  title: 'tsmp: An R Package for Time Series with Matrix Profile'
  bibtitle: 'tsmp: An R Package for Time Series with Matrix Profile'
  author:
  - Francisco Bischoff
  - Pedro Pereira Rodrigues
  bibauthor: Francisco Bischoff and Pedro Pereira Rodrigues
  abstract: '  Abstract This article describes tsmp, an R package that implements
    the MP concept for TS. The tsmp            package is a toolkit that allows all-pairs
    similarity joins, motif, discords and chains discovery, semantic            segmentation,
    etc. Here we describe how the tsmp package may be used by showing some of the            use-cases
    from the original articles and evaluate the algorithm speed in the R environment.
    This            package can be downloaded at https://CRAN.R-project.org/package=tsmp.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs: tsmp
  landing: '2020'
  pages:
  - 76
  - 86
- slug: RJ-2020-020
  title: ' Individual-Level Modelling of Infectious Disease Data: EpiILM'
  bibtitle: |-
    Individual-Level Modelling of Infectious Disease Data:
              EpiILM
  author:
  - Vineetha Warriyar K. V.
  - Waleed Almutiry
  - Rob Deardon
  bibauthor: Vineetha Warriyar K. V. and Waleed Almutiry and Rob Deardon
  abstract: '  Abstract In this article we introduce the R package EpiILM, which provides
    tools for simulation from,            and inference for, discrete-time individual-level
    models of infectious disease transmission proposed by            Deardon et al.
    (2010). The inference is set in a Bayesian framework and is carried out via Metropolis           Hastings
    Markov chain Monte Carlo (MCMC). For its fast implementation, key functions are
    coded in            Fortran. Both spatial and contact network models are implemented
    in the package and can be set in            either susceptible-infected (SI) or
    susceptible-infected-removed (SIR) compartmental frameworks. Use            of
    the package is demonstrated through examples involving both simulated and real
    data.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - R0
  - EpiEstim
  - EpiModel
  - epinet
  - surveillance
  - EpiILM
  - igraph
  - ergm
  - adaptMCMC
  - coda
  CTV_rev:
  - gR
  - Bayesian
  - Environmetrics
  - Graphics
  - Optimization
  - SocialSciences
  - Spatial
  - SpatioTemporal
  - TimeSeries
  landing: '2020'
  pages:
  - 87
  - 104
- slug: RJ-2020-018
  title: 'SurvBoost: An R Package for High-Dimensional Variable Selection in the Stratified
    Proportional Hazards Model via Gradient Boosting'
  bibtitle: |-
    SurvBoost: An R Package for High-Dimensional Variable
              Selection in the Stratified Proportional Hazards Model via
              Gradient Boosting
  author:
  - Emily Morris
  - Kevin He
  - Yanming Li
  - Yi Li
  - Jian Kang
  bibauthor: |-
    Emily Morris and Kevin He and Yanming Li and Yi Li and Jian
              Kang
  abstract: '  Abstract High-dimensional variable selection in the proportional hazards
    (PH) model has many            successful applications in different areas. In
    practice, data may involve confounding variables that do            not satisfy
    the PH assumption, in which case the stratified proportional hazards (SPH) model
    can be            adopted to control the confounding effects by stratification
    without directly modeling the confounding            effects. However, there is
    a lack of computationally efficient statistical software for high-dimensional            variable
    selection in the SPH model. In this work an R package, SurvBoost, is developed
    to implement            the gradient boosting algorithm for fitting the SPH model
    with high-dimensional covariate variables.            Simulation studies demonstrate
    that in many scenarios SurvBoost can achieve better selection accuracy            and
    reduce computational time substantially compared to the existing R package that
    implements            boosting algorithms without stratification. The proposed
    R package is also illustrated by an analysis            of gene expression data
    with survival outcome in The Cancer Genome Atlas study. In addition, a            detailed
    hands-on tutorial for SurvBoost is provided.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - mboost
  - survival
  - Rcpp
  - RcppArmadillo
  - RcppParallel
  CTV_rev:
  - HighPerformanceComputing
  - NumericalMathematics
  - Survival
  - ClinicalTrials
  - Econometrics
  - MachineLearning
  - SocialSciences
  landing: '2020'
  pages:
  - 105
  - 117
- slug: RJ-2020-024
  title: 'CoxPhLb: An R Package for Analyzing Length Biased Data under Cox Model'
  bibtitle: |-
    CoxPhLb: An R Package for Analyzing Length Biased Data under
              Cox Model
  author:
  - Chi Hyun Lee
  - Heng Zhou
  - Jing Ning
  - Diane D. Liu
  - Yu Shen
  bibauthor: |-
    Chi Hyun Lee and Heng Zhou and Jing Ning and Diane D. Liu
              and Yu Shen
  abstract: '  Abstract Data subject to length-biased sampling are frequently encountered
    in various applications            including prevalent cohort studies and are
    considered as a special case of left-truncated data under            the stationarity
    assumption. Many semiparametric regression methods have been proposed for length           biased
    data to model the association between covariates and the survival outcome of interest.
    In            this paper, we present a brief review of the statistical methodologies
    established for the analysis of            length-biased data under the Cox model,
    which is the most commonly adopted semiparametric model,            and introduce
    an R package CoxPhLb that implements these methods. Specifically, the package            includes
    features such as fitting the Cox model to explore covariate effects on survival
    times and            checking the proportional hazards model assumptions and the
    stationarity assumption. We illustrate            usage of the package with a
    simulated data example and a real dataset, the Channing House data,            which
    are publicly available.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - CoxPhLb
  - survival
  - KMsurv
  - coxphw
  CTV_rev:
  - Survival
  - ClinicalTrials
  - Econometrics
  - SocialSciences
  landing: '2020'
  pages:
  - 118
  - 130
- slug: RJ-2020-006
  title: 'SortedEffects: Sorted Causal Effects in R'
  bibtitle: 'SortedEffects: Sorted Causal Effects in R'
  author:
  - Shuowen Chen
  - Victor Chernozhukov
  - Iván Fernández-Val
  - Ye Luo
  bibauthor: |-
    Shuowen Chen and Victor Chernozhukov and Iván Fernández-Val
              and Ye Luo
  abstract: '  Abstract Chernozhukov et al. (2018) proposed the sorted effect method
    for nonlinear regression            models. This method consists of reporting
    percentiles of the partial effects, the sorted effects, in            addition
    to the average effect commonly used to summarize the heterogeneity in the partial
    effects.            They also propose to use the sorted effects to carry out classification
    analysis where the observational            units are classified as most and least
    affected if their partial effect are above or below some tail sorted            effects.
    The R package SortedEffects implements the estimation and inference methods therein
    and            provides tools to visualize the results. This vignette serves as
    an introduction to the package and            displays basic functionality of
    the functions within.'
  acknowledged: []
  online: '2020-03-31'
  CRANpkgs:
  - SortedEffects
  - SortedEffect
  - quantreg
  - margins
  - parallel
  - boot
  CTV_rev:
  - Econometrics
  - Optimization
  - SocialSciences
  - Survival
  - Environmetrics
  - ReproducibleResearch
  - Robust
  - TimeSeries
  suppl: 1.6 Kb
  landing: '2020'
  pages:
  - 131
  - 146
- slug: RJ-2020-022
  title: 'npordtests: An R Package of Nonparametric Tests for Equality of Location
    Against Ordered Alternatives'
  bibtitle: |-
    npordtests: An R Package of Nonparametric Tests for Equality
              of Location Against Ordered Alternatives
  author:
  - Bulent Altunkaynak
  - Hamza Gamgam
  bibauthor: Bulent Altunkaynak and Hamza Gamgam
  abstract: '  Abstract Ordered alternatives are an important statistical problem
    in many situation such as increased            risk of congenital malformation
    caused by excessive alcohol consumption during pregnancy life test            experiments,
    drug-screening studies, dose-finding studies, the dose-response studies, age-related            response.
    There are numerous other examples of this nature. In this paper, we present the
    npordtests            package to test the equality of locations for ordered alternatives.
    The package includes the Jonckheere           Terpstra, Beier and Buning’s Adaptive,
    Modified Jonckheere-Terpstra, Terpstra-Magel, Ferdhiana           Terpstra-Magel,
    KTP, S and Gaur’s Gc tests. A simulation study is conducted to determine which
    test            is the most appropriate test for which scenario and to suggest
    it to the researchers.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - clinfun
  - jtGWAS
  - fastJT
  - kSamples
  - StatCharrms
  - PMCMRplus
  - npordtests
  CTV_rev:
  - ClinicalTrials
  - Environmetrics
  - Survival
  landing: '2020'
  pages:
  - 147
  - 171
- slug: RJ-2020-005
  title: 'lspartition: Partitioning-Based Least Squares Regression'
  bibtitle: 'lspartition: Partitioning-Based Least Squares Regression'
  author:
  - Matias D. Cattaneo
  - Max H. Farrell
  - Yingjie Feng
  bibauthor: Matias D. Cattaneo and Max H. Farrell and Yingjie Feng
  abstract: '  Abstract Nonparametric partitioning-based least squares regression
    is an important tool in empirical            work. Common examples include regressions
    based on splines, wavelets, and piecewise polynomials.            This article
    discusses the main methodological and numerical features of the R software package            lspartition,
    which implements results for partitioning-based least squares (series) regression
    estimation            and inference from Cattaneo and Farrell (2013) and Cattaneo,
    Farrell, and Feng (2020). These results            cover the multivariate regression
    function as well as its derivatives. First, the package provides            data-driven
    methods to choose the number of partition knots optimally, according to integrated
    mean            squared error, yielding optimal point estimation. Second, robust
    bias correction is implemented to            combine this point estimator with
    valid inference. Third, the package provides estimates and inference            for
    the unknown function both pointwise and uniformly in the conditioning variables.
    In particular,            valid confidence bands are provided. Finally, an extension
    to two-sample analysis is developed, which            can be used in treatment-control
    comparisons and related problems.'
  acknowledged: []
  online: '2020-03-31'
  CRANpkgs: ggplot2
  CTV_rev:
  - Graphics
  - Phylogenetics
  - TeachingStatistics
  suppl: 1.9 Kb
  landing: '2020'
  pages:
  - 172
  - 187
- slug: RJ-2020-019
  title: Skew-t Expected Information Matrix Evaluation and Use for Standard Error
    Calculations
  bibtitle: |-
    Skew-t Expected Information Matrix Evaluation and Use for
              Standard Error Calculations
  author:
  - R. Douglas Martin
  - Chindhanai Uthaisaad
  - Daniel Z. Xia
  bibauthor: R. Douglas Martin and Chindhanai Uthaisaad and Daniel Z. Xia
  abstract: '  Abstract Skew-t distributions derived from skew-normal distributions,
    as developed by Azzalini            and several co-workers, are popular because
    of their theoretical foundation and the availability of            computational
    methods in the R package sn. One difficulty with this skew-t family is that the
    elements            of the expected information matrix do not have closed form
    analytic formulas. Thus, we developed            a numerical integration method
    of computing the expected information matrix in the R package            skewtInfo.
    The accuracy of our expected information matrix calculation method was confirmed            by
    comparing the result with that obtained using an observed information matrix for
    a very large            sample size. A Monte Carlo study to evaluate the accuracy
    of the standard errors obtained with            our expected information matrix
    calculation method, for the case of three realistic skew-t parameter            vectors,
    indicates that use of the expected information matrix results in standard errors
    as accurate as,            and sometimes a little more accurate than, use of an
    observed information matrix.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs: sn
  CTV_rev:
  - Distributions
  - Multivariate
  suppl: 2.5 Kb
  landing: '2020'
  pages:
  - 188
  - 205
- slug: RJ-2020-012
  title: 'rcosmo: R Package for Analysis of Spherical, HEALPix and Cosmological Data'
  bibtitle: |-
    rcosmo: R Package for Analysis of Spherical, HEALPix and
              Cosmological Data
  author:
  - Daniel Fryer
  - Ming Li
  - Andriy Olenko
  bibauthor: Daniel Fryer and Ming Li and Andriy Olenko
  abstract: '  Abstract The analysis of spatial observations on a sphere is important
    in areas such as geosciences,            physics and embryo research, just to
    name a few. The purpose of the package rcosmo is to conduct            efficient
    information processing, visualisation, manipulation and spatial statistical analysis
    of Cosmic            Microwave Background (CMB) radiation and other spherical
    data. The package was developed for            spherical data stored in the Hierarchical
    Equal Area isoLatitude Pixelation (Healpix) representation.            rcosmo
    has more than 100 different functions. Most of them initially were developed for
    CMB, but            also can be used for other spherical data as rcosmo contains
    tools for transforming spherical data in            cartesian and geographic coordinates
    into the HEALPix representation. We give a general description            of the
    package and illustrate some important functionalities and benchmarks.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - sp
  - sphereplot
  - rgl
  - geosphere
  - SpherWave
  - SphericalCubature
  - RandomFields
  - geoR
  - Directional
  - gensphere
  - CircNNTSR
  - VecStatGraphs3D
  - sm
  - cosmoFns
  - CRAC
  - FITSio
  - spider
  - astro
  - rcosmo
  - microbenchmark
  CTVs: Spatial
  CTV_rev:
  - Spatial
  - ChemPhys
  - SpatioTemporal
  - Bayesian
  - Distributions
  - Graphics
  - Multivariate
  - NumericalMathematics
  - SocialSciences
  landing: '2020'
  pages:
  - 206
  - 225
- slug: RJ-2020-011
  title: Tools for Analyzing R Code the Tidy Way
  bibtitle: Tools for Analyzing R Code the Tidy Way
  author:
  - Lucy D’Agostino McGowan
  - Sean Kross
  - Jeffrey Leek
  bibauthor: Lucy D’Agostino McGowan and Sean Kross and Jeffrey Leek
  abstract: '  Abstract With the current emphasis on reproducibility and replicability,
    there is an increasing need            to examine how data analyses are conducted.
    In order to analyze the between researcher variability            in data analysis
    choices as well as the aspects within the data analysis pipeline that contribute
    to            the variability in results, we have created two R packages: matahari
    and tidycode. These packages            build on methods created for natural language
    processing; rather than allowing for the processing of            natural language,
    we focus on R code as the substrate of interest. The matahari package facilitates
    the            logging of everything that is typed in the R console or in an R
    script in a tidy data frame. The tidycode            package contains tools to
    allow for analyzing R calls in a tidy manner. We demonstrate the utility of            these
    packages as well as walk through two examples.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - matahari
  - tidycode
  - tidyverse
  - tidytext
  - dplyr
  - purrr
  - wordcloud
  - data.table
  - gh
  CTV_rev:
  - NaturalLanguageProcessing
  - Databases
  - Finance
  - HighPerformanceComputing
  - ModelDeployment
  - TimeSeries
  - WebTechnologies
  landing: '2020'
  pages:
  - 226
  - 242
- slug: RJ-2020-027
  title: 'spinifex: An R Package for Creating a Manual Tour of Low-dimensional Projections
    of Multivariate Data'
  bibtitle: |-
    spinifex: An R Package for Creating a Manual Tour of Low-
              dimensional Projections of Multivariate Data
  author:
  - Nicholas Spyrison
  - Dianne Cook
  bibauthor: Nicholas Spyrison and Dianne Cook
  abstract: '  Abstract Dynamic low-dimensional linear projections of multivariate
    data collectively known as tours            provide an important tool for exploring
    multivariate data and models. The R package tourr provides            functions
    for several types of tours: grand, guided, little, local and frozen. Each of these
    can be viewed            dynamically, or saved into a data object for animation.
    This paper describes a new package, spinifex,            which provides a manual
    tour of multivariate data where the projection coefficient of a single variable            is
    controlled. The variable is rotated fully into the projection, or completely out
    of the projection. The            resulting sequence of projections can be displayed
    as an animation, with functions from either the            plotly or gganimate
    packages. By varying the coefficient of a single variable, it is possible to explore            the
    sensitivity of structure in the projection to that variable. This is particularly
    useful when used            with a projection pursuit guided tour to simplify
    and understand the solution. The use of the manual            tour is applied
    particle physics data to illustrate the sensitivity of structure in a projection
    to specific            variable contributions.'
  acknowledged: '2019-07-18'
  online: '2020-09-13'
  CRANpkgs:
  - tourr
  - spinifex
  - plotly
  - gganimate
  - ggplot2
  - shiny
  - knitr
  - rmarkdown
  CTV_rev:
  - TeachingStatistics
  - ReproducibleResearch
  - WebTechnologies
  - Graphics
  - Phylogenetics
  landing: '2020'
  pages:
  - 243
  - 257
- slug: RJ-2020-023
  title: 'ari: The Automated R Instructor'
  bibtitle: 'ari: The Automated R Instructor'
  author:
  - Sean Kross
  - Jeffrey T. Leek
  - John Muschelli
  bibauthor: Sean Kross and Jeffrey T. Leek and John Muschelli
  abstract: '  Abstract We present the ari package for automatically generating technology-focused
    educational            videos. The goal of the package is to create reproducible
    videos, with the ability to change and            update video content seamlessly.
    We present several examples of generating videos including using R            Markdown
    slide decks, PowerPoint slides, or simple images as source material. We also discuss
    how            ari can help instructors reach new audiences through programmatically
    translating materials into            other languages.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - ari
  - text2speech
  - aws.polly
  - tuneR
  - ariExtra
  - animation
  - aws.signature
  - rmarkdown
  - xaringan
  - webshot
  - rgoogleslides
  - readOffice
  - officer
  - pdftools
  - docxtractr
  - mscstts
  - googleLanguageR
  CTV_rev:
  - ReproducibleResearch
  - WebTechnologies
  - Graphics
  - TeachingStatistics
  landing: '2020'
  pages:
  - 258
  - 265
- slug: RJ-2020-025
  title: 'CopulaCenR: Copula based Regression Models for Bivariate Censored Data in
    R'
  bibtitle: |-
    CopulaCenR: Copula based Regression Models for Bivariate
              Censored Data in R
  author:
  - Tao Sun
  - Ying Ding
  bibauthor: Tao Sun and Ying Ding
  abstract: '  Abstract Bivariate time-to-event data frequently arise in research
    areas such as clinical trials and            epidemiological studies, where the
    occurrence of two events are correlated. In many cases, the            exact event
    times are unknown due to censoring. The copula model is a popular approach for            modeling
    correlated bivariate censored data, in which the two marginal distributions and
    the between           margin dependence are modeled separately. This article presents
    the R package CopulaCenR, which            is designed for modeling and testing
    bivariate data under right or (general) interval censoring in            a regression
    setting. It provides a variety of Archimedean copula functions including a flexible            two-parameter
    copula and different types of regression models (parametric and semiparametric)            for
    marginal distributions. In particular, it implements a semiparametric transformation
    model for            the margins with proportional hazards and proportional odds
    models being its special cases. The            numerical optimization is based
    on a novel two-step algorithm. For the regression parameters, three            likelihood-based
    tests (Wald, generalized score and likelihood ratio tests) are also provided.
    We use            two real data examples to illustrate the key functions in CopulaCenR.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - CopulaCenR
  - survival
  - parfm
  - frailtypack
  - coxme
  - phmm
  - copula
  - VineCopula
  - CopulaRegression
  - gcmr
  - gamCopula
  - Copula.surv
  - Sunclarco
  - GJRM
  CTV_rev:
  - Survival
  - Distributions
  - ClinicalTrials
  - Econometrics
  - ExtremeValue
  - Finance
  - Multivariate
  - SocialSciences
  landing: '2020'
  pages:
  - 266
  - 282
- slug: RJ-2020-003
  title: 'mistr: A Computational Framework for Mixture and Composite Distributions'
  bibtitle: 'mistr: A Computational Framework for Mixture and Composite Distributions'
  author:
  - Lukas Sablica
  - Kurt Hornik
  bibauthor: Lukas Sablica and Kurt Hornik
  abstract: ' Abstract Finite mixtures and composite distributions allow to model
    the probabilistic representation           of data with more generality than simple
    distributions and are useful to consider in a wide range           of applications.
    The R package mistr provides an extensible computational framework for creating,           transforming,
    and evaluating these models, together with multiple methods for their visualization           and
    description. In this paper we present the main computational framework of the
    package and           illustrate its application. In addition, we provide and
    show functions for data modeling using two           specific composite distributions
    as well as a numerical example where a composite distribution is           estimated
    to describe the log-returns of selected stocks.'
  acknowledged: []
  online: '2019-12-27'
  CRANpkgs:
  - mistr
  - distr
  - CompLognormal
  - evmix
  - OpVar
  - ReIns
  - gendist
  - ggplot2
  - actuar
  - bbmle
  CTV_rev:
  - Distributions
  - ExtremeValue
  - Finance
  - Graphics
  - Phylogenetics
  - Robust
  - TeachingStatistics
  suppl: 1.9 Kb
  landing: '2020'
  pages:
  - 283
  - 299
- slug: RJ-2020-014
  title: 'difNLR: Generalized Logistic Regression Models for DIF and DDF Detection'
  bibtitle: |-
    difNLR: Generalized Logistic Regression Models for DIF and
              DDF Detection
  author:
  - Adéla Hladká
  - Patrícia Martinková
  bibauthor: Adéla Hladká and Patrícia Martinková
  abstract: '  Abstract Differential item functioning (DIF) and differential distractor
    functioning (DDF) are impor           tant topics in psychometrics, pointing to
    potential unfairness in items with respect to minorities or            different
    social groups. Various methods have been proposed to detect these issues. The
    difNLR            R package extends DIF methods currently provided in other packages
    by offering approaches based            on generalized logistic regression models
    that account for possible guessing or inattention, and by pro           viding
    methods to detect DIF and DDF among ordinal and nominal data. In the current paper,
    we            describe implementation of the main functions of the difNLR package,
    from data generation, through            the model fitting and hypothesis testing,
    to graphical representation of the results. Finally, we provide            a real
    data example to bring the concepts together.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - difR
  - DIFlasso
  - DIFboost
  - GDINA
  - mirt
  - lordif
  - psychotree
  - difNLR
  - ShinyItemAnalysis
  - ggplot2
  - stats
  - VGAM
  - nnet
  CTV_rev:
  - Psychometrics
  - Econometrics
  - SocialSciences
  - Distributions
  - Environmetrics
  - ExtremeValue
  - Graphics
  - MachineLearning
  - MissingData
  - Multivariate
  - Phylogenetics
  - Survival
  - TeachingStatistics
  landing: '2020'
  pages:
  - 300
  - 323
- slug: RJ-2020-026
  title: 'BayesMallows: An R Package for the Bayesian Mallows Model'
  bibtitle: 'BayesMallows: An R Package for the Bayesian Mallows Model'
  author:
  - Øystein Sørensen
  - Marta Crispino
  - Qinghua Liu
  - Valeria Vitelli
  bibauthor: |-
    Øystein Sørensen and Marta Crispino and Qinghua Liu and
              Valeria Vitelli
  abstract: '  Abstract BayesMallows is an R package for analyzing preference data
    in the form of rankings with            the Mallows rank model, and its finite
    mixture extension, in a Bayesian framework. The model is            grounded on
    the idea that the probability density of an observed ranking decreases exponentially
    with            the distance to the location parameter. It is the first Bayesian
    implementation that allows wide choices            of distances, and it works
    well with a large amount of items to be ranked. BayesMallows handles            non-standard
    data: partial rankings and pairwise comparisons, even in cases including non-transitive            preference
    patterns. The Bayesian paradigm allows coherent quantification of posterior uncertainties            of
    estimates of any quantity of interest. These posteriors are fully available to
    the user, and the package            comes with convienient tools for summarizing
    and visualizing the posterior distributions.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - BayesMallows
  - PerMallows
  - pmr
  - rankdist
  - microbenchmark
  - dplyr
  - parallel
  - tidyr
  - label.switching
  CTV_rev:
  - Databases
  - ModelDeployment
  landing: '2020'
  pages:
  - 324
  - 342
- slug: RJ-2020-013
  title: Variable Importance Plots—An Introduction to the vip Package
  bibtitle: Variable Importance Plots—An Introduction to the vip Package
  author:
  - Brandon M. Greenwell
  - Bradley C. Boehmke
  bibauthor: Brandon M. Greenwell and Bradley C. Boehmke
  abstract: '  Abstract In the era of “big data”, it is becoming more of a challenge
    to not only build state-of-the-art            by Brandon M. Greenwell, Bradley
    C. Boehmke            Introduction to the vip Package            Variable Importance
    Plots—An'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - iml
  - R6
  - foreach
  - ingredients
  - DALEX
  - mmpf
  - varImp
  - party
  - measures
  - vita
  - rfVarImpOOB
  - randomForestExplainer
  - tree.interpreter
  - pkgsearch
  - caret
  - mlr
  - ranger
  - vip
  - ggplot2
  - partykit
  - earth
  - nnet
  - vivo
  - pdp
  - microbenchmark
  - iBreakDown
  - fastshap
  - xgboost
  - ALEPlot
  - DT
  - mlr3
  - data.table
  - AmesHousing
  - SuperLearner
  - glmnet
  - kernlab
  - plyr
  - doParallel
  CTV_rev:
  - MachineLearning
  - HighPerformanceComputing
  - Multivariate
  - Survival
  - Environmetrics
  - TeachingStatistics
  - Cluster
  - Econometrics
  - Finance
  - Graphics
  - ModelDeployment
  - NaturalLanguageProcessing
  - Optimization
  - Phylogenetics
  - ReproducibleResearch
  - SocialSciences
  - TimeSeries
  landing: '2020'
  pages:
  - 343
  - 366
- slug: RJ-2020-017
  title: 'SimilaR: R Code Clone and Plagiarism Detection'
  bibtitle: 'SimilaR: R Code Clone and Plagiarism Detection'
  author:
  - Maciej Bartoszuk
  - Marek Gagolewski
  bibauthor: Maciej Bartoszuk and Marek Gagolewski
  abstract: '  Abstract Third-party software for assuring source code quality is becoming
    increasingly popular.            Tools that evaluate the coverage of unit tests,
    perform static code analysis, or inspect run-time            memory use are crucial
    in the software development life cycle. More sophisticated methods allow            for
    performing meta-analyses of large software repositories, e.g., to discover abstract
    topics they            relate to or common design patterns applied by their developers.
    They may be useful in gaining a            better understanding of the component
    interdependencies, avoiding cloned code as well as detecting            plagiarism
    in programming classes.                A meaningful measure of similarity of computer
    programs often forms the basis of such tools.            While there are a few
    noteworthy instruments for similarity assessment, none of them turns out            particularly
    suitable for analysing R code chunks. Existing solutions rely on rather simple
    techniques            and heuristics and fail to provide a user with the kind
    of sensitivity and specificity required for            working with R scripts.
    In order to fill this gap, we propose a new algorithm based on a Program            Dependence
    Graph, implemented in the SimilaR package. It can serve as a tool not only for
    improving            R code quality but also for detecting plagiarism, even when
    it has been masked by applying some            obfuscation techniques or imputing
    dead code. We demonstrate its accuracy and efficiency in a            real-world
    case study.'
  acknowledged: '2020-04-01'
  online: '2020-09-10'
  CRANpkgs:
  - magrittr
  - SimilaR
  - nortest
  - DescTools
  CTV_rev:
  - MissingData
  - WebTechnologies
  landing: '2020'
  pages:
  - 367
  - 385
- slug: RJ-2020-008
  title: Linear Fractional Stable Motion with the rlfsm R Package
  bibtitle: Linear Fractional Stable Motion with the rlfsm R Package
  author:
  - Stepan Mazur
  - Dmitry Otryakhin
  bibauthor: Stepan Mazur and Dmitry Otryakhin
  abstract: ' Abstract Linear fractional stable motion is a type of a stochastic integral
    driven by symmetric           alpha-stable Lévy motion. The integral could be
    considered as a non-Gaussian analogue of the           fractional Brownian motion.
    The present paper discusses R package rlfsm created for numerical           procedures
    with the linear fractional stable motion. It is a set of tools for simulation
    of these processes           as well as performing statistical inference and simulation
    studies on them. We introduce: tools that           we developed to work with
    that type of motions as well as methods and ideas underlying them.           Also
    we perform numerical experiments to show finite-sample behavior of certain estimators
    of the           integral, and give an idea of how to envelope workflow related
    to the linear fractional stable motion           in S4 classes and methods. Supplementary
    materials, including codes for numerical experiments, are           available
    online. rlfsm could be found on CRAN and gitlab.'
  acknowledged: '2020-04-05'
  online: '2020-09-10'
  CRANpkgs:
  - rlfsm
  - somebm
  - stabledist
  - stable
  - ggplot2
  CTV_rev:
  - Distributions
  - Graphics
  - Phylogenetics
  - TeachingStatistics
  landing: '2020'
  pages:
  - 386
  - 405
- slug: RJ-2020-015
  title: The R package NonProbEst for estimation in non-probability surveys
  bibtitle: |-
    The R package NonProbEst for estimation in non-probability
              surveys
  author:
  - M. Rueda
  - R. Ferri-García
  - L. Castro
  bibauthor: M. Rueda and R. Ferri-García and L. Castro
  abstract: '  Abstract Different inference procedures are proposed in the literature
    to correct selection bias that            might be introduced with non-random
    sampling mechanisms. The R package NonProbEst enables            the estimation
    of parameters using some of these techniques to correct selection bias in non-probability            surveys.
    The mean and the total of the target variable are estimated using Propensity Score
    Adjustment,            calibration, statistical matching, model-based, model-assisted
    and model-calibratated techniques.            Confidence intervals can also obtained
    for each method. Machine learning algorithms can be used            for estimating
    the propensities or for predicting the unknown values of the target variable for
    the            non-sampled units. Variance of a given estimator is performed by
    two different Leave-One-Out            jackknife procedures. The functionality
    of the package is illustrated with example data sets.'
  acknowledged: '2020-04-05'
  online: '2020-09-10'
  CRANpkgs:
  - NonProbEst
  - caret
  - sampling
  - survey
  CTV_rev:
  - OfficialStatistics
  - HighPerformanceComputing
  - MachineLearning
  - Multivariate
  - SocialSciences
  - Survival
  landing: '2020'
  pages:
  - 406
  - 418
- slug: RJ-2020-009
  title: 'ProjectManagement: an R Package for Managing Projects'
  bibtitle: 'ProjectManagement: an R Package for Managing Projects'
  author:
  - Juan Carlos Gonçalves-Dosantos
  - Ignacio García-Jurado
  - Julián Costa
  bibauthor: |-
    Juan Carlos Gonçalves-Dosantos1 and Ignacio García-Jurado
              and Julián Costa
  abstract: '  Abstract Project management is an important body of knowledge and practices
    that comprises the            planning, organisation and control of resources
    to achieve one or more pre-determined objectives. In            this paper, we
    introduce ProjectManagement, a new R package that provides the necessary tools
    to            manage projects in a broad sense, and illustrate its use by examples.'
  acknowledged: []
  online: '2020-09-10'
  CRANpkgs:
  - PlotPrjNetworks
  - plan
  - ProjectManagement
  - triangle
  - plotly
  - igraph
  - kappalab
  - GameTheory
  - lpSolveAPI
  CTV_rev:
  - Optimization
  - Distributions
  - gR
  - Graphics
  - Spatial
  - WebTechnologies
  landing: '2020'
  pages:
  - 419
  - 436
- slug: RJ-2020-007
  title: 'The Rockerverse: Packages and Applications for Containerisation with R'
  bibtitle: |-
    The Rockerverse: Packages and Applications for
              Containerisation with R
  author:
  - Daniel Nüst
  - Dirk Eddelbuettel
  - Dom Bennett
  - Robrecht Cannoodt
  - Dav Clark
  - Gergely Daróczi
  - '           Mark Edmondson'
  - Colin Fay
  - Ellis Hughes
  - Lars Kjeldgaard
  - Sean Lopp
  - Ben Marwick
  - Heather            Nolis
  - Jacqueline Nolis
  - Hong Ooi
  - Karthik Ram
  - Noam Ross
  - Lori Shepherd
  - Péter Sólymos
  - Tyson            Lee Swetnam
  - Nitesh Turaga
  - Charlotte Van Petegem
  - Jason Williams
  - Craig Willis
  - Nan Xiao
  bibauthor: |-
    Daniel Nüst and Dirk Eddelbuettel and Dom Bennett and
              Robrecht Cannoodt and Dav Clark and Gergely Daróczi and
              Mark Edmondson and Colin Fay and Ellis Hughes and Lars
              Kjeldgaard and Sean Lopp and Ben Marwick and Heather Nolis
              and Jacqueline Nolis and Hong Ooi and Karthik Ram and Noam
              Ross and Lori Shepherd and Péter Sólymos and Tyson Lee
              Swetnam and Nitesh Turaga and Charlotte Van Petegem and
              Jason Williams and Craig Willis and Nan Xiao
  abstract: '  Abstract The Rocker Project provides widely used Docker images for
    R across different application            scenarios. This article surveys downstream
    projects that build upon the Rocker Project images and            presents the
    current state of R packages for managing Docker images and controlling containers.
    These            use cases cover diverse topics such as package development, reproducible
    research, collaborative work,            cloud-based data processing, and production
    deployment of services. The variety of applications            demonstrates the
    power of the Rocker Project specifically and containerisation in general. Across
    the            diverse ways to use containers, we identified common themes: reproducible
    environments, scalability            and efficiency, and portability across clouds.
    We conclude that the current growth and diversification            of use cases
    is likely to continue its positive impact, but see the need for consolidating
    the Rockerverse            ecosystem of packages, developing common practices
    for applications, and exploring alternative            containerisation software.'
  acknowledged: '2020-04-30'
  online: '2020-09-10'
  CRANpkgs:
  - sys
  - stevedore
  - AzureContainers
  - googleCloudRunner
  - babelwhale
  - BiocManager
  - reticulate
  - Shiny
  - dockerfiler
  - dockr
  - liftr
  - checkpoint
  - renv
  - sf
  - rgdal
  - sanitizers
  - RSelenium
  - batchtools
  - googleComputeEngineR
  - future
  - plumber
  - drake
  - golem
  - analogsea
  - Rserve
  - svSocket
  - keras
  - DBI
  - dbplyr
  - dplyr
  - testthat
  - tinytest
  - ttdo
  - diffobj
  CTV_rev:
  - ModelDeployment
  - WebTechnologies
  - HighPerformanceComputing
  - ReproducibleResearch
  - Databases
  - NumericalMathematics
  - Spatial
  - SpatioTemporal
  landing: '2020'
  pages:
  - 437
  - 461
- heading: Special Articles
- slug: RJ-2020-028
  title: S, R, and Data Science
  bibtitle: S, R, and Data Science
  author: John M. Chambers
  bibauthor: John M. Chambers
  abstract: '  Data science is increasingly important and challenging. It requires
    computational tools and programming environments that handle big data and difficult
    computations, while supporting creative, high-quality analysis. The R language
    and related software play a major role in computing for data science. R is featured
    in most programs for training in the field. R packages provide tools for a wide
    range of purposes and users. The description of a new technique, particularly
    from research in statistics, is frequently accompanied by an R package, greatly
    increasing the usefulness of the description. The history of R makes clear its
    connection to data science. R was consciously designed to replicate in open-source
    software the contents of the S software. S in turn was written by data analysis
    researchers at Bell Labs as part of the computing environment for research in
    data analysis and collaborations to apply that research, rather than as a separate
    project to create a programming language. The features of S and the design decisions
    made for it need to be understood in this broader context of supporting effective
    data analysis (which would now be called data science). These characteristics
    were all transferred to R and remain central to its effectiveness. Thus, R can
    be viewed as based historically on a domain-specific language for the domain of
    data science. Note to R Journal readers: The following paper was published online
    in the History of Programming Languages (HOPL), Volume 4, in June 2020 (DOI 10.1145/3386334).
    The content seems likely to be of interest to many R Journal readers, and since
    HOPL is plausibly not typical reading for data scientists, the editors of the
    R Journal have kindly offered to republish the paper here. This is possible thanks
    also to the enlightened policy of the ACM, providing for open distribution through
    the chosen copyright declaration.'
  landing: '2020'
  pages:
  - 462
  - 476
- slug: RJ-2020-029
  title: Provenance of R’s Gradient Optimizers
  bibtitle: Provenance of R’s Gradient Optimizers
  author: John C. Nash
  bibauthor: John C. Nash
  abstract: '  Gradient optimization methods (function minimizers) are well-represented
    in both the base and package universe of R (R Core Team, 2019). However, some
    of the methods and the codes developed from them were published before standards
    for hardware and software were established, in particular the IEEE arithmetic
    (IEEE, 1985). There have been cases of unexpected behaviour or outright errors,
    and these are the focus of the histoRicalg project. A summary history of some
    of the tools in R for gradient optimization methods is presented to give perspective
    on such methods and the occasions where they could be used effectively.'
  landing: '2020'
  pages:
  - 477
  - 483
- heading: News and Notes
- slug: whyR
  author:
  - Michał Burdukiewicz
  - Filip Pietluch
  - Jarosław Chilimoniuk
  - Katarzyna Sidorczuk
  - Dominik Rafacz
  - Leon Eyrich Jessen
  - Stefan Rödiger
  - Marcin Kosin ́ski
  - Piotr Wójcik
  title: 'Conference Report: Why R? 2019'
  bibauthor: Michał Burdukiewicz, Filip Pietluch, Jarosław Chilimoniuk, Katarzyna
    Sidorczuk, Dominik Rafacz, Leon Eyrich Jessen, Stefan Rödiger, Marcin Kosin ́ski,
    PiotrWójcik
  pages:
  - 484
  - 494
- slug: cran
  author:
  - Kurt Hornik
  - Uwe Ligges
  - Achim Zeileis
  title: Changes on CRAN
  bibtitle: Changes on CRAN
  bibauthor: Kurt Hornik, Uwe Ligges and Achim Zeileis
  pages:
  - 485
  - 497
- slug: foundation
  author: Torsten Hothorn
  title: R Foundation News
  bibtitle: R Foundation News
  bibauthor: Torsten Hothorn
  pages: 498
