C ONTRIBUTED RESEARCH ARTICLE

1

mixedsde: A Package to Fit Mixed
Stochastic Differential Equations
by Charlotte Dion, Simone Hermann, Adeline Samson
Abstract Stochastic differential equations (SDEs) are useful to model continuous stochastic processes.
When (independent) repeated temporal data are available, variability between the trajectories can be
modeled by introducing random effects in the drift of the SDEs. These models are useful to analyze
neuronal data, crack length data, pharmacokinetics, financial data, to cite some applications among
other. The R package focuses on the estimation of SDEs with linear random effects in the drift. The goal
is to estimate the common density of the random effects from repeated discrete observations of the
SDE. The package mixedsde proposes three estimation methods: a Bayesian parametric, a frequentist
parametric and a frequentist nonparametric method. The three procedures are described as well as the
main functions of the package. Illustrations are presented on simulated and real data.

Introduction
Continuous stochastic processes are usually observed discretely in time (with equidistant time points
or not) leading to times series, although their intrinsic nature is of continuous time. While discrete
time stochastic models such as auto-regressive models (ARMA, GARCH, ...) have been widely
developed for time series with equidistant times, more and more attention have been focused on
Stochastic Differential Equations (SDEs). Examples of applications where SDEs have been used include
dynamics of thermal systems (Bacher and Madsen, 2011), solar and wind power forecasting (Iversen
et al., 2014), neuronal dynamics (Ditlevsen and Samson, 2014), pharmacokinetic/pharmacodynamic
(PK/PD) (Hansen et al., 2014), crack growth (Hermann et al., 2016). Estimation for SDE is available in
different softwares. We can cite among others the computer software CTSM with a (extended) Kalman
filter approach (Kristensen and Madsen, 2003), the sde package which proposes several tools for the
simulation and the estimation of a variety of SDEs, and more recently the R-packages Sim.DiffProc
(Guidoum and Boukhetala, 2017) and yuima (Iacus, 2018) (the last one proposes also some tools for
quantitative finance).
Depending on the applications, independent repeated temporal measures might be available.
For examples, drug concentration of several subjects is usually observed in PK; dynamics of several
neurons is measured along time; time to crack lengths can be measured repeatedly in crack growth
study. Each trajectory represents the behavior of a unit/subject. The functional form is similar for all
the trajectories. Fitting the overall data simultaneously obviously improves the quality of estimation,
but one has to take into account these variabilities between experiments. This is the typical framework
of mixed-effects models where some parameters are considered as random variables (random effects)
and proper to each trajectory. Hence the random effects represent the particularity of each subject.
Some parameters can also be considered as common to all the trajectories (fixed effects).
In this work the model of interest is thus a mixed-effects stochastic differential equation (MSDE),
mixed-effects for both fixed and random effects. The mixedsde package has been developed to
estimate the density of the random effects from the discrete observations of M independent trajectories
of a MSDE. It is available from the Comprehensive R Archive Network (CRAN Dion et al., 2016). The
package’s development is actively continued with the latest source code available from a GitHub
repository https://github.com/charlottedion/mixedsde.
More precisely, we focus on MSDE with linear drift. We consider M diffusion processes ( X j (t), t ≥
0), j = 1, . . . , M with dynamics ruled by SDE, for t ∈ [0, T ]
(
dX j (t) = (α j − β j X j (t))dt + σa( X j (t))dWj (t)
(1)
X j (0) = x j
where (Wj )1...j...M are M independent Wiener processes, (α j , β j ) are two (random) parameters, σa( X j (·))
is the diffusion coefficient with a a known function and σ an unknown constant. The initial condition
x j is assumed fixed (and known) in the paper with possibly different values for each trajectory.
In the package, we restrict the models to the two famous SDEs with linear drift, namely the
Ornstein-Uhlenbeck
model (OU) with a( x ) = 1 and the Cox-Ingersoll-Ross model (CIR) with a( x ) =
√
x. For the CIR model, we assume that x j > 0, σ > 0, α j > σ2 /2 and β j > 0 to ensure that the process
never crosses zero.
The random parameters are denoted φj and belong to Rd with either d = 1 or d = 2:

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

2

• (d = 1) φj = α j random and for all j = 1, . . . , M, β j = β fixed,
• (d = 1) φj = β j random and for all j = 1, . . . , M, α j = α fixed,
• (d = 2) φj = (α j , β j ) random.
The φj ’s are assumed independent and identically distributed (i.i.d.) and independent of the Wj ’s.
The mixedsde package aims at estimating the random effects φj and their distribution whose density
is denoted f , from N discrete observations of the M trajectories ( X j (t)) j from Equation 1 at discrete
times t0 = 0 < t1 < . . . < t N = T (not necessarily equidistant).
Context: To the best of our knowledge, this is the first package in R language dedicated to the
estimation of MSDE. The main software considering mixed models is MONOLIX (2003) but methods
for mixed stochastic differential equations are not implemented for R. One package named PSM
(Mortensen and Klim, 2013) provides functions for estimation of linear and non-linear mixed-effects
models using stochastic differential equations. But the model includes measurement noise and
proposes only parameter estimation. Moreover, there is no mathematical property about the used
estimators. In this context, the package presented is this paper is pioneer.
Estimation procedures for MSDE have been proposed in the non-parametric and the parametric
frameworks, with a frequentist and a Bayesian point of view. The parametric approaches assume
Gaussian random effects φj . Among other references, for parametric maximum likelihood estimation,
we can cite Ditlevsen and de Gaetano (2005); Picchini et al. (2010) (Hermite expansion of the likelihood);
Delattre et al. (2013) (explicit integration of the Girsanov likelihood) or Delattre et al. (2016) (mixture of
Gaussian distributions for the random effects); for parametric Bayesian estimation, we can cite Oravecz
et al. (2009) (restricted to Ornstein-Uhlenbeck) and Hermann et al. (2016) (general methodology); for
non-parametric estimation, we can cite Comte et al. (2013); Dion (2014); Dion and Genon-Catalot (2015)
(kernel estimator and deconvolution estimators).
Three estimation procedures are implemented in the mixedsde package: a kernel nonparametric
estimator (Dion and Genon-Catalot, 2015), a parametric maximum likelihood estimator (Delattre et al.,
2013) and a parametric Bayesian estimator (Hermann et al., 2016). The parametric frequentist and
Bayesian approaches assume the random effects Gaussian. The Bayesian approach seems the most
appropriate method for a small time of observation T and a small number of trajectories M. The
nonparametric approach can be used when no prior idea on the density is available and when T
and M are both large enough. Finally, the parametric frequentist estimation can be used with a large
number of discrete observations.
This paper reviews in Section 2.2 the three estimation methods. An overview of the mixedsde
package is given in Section 2.3 through a description of the main functions and of other related
companion functions. The practical use of this package is illustrated in Section 2.4 on simulated data
and in Section 2.5 on one real dataset in neuronal modeling.

Density estimation in mixed stochastic differential models
We briefly recall the methodology of the three estimators implemented in the mixedsde package. We
start with the nonparametric approach, then the frequentist parametric Gaussian method and finally
the Bayesian parametric Gaussian method.

Nonparametric estimation of the random effects density
The first step of the nonparametric approach is to estimate the random effects. The idea is to maximize
ϕ
the likelihood of the process X j solution of the stochastic differential equation with fixed ϕ. Assuming
continuous observations of ( X j (t), 0 ≤ t ≤ T ), the likelihood function is obtained with the Girsanov
formula:
ϕ
2 !
Z T α − βX ϕ (s)
Z
1 T (α − βX j (s))
j
`T ( ϕ) = exp
dX j (s) −
ds .
ϕ
2 0 σ2 a2 ( X ϕ (s))
0 σ2 a2 ( X ( s ))
j
j
Maximizing the likelihood yields to the following estimator of φj
A j := Vj−1 Uj

The R Journal Vol. 11/01, June 2019

(2)

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

3

where Uj and Vj are the two sufficient statistics of the model. They are explicit depending on the form
of the random effects:
• α j random and β known
Uj :=

Z T
0

1
σ 2 a2 ( X

j ( s ))

dX j (s) + β

Z T
0

X j (s)
ds,
σ2 a2 ( X j (s))

Vj :=

Z T
0

1
ds,
σ2 a2 ( X j (s))

• β j random and α known
Uj := −

Z T

X j (s)

0

σ2 a2 ( X j (s))

dX j (s) + α

Z T

X j (s)

0

σ2 a2 ( X j (s))

ds,

Vj :=

Z T

X j ( s )2

0

σ2 a2 ( X j (s))

ds,

• (α j , β j ) random, denote b( x ) = (1, − x )t with ut the transposition of vector u. Here Uj is a
column vector with size 2 × 1 and Vj = (Vj,k,` )k,`∈{1,2} a 2 × 2 symmetric matrix:
T b bt
b
( X j (s))dX j (s), Vj :=
( X j (s))ds.
(3)
2
2
0 σ a
0 σ 2 a2
Truncated versions of this estimator have been introduced for theoretical reasons. In the bidimensional
case φj = (α j , β j ), Dion and Genon-Catalot (2015) propose the following estimator

Uj :=

Z T

Z

√
√
c
A j := A j 1 Bj , Bj := {Vj ≥ κ TI2 } = {min(λ1,j , λ2,j ) ≥ κ T }

(4)

with I2 the 2 × 2 identity matrix and λi,j , i = 1, 2 the two eigenvalues of the symmetric non negative
matrix Vj , and κ a numerical constant that has been calibrated (Dion and Genon-Catalot, 2015). In the
one-dimensional case φj = β j with α = 0, Genon-Catalot and Larédo (2016) propose
c
A j : = A j 1V ≥κ √ T

(5)

j

with κ a numerical constant calibrated in practice. Based on these estimators of the φj ’s, we can
proceed to the second step, the estimation of their density f . Several nonparametric estimators of f
have been proposed (see Comte et al., 2013, for example). In the package mixedsde, we focus on the
kernel estimator of f . Let us introduce the kernel function K : Rd → R, with d = 1, 2 depending on
the dimension of φj . We assume K to be a C 2 function satisfying
Z

K (u)du = 1, kK k2 =

Z

K2 (u)du < +∞,

Z

(∇K (u))2 du < +∞

(with ∇K the gradient of K). A bandwidth h ∈ (R+ )d , for d = 1, 2, is used to define the function
Kh ( x ) =

1 x
K
, x ∈ Rd .
h
h

Note that in the bidimensional case, h = (h1 , h2 ) and the two marginal bandwidths are different. The
nonparametric estimator of the density f of φj is
1 M
fbh ( x ) =
K h ( x − A j ).
M j∑
=1

(6)

1 M
b
bj ) is computed when the truncated estimator Â j is different
and the estimator fbh ( x ) =
Kh ( x − A
M j∑
=1
than A j .
In the mixedsde package, Gaussian kernel estimators are implemented with the R -functions
density (available in package stats) when d = 1 and kde2d (available in package MASS Venables and
Ripley (2016)) when d = 2 with an automatic selection of the bandwidth h. Note that when there is
only one random effect, the bandwidth is selected by unbiased cross-validation with the argument
bw="ucv", or as the default value given by the rule-of-thumb if the chosen bandwidth is too small.
Note that the estimator is unstable for small variance of the random effects.
It is important to notice that the two random effects are not assumed independent. When there is
only one random effect, the fixed parameter has to be entered by the user.
The computation of A j = Vj−1 Uj does not require the knowledge of σ2 as it appears both in
Uj and Vj . It requires however the evaluation of the two continuous integrals in Uj and Vj while
observing the trajectories ( X j ) at discrete times (t0 , t1 , . . . , t N ). For ∆k = tk+1 − tk , k = 0, . . . , N − 1,

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

4

the non-stochastic integrals

RT
0

g( X j (s))ds for the functions g =
Z T
0

N −1

g( X j (s))ds ≈

∑

b
a2

or g =

b bt
a2

are approximated by

g( X j (tk ))∆k .

k =0

For the stochastic integrals, we use the following simple discretization
Z T
0

N −1

g( X j (s))dX j (s) ≈

∑

g( X j (tk ))( X j (tk+1 ) − ( X j (tk )))∆k .

k =0

Note that there is no integrability issue for these two types of integrals considering the two functions
t
g = ab2 or g = bab2 involved in the sufficient statistics.

Frequentist parametric estimation approach
In this section and the following one, we assume that the random parameters φj are Gaussian:
• when d = 1, φj ∼ N (µ, ω 2 ) with µ ∈ R,
• when d = 2, φj ∼ N (µ, Ω) with µ ∈ R2 and a diagonal covariance matrix Ω = diag(ω12 , ω22 ).
For the bidimensional case d = 2 we estimate by maximum likelihood the parameters θ := (µ, Ω).
We define the likelihood function assuming first that the trajectories are continuously observed,
similarly to the nonparametric approach (Section 2.2.1). Thanks to the Girsanov formula, the likelihood
function of the jth trajectory X j is
L( X j , θ ) = q





1
1 0 −1
1
−1
exp − (µ − Vj−1 Uj )0 R−
U
V
U
(
µ
−
V
U
)
exp
j
j
j
j
2
2 j j
det( I2 + ΩVj )
1

1
−1
with R−
j = ( I2 + Vj Ω ) Vj and I2 is the 2 × 2 identity matrix.

For the case d = 1, the parameters to estimate are θ := (µ, ω, ψ) where ψ denotes the fixed effect α
or β. We adopt the subscript r for the value of random, equal to 1 or 2, and c for the position of the
common fixed effect (thus 2 or 1). The likelihood function of the jth trajectory X j is
L( X j , θ )

=

1
q



1
−1
exp − Vj,r,r (1 + ω 2 Vj,r,r )−1 (µ − Vj,r,r
(Uj,r − ψVj,c,r ))2
2



1 + ω 2 Vj,r,r




ψ2
1
−1
× exp ψUj,c −
Vj,c,c exp
(Uj,r − ψVj,r,c )2 Vj,r,r
2
2

with the notations U, V from Equation 3. Details on this formula are available in the Appendix 2.6.
The likelihood function is defined as L(θ ) = ∏ jM
=1 L ( X j , θ ). The maximum likelihood estimator
b ψ
b ) when d = 2 is defined by
b) when d = 1 and θb := (µ
b, Ω,
b, Ω
θb := (µ
M

θb = arg max L(θ ) = arg max ∏ L( X j , θ ).
θ

θ

(7)

j =1

This estimator is not explicit. In the mixedsde package, the function optim is used to maximize
numerically the likelihood. The maximum is generally not unique and depend on the initialization.
A good initialization is another estimator, for example the moment estimator of θ. Function optim is
thus initialized with the mean and the variance of the estimators A j of the random parameters (see
Equation 2). Sufficient statistics Uj and Vj are discretized as explained in Section 2.2.1.
Note that this parametric approach requires the knowledge of σ2 to compute the sufficient statistics
Uj and Vj because Vj appears alone in R j . We plug the following estimator of σ2
M
c2 = 1
σ
∑
M j =1

2
1 N −1 ( X j (tk+1 ) − X j (tk ))
N k∑
∆k a2 ( X j (tk ))
=0

!
.

(8)

Selection of (non-nested) models can be performed with the BIC criteria, defined by −2 log L(θb) +
2 log( M) for model with one random effect and −2 log L(θb) + 4 log( M) with two random effects
and the AIC criteria defined by −2 log L(θb) + 2 for one random effect and −2 log L(θb) + 4 for two

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

5

random effects. These asymptotic criteria indicate the trade-off between maximizing fit and minimizing model complexity. Note that their theoretical properties are guaranteed only when σ2 is known.
Theoretical results are obtained on these estimators in the continuous observations context under
the asymptotic regime T → ∞, N → ∞, see (Dion and Genon-Catalot, 2015; Delattre et al., 2013). For
discrete observations, similar results are obtained in the high frequency context: T = n∆, n → ∞
(∆ → 0). Nevertheless, in practice the points may not be equidistant and the package allows a nonregular grid. The influence of T is lighter in the parametric strategy. Moreover, asymptotic normality
is obtained under the additional assumption n/N → ∞.

Bayesian parametric approach
For the Bayesian approach we assume similarly to the frequentist parametric estimation method a
Gaussian distribution for φj , with a diagonal covariance matrix Ω = diag(ω12 , ω22 ). In this method, we
estimate in the same time the diffusion coefficient σ. The parameters of interest are thus θ = (µ, Ω, σ)
and we want to estimate their posterior distribution p(θ |( X j (tk )) j=1,...,M,k=1,...,N ). Let denote X1:M =
( X j (tk )) j=1,...,M,k=1,...,N in the following.
We now introduce prior distributions implemented in mixedsde package for the parameters θ:
µ ∼ N (m, V ), V = diag(v)
ωi2 ∼ IG(αω,i , β ω,i ), i = 1, 2
σ2 ∼ IG(ασ , β σ ),
where IG is the Inverse Gamma distribution which is conjugate to the normal likelihood and m, V, αω,i ,
β ω,i , ασ , β σ are hyperparameters fixed by the user. The case of only one random effect is nested by
setting ω12 or ω22 equal to zero.
The aim is to calculate the posterior distribution p(θ |X1:M ) which is not explicit for the whole
vector of parameters. Therefore, we simulate it through a Gibbs sampler (see e.g., Robert and Casella,
2004). Here, we have a true transition density of both processes that is used for the likelihood, see
Iacus (2008). For a general hierarchical diffusion approach based on the Euler approximation, see
Hermann et al. (2016).
Analogically to the frequentist approach, there is a first step: sample from the full conditional
posterior of the random effects p(φj |( X j (tk ))k=1,...,N , θ ), j = 1, . . . , M. This is done by a Metropolis
Hastings (MH) algorithm.
The second step is the estimation of the hierarchical parameters µ and Ω. Full conditional posteriors
p(µ|φ1 , . . . , φ M , Ω) (resp. p(Ω|φ1 , . . . , φ M , µ)) are Gaussian (resp. inverse Gamma) and can, for
example, be found in Hermann et al. (2016).
The last step of the Gibbs sampler is sampling from the full conditional posterior of σ2 . For the
CIR model, this is also conducted by a MH step. For the OU model, the inverse Gamma distribution is
conjugate to the normal likelihood. The full conditional posterior distribution is given by
σ2 |X1:M , φ1 , ..., φ M ∼

βj
MN
1 M N
, βσ + ∑ ∑
IG ασ +
2
2 j=1 k=1 1 − e−2β j ∆k

X j (tk ) −

αj
βj

−

X j ( t k −1 ) −

αj
βj

!

!2 
e − β j ∆k  .

In the case of one random effect, there is one additional Gibbs sampler step for the fixed effect,
that is also conducted through a MH algorithm.
In the package, the starting values for the Gibbs sampler are set equal to the mean of the prior
distributions. In all the MH algorithms, one each has to choose a proposal density. In the package
mixedsde, we use a normal density for all location parameters with mean equal to the last chain
iteration and a proposal variance
q that has to be chosen. For the CIR model, the proposal distribution
√
2
2 , variance) where σ2
for σ2 is chosen by σ2 ∼ N ( σprev
prev is the previous value of σ . The remaining
question is how to choose the suitable proposal variance. This variance controls the chain dependence
and the acceptance rate. If the variance is small, the acceptance rate is large and the chains gets very
dependent. If the proposal variance is large, only few candidates are accepted with the advantage of
weakly dependent chains. This problem is solved in the package with an adaptive Metropolis-within
Gibbs algorithm (Rosenthal, 2011) using the proposal distribution N (0, e2l ) with l the logarithm
of the standard deviation of the increment. This parameter is chosen so that the acceptance rate is
approximately 0.44 which is proposed to be optimal in the Metropolis-within Gibbs sampler (Rosenthal,

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

6

2011). It is proposed to add/subtract an adoption amount δ(n) = min(0.1, n−1/2 ) to/from t after
every 50th iteration and adapt the proposal variance if the acceptance rate is smaller than 0.3 or larger
than 0.6.

Predictions
In many cases, one is not only interested in parameter estimation but also in the prediction for future
observations. The first step is the prediction of a future random effect φpred . The simulation of a
b ). For
b, Ω
new random effect is direct for the frequentist parametric approach sampling from N (µ
the nonparametric approach, first note that fbh is an estimator given on a discrete grid { x1 , . . . , xn },
i.e. a vector of corresponding { p1 , . . . , pn } after normalisation. Simulating from the estimator fbh
can therefore be performed simulating a discrete variable from vector { x1 , . . . , xn } with (normalized)
probabilities { p1 , . . . , pn }. For the Bayesian approach, a new φpred is sampled from the predictive
R
distribution p(φpred |X1:M ) = p(φpred |µ, Ω) p(µ, Ω|X1:M ) d(µ, Ω) where the posterior of µ and Ω is
approximated by the results of the Gibbs sampler. This distribution is not explicit, and hence we
suggest to sample over a grid through inversion method, equal to the nonparametric case.
Given a new random effect φpred , we are able to simulate predictive trajectories. This is performed
using the transition density p( X (tk )| X (tk−1 ), φpred , σ2 ) for the frequentist approach. The starting
points of the process x j are the observed ones. For the Bayesian approach, we implement two
prediction settings. Firstly, analogously to the frequentist approach a new trajectory is simulated using
the transition density p( X (tk )| X (tk−1 ), φpred , σ2 ) where φpred is sampled from the MCMC (Markov
chain Monte Carlo) posterior distribution p(φ| X1:M ). Secondly, we can calculate the predictive
distribution
Z
p( X (ti )|X1:M ) = p( X (ti )|φpred , σ2 ) p(φpred , σ2 |X1:M ) d(φpred , σ2 )
in each time point. We can then calculate only the quantiles for a prediction interval or to draw directly
samples from the predictive distribution. For this predictive distribution, we take the starting point
x j = x0 to be the same for all series. If the starting points would vary, this is an additional random
effect whose density has to be estimated. This is not implemented in the estimation procedure and
will, therefore, left out for the prediction.
It is then interesting to compare the new trajectories with the real ones. If the number of new
trajectories is large enough we compute an empirical confidence interval.

Overview of the mixedsde functions
This Section presents an overview of the functions implemented in the package. Illustrations of the
code are given in Section 2.4.

Data
Data is a matrix X of size M × N for M trajectories with N time points. The time points are not
necessarily equidistant but are the same for the M trajectories. These time points are gathered in the
vector times of length N. Real datasets are available on the package, and detailed on Section 2.5.
To lead a simulation study, the function mixedsde.sim allows to generate a list with a M × N
matrix X of M trajectories on the interval [0, T ] with N equidistant points (default value 100) and a
vector times with the equidistant times. This function leans on function sde.sim available via package
sde (Iacus, 2006) to simulate SDE. One has to choose: model either OU or CIR; random that fixes the
position and the number of random effects: random = 1 for α j random, random = 2 for β j random
or random = c(1,2) for α j and β j random; σ the diffusion coefficient; invariant, default value 0
means that X0 is 0 (default) or fixed by the user, value 1 means that X0 is generated from the invariant
distribution (see details in the package documentation); density.phi to choose the distribution of the
random effect (see package documentations).

Main function
Main function is mixedsde.fit producing estimation of the random effects and their common density.
Inputs of mixedsde.fit are
• X a M × N matrix containing the trajectories by rows.
• times The vector of observations times.

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

7

Class
Method
Method
Method
Method
Method
Method
Method

Freq.fit
out
plot
–
print
summary
pred
valid

Bayes.fit
out
plot
plot2compare
print
summary
pred
valid

Table 1: Summary of the different methods for the two S4-classes Freq.fit and Bayes.fit resulting
of the package mixedsde.
• model The chosen model either OU or CIR.
• random It fixes the position and the number of random effects: random = 1 for α j random, random
= 2 for β j random or random = c(1,2) for α j and β j random.
• estim.method The estimation method: nonparam (see Section 2.2.1), paramML (see Section 2.2.2)
or paramBayes (see Section 2.2.3).
• fixed The value of the fixed effect β (resp. α) when random = 1 (resp. random = 2), default 0.
(Only for the frequentist approaches).
• estim.fix 1 if the fixed effect is estimated, default 0. (Only for the frequentist parametric
approach when random=1 or 2).
• gridf The x-axis grid on which the random effect distribution is computed: we recommend a
bj
fine grid with at least 200 points, default value is a sequence of length 500 starting in 0.8 × min j φ
bj . (Only for the frequentist approaches).
and ending in 1.2 × max j φ
• prior The list of prior parameters m,v,alpha.omega,beta.omega,alpha.sigma,
beta.sigma for paramBayes method: Default values are calculated based on the estimations
( A j ) j for the first min(3, d M · 0.1e) series and main estimation is only made with the remaining
b M · 0.9c. (Only for the Bayesian approach).
• nMCMC The length of the Markov chain for paramBayes method. (Only for the Bayesian approach).
Note that for the frequentist approach if there is only one random effect, then the user has the choice:
fix it to a value of the user choice (using: fixed= the value and estim.fix=0) or estimate it through
the package (choosing estim.fix=1. In the following we describe the related methods, proposed in
the package, they are summarized in Table 1.

Outputs
Output of mixedsde.fit is a S4 class called Freq.fit for the frequentist approaches and Bayes.fit
for the Bayesian approach. Results of the estimation procedure are available as a list applying function
out to the Freq.fit (resp. Bayes.fit) object.
Elements of Freq.fit are:
c2 given in Equation 8 of the diffusion coefficient.
• sigma2 Estimator σ
• estimphi Estimator ( A j ) j given in Equation 2 of the random effects.
• estimphi.trunc The truncated estimator ( c
A j ) j given in Equation 4 or 5 of the random effects.
• estim.fixed The estimator of the fixed effect if random = 1 or 2, estim.method = paramML;
estim.fix = 1, default 0.
• gridf The x-axis grid on which the random effect distribution is computed.
• estimf The estimator of the density of the random effects (for both paramML method with
Equation 7 and nonparam method with Equation 6).
• cutoff Binary M-vector of binary values indicating the truncated trajectories, default FALSE
when no truncation.
• estimf.trunc The truncated estimation of the density of the random effects.
• mu Estimation of Gaussian mean of the random effects (only for paramML method from Equation
7).
• omega Estimation of Gaussian variance matrix of the random effects (only for paramML method
method from Equation 7).

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

8

• aic and bic AIC and BIC criteria (only for paramML method).
• index Indices of trajectories used for the estimation, excluded are trajectories with Vj = 0 or
Vj = +∞ (one random effect) or det V = +∞ (two random effects), trajectories containing
negative values for CIR model.
Elements of Bayes.fit are:
• sigma2 Trace of the Markov chain simulated from the posterior of σ2 .
• mu Trace of the Markov chain simulated from the posterior of µ .
• omega Trace of the Markov chain simulated from the posterior of ω 2 .
• alpha Trace of the Markov chain simulated from the posterior of α j , nMCMC× M matrix if α is
random effect, nMCMC×1 otherwise.
• beta Trace of the Markov chain simulated from the posterior of β j , nMCMC× M matrix if β is
random effect, nMCMC×1 otherwise.
• burnIn A proposal for the burn-in phase.
• thinning A proposal for the thin rate.
• ind.4.prior The indices used for the prior parameter calculation, M + 1 if prior parameters
were specified.
Outputs burnIn and thinning are only proposals for a burn-in phase and a thin rate. The proposed
burnIn is calculated by dividing the Markov chains into 10 blocks and calculate the 95% credibility
intervals and the respective mean. Starting in the first one, the block is taken as burn-in as long as the
mean of the current block is not in the credibility interval of the following block or vice versa. The
thinning rate is proposed by the first lag which leads to a chain autocorrelation of less than 80%. It is
not easy to automate these choices, so it is highly recommended by the authors to plot the chains and
look at the mixing property (the chain should not be piecewise constant).
Command plot() applied to a Freq.fit object produces a frequencies histogram of ( A j ( T )) j (one
or two according to the number of random effects) with the estimated density (red curve) and the
truncated estimator if available (dotted grey red curve) and a quantile-quantile graph with the quantiles
of the A j ’s versus the quantiles of a normal sample of the same length, with the same empirical mean
and standard deviation. This illustrates the normality of the sample. Applying this function to the
nonparametric results indicates if the Gaussian assumption of the parametric approach is appropriate.
When plot() is applied to a Bayes.fit object, one can choose four different options, named style.
The default value is chains, it plots the Markov chains for the different parameter values. acf leads to
the corresponding autocorrelation functions, density to the approximated densities for each parameter
and cred.int leads to the credibility intervals of the random parameters with the input parameter
level with default 0.05. For all options, with the input parameter reduced = TRUE, the burn-in period
is excluded and a thinning rate is taken, default is FALSE. There is also a possibility to include the prior
means in the plots by lines with plot.priorMean = TRUE, default is FALSE.
In the Bayesian estimation the influence of prior parameters is interesting, thus for the Bayes.fit
object, there is a second plot method, named plot2compare where three estimation objects can be
compared. For reasons of clarity, only the densities are compared, with the default reduced = TRUE.
Here, there is also a possibility to include true.values, a list of the true parameters for the comparison
in a simulation example.
Command summary() applied to a Freq.fit object computes the kurtosis and the skewness of the
c2 , the empirical mean and standard deviation computed from the estimators ( A ) , µ
distribution, σ
j j b,
b AIC, BIC criteria for the frequentist MLE method. When applied to a
b (and the fixed effect b
Ω
α or β),
Bayes.fit object, it computes means and credibility interval (default level 95%) for each parameter
(µ, Ω, σ, α, β). Here, there is also a possibility to choose the burn-in and the thinning rate manually by
the input parameters burnIn and thinning.
Command print() applied to a Freq.fit object returns the use or not of the cutoff and the vector
of excluded trajectories. When applied to a Bayes.fit object, it returns the acceptance rates of the
MCMC procedure.

Validation methods
Validation of a mixed model, obtained with function valid, is an individual validation. Indeed,
the validation of estimation of trajectory number j is obtained comparing it to M new trajectories
bj ) in the frequentist approaches and to
simulated with parameters (α, β) fixed to the estimator A j (or A
the posterior means in the Bayesian approach. Inputs of the function are

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

9

• Freq.fit or Bayes.fit object.
• plot.valid 1 to generate a figure (default value is 1).
• numj A specific individual trajectory to validate (default: randomly chosen between 1 and M).
• Mrep The number of simulated trajectories (default value 100).
Mrep

1
Each observation Xnumj (tk ) is compared with the Mrep simulated values ( Xnumj
(tk ), . . . , Xnumj (tk )),
for k = 1, . . . , N.
Mrep

1
Outputs are the list of the ( Xnumj
(tk ), . . . , Xnumj (tk )). If plot.valid=1, two plots are produced.
Left: plot of the Mrep new trajectories (black) and the true trajectory number numj (in grey/red).
Right: quantile-quantile plot of the quantiles of a uniform distribution and the N quantiles obtained
Mrep

1
comparing Xnumj (tk ) with the Mrep simulated values ( Xnumj
(tk ), . . . , Xnumj (tk )), for k = 1, . . . , N.

This is an empirical method. The recent work Kuelbs and Zinn (2015) on depth and quantile
regions for stochastic processes (see for example Zuo and Serfling (2000) for depth functions definitions)
should provide the theoretical context for a more extensive study. This could be done in further works.

Prediction methods
Prediction (see Section 2.2.4) is implemented in function pred. Main inputs of the function are
• Freq.fit or Bayes.fit object.
• invariant TRUE if the new trajectories are simulated according to the invariant distribution.
• level The level of the empiric prediction intervals (default 0.05).
• plot.pred TRUE to generate a figure (default TRUE).
(and optional plot parameters). Function pred applied to a Freq.fit object returns a list with predicted
random effects phipred, predicted trajectories Xpred and indexes of the corresponding true trajectories
indexpred (see Section 2.2.4 for details of simulation). If plot.pred = TRUE (default) three plots are
produced. Left predicted random effects versus estimated random effects. Middle: true trajectories.
Right predicted trajectories and their empirical 95% prediction intervals (default value level=0.05).
b
bj given by Equation 5,
The prediction can also be done from the truncated estimator fbh based on the A
if the argument pred.trunc = 1.
Function pred applied to a Bayes.fit object returns a S4 class object Bayes.pred. The first element
of this class is Xpred, which depends on the input parameters. Including the input trajectories
= TRUE, matrix Xpred contains the M drawn trajectories by rows (see first method described for the
Bayesian approach in Section 2.2.4). Default is trajectories = FALSE which leads to the calculation of
the predictive distribution explained in Section 2.2.4. With the input only.interval = TRUE (default),
only the quantiles for the 1- level prediction interval are calculated, stored in qu.l and qu.u. Input
only.interval = FALSE provides additionally Xpred containing sample.length (default 500) samples
from the predictive distribution in each time point of the observations (except the first). In both cases,
with plot.pred = TRUE, two figures are produced. On the left side, the data trajectories are compared
with the prediction intervals and on the right side, the coverage rate is depicted which is stored in
entry coverage.rate, namely the amount of series covered by the prediction intervals for each time
point. The last class entry estim stores the results from the Bayes.fit object in a list. Other input
parameters are burnIn and thinning which allow for the choice of other burn-in phase and thinning
rate than proposed in the Bayes.fit object.
For the Bayes.pred class object, two plot methods are available. plot() repeats the figures that are
created with the plot.pred = TRUE command in the pred method. plot2compare() compares up to
three Bayes.pred objects, where in a first figure the prediction intervals are presented in colors black,
red and green and the observed data series in grey and in a second figure the corresponding coverage
rates are compared. With the input parameter names a vector of characters to be written in a legend
can be indicated.
Note that to avoid over-fitting, we recommend to use only 2/3 of the data for the estimation of the
density f and the last third for the prediction.

Package mixedsde through simulated examples
In this part two simulated examples are given to illustrate the strengths of each proposed method.
Two datasets are simulated according to:

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

10

1. CIR model with one non-Gaussian random effect β j ∼ Γ(1.8, 0.8), α j = 1, T = 50, M = 200,
N = 1000:

R> model1 <- "CIR"; random1 <- 2; fixed1 <- 1; sigma1 <- 0.1 ; M1 <- 200;
R> T1 <- 50; N1 <- 1000; X01 <- 1; density.phi1 <- "gamma";
+ param1 <- c(1.8,0.8);
R>
+
+
R>

simu1 <- mixedsde.sim(M = M1, T = T1, N = N1, model = model1,
random =random1, fixed = fixed1, density.phi = density.phi1,
param = param1, sigma = sigma1, X0 = X01)
X1<- simu1$X; phi1 <- simu1$phi; times1 <-simu1$times

2. OU model with one Gaussian random effect α j ∼ N (3, 0.52 ), β j = 5, T = 1, M = 50, N = 500:

R>
+
+
R>
+
+
R>

model2 <- "OU"; random2 <- 1; sigma2 <- 0.1; fixed2 <- 5; M2 <- 50;
T2 <- 1;N2 <- 500; X02 <- 0; density.phi2 <- "normal";
param2 <- c(3, 0.5);
simu2 <- mixedsde.sim(M = M2, T = T2, N = N2, model = model2,
random = random2, fixed = fixed2, density.phi = density.phi2,
param = param2, sigma = sigma2, X0 = X02)
X2 <- simu2$X; phi2 <- simu2$phi; times2 <- simu2$times

Example 1 has non Gaussian random effect, the nonparametric method is the most appropriate
approach. Example 2 has T small and Gaussian random effect, nonparametric method is therefore not
the most appropriate approach. Parametric methods should performed better than the non-parametric
one as the number of trajectories M2 = 50 is not large (and only 2/3 are used for the estimation of
f ). A small number of trajectories is especially a good framework to apply the Bayesian estimation
method.

Frequentist nonparametric estimation
We illustrate nonparametric estimation on Example 1. Code for the nonparametric estimation is

R>
R>
+
R>

estim.method <- 'nonparam'
estim_nonparam <- mixedsde.fit(times = times1, X = X1, model = model1,
random = random1, fixed = fixed1, estim.method = estim.method)
outputsNP <- out(estim_nonparam) # stores the results in a list

Summary function provides:

R> summary(estim_nonparam)
[,1]
[,2]
[1,] "sigma" "0.099868"
Random effect:
empiric mean
empiric sd
kurtosis
skewness

[,1]
1.355403
0.939410
3.695013
1.083577

As expected kurtosis is larger than 3 and skewness is positive which means that the distribution is
right-tail. Figure 1 is provided by

R> plot(estim_nonparam)
Nonparametric estimation fits well the histogram of ( A j ) (left plot) and we see that the random
effects are non-Gaussian (right plot). Because we are working on simulated data, we can compare the
estimations with the true random effects and the true f :

# Comparison of the true f and its estimation
R> gridf1 <- outputsNP$gridf
# True density function
R> f1 <- dgamma(gridf1, shape = param1[1], scale = param1[2])
# Nonparametric estimated density function
R> fhat <- outputsNP$estimf
R> plot(gridf1, f1, type='l', lwd=2, xlab='', ylab='')
R> lines(gridf1, fhat, col='red')

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

11

3
2
0

0.0

1

0.2

0.4

Sample Quantiles

0.6

4

5

0.8

Density of the random effect

0

1

2

3

4

5

0

1

2

3

4

5

Normal Quantiles

0.0

0

0.1

1

0.2

2

3

0.3

4

0.4

5

0.5

Figure 1: Simulated example 1 (CIR with one Gamma random effect), nonparametric estimation. Left:
histogram of estimated random effects ( A j ) and nonparametric estimation of f . Right: qqplot of ( A j )
versus a Normal sample (true distribution is Gamma).

0

1

2

3

4

5

0

1

2

3

4

5

Figure 2: Simulated example 1 (CIR with one Gamma random effect), nonparametric estimation,
comparison to the truth. Left: estimation fb (dotted line) and true density f (plain line). Right:
Estimated random effects A j versus true random effects φj .

# Comparison of the true random effects and their estimations
# Estimated random effects
R> phihat1 <- outputsNP$estimphi
R> plot(phi1, phihat1, type = "p", pch = 18, xlab='', ylab='')
R> abline(0, 1)
This results in Figure 2. On the left plot, the estimated density (dotted curve) is very close to the true
density f (plain line). The right plot shows that A j is a good estimation of φj . This confirms that
the nonparametric approach performs well for this settings. Validation of the MSDE is produced by
function valid. The two graphs on the right of Figure 5 are obtained by

R> validationCIR <- valid(estim_nonparam)
Prediction are obtained with pred and similar Figure 6 (not shown) can be obtained with

R> predNPCIR <- pred(estim_nonparam)

Frequentist parametric estimation
We present the parametric estimation on Example 2. The code is

# Parametric estimation
R> estim.method<-'paramML';
R> estim_param <- mixedsde.fit(times2, X = X2, model = model2,
+ random = random2, estim.fix = 1, estim.method = 'paramML' )
# Store the results in a list:
R> outputsP <- out(estim_param)
Summary function provides:

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

12

3.5
3.0

0.0

2.0

0.2

2.5

0.4

0.6

Sample Quantiles

4.0

0.8

4.5

1.0

5.0

Density of the random effect

2.0

2.5

3.0

3.5

4.0

4.5

5.0

2.0

2.5

3.0

3.5

4.0

4.5

5.0

Normal Quantiles

Figure 3: Simulated example 2 (OU with one Gaussian random effect) frequentist parametric estimation. Left: histogram of the ( A j ) and Gaussian parametric estimation of f . Right parametric qqplot of
( A j ) versus a Normal sample.

R> summary(estim_param)
[,1]
[,2]
[1,] "sigma" "0.109144"
Random and fixed effects:
[,1]
estim.fixed 4.914685
empiric mean 2.955582
MLE mean
2.955512
empiric sd 0.536956
MLE sd
0.519955
kurtosis
2.472399
skewness
0.427223
[,1] [,2]
[1,] "BIC" "-3780.383134"
[2,] "AIC" "-3795.335809"
Kurtosis is, as expected, close to 3 and skewness close to 0. The diffusion parameter σ is well estimated
(true value 0.1). The fixed effect is also well estimated (true value 5). Empirical mean and standard
deviations are very close to MLE (estimator of the mean is the same in that case) and close to the real
ones (3, 0.5). Then, Figure 3 (left and right) is provided by

R> plot(estim_param)
The small number of observations makes the estimation harder, nevertheless here, the histogram
seems pretty well fitted by the parametrically estimated density. Because we are working on simulated
data, we can compare the estimations with the true random effects and the true f :

# Comparison of the true f and its estimation
R> gridf2 <- outputsP$gridf
# True density
R> f2 <- dnorm(gridf2, param2[1], param2[2])
# Parametric estimated density
R> fhat_param <- outputsP$estimf
R> plot(gridf2, f2, type = 'l', lwd = 2, xlab = '', ylab = '')
R> lines(gridf2, fhat_param, col='red', lty = 2, lwd = 2)
# Comparison of the true random effects and their estimations
# Estimated random effects
R> phihat2 <- outputsP$estimphi
R> plot(phi2, phihat2, type="p", pch=18, xlab='', ylab='')
R> abline(0, 1)
This results in Figure 4. It shows that estimation of the density is satisfactory (left) and estimation of
the random effects is very good (right). Validation of the MSDE is produced by function valid. For
example the individual validation of the first trajectory is plotted Figure 5, the first two graphs on the
left, using

R> validationOU <- valid(estim_param)

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

13

0

0.0

1

0.2

2

0.4

3

0.6

4

0.8

5

C ONTRIBUTED RESEARCH ARTICLE

2.0

2.5

3.0

3.5

4.0

4.5

5.0

0

1

2

3

4

5

Figure 4: Simulated example 2 (OU with one Gaussian random effect) frequentist parametric estimab 2 ) (dotted line) and true f (plain
b, ω
tion, comparison to the truth. Left: parametric estimation N (µ
line). Right: true φj versus estimated random effects A j .

Figure 5: Simulated examples frequentist approaches, outputs of valid method. Two top plots:
frequentist nonparametric estimation on example 1 (CIR process). Two bottom plots: frequentist
parametric estimation on example 2 (OU process).

This illustrates the good estimation of the random effects: a beam of trajectories with the true one in
the middle and the lining up of the quantiles.
Finally, we can predict some trajectories using pred. Predictions are shown on Figure 6, as a result
of

R> predPOU <- pred(estim_param)
Beam of 32 predicted trajectories (right) is close to the true ones (middle). The lining up of
the predicted random effects versus the estimated random effects (left) shows the goodness of the
prediction from the estimated density, thus of the estimation of the density.

Bayesian estimation
Bayesian method is applied to Example 2. Priors are constructed from the true values, but default
values can be used.

R>
+
+
R>

prior2 <- list( m = c(param2[1], fixed2), v = c(param2[1], fixed2),
alpha.omega = 11, beta.omega = param2[2] ^ 2 * 10, alpha.sigma = 10,
beta.sigma = sigma2 ^ 2 * 9)
estim.method <- 'paramBayes'

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

14

2

3

4

5

1.2
1.0
0.8
0.6
0.4
0.2
0.0

0.0

2

0.2

0.4

3

0.6

0.8

4

1.0

1.2

5

1.4

Predictive trajectories

1.4

True trajectories

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

Figure 6: Simulated example 2 (OU with one Gaussian random effect), frequentist parametric estimation. Left: predicted random effects versus estimated random effects. Middle: true trajectories. Right:
predicted trajectories in black and 95% prediction interval in grey (green).

Figure 7: Simulated example 2 (OU with one Gaussian random effect) Bayesian estimation. Markov
chains of µ1 , β, ω12 and σ2 .

R> estim_bayes <- mixedsde.fit(times = times2, X = X2, model = 'OU',
+ random = random2, estim.method = estim.method, prior = prior2, nMCMC = 10000)
R> outputsBayes <- out(estim_bayes)
Figure 7 is produced by

R> plot(estim_bayes)
Traces of the Markov chains of µ1 , β, ω12 and σ are plotted, showing that all chains converge and have
the correct location. Command print() yields acceptance rates of the MH algorithm:

R> print(estim_bayes)
acceptance rates for random effect:
Min. 1st Qu. Median
Mean 3rd Qu.
Max.
0.5569 0.5646 0.5676 0.5682 0.5718 0.5805
acceptance rate for fixed effect: 0.4248
The fixed effect β has a small acceptance rate, explaining the dependent chain (Figure 7 top right). This
is due to a very sharp likelihood because of the large amount of observations (N · M) in comparison to
the random effect (N).

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

15

0.85

0.2

0.4

X

coverage rates
0.90

0.6

0.95

0.8

1.00

C ONTRIBUTED RESEARCH ARTICLE

0.0

data
prediction

0.0

0.2

0.4

0.6

inter vals

0.8

1.0

95%

0.0

0.2

times

0.4

0.6

0.8

1.0

times

Figure 8: Simulated example 2 (OU with one Gaussian random effect) Bayesian estimation. Left:
predicted trajectories in black and 95% prediction interval in grey (green). Right: coverage rates:
amount of observed values covered by the prediction intervals.

Predictions in the Bayesian framework and the corresponding Figure 8 is obtained by

R> pred.result <- pred(estim_bayes)
Figure 8 shows the beam of simulated data trajectories together with the 95% prediction interval.
Coverage rates are shown on the right plot and we see that the intervals hold the level.

Package mixedsde through a real data example
A real dataset is available (neuronal.data.rda) through lists of a matrix X and a vector times. We detail
below the analysis of this dataset, following the next steps: run the two random effects model with
both the parametric and nonparametric procedure; choose the number of random effects depending
b
on the variability of the estimators ( A j,1 , A j,2 ), on the shape of fbh and the variance Ω.
These data are available thanks to Rune Berg and Jufang He. Details on data acquisition can be
found in Lansky et al. (2006).

Neuronal data
Neurons are the basement of nervous system and each neuron is connected with around 1000 other
neurons. They are communicating through emission of electrical signal. We focus on the dynamic
of the neuron membrane potential between two spikes emission measured in volts as the difference
of ions concentration between the exterior and the interior of the cell. Data are obtained from one
single neuron of a pig. Data are composed of M = 240 membrane potential trajectories with N = 2000
equidistant observation times. Time step is δ = 0.00015 [s] and observation time is T = 0.3 [s]. Data
are uploaded using data("neuronal.data"). They are presented on Figure 9.
These data have been previously analysed with a Ornstein-Uhlenbeck model with one additive
random effect (α j ): Picchini et al. (2008) and Picchini et al. (2010) use parametric methods assuming the
normality of the random effect, and Dion (2014) with a nonparametric method. Here α j represents the
local average input that the neuron receives after the jth spike. The initial voltage (the value following
a spike) is assumed to be equal to the resting potential and set to zero: x j = 0. Parameter β j (non
negative) is the time constant of the neuron. It was fixed in Picchini et al. (2008) and Picchini et al.
(2010).
In this new analysis, we assume that both α j and β j may change from one trajectory to another
because of other neurons or environment influence, for example. Indeed, the form of each trajectory
lead us to think that this is the good model: each one has its mean-reverting value and its own speed
to reach this value. There is no reason to assume that the speed is always the same, but looking at the
trajectories the stationary state seems to be reached nearly at the same time, thus the second random
effect should have a small variance.

Fitting with MSDEs
Our goal is also to compare the two models OU and CIR, both with two random effects, and two
approaches: the nonparametric density estimation and the parametric density estimation. Let us

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

16

Figure 9: Neuronal data.

remark that for the CIR model the algorithm removes two trajectories: 168 and 224, because they
contain negatives values. For two random effects the command is

R> estim <- mixedsde.fit(times, X = X, model = model, random = c(1,2),
+ estim.method = estim.method)
and they can be found in the help data file (command ?neuronal.data). We first apply the two frequentist approaches on models with two random effects. Kurtosis and skewness of the distribution of
the estimation A j of the random effects given in Table 2 are not closed to a symmetric distribution. The
bidimensional density of (α j , β j ) is estimated for both models with the parametric and nonparametric
methods running function mixedsde.fit. Figure 10 gives the 4 estimated marginals. The blue (black) is
for the OU model and the green (grey) for the CIR model. The dotted lines are the estimations from the
parametric method, the plain lines for the nonparametric estimation. Parametric and nonparametric
estimators are close, except for the second random effect with the OU model. Indeed, parametric
estimation produces a small variance for the second random effect, suggesting it could be fixed. Would
this assumption be valid, it explains the difference with the nonparametric estimator which is not
stable if the variance is to small. Estimation of σ is b
σ = 0.0136 for the OU model and b
σ = 0.163 for the
CIR model.
To compare with previous literature results, we focus on the OU model. To select the number and
the position of the random effects, we run the code with one random effect, additive or multiplicative:
random = 1 or random = 2, for both models estimating the common fixed parameter with the
parametric frequentist strategy. Estimators of the means µ1 , µ2 and standard deviations ω1 , ω2 are
given in Table 3. Criteria AIC and BIC are also given in Table 3. From this table, we can see that models
random = 1 and random = c(1,2) are the best according to the BIC and AIC criteria.
Finally, in Table 4 we compare the BIC and AIC criteria for random = 1 when the value of the fixed
effect is plugged in: the one we obtained in Table 3 and to values obtained in Picchini et al. (2008) and
Picchini et al. (2010). The preferred model is the one minimizing both criteria. Thus, the OU model
with one additive random effect φj = α j and βb = 37.22 seems to be the best model to describe these
data. The summary method gives for the kurtosis: 4.55 and for the skewness -0.95. Also b
σ = 0.0136.
Estimated densities obtained for this model with βb = 37.22 are given in Figure 11. The dotted line is
the result of the parametric estimation and the plain line of the nonparametric estimation, plotted on
the histogram of the A j ( T )’s. The nonparametric estimation detects a left tail that is not detected by
the parametric one. Otherwise both estimators are very close.
The OU model with random = 1 is then validated with valid function. Figure 12 illustrates the
result for a random trajectory (number 141): 100 simulated trajectories (black) and true trajectory
( X141 , red) (left plot) and quantiles of the true measurement among the 100 simulated points at each
time points versus uniform quantiles. The qq-plot is satisfactory (compared to the graph obtained on
simulated data Figure 5).
Finally some prediction plots are performed (not shown) with the pred method and they confirm
that model OU with random = c(1,2) with the parameters obtain from the parametric estimation,
and the OU model with random = 1 and βb = 37.22 produce very close trajectories and could be both

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

17

Aj1 Kurtosis
Skewness
Aj2 Kurtosis
Skewness

OU
6.17
0.96
6.68
0.96

CIR
11.70
2.32
7.07
2.32

Table 2: Neuronal data. Kurtosis and skewness estimations for samples ( A j,1 )’s and ( A j,2 )’s, for OU
and CIR models.

random=c(1,2)
random=2
random=1

µ1
0.38
0.37
0.38

ω1
0.06
-0.06

µ2
37.30
37.70
37.22

ω2
1.10
7.47
--

BIC
-3229.67
-3082.36
-3227.47

AIC
-3247.59
-3103.40
-3248.51

Table 3: Neuronal data. MLE given by Equation 7, BIC and AIC criteria, for OU model, depending on
the number of random effects (with estim.fix=1 for random = 1 or random = 2).

β from Picchini 2008
β from Picchini 2010
Previous estimator MLE of β Table 3

µ1
0.27
0.47
0.38

ω1
0.04
0.08
0.06

β
25.64
47.00
37.22

BIC
-2971.59
-3043.89
-3240.55

AIC
-2980.55
-3052.86
-3249.51

Table 4: Neuronal data. Results obtained with random=1 for the OU model, where the value of the
fixed effect β is plugged in.

validated.
We then apply the Bayesian procedure. As already mentioned, for the Bayesian procedure, large
data sets are a problem because of the very long running time. Therefore, we thin the data set by 10.
That means, every 10th data point of the series is used for the estimation and also for the prediction.
Even with this thinning, one estimation with 20000 samples takes half an hour.
Based on the best model selected by the frequentist approach, the OU model with one random
effect φj = α j is fitted. No prior knowledge is available, we therefore leave this information out and let
the algorithm take the first 10%, i.e. 24, series for the calculation of the prior parameter, as described
in Section 2.3.2. Figure 13 plots the Markov chains estimated from the remaining M − 24 = 216
trajectories and showq
good convergence of the chains. Bayesian point estimations, i.e. posterior means,
√
b1 = 0.34, ω
b1 = ω
b 2 = 0.06, βb = 33 and b
σ= b
σ2 = 0.01. Compared to frequentist estimation
are µ
1

(Table 4), we notice that these results are a compromise between Picchini et al. (2010) and frequentist
estimation.
In Figure 14, we can see a comparison of the prediction results for all three cases, α, β or both
being random effects. The black and the green lines are very similar, which means, that the prediction
intervals are nearly the same for α and both parameters being random effects. This confirms the
frequentist conclusion of Table 3. Therefore, it could be enough to treat α as random and β as fixed
effect.

Discussion
In this paper we illustrate the functionality of the package mixedsde for inference of stochastic
differential equations with random and/or fixed effects. This package, and mainly the function
misedsde.fit, can be used to choose the best model to fit some data. It allows to compare two
models: OU or CIR with one or two random effects. The three estimation methods can be used to
help the decision maker. Nevertheless each method can be more appropriate to a specific situation,
as explained before: the Bayesian method is recommended for a small number of observations, the
frequentist nonparametric is a good tool with two random effects and no prior available. In particular
the frequentist parametric proposes for a large sample, an estimation of the fixed effect and of the

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

18

0

0.0

2

0.1

4

0.2

6

0.3

8

0.4

C ONTRIBUTED RESEARCH ARTICLE

0.2

0.4

0.6

0.8

1.0

20

40

60

80

100

120

140

0

2

4

6

8

Figure 10: Neuronal data. Frequentist estimated marginals of the bidimensionnal density of the
random effects obtained from 4 estimators. Left: α j ’s density, right: β j ’s density. CIR model in green
(grey), OU in blue (black). Nonparametric in plain line, parametric in dotted line.

0.0

0.1

0.2

0.3

0.4

0.5

0.6

Figure 11: Neuronal data, OU model, α random, β fixed to the estimator obtained by the maximum
likelihood estimator. Histogram of the A j ’s estimators of the φj = α j . Estimator of the density f :
N (µ, ω 2 ) parametric estimation in blue (black) dotted line, non-parametric estimation blue (black)
plain line.

Figure 12: Neuronal data, OU model, α random, β fixed, validation of the frequentist approaches.
Individual validation of trajectory 232. Left: 100 simulated trajectories in black and true trajectory ( X j )
in grey (red). Right: quantiles of the true measurement among the 100 simulated points at each time
points versus uniform quantiles.

parameters of the Gaussian distribution for the fixed effect when there is only one. A neuronal dataset
is studied with the three methods. Furthermore, other real data should be investigated with the
present package.
Recently, the parameter estimation method developed in Delattre et al. (2016) for random effects
distributed according to a Gaussian mixture distribution has been implemented in the R package
MseParEst (Delattre and Dion, 2016).

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

19

0.000
0.00

0.05

0.10

0.15

0.20

0.25

times

0.30

0.95
0.90

coverage rates

95%
random=1
random=2
random=(1,2)

0.85

0.010

data
random=1
random=2
random=(1,2)

0.005

X

0.015

1.00

Figure 13: Neuronal data, OU model, α random, β fixed, Bayesian estimation. Reduced Markov chains
(less the burn-in phase and the thinning rate).

0.00

0.05

0.10

0.15

0.20

0.25

0.30

times

Figure 14: Neuronal data. Bayesian prediction results using the OU model, left: pointwise 95%
prediction intervals and data series, right: coverage rates, which means the amount of observed values
covered by the prediction intervals.

Acknowledgements
The authors would like to thank Vincent Brault and Laurent Bergé for technical help on the package.
This work has been partially supported by the LabExPERSYVAL-Lab(ANR-11-LABX-0025-01).
The second author, Simone Hermann, was financially supported by Project B5 “Statistical methods
for damage processes under cyclic load” of the Collaborative Research Center “Statistical modeling of
nonlinear dynamic processes” (SFB 823) of the German Research Foundation (DFG).

Bibliography
P. Bacher and H. Madsen. Identifying Suitable Models for the Heat Dynamics of Buildings. Energy and
Buildings, 43:1511–1522, 2011. [p1]
F. Comte, V. Genon-Catalot, and A. Samson. Nonparametric Estimation for Stochastic Differential
Equation with Random Effects. Stochastic Processes and their Applications, 7:2522–2551, 2013. [p2, 3]
M. Delattre and C. Dion. MsdeParEst: Parametric Estimation in Mixed-Effects Stochastic Differential
Equations, 2016. URL https://CRAN.R-project.org/package=MsdeParEst. R package version 1.7.
[p18]
M. Delattre, V. Genon-Catalot, and A. Samson. Maximum Likelihood Estimation for Stochastic

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

20

Differential Equations with Random Effects. Scandinavian Journal of Statistics, 40:322–343, 2013. [p2,
5]
M. Delattre, V. Genon-Catalot, and A. Samson. Mixture of Stochastic Differential Equations with
Random Effects: Application to Data Clustering. to appear in Journal of Statistical Planning and
Inference, 2016. [p2, 18]
C. Dion. Nonparametric Estimation in a Mixed-Effect Ornstein-Uhlenbeck Model. Metrika, 2014. [p2,
15]
C. Dion and V. Genon-Catalot. Bidimensional Random Effect Estimation in Mixed Stochastic Differential Model. Statistical Inference for Stochastic Processes, 18(3):1–28, 2015. [p2, 3, 5]
C. Dion, S. Hermann, and A. Samson. mixedsde: Mixed Stochastic Differential Equations, 2016. URL
https://CRAN.R-project.org/package=mixedsde. R package version 4.0. [p1]
S. Ditlevsen and A. de Gaetano. Mixed Effects in Stochastic Differential Equation. REVSTAT - Statistical
Journal, 2:137–153, 2005. [p2]
S. Ditlevsen and A. Samson. Estimation in Partially Observed Stochastic Morris-Lecar Neuronal Model
with Particle Filter and Stochastic Approximation Methods. The annals of applied statistics, 8:674–702,
2014. [p1]
V. Genon-Catalot and C. Larédo. Estimation for Stochastic Differential Equations with Mixed Effects.
Statistics, pages 1–22, 2016. [p3]
A. C. Guidoum and K. Boukhetala. Sim.DiffProc: Simulation of Diffusion Processes, 2017. URL
https://CRAN.R-project.org/package=Sim.DiffProc. R package version 4.0. [p1]
A. Hansen, A. K. Duun-Henriksen, R. Juhl, S. Schmidt, K. Norgaard, J. B. Jorgensen, and H. Madsen.
Predicting Plasma Glucose from Interstitial Glucose Observations Using Bayesian Methods. Journal
of diabetes science and technology, 8:321–330, 2014. [p1]
S. Hermann, K. Ickstadt, and C. Müller. Bayesian Prediction of Crack Growth Based on a Hierarchical
Diffusion Model. to appear in: Applied Stochastic Models in Business and Industry, 2016. [p1, 2, 5]
S. M. Iacus. sde: Stochastic Differential Equations, 2006. URL http://CRAN.R-project.org/package=sde.
R package version 2.0-15. [p6]
S. M. Iacus. Simulation and Inference for Stochastic Differential Equations. Springer-Verlag, 2008. [p5]
S. M. Iacus. yuima: The YUIMA Project Package for SDEs, 2018. URL https://CRAN.R-project.org/
package=yuima. R package version 1.8.1. [p1]
E. B. Iversen, J. M. Morales, J. K. Moller, and H. Madsen. Probabilistic Forecasts of Solar Irradiance
Using Stochastic Differential Equations. Environmetrics, 25:152–164, 2014. [p1]
N. R. Kristensen and H. Madsen. Continuous time stochastic modelling, ctsm 2.3—mathematics guide.
Technical report, DTU, 2003. [p1]
J. Kuelbs and J. Zinn. Limit Theorems for Quantile and Depth Regions for Stochastic Processes. to
appear in High dimensional probability VII-Progress in Probabiliy, 2015. [p9]
P. Lansky, P. Sanda, and J. He. The Parameters of the Stochastic Leaky Integrate-and-Fire Neuronal
Model. Journal of Computational Neuroscience, 21:211–223, 2006. [p15]
MONOLIX. MONOLIX Software. MOdèles NOn LInéaires à Effets miXtes, 2003. URL http://www.lixoft.
com/. LIXOFT and INRIA. [p2]
S. B. Mortensen and S. Klim. PSM: Population Stochastic Modelling, 2013. URL https://CRAN.Rproject.org/package=PSM. R package version 0.8-10. [p2]
Z. Oravecz, F. Tuerlinckx, and J. Vandekerckhove. A Hierarchical Ornstein-Uhlenbeck Model for
Continuous Repeated Measurement Data. Psychometrica, 74:395–418, 2009. [p2]
U. Picchini, S. Ditlevsen, A. De Gaetano, and P. Lansky. Parameters of the Diffusion Leaky Integrateand-Fire Neuronal Model for a Slowly Fluctuating Signal. Neural Computation, 20:2696–2714, 2008.
[p15, 16]
U. Picchini, A. De Gaetano, and S. Ditlevsen. Stochastic Differential Mixed-Effects Models. Scandinavian
Journal of statistics, 37(1):67–90, 2010. [p2, 15, 16, 17]

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

21

C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer-Verlag, 2004. [p5]
J. S. Rosenthal. Optimal Proposal Distributions and Adaptive MCMC. Handbook of Markov Chain Monte
Carlo, pages 93–112, 2011. [p5]
W. N. Venables and B. D. Ripley. MASS: Modern Applied Statistics with S, 2016. URL https://CRAN.Rproject.org/package=MASS. R package version 7.3-45. [p3]
Y. Zuo and R. Serfling. General Notions of Statistical Depth Function. Annals of statistics, 28:461–482,
2000. [p9]

Appendix
When there is one random effect, what is the likelihood function and the MLE of the fixed effect?
Assume that we are in the case of random = 1, thus the process is
dX j (t) = (α − φj X j (t))dt + σa( X j (t))dWj (t).
Let us compute the log-likelihood function when φj = ϕ fixed. We omit the subscript j in the following.
We use the same notation as for random=c(1,2), where V = (Vk,` )k,`∈{1,2} is a symmetric matrix size
2 × 2. We have :
log L( X, α, ϕ)

=

Z T
b ( X ( s ), ϕ )
0

=

σ2 ( X (s))

αU1 −

dX (s) −

1
2

Z T 2
b ( X ( s ), ϕ )
0

σ2 ( X (s))

ds

α2
ϕ2
V1,1 + ϕ[U2 − αV1,2 ] −
V .
2
2 2,2

We assume that the random effect is Gaussian with density f ξ , and denote ξ = (µ, ω ) and θ := (µ, ω, α).
Thus,


Z
Z
α2
ϕ2
L( X, θ ) = exp αU1 − V1,1 + ϕ[U2 − αV1,2 ] −
V2,2 f ξ ( ϕ)dϕ = exp(E ( ϕ))dϕ.
2
2
We find:

E ( ϕ)

=
=

α2
V −
2 1,1
α2
αU1 − V1,1 −
2
αU1 −

with
m=

i
1h 2
ϕ (V2,2 + ω −2 ) − 2ϕ(U2 − αV1,2 + µω −2 )
2
1
m2
1
( ϕ − m )2 + 2 − µ 2 ω −2
2
2
2Σ
2Σ

µ + ω 2 U2 − ω 2 V1,2 α
,
1 + ω 2 V2,2

Σ2 =

ω2
.
1 + ω 2 V2,2

Finally after simplification we get:
m2
1
1
1
−1
− µ2 ω −2 = − (1 + ω 2 V2,2 )−1 V2,2 [µ − V2,2
(U − αV1,2 )2 .
(U2 − αV1,2 )]2 +
2
2
2V2,2 2
2Σ2
Thus for random=1 we get
L( X, θ ) = q

1
1 + ω 2 V2,2

"
exp αU1 −

#
(U2 − αV1,2 )2
V2,2
α2
−1
2
V1,1 −
[
µ
−
V
(
U
−
αV
)]
+
.
2
1,2
2,2
2
2V2,2
2(1 + ω 2 V2,2 )

Then, when random = 2 the roles of α and ϕ are exchanged. To implement a general formula, we note:
r for random: 1 or 2, and c for the number of the common effect. We denote ψ the fixed effect and we
the get the general formula:


1
ψ2
Vr,r
(Ur − ψVr,c )2
−1
2
L( X, θ ) = p
exp ψUc −
Vc,c −
[
µ
−
V
(
U
−
ψV
)]
+
.
r
c,r
r,r
2
2Vr,r
2(1 + ω 2 Vr,r )
1 + ω 2 Vr,r
Charlotte Dion
Laboratory Jean Kuntzmann
Université Grenoble Alpes

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

C ONTRIBUTED RESEARCH ARTICLE

22

Batiment IMAG
700 avenue Centrale
Campus de Saint Martin d’Hères BP 53
38041 Grenoble cedex 09 - France
and
Laboratory MAP5
Université Paris Descartes 45, rue des Saint-Pères
75005 Paris
and
Laboratory LSTA
Université Pierre et Marie Curie 4, place Jussieu
75005 Paris
charlotte.dion@upmc.fr
Simone Hermann
Mathematik Raum 744
Anschrift: Fakultät Statistik
Technische Universität Dortmund
44221 Dortmund
hermann@statistik.tu-dortmund.de
Adeline Samson
Laboratory Jean Kuntzmann
Université Grenoble Alpes
Batiment IMAG
700 avenue Centrale
Campus de Saint Martin d’Hères BP 53
38041 Grenoble cedex 09 - France
adeline.leclercq-samson@univ-grenoble-alpes.fr

The R Journal Vol. 11/01, June 2019

ISSN 2073-4859

