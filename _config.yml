markdown: kramdown
issues:
- issue: accepted
  articles:
  - title: 'iotools: High-Performance I/O Tools for R'
    bibtitle: 'iotools: High-Performance I/O Tools for R'
    slug: RJ-2017-001
    author:
    - Taylor Arnold
    - Michael J. Kane
    - Simon Urbanek
    bibauthor: Taylor Arnold and Michael J. Kane and Simon Urbanek
    abstract: '  Abstract The iotools package provides a set of tools for input and
      output intensive data processing in            R. The functions chunk.apply
      and read.chunk are supplied to allow for iteratively loading contiguous            blocks
      of data into memory as raw vectors. These raw vectors can then be efficiently
      converted            into matrices and data frames with the iotools functions
      mstrsplit and dstrsplit. These functions            minimize copying of data
      and avoid the use of intermediate strings in order to drastically improve            performance.
      Finally, we also provide read.csv.raw to allow users to read an entire dataset
      into            memory with the same efficient parsing code. In this paper,
      we present these functions through a            set of examples with an emphasis
      on the flexibility provided by chunk-wise operations. We provide            benchmarks
      comparing the speed of read.csv.raw to data loading functions provided in base
      R and            other contributed packages.'
    acknowledged: '2015-03-20'
    online: '2017-05-10'
    CRANpkgs:
    - bigmemory
    - ff
    - readr
    - foreach
    - iterators
    - iotools
    CTV_rev: HighPerformanceComputing
    landing: '2017'
  - title: 'IsoGeneGUI: Multiple Approaches for Dose-Response Analysis of Microarray
      Data Using R'
    bibtitle: |-
      IsoGeneGUI: Multiple Approaches for Dose-Response Analysis
                of Microarray Data Using R
    slug: RJ-2017-002
    author:
    - Martin Otava
    - Rudradev Sengupta
    - Ziv Shkedy
    - Dan Lin
    - Setia Pramana
    - Tobias Verbeke
    - Philippe            Haldermans
    - Ludwig A. Hothorn
    - Daniel Gerhard
    - Rebecca M. Kuiper
    - Florian Klinglmueller
    - '           Adetayo Kasim'
    bibauthor: |-
      Martin Otava and Rudradev Sengupta and Ziv Shkedy and
                Dan Lin and Setia Pramana and Tobias Verbeke and Philippe
                Haldermans and Ludwig A. Hothorn and Daniel Gerhard and
                Rebecca M. Kuiper and Florian Klinglmueller and Adetayo
                Kasim
    abstract: '  Abstract The analysis of transcriptomic experiments with ordered
      covariates, such as dose-response            data, has become a central topic
      in bioinformatics, in particular in omics studies. Consequently,            multiple
      R packages on CRAN and Bioconductor are designed to analyse microarray data
      from various            perspectives under the assumption of order restriction.
      We introduce the new R package IsoGene            Graphical User Interface (IsoGeneGUI),
      an extension of the original IsoGene package that includes            methods
      from most of available R packages designed for the analysis of order restricted
      microarray            data, namely orQA, ORIClust, goric and ORCME. The methods
      included in the new IsoGeneGUI            range from inference and estimation
      to model selection and clustering tools. The IsoGeneGUI is not            only
      the most complete tool for the analysis of order restricted microarray experiments
      available in            R but also it can be used to analyse other types of
      dose-response data. The package provides all the            methods in a user
      friendly fashion, so analyses can be implemented by users with limited knowledge            of
      R programming.'
    acknowledged: '2015-07-22'
    online: '2017-05-10'
    CRANpkgs:
    - IsoGene
    - orQA
    - goric
    - ORCME
    - ORIClust
    - limma
    - mratios
    CTV_rev: Cluster
    landing: '2017'
  - title: 'OrthoPanels: An R Package for Estimating a Dynamic Panel Model with Fixed
      Effects Using the Orthogonal Re-parameterization Approach'
    bibtitle: |-
      OrthoPanels: An R Package for Estimating a Dynamic
                Panel Model with Fixed Effects Using the Orthogonal Re-
                parameterization Approach
    slug: RJ-2017-003
    author:
    - Mark Pickup
    - Paul Gustafson
    - Davor Cubranic
    - Geoffrey Evans
    bibauthor: |-
      Mark Pickup and Paul Gustafson and Davor Cubranic and
                Geoffrey Evans
    abstract: '  Abstract This article describes the R package OrthoPanels, which
      includes the function opm(). This            function implements the orthogonal
      reparameterization approach recommended by Lancaster (2002) to            estimate
      dynamic panel models with fixed effects (and optionally: wave specific intercepts).
      This article            provides a statistical description of the orthogonal
      reparameterization approach, a demonstration of            the package using
      real-world data, and simulations comparing the estimator to the known-to-be-biased            OLS
      estimator and the commonly used GMM estimator.'
    acknowledged: '2015-11-15'
    online: '2017-05-10'
    CRANpkgs:
    - OrthoPanels
    - plm
    CTV_rev:
    - Econometrics
    - SpatioTemporal
    landing: '2017'
  - title: 'smoof: Single- and Multi-Objective Optimization Test Functions'
    bibtitle: |-
      smoof: Single- and Multi-Objective Optimization Test
                Functions
    slug: RJ-2017-004
    author: Jakob Bossek
    bibauthor: Jakob Bossek
    abstract: '  Abstract Benchmarking algorithms for optimization problems usually
      is carried out by running the            algorithms under consideration on a
      diverse set of benchmark or test functions. A vast variety of            test
      functions was proposed by researchers and is being used for investigations in
      the literature. The            smoof package implements a large set of test
      functions and test function generators for both the single           and multi-objective
      case in continuous optimization and provides functions to easily create own
      test            functions. Moreover, the package offers some additional helper
      methods, which can be used in the            context of optimization.'
    acknowledged: '2016-02-28'
    online: '2017-05-10'
    CRANpkgs:
    - emoa
    - mco
    - ecr
    - cec2005benchmark
    - cec2013
    - globalOptTests
    - soobench
    - smoof
    - ParamHelpers
    - ggplot2
    CTVs: Optimization
    CTV_rev:
    - Optimization
    - Graphics
    - Phylogenetics
    landing: '2017'
  - title: ' alineR: an R Package for Optimizing Feature-Weighted Alignments and Linguistic
      Distances'
    bibtitle: |-
      alineR: an R Package for Optimizing Feature-Weighted
                Alignments and Linguistic Distances
    slug: RJ-2017-005
    author:
    - Sean S. Downey
    - Guowei Sun
    - Peter Norquest
    bibauthor: Sean S. Downey and Guowei Sun and Peter Norquest
    abstract: '  Abstract Linguistic distance measurements are commonly used in anthropology
      and biology when            quantitative and statistical comparisons between
      words are needed. This is common, for example,            when analyzing linguistic
      and genetic data. Such comparisons can provide insight into historical            population
      patterns and they provide general insight into evolutionary processes. However,
      the            most commonly used linguistic distances are derived from edit
      distances, which do not weight            phonetic features that may, for example,
      represent smaller-scale patterns in linguistic evolution. Thus,            computational
      methods for calculating feature-weighted linguistic distances are needed for
      linguistic,            biological, and evolutionary applications; additionally,
      the linguistic distances presented here are            generic and may have
      broader applications in fields such as text mining and search, as well as            applications
      in psycholinguistics and morphology. To facilitate this research, we are making
      our            software available as an open-source R software package that
      performs feature-weighted linguistic            distance calculations. The package
      includes a supervised learning methodology that uses a genetic            algorithm
      and manually determined alignments to estimate 13 linguistic parameters including
      feature            weights and a skip penalty. Here we present the package and
      use it to demonstrate a supervised            learning methodology to estimate
      the optimal linguistic parameters for a sample of Austronesian            languages.
      Our results show that the methodology can estimate these parameters for both
      simulated            language data and for real language data, that optimizing
      feature weights improves alignment            accuracy by approximately 29%,
      and that optimization and significantly affects the resulting distance            measurements.
      Availability: alineR is available on CRAN.'
    acknowledged: '2016-04-18'
    online: '2017-05-10'
    CRANpkgs:
    - alineR
    - stringdist
    - RecordLinkage
    - doMC
    BIOpkgs: Biostrings
    CTV_rev:
    - OfficialStatistics
    - HighPerformanceComputing
    landing: '2017'
  - title: Implementing a Metapopulation Bass Diffusion Model using the R Package
      deSolve
    bibtitle: |-
      Implementing a Metapopulation Bass Diffusion Model using the
                R Package deSolve
    slug: RJ-2017-006
    author: Jim Duggan
    bibauthor: Jim Duggan
    abstract: '  Abstract Diffusion is a fundamental process in physical, biological,
      social and economic settings.            Consumer products often go viral, with
      sales driven by the word of mouth effect, as their adoption            spreads
      through a population. The classic diffusion model used for product adoption
      is the Bass            diffusion model, and this divides a population into two
      groups of people: potential adopters who            are likely to adopt a product,
      and adopters who have purchased the product, and influence others            to
      adopt. The Bass diffusion model is normally captured in an aggregate form, where
      no significant            consumer differences are modeled. This paper extends
      the Bass model to capture a spatial perspective,            using metapopulation
      equations from the field of infectious disease modeling. The paper’s focus is
      on            simulation of deterministic models by solving ordinary differential
      equations, and does not encompass            parameter estimation. The metapopulation
      model in implemented in R using the deSolve package,            and shows the
      potential of using the R framework to implement large-scale integral equation
      models,            with applications in the field of marketing and consumer
      behaviour.'
    acknowledged: '2016-04-30'
    online: '2017-05-10'
    CRANpkgs:
    - deSolve
    - EpiModel
    - ggplot2
    - scales
    CTV_rev:
    - DifferentialEquations
    - Graphics
    - Phylogenetics
    landing: '2017'
  - title: 'MDplot: Visualise Molecular Dynamics'
    bibtitle: 'MDplot: Visualise Molecular Dynamics'
    slug: RJ-2017-007
    author:
    - Christian Margreitter
    - Chris Oostenbrink
    bibauthor: Christian Margreitter and Chris Oostenbrink
    abstract: '  Abstract The MDplot package provides plotting functions to allow
      for automated visualisation of            molecular dynamics simulation output.
      It is especially useful in cases where the plot generation is            rather
      tedious due to complex file formats or when large amounts of plots are generated.
      The graphs            that are supported range from those which are standard
      such as RMSD/RMSF (root-mean-square            deviation and root-mean-square
      fluctuation, respectively) to thermodynamic integration analysis and            hydrogen
      bond monitoring over time and address many commonly used analyses. In this article,            we
      set out the package’s functions, give examples of the function calls and show
      the associated            plots. Plotting and data parsing is separated in all
      cases, i.e. the respective functions can be used            independently. Thus,
      data manipulation and the integration of additional file formats is fairly easy.            Currently,
      the loading functions support GROMOS, GROMACS and AMBER file formats. Moreover,            we
      also provide a bash interface that allows simple embedding of MDplot into bash
      scripts as the final            analysis step.            Availability: The
      package can be obtained in the latest major version from CRAN (https://cran.r           project.org/package=MDplot)
      or in the most recent version from the project’s GitHub page at            https://github.com/MDplot/MDplot,
      where feedback is also most welcome. MDplot is published            under the
      GPL-3 license.'
    acknowledged: '2016-04-30'
    online: '2017-05-10'
    CRANpkgs:
    - MDplot
    - bio3d
    - Rknots
    landing: '2017'
  - title: 'On some extensions to GA package: hybrid optimisation, parallelisation
      and islands evolution'
    bibtitle: |-
      On some extensions to GA package: hybrid optimisation,
                parallelisation and islands evolution
    slug: RJ-2017-008
    author: Luca Scrucca
    bibauthor: Luca Scrucca
    abstract: '  Abstract Genetic algorithms are stochastic iterative algorithms in
      which a population of individuals            evolve by emulating the process
      of biological evolution and natural selection. The R package GA            provides
      a collection of general purpose functions for optimisation using genetic algorithms.
      This            paper describes some enhancements recently introduced in version
      3 of the package. In particular,            hybrid GAs have been implemented
      by including the option to perform local searches during the            evolution.
      This allows to combine the power of genetic algorithms with the speed of a local
      optimiser.            Another major improvement is the provision of facilities
      for parallel computing. Parallelisation has            been implemented using
      both the master-slave approach and the islands evolution model. Several            examples
      of usage are presented, with both real-world data examples and benchmark functions,            showing
      that often high-quality solutions can be obtained more efficiently.'
    acknowledged: '2016-05-29'
    online: '2017-05-10'
    CRANpkgs:
    - rgenoud
    - Rmalschains
    - DEoptim
    - GenSA
    - pso
    - cmaes
    - tabuSearch
    - GA
    - quantmod
    - doParallel
    - foreach
    - iterators
    - doRNG
    - forecast
    - astsa
    - globalOptTests
    - Rcpp
    - memoise
    CTVs:
    - Optimization
    - HighPerformanceComputing
    CTV_rev:
    - Optimization
    - HighPerformanceComputing
    - Finance
    - MachineLearning
    - TimeSeries
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    landing: '2017'
  - title: 'imputeTS: Time Series Missing Value Imputation in R'
    bibtitle: 'imputeTS: Time Series Missing Value Imputation in R'
    slug: RJ-2017-009
    author:
    - Steffen Moritz
    - Thomas Bartz-Beielstein
    bibauthor: Steffen Moritz and Thomas Bartz-Beielstein
    abstract: '  Abstract The imputeTS package specializes on univariate time series
      imputation. It offers multiple            state-of-the-art imputation algorithm
      implementations along with plotting functions for time series            missing
      data statistics. While imputation in general is a well-known problem and widely
      covered by R            packages, finding packages able to fill missing values
      in univariate time series is more complicated. The            reason for this
      lies in the fact that most imputation algorithms rely on inter-attribute correlations,
      while            univariate time series imputation instead needs to employ time
      dependencies. This paper provides an            introduction to the imputeTS
      package and its provided algorithms and tools. Furthermore, it gives a            short
      overview about univariate time series imputation in R.'
    acknowledged: '2016-07-12'
    online: '2017-05-10'
    CRANpkgs:
    - AMELIA
    - mice
    - VIM
    - missMDA
    - imputeTS
    - zoo
    - forecast
    - spacetime
    - timeSeries
    - xts
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - OfficialStatistics
    - Environmetrics
    - Multivariate
    - SocialSciences
    - SpatioTemporal
    - Psychometrics
    - Spatial
    landing: '2017'
  - title: Update of the nlme Package to Allow a Fixed Standard Deviation of the Residual
      Error
    bibtitle: |-
      Update of the nlme Package to Allow a Fixed Standard
                Deviation of the Residual Error
    slug: RJ-2017-010
    author:
    - Simon H. Heisterkamp
    - Engelbertus van Willigen
    - Paul-Matthias Diderichsen
    - John Maringwa
    bibauthor: |-
      Simon H. Heisterkamp and Engelbertus van Willigen and Paul-
                Matthias Diderichsen and John Maringwa
    abstract: '  Abstract The use of linear and non-linear mixed models in the life
      sciences and pharmacometrics            is common practice. Estimation of the
      parameters of models not involving a system of differential            equations
      is often done by the R or S-Plus software with the nonlinear mixed effects nlme
      package.            The estimated residual error may be used for diagnosis of
      the fitted model, but not whether the            model correctly describes the
      relation between response and included variables including the true            covariance
      structure. The latter is only true if the residual error is known in advance.
      Therefore, it            may be necessary or more appropriate to fix the residual
      error a priori instead of estimate its value.            This can be the case
      if one wants to include evidence from past studies or a theoretical derivation;            e.g.,
      when using a binomial model. S-Plus has an option to fix this residual error
      to a constant, in            contrast to R. For convenience, the nlme package
      was customized to offer this option as well. In this            paper, we derived
      the log-likelihoods for the mixed models using a fixed residual error. By using
      some            well-known examples from mixed models, we demonstrated the equivalence
      of R and S-Plus with            respect to the estimates. The updated package
      has been accepted by the Comprehensive R Archive            Network (CRAN) team
      and will be available at the CRAN website.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs: nlme
    CTV_rev:
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - Spatial
    - SpatioTemporal
    landing: '2017'
  - title: 'EMSaov: An R Package for the Analysis of Variances with the Expected Mean
      Squares and its Shiny Application'
    bibtitle: |-
      EMSaov: An R Package for the Analysis of Variances with the
                Expected Mean Squares and its Shiny Application
    slug: RJ-2017-011
    author:
    - Hye-Min Choe
    - Mijeong Kim
    - Eun-Kyung Lee
    bibauthor: Hye-Min Choe and Mijeong Kim and Eun-Kyung Lee
    abstract: '  Abstract EMSaov is a new R package that we developed to provide users
      with an analysis of variance            table including the expected mean squares
      (EMS) for various types of experimental design. It is not            easy to
      find the appropriate test, particularly the denominator for the F statistic
      that depends on the            EMS, when some variables exhibit random effects
      or when we use a special experimental design such            as nested design,
      repeated measures design, or split-plot design. With EMSaov, a user can easily            find
      the F statistic denominator and can determine how to analyze the data when using
      a special            experimental design. We also develop a web application
      with a GUI interface using the shiny package            in R . We expect that
      our application can contribute to the efficient and easy analysis of experimental            data.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - nlme
    - afex
    - EMSaov
    - shiny
    CTV_rev:
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - Spatial
    - SpatioTemporal
    - WebTechnologies
    landing: '2017'
  - title: 'GsymPoint: An R Package to Estimate the Generalized Symmetry Point, an
      Optimal Cut-off Point for Binary Classification in Continuous Diagnostic Tests'
    bibtitle: |-
      GsymPoint: An R Package to Estimate the Generalized Symmetry
                Point, an Optimal Cut-off Point for Binary Classification in
                Continuous Diagnostic Tests
    slug: RJ-2017-015
    author:
    - Mónica López-Ratón
    - Elisa M. Molanes-López
    - Emilio Letón
    - Carmen Cadarso-Suárez
    bibauthor: |-
      Mónica López-Ratón and Elisa M. Molanes-López and Emilio
                Letón and Carmen Cadarso-Suárez
    abstract: '  Abstract In clinical practice, it is very useful to select an optimal
      cutpoint in the scale of a continuous            biomarker or diagnostic test
      for classifying individuals as healthy or diseased. Several methods for            choosing
      optimal cutpoints have been presented in the literature, depending on the ultimate
      goal. One            of these methods, the Generalized Symmetry point, recently
      introduced, generalizes the Symmetry            point by incorporating the misclassification
      costs. Two statistical approaches have been proposed in the            literature
      for estimating this optimal cutpoint and its associated sensitivity and specificity
      measures, a            parametric method based on the Generalized Pivotal Quantity
      and a nonparametric method based on            Empirical Likelihood. In this
      paper, we introduce GsymPoint, an R package that implements these            methods
      in a user-friendly environment, allowing the end-user to calculate the Generalized
      Symmetry            point depending on the levels of certain categorical covariates.
      The practica l use of this package is            illustrated using three real
      biomedical datasets.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - GsymPoint
    - PresenceAbsence
    - DiagnosisMed
    - pROC
    - OptimalCutpoints
    - GsymPoint
    landing: '2017'
  - title: Multilabel Classification with R Package mlr
    bibtitle: Multilabel Classification with R Package mlr
    slug: RJ-2017-012
    author:
    - Philipp Probst
    - Quay Au
    - Giuseppe Casalicchio
    - Clemens Stachl
    - Bernd Bischl
    bibauthor: |-
      Philipp Probst and Quay Au and Giuseppe Casalicchio and
                Clemens Stachl and Bernd Bischl
    abstract: '  Abstract We implemented several multilabel classification algorithms
      in the machine learning package            mlr. The implemented methods are
      binary relevance, classifier chains, nested stacking, dependent            binary
      relevance and stacking, which can be used with any base learner that is accessible
      in mlr.            Moreover, there is access to the multilabel classification
      versions of randomForestSRC and rFerns.            All these methods can be
      easily compared by different implemented multilabel performance measures            and
      resampling methods in the standardized mlr framework. In a benchmark experiment
      with several            multilabel datasets, the performance of the different
      methods is evaluated.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - mldr
    - rFerns
    - randomForestSRC
    - randomForestSRC
    - ada
    - batchtools
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
    - Survival
    landing: '2017'
  - title: 'pdp: An R Package for Constructing Partial Dependence Plots'
    bibtitle: 'pdp: An R Package for Constructing Partial Dependence Plots'
    slug: RJ-2017-016
    author: Brandon M. Greenwell
    bibauthor: Brandon M. Greenwell
    abstract: '  Abstract Complex nonparametric models—like neural networks, random
      forests, and support vector            machines—are more common than ever in
      predictive analytics, especially when dealing with large            observational
      databases that don’t adhere to the strict assumptions imposed by traditional
      statistical            techniques (e.g., multiple linear regression which assumes
      linearity, homoscedasticity, and normality).            Unfortunately, it can
      be challenging to understand the results of such models and explain them to            management.
      Partial dependence plots offer a simple solution. Partial dependence plots are
      low           dimensional graphical renderings of the prediction function fb
      ( x) so that the relationship between the            outcome and predictors
      of interest can be more easily understood. These plots are especially useful
      in            explaining the output from black box models. In this paper, we
      introduce pdp, a general R package            for constructing partial dependence
      plots.'
    acknowledged: '2016-09-30'
    online: '2017-05-10'
    CRANpkgs:
    - randomForest
    - gbm
    - party
    - partykit
    - pdp
    - plotmo
    - lattice
    - ICEbox
    - car
    - effects
    - ggplot2
    - grid
    - latticeExtra
    - gridExtra
    - nnet
    - C50
    - rpart
    - adabag
    - ipred
    - adabag
    - xgboost
    - Cubist
    - MASS
    - earth
    - mda
    - ranger
    - e1071
    - kernlab
    - caret
    - magrittr
    - foreach
    - viridis
    - plyr
    - doMC
    - doParallel
    - dplyr
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Environmetrics
    - Survival
    - Econometrics
    - SocialSciences
    - Graphics
    - HighPerformanceComputing
    - Cluster
    - Distributions
    - Psychometrics
    - Finance
    - NaturalLanguageProcessing
    - NumericalMathematics
    - Optimization
    - Phylogenetics
    - Robust
    - WebTechnologies
    landing: '2017'
  - title: 'milr: Multiple-Instance Logistic Regression with Lasso Penalty'
    bibtitle: |-
      milr: Multiple-Instance Logistic Regression with Lasso
                Penalty
    slug: RJ-2017-013
    author:
    - Ping-Yang Chen
    - Ching-Chuan Chen
    - Chun-Hao Yang
    - Sheng-Mao Chang
    - Kuo-Jung Lee
    bibauthor: |-
      Ping-Yang Chen and Ching-Chuan Chen and Chun-Hao Yang and
                Sheng-Mao Chang and Kuo-Jung Lee
    abstract: '  Abstract The purpose of the proposed package milr is to analyze multiple-instance
      data. Ordinary            multiple-instance data consists of many independent
      bags, and each bag is composed of several            instances. The statuses
      of bags and instances are binary. Moreover, the statuses of instances are not            observed,
      whereas the statuses of bags are observed. The functions in this package are
      applicable            for analyzing multiple-instance data, simulating data
      via logistic regression, and selecting important            covariates in the
      regression model. To this end, maximum likelihood estimation with an expectation           maximization
      algorithm is implemented for model estimation, and a lasso penalty added to
      the            likelihood function is applied for variable selection. Additionally,
      an “milr” object is applicable to            generic functions fitted, predict
      and summary. Simulated data and a real example are given to            demonstrate
      the features of this package.'
    acknowledged: '2016-11-16'
    online: '2017-05-10'
    CRANpkgs: milr
    landing: '2017'
  - title: 'spcadjust: An R Package for Adjusting for Estimation Error in Control
      Charts'
    bibtitle: |-
      spcadjust: An R Package for Adjusting for Estimation Error
                in Control Charts
    slug: RJ-2017-014
    author:
    - Axel Gandy
    - Jan Terje Kvaløy
    bibauthor: Axel Gandy and Jan Terje Kvaløy
    abstract: '  Abstract In practical applications of control charts the in-control
      state and the corresponding chart            parameters are usually estimated
      based on some past in-control data. The estimation error then            needs
      to be accounted for. In this paper we present an R package, spcadjust, which
      implements a            bootstrap based method for adjusting monitoring schemes
      to take into account the estimation error.            By bootstrapping the past
      data this method guarantees, with a certain probability, a conditional            performance
      of the chart. In spcadjust the method is implement for various types of Shewhart,            CUSUM
      and EWMA charts, various performance criteria, and both parametric and non-parametric            bootstrap
      schemes. In addition to the basic charts, charts based on linear and logistic
      regression            models for risk adjusted monitoring are included, and
      it is easy for the user to add further charts. Use            of the package
      is demonstrated by examples.'
    acknowledged: '2016-11-16'
    online: '2017-05-10'
    CRANpkgs:
    - spcadjust
    - surveillance
    - spc
    - qcc
    - IQCC
    - qcr
    - edcc
    - MSQC
    CTV_rev:
    - Environmetrics
    - SpatioTemporal
    - TimeSeries
    landing: '2017'
  - title: Weighted Effect Coding for Observational Data with wec
    bibtitle: Weighted Effect Coding for Observational Data with wec
    slug: RJ-2017-017
    author:
    - Rense Nieuwenhuis
    - Manfred te Grotenhuis
    - Ben Pelzer
    bibauthor: Rense Nieuwenhuis and Manfred te Grotenhuis and Ben Pelzer
    abstract: '  Abstract Weighted effect coding refers to a specific coding matrix
      to include factor variables in            generalised linear regression models.
      With weighted effect coding, the effect for each category            represents
      the deviation of that category from the weighted mean (which corresponds to
      the sample            mean). This technique has particularly attractive properties
      when analysing observational data, that            commonly are unbalanced.
      The wec package is introduced, that provides functions to apply weighted            effect
      coding to factor variables, and to interactions between (a.) a factor variable
      and a continuous            variable and between (b.) two factor variables.'
    acknowledged: '2016-12-23'
    online: '2017-05-10'
    CRANpkgs: wec
    landing: '2017'
  - title: 'coxphMIC: An R Package for Sparse Estimation of Cox Proportional Hazards
      Models via Approximated Information Criteria'
    bibtitle: |-
      coxphMIC: An R Package for Sparse Estimation of Cox
                Proportional Hazards Models via Approximated Information
                Criteria
    slug: RJ-2017-018
    author:
    - Razieh Nabi
    - Xiaogang Su
    bibauthor: Razieh Nabi and Xiaogang Su
    abstract: '  Abstract In this paper, we describe an R package named coxphMIC,
      which implements the sparse            estimation method for Cox proportional
      hazards models via approximated information criterion (Su            et al.,
      2016). The developed methodology is named MIC which stands for “Minimizing approximated            Information
      Criteria". A reparameterization step is introduced to enforce sparsity while
      at the same            time keeping the objective function smooth. As a result,
      MIC is computationally fast with a superior            performance in sparse
      estimation. Furthermore, the reparameterization tactic yields an additional            advantage
      in terms of circumventing post-selection inference (Leeb and Pötscher, 2005).
      The MIC            method and its R implementation are introduced and illustrated
      with the PBC data.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    landing: '2017'
  - title: Retrieval and Analysis of Eurostat Open Data with the eurostat Package
    bibtitle: |-
      Retrieval and Analysis of Eurostat Open Data with the
                eurostat Package
    slug: RJ-2017-019
    author:
    - Leo Lahti
    - Janne Huovari
    - Markus Kainu
    - Przemysław Biecek
    bibauthor: |-
      Leo Lahti and Janne Huovari and Markus Kainu and Przemysław
                Biecek
    abstract: '  Abstract The increasing availability of open statistical data resources
      is providing novel opportunities            for research and citizen science.
      Efficient algorithmic tools are needed to realize the full potential of the            new
      information resources. We introduce the eurostat R package that provides a collection
      of custom            tools for the Eurostat open data service, including functions
      to query, download, manipulate, and            visualize these data sets in
      a smooth, automated and reproducible manner. The online documentation            provides
      detailed examples on the analysis of these spatio-temporal data collections.
      This work            provides substantial improvements over the previously available
      tools, and has been extensively            tested by an active user community.
      The eurostat R package contributes to the growing open source            ecosystem
      dedicated to reproducible research in computational social science and digital
      humanities.'
    acknowledged: '2016-09-15'
    online: '2017-05-10'
    CRANpkgs:
    - eurostat
    - eurostat
    - eurostat
    - FAOSTAT
    - WDI
    - pxweb
    - osmar
    - eurostat
    - smarterpoland
    - eurostat
    - eurostat
    - rsdmx
    - datamart
    - quandl
    - pdfetch
    - rsdmx
    - eurostat
    - classInt
    - httr
    - jsonlite
    - readr
    - sp
    - stringi
    - eurostat
    - eurostat
    - tibble
    - eurostat
    - plotrix
    - grid
    - maptools
    - rgdal
    - rgeos
    - scales
    - stringr
    - eurostat
    - eurostat
    - countrycode
    - eurostat
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Graphics
    - NaturalLanguageProcessing
    - SpatioTemporal
    - TimeSeries
    landing: '2017'
  - title: Market Area Analysis for Retail and Service Locations with MCI
    bibtitle: |-
      Market Area Analysis for Retail and Service Locations with
                MCI
    slug: RJ-2017-020
    author: Thomas Wieland
    bibauthor: Thomas Wieland
    abstract: '  Abstract In retail location analysis, marketing research and spatial
      planning, the market areas of            stores and/or locations are a frequent
      subject. Market area analyses consist of empirical observations            and
      modeling via theoretical and/or econometric models such as the Huff Model or
      the Multiplicative            Competitive Interaction Model. The authors’ package
      MCI implements the steps of market area            analysis into R with a focus
      on fitting the models and data preparation and processing.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - MCI
    - SpatialPosition
    - ggmap
    - osmar
    - osrm
    - car
    - spgwr
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Econometrics
    - Finance
    - Multivariate
    - SocialSciences
    landing: '2017'
  - title: 'PSF: Introduction to R Package for Pattern Sequence Based Forecasting
      Algorithm'
    bibtitle: |-
      PSF: Introduction to R Package for Pattern Sequence Based
                Forecasting Algorithm
    slug: RJ-2017-021
    author:
    - Neeraj Bokde
    - Gualberto Asencio-Cortés
    - Francisco Martínez-Álvarez
    - Kishore Kulat
    bibauthor: |-
      Neeraj Bokde and Gualberto Asencio-Cortés and Francisco
                Martínez-Álvarez and Kishore Kulat
    abstract: '  Abstract This paper introduces the R package that implements the
      Pattern Sequence based Forecasting            (PSF) algorithm, which was developed
      for univariate time series forecasting. This algorithm has been            successfully
      applied to many different fields. The PSF algorithm consists of two major parts:
      clustering            and prediction. The clustering part includes selection
      of the optimum number of clusters. It labels            time series data with
      reference to such clusters. The prediction part includes functions like optimum            window
      size selection for specific patterns and prediction of future values with reference
      to past            pattern sequences. The PSF package consists of various functions
      to implement the PSF algorithm. It            also contains a function which
      automates all other functions to obtain optimized prediction results.            The
      aim of this package is to promote the PSF algorithm and to ease its usage with
      minimum efforts.            This paper describes all the functions in the PSF
      package with their syntax. It also provides a simple            example. Finally,
      the usefulness of this package is discussed by comparing it to auto.arima and
      ets,            well-known time series forecasting functions available on CRAN
      repository.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - PSF
    - cluster
    - data.table
    - forecast
    CTV_rev:
    - Environmetrics
    - Finance
    - Cluster
    - Econometrics
    - HighPerformanceComputing
    - Multivariate
    - TimeSeries
    landing: '2017'
  - title: 'BayesBinMix: an R Package for Model Based Clustering of Multivariate Binary
      Data'
    bibtitle: |-
      BayesBinMix: an R Package for Model Based Clustering of
                Multivariate Binary Data
    slug: RJ-2017-022
    author:
    - Panagiotis Papastamoulis
    - Magnus Rattray
    bibauthor: Panagiotis Papastamoulis and Magnus Rattray
    abstract: '  Abstract The BayesBinMix package offers a Bayesian framework for
      clustering binary data with or            without missing values by fitting
      mixtures of multivariate Bernoulli distributions with an unknown            number
      of components. It allows the joint estimation of the number of clusters and
      model parameters            using Markov chain Monte Carlo sampling. Heated
      chains are run in parallel and accelerate the            convergence to the
      target posterior distribution. Identifiability issues are addressed by implementing            label
      switching algorithms. The package is demonstrated and benchmarked against the
      Expectation           Maximization algorithm using a simulation study as well
      as a real dataset.'
    acknowledged: '2016-09-30'
    online: '2017-05-10'
    CRANpkgs:
    - BayesBinMix
    - label.switching
    - foreach
    - doParallel
    - coda
    - FlexMix
    - flexclust
    CTV_rev:
    - Bayesian
    - Cluster
    - gR
    - HighPerformanceComputing
    landing: '2017'
  - title: 'The mosaic package: helping students to `think with data'' using R'
    bibtitle: |-
      The mosaic package: helping students to `think with data'
                using R
    slug: RJ-2017-024
    author:
    - Randall Pruim
    - Daniel T Kaplan
    - Nicholas J Horton
    bibauthor: Randall Pruim and Daniel T Kaplan and Nicholas J Horton
    abstract: '  Abstract The mosaic package provides a simplified and systematic
      introduction to the core functional           ity related to descriptive statistics,
      visualization, modeling, and simulation-based inference required            in
      first and second courses in statistics. This introduction to the package describes
      some of the guiding            principles behind the design of the package and
      provides illustrative examples of several of the most            important functions
      it implements. These can be combined to help students “think with data" using
      R            in their early course work, starting with simple, yet powerful,
      declarative commands.'
    acknowledged: '2015-11-19'
    online: '2017-05-10'
    CRANpkgs:
    - mosaic
    - lattice
    - mosaic
    - mosaic
    - mosaicData
    - ggplot2
    - dplyr
    - parallel
    - MASS
    CTV_rev:
    - Graphics
    - Multivariate
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Phylogenetics
    - Psychometrics
    - Robust
    - SocialSciences
    landing: '2017'
  - title: 'autoimage: Multiple Heat Maps for Projected Coordinates'
    bibtitle: 'autoimage: Multiple Heat Maps for Projected Coordinates'
    slug: RJ-2017-025
    author: Joshua P. French
    bibauthor: Joshua P. French
    abstract: 'Heat maps are commonly used to display the spatial distribution of
      a response observed on a two-dimensional grid. The autoimage package provides
      convenient functions for constructing multiple heat maps in unified, seamless
      way, particularly when working with projected coordinates. The autoimage package
      natively supports: 1. automatic inclusion of a color scale with the plotted
      image, 2. construction of heat maps for responses observed on regular or irregular
      grids, as well as non-gridded data, 3. construction of a matrix of heat maps
      with a common color scale, 4. construction of a matrix of heat maps with individual
      color scales, 5. projecting coordinates before plotting, 6. easily adding geographic
      borders, points, and other features to the heat maps. After comparing the autoimage
      package’s capabilities for constructing heat maps to those of existing tools,
      a carefully selected set of examples is used to highlight the capabilities of
      the autoimage package.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - autoimage
    - fields
    - lattice
    - sp
    - ggplot2
    - spatstat
    - gridExtra
    - cowplot
    - akima
    - mapproj
    - gear
    - viridisLite
    - maps
    CTV_rev:
    - Spatial
    - Graphics
    - SpatioTemporal
    - Multivariate
    - NumericalMathematics
    - Phylogenetics
    - Survival
    landing: '2017'
  - title: Network Visualization with ggplot2
    bibtitle: Network Visualization with ggplot2
    slug: RJ-2017-023
    author:
    - Sam Tyner
    - François Briatte
    - Heike Hofmann
    bibauthor: Sam Tyner and François Briatte and Heike Hofmann
    abstract: '  Abstract This paper explores three different approaches to visualize
      networks by building on the            grammar of graphics framework implemented
      in the ggplot2 package. The goal of each approach is            to provide the
      user with the ability to apply the flexibility of ggplot2 to the visualization
      of network            data, including through the mapping of network attributes
      to specific plot aesthetics. By incorporating            networks in the ggplot2
      framework, these approaches (1) allow users to enhance networks with            additional
      information on edges and nodes, (2) give access to the strengths of ggplot2,
      such as layers            and facets, and (3) convert network data objects to
      the more familiar data frames.'
    acknowledged: '2015-11-14'
    online: '2017-05-10'
    CRANpkgs:
    - igraph
    - sna
    - network
    - statnet
    - ggplot2
    - ggnetwork
    - geomnet
    - ggmap
    - ggfortify
    - GGally
    - gcookbook
    - intergraph
    - grid
    - ggrepel
    - ndtv
    - gridExtra
    - tnet
    - ggCompNet
    - tidyverse
    - plyr
    - dplyr
    BIOpkgs:
    - ggbio
    - ggtree
    CTV_rev:
    - gR
    - SocialSciences
    - Graphics
    - Optimization
    - Spatial
    - Bayesian
    - Phylogenetics
    - WebTechnologies
    landing: '2017'
  - title: 'Hosting Data Packages via drat: A Case Study with Hurricane Exposure Data'
    bibtitle: |-
      Hosting Data Packages via drat: A Case Study with Hurricane
                Exposure Data
    slug: RJ-2017-026
    author:
    - G. Brooke Anderson
    - Dirk Eddelbuettel
    bibauthor: G. Brooke Anderson and Dirk Eddelbuettel
    abstract: '  Abstract Data-only packages offer a way to provide extended functionality
      for other R users. However,            such packages can be large enough to
      exceed the package size limit (5 megabytes) for the Comprehen           sive
      R Archive Network (CRAN). As an alternative, large data packages can be posted
      to additional            repostiories beyond CRAN itself in a way that allows
      smaller code packages on CRAN to access and            use the data. The drat
      package facilitates creation and use of such alternative repositories and makes            it
      particularly simple to host them via GitHub. CRAN packages can draw on packages
      posted to drat            repositories through the use of the ‘Additonal_repositories’
      field in the DESCRIPTION file. This paper            describes how R users can
      create a suite of coordinated packages, in which larger data packages are            hosted
      in an alternative repository created with drat, while a smaller code package
      that interacts with            this data is created that can be submitted to
      CRAN.'
    acknowledged: '2017-02-17'
    online: '2017-05-10'
    CRANpkgs:
    - NMMAPSlite
    - stashR
    - rnoaa
    - tigris
    - UScensus2000
    - drat
    - grattan
    - hurricaneexposure
    - devtools
    - rcmdcheck
    - git2r
    - littler
    - knitr
    - roxygen2
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
    landing: '2017'
  - title: 'The NoiseFiltersR Package: Label Noise Preprocessing in R'
    bibtitle: 'The NoiseFiltersR Package: Label Noise Preprocessing in R'
    slug: RJ-2017-027
    author:
    - Pablo Morales
    - Julián Luengo
    - Luís P.F. Garcia
    - Ana C. Lorena
    - André C.P.L.F. de Carvalho
    - '           Francisco Herrera'
    bibauthor: |-
      Pablo Morales and Julián Luengo and Luís P.F. Garcia and
                Ana C. Lorena and André C.P.L.F. de Carvalho and Francisco
                Herrera
    abstract: '  Abstract In Data Mining, the value of extracted knowledge is directly
      related to the quality of the            used data. This makes data preprocessing
      one of the most important steps in the knowledge discovery            process.
      A common problem affecting data quality is the presence of noise. A training
      set with label            noise can reduce the predictive performance of classification
      learning techniques and increase the            overfitting of classification
      models. In this work we present the NoiseFiltersR package. It contains the            first
      extensive R implementation of classical and state-of-the-art label noise filters,
      which are the most            common techniques for preprocessing label noise.
      The algorithms used for the implementation of the            label noise filters
      are appropriately documented and referenced. They can be called in a R-user-friendly            manner,
      and their results are unified by means of the "filter" class, which also benefits
      from adapted            print and summary methods.'
    acknowledged: '2016-07-12'
    online: '2017-05-10'
    CRANpkgs:
    - MICE
    - Amelia
    - caret
    - FSelector
    - mvoutlier
    - robustDA
    - probFDA
    - NoiseFiltersR
    - unbalanced
    - RWeka
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Robust
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - OfficialStatistics
    - SocialSciences
    landing: '2017'
- issue: 2009-1
  year: 2009
  volume: 1
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2009-008
    old_slug: Chambers
    title: Facets of R
    bibtitle: Facets of R
    author: John M. Chambers
    bibauthor: John M. Chambers
    landing: '2009'
    abstract: We are seeing today a widespread, and welcome, tendency for non-computer-specialists
      among statisticians and others to write collections of R functions that organize
      and communicate their work. Along with the flood of software sometimes comes
      an attitude that one need only learn, or teach, a sort of basic how-to-write-the-function
      level of R programming, beyond which most of the detail is unimportant or can
      be absorbed without much discussion. As delusions go, this one is not very objectionable
      if it encourages participation. Nevertheless, a delusion it is. In fact, functions
      are only one of a variety of important facets that R has acquired by intent
      or circumstance during the three-plus decades of the history of the software
      and of its predecessor S. To create valuable and trustworthy software using
      R often requires an understanding of some of these facets and their interrelations.
      This paper identifies six facets, discussing where they came from, how they
      support or conflict with each other, and what implications they have for the
      future of programming with R.
    pages:
    - 5
    - 8
  - slug: RJ-2009-007
    old_slug: Theussl+Zeileis
    title: Collaborative Software Development Using R-Forge
    bibtitle: Collaborative Software Development Using R-Forge
    author:
    - Stefan Theußl
    - Achim Zeileis
    bibauthor: Stefan Theußl and Achim Zeileis
    landing: '2009'
    abstract: 'Open source software (OSS) is typically created in a decentralized
      self-organizing process by a community of developers having the same or similar
      interests (see the famous essay by ?). A key factor for the success of OSS over
      the last two decades is the Internet: Developers who rarely meet face-to-face
      can employ new means of communication, both for rapidly writing and deploying
      software (in the spirit of Linus Torvald’s “release early, release often paradigm”).
      Therefore, many tools emerged that assist a collaborative software development
      process, including in particular tools for source code management (SCM) and
      version control.'
    pages:
    - 9
    - 14
  - slug: RJ-2009-006
    old_slug: Murrell
    title: Drawing Diagrams with R
    bibtitle: Drawing Diagrams with R
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2009'
    abstract: R provides a number of well-known high-level facilities for producing
      sophisticated statistical plots, including the “traditional” plots in the graphics
      package (R Development Core Team, 2008), the Trellis-style plots provided by
      lattice (Sarkar, 2008), and the grammar-of-graphics-inspired approach of ggplot2
      (Wickham, 2009).
    pages:
    - 15
    - 21
    CRANpkgs:
    - graphics
    - lattice
    - ggplot2
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
  - slug: RJ-2009-009
    old_slug: Pau+Huber
    title: 'The hwriter package: Composing HTML documents with R objects'
    bibtitle: 'The hwriter package: Composing HTML documents with R objects'
    author:
    - Gregoire Pau
    - Wolfgang Huber
    bibauthor: Gregoire Pau and Wolfgang Huber
    landing: '2009'
    abstract: HTML documents are structured documents made of diverse elements such
      as paragraphs, sections, columns, figures and tables organized in a hierarchical
      layout. Combination of HTML documents and hyperlinking is useful to report analysis
      results; for example, in the package arrayQualityMetrics, estimating the quality
      of microarray data sets and cellHTS2, performing the analysis of cell-based
      screens.
    pages:
    - 22
    - 24
  - slug: RJ-2009-003
    old_slug: Ardia+et+al
    title: AdMit
    bibtitle: AdMit
    author:
    - David Ardia
    - Lennart F. Hoogerheide
    - Herman K. van Dijk
    bibauthor: |-
      David Ardia and Lennart F. Hoogerheide and Herman K. van
                Dijk
    landing: '2009'
    abstract: A package for constructing and using an adaptive mixture of Student-t
      distributions as a flexible candidate distribution for efficient simulation.
    pages:
    - 25
    - 30
  - slug: RJ-2009-005
    old_slug: Goulet+et+al
    title: 'expert: Modeling Without Data Using Expert Opinion'
    bibtitle: 'expert: Modeling Without Data Using Expert Opinion'
    author:
    - Vincent Goulet
    - Michel Jacques
    - Mathieu Pigeon
    bibauthor: Vincent Goulet and Michel Jacques and Mathieu Pigeon
    landing: '2009'
    abstract: The expert package provides tools to create and manipulate empirical
      statistical models using expert opinion (or judgment). Here, the latter expression
      refers to a specific body of techniques to elicit the distribution of a random
      variable when data is scarce or unavailable. Opinions on the quantiles of the
      distribution are sought from experts in the field and aggregated into a final
      estimate. The package supports aggregation by means of the Cooke, Mendel–Sheridan
      and predefined weights models.
    pages:
    - 31
    - 36
  - slug: RJ-2009-001
    old_slug: Mi+et+al
    title: New Numerical Algorithm for Multivariate Normal Probabilities in Package
      mvtnorm
    bibtitle: |-
      New Numerical Algorithm for Multivariate Normal
                Probabilities in Package mvtnorm
    author:
    - Xuefei Mi
    - Tetsuhisa Miwa
    - Torsten Hothorn
    bibauthor: Xuefei Mi and Tetsuhisa Miwa and Torsten Hothorn
    landing: '2009'
    abstract: '? proposed a numerical algorithm for evaluating multivariate normal
      probabilities. Starting with version 0.9-0 of the mvtnorm package (??), this
      algorithm is available to the R community. We give a brief introduction to Miwa’s
      procedure and compare it to a quasi-randomized Monte-Carlo procedure proposed
      by ?, which has been available through mvtnorm for some years now, both with
      respect to computing time and accuracy.'
    pages:
    - 37
    - 39
  - slug: RJ-2009-002
    old_slug: Kim+Oh
    title: 'EMD: A Package for Empirical Mode Decomposition and Hilbert Spectrum'
    bibtitle: |-
      EMD: A Package for Empirical Mode Decomposition and Hilbert
                Spectrum
    author:
    - Donghoh Kim
    - Hee-Seok Oh
    bibauthor: Donghoh Kim and Hee-Seok Oh
    landing: '2009'
    abstract: The concept of empirical mode decomposition (EMD) and the Hilbert spectrum
      (HS) has been developed rapidly in many disciplines of science and engineering
      since Huang et al. (1998) invented EMD. The key feature of EMD is to decompose
      a signal into so-called intrinsic mode function (IMF). Furthermore, the Hilbert
      spectral analysis of intrinsic mode functions provides frequency information
      evolving with time and quantifies the amount of variation due to oscillation
      at different time scales and time locations. In this article, we introduce an
      R package called EMD (Kim and Oh, 2008) that performs oneand twodimensional
      EMD and HS.
    pages:
    - 40
    - 46
  - slug: Orr+Liu
    title: Sample Size Estimation while Controlling False Discovery Rate for Microarray
      Experiments Using the ssize.fdr Package
    bibtitle: Sample Size Estimation while Controlling False Discovery Rate for Microarray
      Experiments Using the {ssize.fdr} Package
    author:
    - Megan Orr
    - Peng Liu
    pages:
    - 47
    - 53
  - slug: RJ-2009-004
    old_slug: Knaus+et+al
    title: Easier parallel computing in R with snowfall and sfCluster
    bibtitle: Easier parallel computing in R with snowfall and sfCluster
    author:
    - Jochen Knaus
    - Christine Porzelius
    - Harald Binder
    - Guido Schwarzer
    bibauthor: |-
      Jochen Knaus and Christine Porzelius and Harald Binder and
                Guido Schwarzer
    landing: '2009'
    abstract: Many statistical analysis task in areas such as bioinformatics are computationally
      very intensive, while lots of them rely on embarrasingly parallel computations
      (Ananth Grama, 2003). Multiple computers or even multiple processor cores on
      standard desktop computers, which are widespread available nowadays, can easily
      contribute to faster analyses.
    pages:
    - 54
    - 59
  - slug: RJ-2009-010
    old_slug: Guazzelli+et+al
    title: 'PMML: An Open Standard for Sharing Models'
    bibtitle: 'PMML: An Open Standard for Sharing Models'
    author:
    - Alex Guazzelli
    - Michael Zeller
    - Wen-Ching Lin
    - Graham Williams
    bibauthor: |-
      Alex Guazzelli and Michael Zeller and Wen-Ching Lin and
                Graham Williams
    landing: '2009'
    abstract: The PMML package exports a variety of predictive and descriptive models
      from R to the Predictive Model Markup Language (Data Mining Group, 2008). PMML
      is an XML-based language and has become the de-facto standard to represent not
      only predictive and descriptive models, but also data preand post-processing.
      In so doing, it allows for the interchange of models among different tools and
      environments, mostly avoiding proprietary issues and incompatibilities.
    pages:
    - 60
    - 65
  notes:
  - title: 'Forthcoming Events: Conference on Quantitative Social Science Research
      Using R'
    bibtitle: 'Forthcoming Events: Conference on Quantitative Social Science Research
      Using {R}'
    page: 66
  - title: 'Forthcoming Events: DSC 2009'
    bibtitle: 'Forthcoming Events: {DSC} 2009'
    page: 66
  - title: 'Forthcoming Events: useR! 2009'
    bibtitle: 'Forthcoming Events: {useR!} 2009'
    page: 67
  - title: 'Conference Review: The 1st Chinese R Conference'
    bibtitle: 'Conference Review: The 1st {C}hinese {R} Conference'
    page: 69
  - title: Changes in R 2.9.0
    bibtitle: Changes in {R} 2.9.0
    page: 71
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 77
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 91
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 92
- issue: 2009-2
  year: 2009
  volume: 1
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2009-014
    old_slug: Fox
    title: Aspects of the Social Organization and Trajectory of the R Project
    bibtitle: |-
      Aspects of the Social Organization and Trajectory of the R
                Project
    author: John Fox
    bibauthor: John Fox
    landing: '2009'
    abstract: Based partly on interviews with members of the R Core team, this paper
      considers the development of the R Project in the context of open-source software
      development and, more generally, voluntary activities. The paper describes aspects
      of the social organization of the R Project, including the organization of the
      R Core team; describes the trajectory of the R Project; seeks to identify factors
      crucial to the success of R; and speculates about the prospects for R.
    pages:
    - 5
    - 13
  - slug: RJ-2009-013
    old_slug: Strobl~et~al
    title: Party on!
    bibtitle: Party on!
    author:
    - Carolin Strobl
    - Torsten Hothorn
    - Achim Zeileis
    bibauthor: Carolin Strobl and Torsten Hothorn and Achim Zeileis
    landing: '2009'
    abstract: Recursive partitioning methods are amongst the most popular and widely
      used statistical learning tools for nonparametric regression and classification.
      Especially random forests, that can deal with large numbers of predictor variables
      even in the presence of complex interactions, are being applied successfully
      in many scientific fields (see, e.g., ??, and the references therein for applications
      in genetics and social sciences). Thus, it is not surprising that there is a
      variety of recursive partitioning tools available in R (see http://CRAN.R-project.org/view=MachineLearning
      for an overview).
    pages:
    - 14
    - 17
  - slug: RJ-2009-011
    old_slug: Lafaye~de~Micheaux+Liquet
    title: 'ConvergenceConcepts: An R Package to Investigate Various Modes of Convergence'
    bibtitle: |-
      ConvergenceConcepts: An R Package to Investigate Various
                Modes of Convergence
    author:
    - Pierre Lafaye de Micheaux
    - Benoit Liquet
    bibauthor: Pierre Lafaye de Micheaux and Benoit Liquet
    landing: '2009'
    abstract: 'ConvergenceConcepts is an R package, built upon the tkrplot, tcltk
      and lattice packages, designed to investigate the convergence of simulated sequences
      of random variables. Four classical modes of convergence may be studied, namely:
      almost sure convergence (a.s.), convergence in probability (P), convergence
      in law (L) and convergence in r-th mean (r). This investigation is performed
      through accurate graphical representations. This package may be used as a pedagogical
      tool. It may give students a better understanding of these notions and help
      them to visualize these difficult theoretical concepts. Moreover, some scholars
      could gain some insight into the behaviour of some random sequences they are
      interested in.'
    pages:
    - 18
    - 25
  - slug: RJ-2009-015
    old_slug: Coeurjolly~et~al
    title: 'asympTest: A Simple R Package for Classical Parametric Statistical Tests
      and Confidence Intervals in Large Samples'
    bibtitle: |-
      asympTest: A Simple R Package for Classical Parametric
                Statistical Tests and Confidence Intervals in Large Samples
    author:
    - J.-F. Coeurjolly
    - R. Drouilhet
    - P. Lafaye de Micheaux
    - J.-F. Robineau
    bibauthor: |-
      J.-F. Coeurjolly and R. Drouilhet and P. Lafaye de Micheaux
                and J.-F. Robineau
    landing: '2009'
    abstract: '  Abstract asympTest is an R package implementing large sample tests
      and confidence intervals. One            and two sample mean and variance tests
      (differences and ratios) are considered. The test statistics            are
      all expressed in the same form as the Student t-test, which facilitates their
      presentation in the            classroom. This contribution also fills the gap
      of a robust (to non-normality) alternative to the chi           square single
      variance test for large samples, since no such procedure is implemented in standard            statistical
      software.'
    pages:
    - 26
    - 30
    CRANpkgs:
    - asympTest
    - asympTest
    - asympTest
  - slug: RJ-2009-012
    old_slug: Carpenter~et~al
    title: 'copas: An R package for Fitting the Copas Selection Model'
    bibtitle: 'copas: An R package for Fitting the Copas Selection Model'
    author:
    - J. Carpenter
    - G. Rücker
    - G. Schwarzer
    bibauthor: J. Carpenter and G. Rücker and G. Schwarzer
    landing: '2009'
    abstract: This article describes the R package copas which is an add-on package
      to the R package meta. The R package copas can be used to fit the Copas selection
      model to adjust for bias in meta-analysis. A clinical example is used to illustrate
      fitting and interpreting the Copas selection model.
    pages:
    - 31
    - 36
    CRANpkgs:
    - copas
    - meta
    CTV_rev:
    - ClinicalTrials
    - MetaAnalysis
  - slug: RJ-2009-018
    old_slug: Damico
    title: 'Transitioning to R: Replicating SAS, Stata, and SUDAAN Analysis Techniques
      in Health Policy Data'
    bibtitle: |-
      Transitioning to R: Replicating SAS, Stata, and SUDAAN
                Analysis Techniques in Health Policy Data
    author: Anthony Damico
    bibauthor: Anthony Damico
    landing: '2009'
    abstract: Statistical, data manipulation, and presentation tools make R an ideal
      integrated package for research in the fields of health policy and healthcare
      management and evaluation. However, the technical documentation accompanying
      most data sets used by researchers in these fields does not include syntax examples
      for analysts to make the transition from another statistical package to R. This
      paper describes the steps required to import health policy data into R, to prepare
      that data for analysis using the two most common complex survey variance calculation
      techniques, and to produce the principal set of statistical estimates sought
      by health policy researchers. Using data from the Medical Expenditure Panel
      Survey Household Component (MEPS-HC), this paper outlines complex survey data
      analysis techniques in R, with side-by-side comparisons to the SAS, Stata, and
      SUDAAN statistical software packages.
    pages:
    - 37
    - 44
  - slug: RJ-2009-016
    old_slug: Williams
    title: 'Rattle: A Data Mining GUI for R'
    bibtitle: 'Rattle: A Data Mining GUI for R'
    author: Graham J Williams
    bibauthor: Graham J Williams
    landing: '2009'
    abstract: '  Abstract Data mining delivers insights, patterns, and descriptive
      and predictive models from the            large amounts of data available today
      in many organisations. The data miner draws heavily on            methodologies,
      techniques and algorithms from statistics, machine learning, and computer science.
      R            increasingly provides a powerful platform for data mining. However,
      scripting and programming            is sometimes a challenge for data analysts
      moving into data mining. The Rattle package provides a            graphical
      user interface specifically for data mining using R. It also provides a stepping
      stone toward            using R as a programming language for data analysis.'
    pages:
    - 45
    - 55
    CRANpkgs:
    - arules
    - RGtk2
    - RGtk2
    - rattle
    - rattle
    - rattle
    - rattle
    - Hmisc
    - fBasics
    - mice
    - rggobi
    - rggobi
    - latticist
    - playwith
    - lattice
    - reshape
    - randomForest
    - Amelia
    - rpart
    - party
    - rpart
    - randomForest
    - ROCR
    - pmml
    - rattle
    - pmml
    - RGtk2
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Graphics
    - Environmetrics
    - OfficialStatistics
    - SocialSciences
    - Survival
    - Bayesian
    - ClinicalTrials
    - Distributions
    - Econometrics
    - Finance
    - Pharmacokinetics
    - ReproducibleResearch
  - slug: RJ-2009-017
    old_slug: Graves~et~al
    title: 'sos: Searching Help Pages of R Packages'
    bibtitle: 'sos: Searching Help Pages of R Packages'
    author:
    - Spencer Graves
    - Sundar Dorai-Raj
    - Romain François
    bibauthor: Spencer Graves and Sundar Dorai-Raj and Romain François
    landing: '2009'
    abstract: The sos package provides a means to quickly and flexibly search the
      help pages of contributed packages, finding functions and datasets in seconds
      or minutes that could not be found in hours or days by any other means we know.
      Its findFn function accesses Jonathan Baron’s R Site Search database and returns
      the matches in a data frame of class "findFn", which can be further manipulated
      by other sos functions to produce, for example, an Excel file that starts with
      a summary sheet that makes it relatively easy to prioritize alternative packages
      for further study. As such, it provides a very powerful way to do a literature
      search for functions and packages relevant to a particular topic of interest
      and could become virtually mandatory for authors of new packages or papers in
      publications such as The R Journal and the Journal of Statistical Software.
    pages:
    - 56
    - 59
    CRANpkgs:
    - sos
    - sos
    - sos
    - sos
    - WriteXLS
    - RODBC
    - sos
    - fda
    - deSolve
    - PKfit
    - sos
    - sos
    - sos
    - sos
    CTV_rev:
    - DifferentialEquations
    - Pharmacokinetics
  - slug: Murdoch+Urbanek
    type: From the Core
    title: The New R Help System
    bibtitle: The New {R} Help System
    author:
    - Duncan Murdoch
    - Simon Urbanek
    pages:
    - 60
    - 65
  notes:
  - title: 'Conference Review: DSC 2009'
    bibtitle: 'Conference Review: {DSC} 2009'
    page: 66
  - title: 'Conference Review: WZUR(2.0) - The Second Meeting of Polish R Users'
    bibtitle: 'Conference Review: {WZUR(2.0)} -- The Second Meeting of {P}olish {R}
      Users'
    page: 67
  - title: 'R Changes: 2.9.1-2.10.0 Patched'
    bibtitle: 'R Changes: 2.9.1--2.10.0 Patched'
    page: 68
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 95
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 96
- issue: 2010-1
  volume: 2
  year: 2010
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2010-001
    old_slug: Pramana~et~al
    title: 'IsoGene: An R Package for Analyzing Dose-response Studies in Microarray
      Experiments'
    bibtitle: |-
      IsoGene: An R Package for Analyzing Dose-response Studies in
                Microarray Experiments
    author:
    - Setia Pramana
    - Dan Lin
    - Philippe Haldermans
    - Ziv Shkedy
    - Tobias Verbeke
    - Hinrich Göhlmann
    - An De Bondt
    - Willem Talloen
    - Luc Bijnens.
    bibauthor: |-
      Setia Pramana and Dan Lin and Philippe Haldermans and Ziv
                Shkedy and Tobias Verbeke and Hinrich Göhlmann and An De
                Bondt and Willem Talloen and Luc Bijnens.
    landing: '2010'
    abstract: IsoGene is an R package for the analysis of dose-response microarray
      experiments to identify gene or subsets of genes with a monotone relationship
      between the gene expression and the doses. Several testing procedures (i.e.,
      the likelihood ratio test, Williams, Marcus, the M, and Modified M), that take
      into account the order restriction of the means with respect to the increasing
      doses are implemented in the package. The inference is based on resampling methods,
      both permutations and the Significance Analysis of Microarrays (SAM).
    pages:
    - 5
    - 12
  - slug: RJ-2010-003
    old_slug: Brown+Zhou
    title: MCMC for Generalized Linear Mixed Models with glmmBUGS
    bibtitle: MCMC for Generalized Linear Mixed Models with glmmBUGS
    author:
    - Patrick Brown
    - Lutong Zhou
    bibauthor: Patrick Brown and Lutong Zhou
    landing: '2010'
    abstract: The glmmBUGS package is a bridging tool between Generalized Linear Mixed
      Models (GLMMs) in R and the BUGS language. It provides a simple way of performing
      Bayesian inference using Markov Chain Monte Carlo (MCMC) methods, taking a model
      formula and data frame in R and writing a BUGS model file, data file, and initial
      values files. Functions are provided to reformat and summarize the BUGS results.
      A key aim of the package is to provide files and objects that can be modified
      prior to calling BUGS, giving users a platform for customizing and extending
      the models to accommodate a wide variety of analyses.
    pages:
    - 13
    - 17
  - slug: RJ-2010-004
    old_slug: Weidmann+Skrede~Gleditsch
    title: Mapping and Measuring Country Shapes
    bibtitle: Mapping and Measuring Country Shapes
    author:
    - Nils B. Weidmann
    - Kristian Skrede Gleditsch
    bibauthor: Nils B. Weidmann and Kristian Skrede Gleditsch
    landing: '2010'
    abstract: The article introduces the cshapes R package, which includes our CShapes
      dataset of contemporary and historical country boundaries, as well as computational
      tools for computing geographical measures from these maps. We provide an overview
      of the need for considering spatial dependence in comparative research, how
      this requires appropriate historical maps, and detail how the cshapes associated
      R package cshapes can contribute to these ends. We illustrate the use of the
      package for drawing maps, computing spatial variables for countries, and generating
      weights matrices for spatial statistics.
    pages:
    - 18
    - 24
  - slug: RJ-2010-005
    old_slug: Wilhelm+Manjunath
    title: 'tmvtnorm: A Package for the Truncated Multivariate Normal Distribution'
    bibtitle: |-
      tmvtnorm: A Package for the Truncated Multivariate Normal
                Distribution
    author:
    - Stefan Wilhelm
    - B. G. Manjunath
    bibauthor: Stefan Wilhelm and B. G. Manjunath
    landing: '2010'
    abstract: '  Abstract In this article we present tmvtnorm, an R package implementation
      for the truncated mul           tivariate normal distribution. We consider random
      number generation with rejection and Gibbs            sampling, computation
      of marginal densities as well as computation of the mean and covariance of            the
      truncated variables. This contribution brings together latest research in this
      field and provides            useful methods for both scholars and practitioners
      when working with truncated normal variables.'
    pages:
    - 25
    - 29
  - slug: RJ-2010-006
    old_slug: Guenther+Fritsch
    title: 'neuralnet: Training of Neural Networks'
    bibtitle: 'neuralnet: Training of Neural Networks'
    author:
    - Frauke Günther
    - Stefan Fritsch
    bibauthor: Frauke Günther and Stefan Fritsch
    landing: '2010'
    abstract: Artificial neural networks are applied in many situations. neuralnet
      is built to train multilayer perceptrons in the context of regression analyses,
      i.e. to approximate functional relationships between covariates and response
      variables. Thus, neural networks are used as extensions of generalized linear
      models.       neuralnet is a very flexible package. The backpropagation algorithm
      and three versions of resilient backpropagation are implemented and it provides
      a custom-choice of activation and error function. An arbitrary number of covariates
      and response variables as well as of hidden layers can theoretically be included.       The
      paper gives a brief introduction to multi-layer perceptrons and resilient backpropagation
      and demonstrates the application of neuralnet using the data set infert, which
      is contained in the R distribution.
    pages:
    - 30
    - 38
  - slug: RJ-2010-007
    old_slug: Werft+Benner
    title: 'glmperm: A Permutation of Regressor Residuals Test for Inference in Generalized
      Linear Models'
    bibtitle: |-
      glmperm: A Permutation of Regressor Residuals Test for
                Inference in Generalized Linear Models
    author:
    - Wiebke Werft
    - Axel Benner
    bibauthor: Wiebke Werft and Axel Benner
    landing: '2010'
    abstract: '  Abstract We introduce a new R package called glmperm for inference
      in generalized linear models            especially for small and moderate-sized
      data sets. The inference is based on the permutation of            regressor
      residuals test introduced by Potter (2005). The implementation of glmperm outperforms            currently
      available permutation test software as glmperm can be applied in situations
      where more            than one covariate is involved.'
    pages:
    - 39
    - 43
  - slug: RJ-2010-002
    old_slug: Thioulouse~et~al
    title: 'Online Reproducible Research: An Application to Multivariate Analysis
      of Bacterial DNA Fingerprint Data'
    bibtitle: |-
      Online Reproducible Research: An Application to Multivariate
                Analysis of Bacterial DNA Fingerprint Data
    author:
    - Jean Thioulouse
    - Claire Valiente-Moro
    - Lionel Zenner
    bibauthor: Jean Thioulouse and Claire Valiente-Moro and Lionel Zenner
    landing: '2010'
    abstract: '  Abstract This paper presents an example of online reproducible multivariate
      data analysis. This            example is based on a web page providing an online
      computing facility on a server. HTML forms            contain editable R code
      snippets that can be executed in any web browser thanks to the Rweb software.            The
      example is based on the multivariate analysis of DNA fingerprints of the internal
      bacterial flora            of the poultry red mite Dermanyssus gallinae. Several
      multivariate data analysis methods from the            ade4 package are used
      to compare the fingerprints of mite pools coming from various poultry farms.            All
      the computations and graphical displays can be redone interactively and further
      explored online,            using only a web browser. Statistical methods are
      detailed in the duality diagram framework, and a            discussion about
      online reproducibility is initiated.'
    pages:
    - 44
    - 52
    CRANpkgs:
    - ade4
    - seqinr
    - ade4
    - vegan
    - CGIwithR
    - R2HTML
    CTV_rev:
    - Environmetrics
    - Multivariate
    - Psychometrics
    - Spatial
    - Graphics
    - Genetics
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2010-008
    old_slug: Fay
    title: Two-sided Exact Tests and Matching Confidence Intervals for Discrete Data
    bibtitle: |-
      Two-sided Exact Tests and Matching Confidence Intervals for
                Discrete Data
    author: Michael P. Fay
    bibauthor: Michael P. Fay
    landing: '2010'
    abstract: '  Abstract There is an inherent relationship between two-sided hypothesis
      tests and confidence intervals.            A series of two-sided hypothesis
      tests may be inverted to obtain the matching 100(1-α)% confidence            interval
      defined as the smallest interval that contains all point null parameter values
      that would not            be rejected at the α level. Unfortunately, for discrete
      data there are several different ways of defining            two-sided exact
      tests and the most commonly used two-sided exact tests are defined one way,
      while            the most commonly used exact confidence intervals are inversions
      of tests defined another way. This            can lead to inconsistencies where
      the exact test rejects but the exact confidence interval contains the            null
      parameter value. The packages exactci and exact2x2 provide several exact tests
      with the matching            confidence intervals avoiding these inconsistencies
      as much as possible. Examples are given for            binomial and Poisson
      parameters and both paired and unpaired 2 × 2 tables.                 Applied
      statisticians are increasingly being encouraged to report confidence intervals
      (CI) and            parameter estimates along with p-values from hypothesis
      tests. The htest class of the stats package            is ideally suited to
      these kinds of analyses, because all the related statistics may be presented
      when            the results are printed. For exact two-sided tests applied to
      discrete data, a test-CI inconsistency may            occur: the p-value may
      indicate a significant result at level α while the associated 100(1-α)% confidence            interval
      may cover the null value of the parameter. Ideally, we would like to present
      a unified report            (Hirji, 2006), whereby the p-value and the confidence
      interval match as much as possible.'
    pages:
    - 53
    - 58
    CRANpkgs:
    - exactci
    - exact2x2
    - exactci
    - exact2x2
    - exactci
    - exact2x2
    - PropCIs
    - rateratio.test
    - coin
    - perm
    CTV_rev:
    - ClinicalTrials
    - Survival
  notes:
  - title: A Beginner's Guide to R
    bibtitle: A Beginner's Guide to {R}
    page: 59
  - title: 'Conference Review: The 2nd Chinese R Conference'
    bibtitle: 'Conference Review: The 2nd {C}hinese {R} Conference'
    page: 60
  - title: 'Introducing NppToR: R Interaction for Notepad++'
    bibtitle: 'Introducing {NppToR}: {R} Interaction for {Notepad++}'
    page: 62
  - title: Changes in R 2.10.1-2.11.1
    bibtitle: Changes in {R} 2.10.1--2.11.1
    page: 64
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 72
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 85
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 86
- issue: 2010-2
  volume: 2
  year: 2010
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2010-013
    old_slug: Soetaert~et~al
    title: Solving Differential Equations in R
    bibtitle: Solving Differential Equations in R
    author:
    - Karline Soetaert
    - Thomas Petzoldt
    - R. Woodrow Setzer
    bibauthor: Karline Soetaert and Thomas Petzoldt and R. Woodrow Setzer
    landing: '2010'
    abstract: Although R is still predominantly applied for statistical analysis and
      graphical representation, it is rapidly becoming more suitable for mathematical
      computing. One of the fields where considerable progress has been made recently
      is the solution of differential equations. Here we give a brief overview of
      differential equations that can now be solved by R.
    pages:
    - 5
    - 15
    CRANpkgs:
    - limSolve
    - rootSolve
    - deSolve
    - bvpSolve
    - ReacTran
    - PBSddesolve
    - sde
    - pomp
    - bvpSolve
    - ReacTran
    - deSolve
    - deSolve
    - ReacTran
    - deSolve
    - odesolve
    - odesolve
    - nlmeODE
    - FME
    - ccems
    - ReacTran
    CTV_rev:
    - DifferentialEquations
    - Pharmacokinetics
    - TimeSeries
    - Bayesian
    - Finance
    - Optimization
  - slug: RJ-2010-010
    old_slug: Murdoch
    title: Source References
    bibtitle: Source References
    author: Duncan Murdoch
    bibauthor: Duncan Murdoch
    landing: '2010'
    abstract: Since version 2.10.0, R includes expanded support for source references
      in R code and ‘.Rd’ files. This paper describes the origin and purposes of source
      references, and current and future support for them.
    pages:
    - 16
    - 19
  - slug: RJ-2010-009
    old_slug: Roennegaard~et~al
    title: 'hglm: A Package for Fitting Hierarchical Generalized Linear Models'
    bibtitle: |-
      hglm: A Package for Fitting Hierarchical Generalized Linear
                Models
    author:
    - Lars Rönnegård
    - Xia Shen
    - Moudud Alam
    bibauthor: Lars Rönnegård and Xia Shen and Moudud Alam
    landing: '2010'
    abstract: '  Abstract We present the hglm package for fitting hierarchical generalized
      linear models. It can be            used for linear mixed models and generalized
      linear mixed models with random effects for a variety            of links and
      a variety of distributions for both the outcomes and the random effects. Fixed
      effects can            also be fitted in the dispersion part of the model.'
    pages:
    - 20
    - 28
    CRANpkgs:
    - hglm
    - lme4
    - MASS
    - dglm
    - HGLMMM
    - nlme
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Psychometrics
    - SocialSciences
    - OfficialStatistics
    - Pharmacokinetics
    - SpatioTemporal
    - Bayesian
    - ChemPhys
    - Distributions
    - Finance
    - Multivariate
    - NumericalMathematics
    - Robust
    - Spatial
  - slug: RJ-2010-011
    old_slug: Solymos
    title: 'dclone: Data Cloning in R'
    bibtitle: 'dclone: Data Cloning in R'
    author: Péter Sólymos
    bibauthor: Péter Sólymos
    landing: '2010'
    abstract: The dclone R package contains low level functions for implementing maximum
      likelihood estimating procedures for complex models using data cloning and Bayesian
      Markov Chain Monte Carlo methods with support for JAGS, WinBUGS and OpenBUGS.
    pages:
    - 29
    - 37
    CRANpkgs:
    - dclone
    - rjags
    - coda
    - R2WinBUGS
    - BRugs
    CTV_rev:
    - gR
    - Bayesian
    - Cluster
    - HighPerformanceComputing
    - Optimization
  - slug: RJ-2010-012
    old_slug: Wickham
    title: 'stringr: modern, consistent string processing'
    bibtitle: 'stringr: modern, consistent string processing'
    author: Hadley Wickham
    bibauthor: Hadley Wickham
    landing: '2010'
    abstract: '  Abstract String processing is not glamorous, but it is frequently
      used in data cleaning and preparation.            The existing string functions
      in R are powerful, but not friendly. To remedy this, the stringr package            provides
      string functions that are simpler and more consistent, and also fixes some functionality
      that            R is missing compared to other programming languages.'
    pages:
    - 38
    - 40
  - slug: RJ-2010-014
    old_slug: Ardia+Hoogerheide
    title: Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations
    bibtitle: |-
      Bayesian Estimation of the GARCH(1,1) Model with Student-t
                Innovations
    author:
    - David Ardia
    - Lennart F. Hoogerheide
    bibauthor: David Ardia and Lennart F. Hoogerheide
    landing: '2010'
    abstract: '  Abstract This note presents the R package bayesGARCH which provides
      functions for the Bayesian            estimation of the parsimonious and effective
      GARCH(1,1) model with Student-t innovations. The            estimation procedure
      is fully automatic and thus avoids the tedious task of tuning an MCMC sampling            algorithm.
      The usage of the package is shown in an empirical application to exchange rate
      log-returns.'
    pages:
    - 41
    - 47
    CRANpkgs:
    - fGarch
    - rgarch
    - tseries
    - bayesGARCH
    - coda
    - foreach
    CTV_rev:
    - Finance
    - Bayesian
    - TimeSeries
    - Econometrics
    - Environmetrics
    - gR
    - HighPerformanceComputing
  - slug: RJ-2010-015
    old_slug: Ferreira~da~Silva
    title: 'cudaBayesreg: Bayesian Computation in CUDA'
    bibtitle: 'cudaBayesreg: Bayesian Computation in CUDA'
    author: Adelino Ferreira da Silva
    bibauthor: Adelino Ferreira da Silva
    landing: '2010'
    abstract: '  Abstract Graphical processing units are rapidly gaining maturity
      as powerful general parallel comput           ing devices. The package cudaBayesreg
      uses GPU–oriented procedures to improve the performance            of Bayesian
      computations. The paper motivates the need for devising high-performance computing            strategies
      in the context of fMRI data analysis. Some features of the package for Bayesian
      analysis of            brain fMRI data are illustrated. Comparative computing
      performance figures between sequential and            parallel implementations
      are presented as well.'
    pages:
    - 48
    - 55
    CRANpkgs:
    - cudaBayesreg
    - bayesm
    - cudaBayesregData
    - oro.nifti
    CTV_rev:
    - MedicalImaging
    - Bayesian
    - HighPerformanceComputing
    - Cluster
    - Distributions
    - Econometrics
    - Multivariate
  - slug: RJ-2010-016
    old_slug: Bilder~et~al
    title: 'binGroup: A Package for Group Testing'
    bibtitle: 'binGroup: A Package for Group Testing'
    author:
    - Christopher R. Bilder
    - Boan Zhang
    - Frank Schaarschmidt
    - Joshua M. Tebbs
    bibauthor: |-
      Christopher R. Bilder and Boan Zhang and Frank Schaarschmidt
                and Joshua M. Tebbs
    landing: '2010'
    abstract: '  Abstract When the prevalence of a disease or of some other binary
      characteristic is small, group            testing (also known as pooled testing)
      is frequently used to estimate the prevalence and/or to identify            individuals
      as positive or negative. We have developed the binGroup package as the first
      package            designed to address the estimation problem in group testing.
      We present functions to estimate an            overall prevalence for a homogeneous
      population. Also, for this setting, we have functions to aid in            the
      very important choice of the group size. When individuals come from a heterogeneous
      population,            our group testing regression functions can be used to
      estimate an individual probability of disease            positivity by using
      the group observations only. We illustrate our functions with data from a multiple            vector
      transfer design experiment and a human infectious disease prevalence study.'
    pages:
    - 56
    - 60
    CRANpkgs:
    - binGroup
    - binom
  - slug: RJ-2010-017
    old_slug: Sariyar+Borg
    title: 'The RecordLinkage Package: Detecting Errors in Data'
    bibtitle: 'The RecordLinkage Package: Detecting Errors in Data'
    author:
    - Murat Sariyar
    - Andreas Borg
    bibauthor: Murat Sariyar and Andreas Borg
    landing: '2010'
    abstract: '  Abstract Record linkage deals with detecting homonyms and mainly
      synonyms in data. The package            RecordLinkage provides means to perform
      and evaluate different record linkage methods. A stochas           tic framework
      is implemented which calculates weights through an EM algorithm. The determination            of
      the necessary thresholds in this model can be achieved by tools of extreme value
      theory. Further           more, machine learning methods are utilized, including
      decision trees (rpart), bootstrap aggregating            (bagging), ada boost
      (ada), neural nets (nnet) and support vector machines (svm). The generation            of
      record pairs and comparison patterns from single data items are provided as
      well. Comparison            patterns can be chosen to be binary or based on
      some string metrics. In order to reduce computation            time and memory
      usage, blocking can be used. Future development will concentrate on additional            and
      refined methods, performance improvements and input/output facilities needed
      for real-world            application.'
    pages:
    - 61
    - 67
  - slug: RJ-2010-018
    old_slug: Ishwaran~et~al
    title: 'spikeslab: Prediction and Variable Selection Using Spike and Slab Regression'
    bibtitle: |-
      spikeslab: Prediction and Variable Selection Using Spike and
                Slab Regression
    author:
    - Hemant Ishwaran
    - Udaya B. Kogalur
    - J. Sunil Rao
    bibauthor: Hemant Ishwaran and Udaya B. Kogalur and J. Sunil Rao
    landing: '2010'
    abstract: '  Abstract Weighted generalized ridge regression offers unique advantages
      in correlated high-dimensional            problems. Such estimators can be efficiently
      computed using Bayesian spike and slab models and are            effective for
      prediction. For sparse variable selection, a generalization of the elastic net
      can be used in            tandem with these Bayesian estimates. In this article,
      we describe the R-software package spikeslab            for implementing this
      new spike and slab prediction and variable selection methodology.'
    pages:
    - 68
    - 73
    CRANpkgs:
    - lars
    - snow
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
  notes:
  - title: What's New?
    page: 74
  - title: useR! 2010
    bibtitle: '{useR!} 2010'
    page: 77
  - title: 'Forthcoming Events: useR! 2011'
    bibtitle: 'Forthcoming Events: {useR!} 2011'
    page: 79
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 81
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 90
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2011-1
  volume: 3
  year: 2011
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2011-002
    old_slug: Wickham
    title: 'testthat: Get Started with Testing'
    bibtitle: 'testthat: Get Started with Testing'
    author: Hadley Wickham
    bibauthor: Hadley Wickham
    landing: '2011'
    abstract: '  Abstract Software testing is important, but many of us don’t do it
      because it is frustrating and boring.            testthat is a new testing framework
      for R that is easy learn and use, and integrates with your existing            workflow.
      This paper shows how, with illustrations from existing packages.'
    pages:
    - 5
    - 10
    CRANpkgs:
    - testthat
    - RUnit
    - svUnit
    - stringr
    - lubridate
    CTV_rev:
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2011-003
    old_slug: Bohn~et~al
    title: Content-Based Social Network Analysis of Mailing Lists
    bibtitle: Content-Based Social Network Analysis of Mailing Lists
    author:
    - Angela Bohn
    - Ingo Feinerer
    - Kurt Hornik
    - Patrick Mair
    bibauthor: |-
      Angela Bohn and Ingo Feinerer and Kurt Hornik and Patrick
                Mair
    landing: '2011'
    abstract: Social Network Analysis (SNA) provides tools to examine relationships
      between people. Text Mining (TM) allows capturing the text they produce in Web
      2.0 applications, for example, however it neglects their social structure. This
      paper applies an approach to combine the two methods named “content-based SNA”.
      Using the R mailing lists, R-help and R-devel, we show how this combination
      can be used to describe people’s interests and to find out if authors who have
      similar interests actually communicate. We find that the expected positive relationship
      between sharing interests and communicating gets stronger as the centrality
      scores of authors in the communication networks increase.
    pages:
    - 11
    - 18
    CRANpkgs:
    - tm.plugin.mail
    - car
    - tm
    - sna
    - igraph
    CTV_rev:
    - NaturalLanguageProcessing
    - Optimization
    - SocialSciences
    - Bayesian
    - Econometrics
    - Finance
    - gR
    - Graphics
    - HighPerformanceComputing
    - Multivariate
    - Spatial
  - slug: RJ-2011-001
    old_slug: Chalabi~et~al
    title: Rmetrics - timeDate Package
    bibtitle: Rmetrics - timeDate Package
    author:
    - Yohan Chalabi
    - Martin Mächler
    - Diethelm Würtz
    bibauthor: Yohan Chalabi and Martin Mächler and Diethelm Würtz
    landing: '2011'
    abstract: '  Abstract The management of time and holidays can prove crucial in
      applications that rely on historical            data. A typical example is the
      aggregation of a data set recorded in different time zones and under dif           ferent
      daylight saving time rules. Besides the time zone conversion function, which
      is well supported            by default classes in R, one might need functions
      to handle special days or holidays. In this respect,            the package
      timeDate enhances default date-time classes in R and brings new functionalities
      to time            zone management and the creation of holiday calendars.'
    pages:
    - 19
    - 24
    CRANpkgs:
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    CTV_rev:
    - Finance
    - TimeSeries
  - slug: RJ-2011-004
    old_slug: Poisot
    title: 'The digitize Package: Extracting Numerical Data from Scatterplots'
    bibtitle: |-
      The digitize Package: Extracting Numerical Data from
                Scatterplots
    author: Timothée Poisot
    bibauthor: Timothée Poisot
    landing: '2011'
    abstract: '  Abstract I present the small R package digitize, designed to extract
      data from scatterplots with a            simple method and suited to small datasets.
      I present an application of this method to the extraction            of data
      from a graph whose source is not available.'
    pages:
    - 25
    - 26
    CRANpkgs:
    - digitize
    - ReadImages
  - slug: RJ-2011-005
    old_slug: Ardia~et~al
    title: Differential Evolution with DEoptim
    bibtitle: Differential Evolution with DEoptim
    author:
    - David Ardia
    - Kris Boudt
    - Peter Carl
    - Katharine M. Mullen
    - Brian G. Peterson
    bibauthor: |-
      David Ardia and Kris Boudt and Peter Carl and Katharine M.
                Mullen and Brian G. Peterson
    landing: '2011'
    abstract: The R package DEoptim implements the Differential Evolution algorithm.
      This algorithm is an evolutionary technique similar to classic genetic algorithms
      that is useful for the solution of global optimization problems. In this note
      we provide an introduction to the package and demonstrate its utility for financial
      applications by solving a non-convex portfolio optimization problem.
    pages:
    - 27
    - 34
    CRANpkgs:
    - DEoptim
    - PortfolioAnalytics
    - quantmod
    - PerformanceAnalytics
    CTV_rev:
    - Finance
    - Optimization
  - slug: RJ-2011-006
    old_slug: South
    title: 'rworldmap : a new R package for mapping global data'
    bibtitle: 'rworldmap : a new R package for mapping global data'
    author: Andy South
    bibauthor: Andy South
    landing: '2011'
    abstract: '  Abstract rworldmap is a new package available on CRAN for mapping
      and visualisation of global            data. The vision is to make the display
      of global data easier, to facilitate understanding and com           munication.
      The initial concentration is on data referenced by country or grid due to the
      frequency            of use of such data in global assessments. Tools to link
      data referenced by country (either name or            code) to a map, and then
      to display the map are provided as are functions to map global gridded data.            Country
      and gridded functions accept the same arguments to specify the nature of categories
      and            colour and how legends are formatted. This package builds on
      the functionality of existing packages,            particularly sp, maptools
      and fields. Example code is provided to produce maps, to link with the            packages
      classInt, RColorBrewer and ncdf, and to plot examples of publicly available
      country and            gridded data.'
    pages:
    - 35
    - 43
  - slug: RJ-2011-007
    old_slug: Lafitte~et~al
    title: Cryptographic Boolean Functions with R
    bibtitle: Cryptographic Boolean Functions with R
    author:
    - Frédéric Lafitte
    - Dirk Van Heule
    - Julien Van hamme
    bibauthor: Frédéric Lafitte and Dirk Van Heule and Julien Van hamme
    landing: '2011'
    abstract: '  Abstract A new package called boolfun is available for R users. The
      package provides tools to handle            Boolean functions, in particular
      for cryptographic purposes. This document guides the user through            some
      (code) examples and gives a feel of what can be done with the package.'
    pages:
    - 44
    - 47
    CRANpkgs:
    - boolfun
    - R.oo
    - multipol
    CTV_rev: NumericalMathematics
  - slug: RJ-2011-008
    old_slug: Murrell
    title: Raster Images in R Graphics
    bibtitle: Raster Images in R Graphics
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2011'
    abstract: '  Abstract The R graphics engine has new support for rendering raster
      images via the functions            rasterImage() and grid.raster(). This leads
      to better scaling of raster images, faster rendering to            screen, and
      smaller graphics files. Several examples of possible applications of these new
      features are            described.'
    pages:
    - 48
    - 54
  - slug: RJ-2011-009
    old_slug: Fraley~et~al
    title: Probabilistic Weather Forecasting in R
    bibtitle: Probabilistic Weather Forecasting in R
    author:
    - Chris Fraley
    - Adrian Raftery
    - Tilmann Gneiting
    - McLean Sloughter
    - Veronica Berrocal
    bibauthor: |-
      Chris Fraley and Adrian Raftery and Tilmann Gneiting and
                McLean Sloughter and Veronica Berrocal
    landing: '2011'
    abstract: '  Abstract This article describes two R packages for probabilistic
      weather forecasting, ensembleBMA,            which offers ensemble postprocessing
      via Bayesian model averaging (BMA), and ProbForecastGOP,            which implements
      the geostatistical output perturbation (GOP) method. BMA forecasting models            use
      mixture distributions, in which each component corresponds to an ensemble member,
      and the            form of the component distribution depends on the weather
      parameter (temperature, quantitative            precipitation or wind speed).
      The model parameters are estimated from training data. The GOP            technique
      uses geostatistical methods to produce probabilistic forecasts of entire weather
      fields for            temperature or pressure, based on a single numerical forecast
      on a spatial grid. Both packages include            functions for evaluating
      predictive performance, in addition to model fitting and forecasting.'
    pages:
    - 55
    - 63
    CRANpkgs:
    - ensembleBMA
    - chron
    - fields
    - maps
    - ProbForecastGOP
    - RandomFields
    - fields
    CTV_rev:
    - Spatial
    - TimeSeries
    - Bayesian
    - SpatioTemporal
  - slug: RJ-2011-010
    old_slug: Kane~et~al
    title: Analyzing an Electronic Limit Order Book
    bibtitle: Analyzing an Electronic Limit Order Book
    author:
    - David Kane
    - Andrew Liu
    - Khanh Nguyen
    bibauthor: David Kane and Andrew Liu and Khanh Nguyen
    landing: '2011'
    abstract: '  Abstract The orderbook package provides facilities for exploring
      and visualizing the data associated            with an order book: the electronic
      collection of the outstanding limit orders for a financial instrument.            This
      article provides an overview of the orderbook package and examples of its use.'
    pages:
    - 64
    - 68
  - slug: Hyndman
    type: Help desk
    title: Giving a useR! Talk
    bibtitle: Giving a {useR!} Talk
    author: Rob J. Hyndman
    pages:
    - 69
    - 71
  - slug: Cook
    type: Help desk
    title: Tips for Presenting Your Work
    author: Dianne Cook
    pages:
    - 72
    - 74
  notes:
  - title: Forest Analytics with R (Use R)
    bibtitle: Forest Analytics with {R} ({Use R})
    page: 75
  - title: 'Conference Review: Third Meeting of Polish R Users, The Influenza Challenge'
    bibtitle: 'Conference Review: Third Meeting of {P}olish {R} Users, The Influenza
      Challenge'
    page: 76
  - title: 'Conference Review: Kickoff Workshop for Project MOSAIC'
    bibtitle: 'Conference Review: Kickoff Workshop for Project {MOSAIC}'
    page: 78
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 79
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 89
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2011-2
  volume: 3
  year: 2011
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2011-011
    old_slug: Baier~et~al
    title: Creating and Deploying an Application with (R)Excel and R
    bibtitle: Creating and Deploying an Application with (R)Excel and R
    author:
    - Thomas Baier
    - Erich Neuwirth
    - Michele De Meo
    bibauthor: Thomas Baier and Erich Neuwirth and Michele De Meo
    landing: '2011'
    abstract: '  Abstract We present some ways of using R in Excel and build an example
      application using the            package rpart. Starting with simple interactive
      use of rpart in Excel, we eventually package the code            into an Excel-based
      application, hiding all details (including R itself) from the end user. In the
      end, our            application implements a service-oriented architecture (SOA)
      with a clean separation of presentation            and computation layer.'
    pages:
    - 5
    - 11
    CRANpkgs: rpart
    CTV_rev:
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Survival
  - slug: RJ-2011-012
    old_slug: Marschner
    title: 'glm2: Fitting Generalized Linear Models with Convergence Problems'
    bibtitle: |-
      glm2: Fitting Generalized Linear Models with Convergence
                Problems
    author: Ian C. Marschner
    bibauthor: Ian C. Marschner
    landing: '2011'
    abstract: '  Abstract The R function glm uses step-halving to deal with certain
      types of convergence problems            when using iteratively reweighted least
      squares to fit a generalized linear model. This works well in            some
      circumstances but non-convergence remains a possibility, particularly with a
      non-standard link            function. In some cases this is because step-halving
      is never invoked, despite a lack of convergence. In            other cases step-halving
      is invoked but is unable to induce convergence. One remedy is to impose a            stricter
      form of step-halving than is currently available in glm, so that the deviance
      is forced to decrease            in every iteration. This has been implemented
      in the glm2 function available in the glm2 package.            Aside from a
      modified computational algorithm, glm2 operates in exactly the same way as glm
      and            provides improved convergence properties. These improvements
      are illustrated here with an identity            link Poisson model, but are
      also relevant in other contexts.'
    pages:
    - 12
    - 15
    CRANpkgs: glm2
  - slug: RJ-2011-013
    old_slug: Lundholm
    title: Implementing the Compendium Concept with Sweave and DOCSTRIP
    bibtitle: Implementing the Compendium Concept with Sweave and DOCSTRIP
    author: Michael Lundholm
    bibauthor: Michael Lundholm
    landing: '2011'
    abstract: This article suggests an implementation of the compendium concept by
      combining Sweave  and the LATEX literate programming environment DOCSTRIP.
    pages:
    - 16
    - 21
  - slug: RJ-2011-014
    old_slug: Hornik+Murdoch
    title: Watch Your Spelling!
    bibtitle: Watch Your Spelling!
    author:
    - Kurt Hornik
    - Duncan Murdoch
    bibauthor: Kurt Hornik and Duncan Murdoch
    landing: '2011'
    abstract: '  Abstract We discuss the facilities in base R for spell checking via
      Aspell, Hunspell or Ispell, which are            useful in particular for conveniently
      checking the spelling of natural language texts in package Rd            files
      and vignettes. Spell checking performance is illustrated using the Rd files
      in package stats. This            example clearly indicates the need for a domain-specific
      statistical dictionary. We analyze the results            of spell checking
      all Rd files in all CRAN packages and show how these can be employed for building            such
      a dictionary.'
    pages:
    - 22
    - 28
  - slug: RJ-2011-015
    old_slug: Wang+Song
    title: 'Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic
      Programming'
    bibtitle: |-
      Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension
                by Dynamic Programming
    author:
    - Haizhou Wang
    - Mingzhou Song
    bibauthor: Haizhou Wang and Mingzhou Song
    landing: '2011'
    abstract: '  Abstract            The heuristic k-means algorithm, widely used
      for cluster analysis, does not guarantee optimality. We            developed
      a dynamic programming algorithm for optimal one-dimensional clustering. The
      algorithm            is implemented as an R package called Ckmeans.1d.dp. We
      demonstrate its advantage in optimality            and runtime over the standard
      iterative k-means algorithm.'
    pages:
    - 29
    - 33
    CRANpkgs: Ckmeans.1d.dp
  - slug: RJ-2011-016
    old_slug: Arnold+Emerson
    title: Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions
    bibtitle: |-
      Nonparametric Goodness-of-Fit Tests for Discrete Null
                Distributions
    author:
    - Taylor B. Arnold
    - John W. Emerson
    bibauthor: Taylor B. Arnold and John W. Emerson
    landing: '2011'
    abstract: '  Abstract Methodology extending nonparametric goodness-of-fit tests
      to discrete null distributions has            existed for several decades. However,
      modern statistical software has generally failed to provide this            methodology
      to users. We offer a revision of R’s ks.test() function and a new cvm.test()
      function            that fill this need in the R language for two of the most
      popular nonparametric goodness-of-fit tests.            This paper describes
      these contributions and provides examples of their usage. Particular attention
      is            given to various numerical issues that arise in their implementation.'
    pages:
    - 34
    - 39
    CRANpkgs:
    - dgof
    - nortest
    - ADGofTest
    - CvM2SL1Test
    - CvM2SL2Test
    - cramer
    CTV_rev: Multivariate
  - slug: RJ-2011-017
    old_slug: Gesmann+de~Castillo
    title: Using the Google Visualisation API with R
    bibtitle: Using the Google Visualisation API with R
    author:
    - Markus Gesmann
    - Diego de Castillo
    bibauthor: Markus Gesmann and Diego de Castillo
    landing: '2011'
    abstract: '  Abstract The googleVis package provides an interface between R and
      the Google Visualisation API            to create interactive charts which can
      be embedded into web pages. The best known of these charts            is probably
      the Motion Chart, popularised by Hans Rosling in his TED talks. With the googleVis            package
      users can easily create web pages with interactive charts based on R data frames
      and display            them either via the local R HTTP help server or within
      their own sites.'
    pages:
    - 40
    - 44
    CRANpkgs:
    - rsp
    - googleVis
    - rjsonio
    - brew
    CTV_rev:
    - ReproducibleResearch
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2011-018
    old_slug: Herve
    title: 'GrapheR: a Multiplatform GUI for Drawing Customizable Graphs in R'
    bibtitle: |-
      GrapheR: a Multiplatform GUI for Drawing Customizable Graphs
                in R
    author: Maxime Hervé
    bibauthor: Maxime Hervé
    landing: '2011'
    abstract: '  Abstract This article presents GrapheR, a Graphical User Interface
      allowing the user to draw customiz           able and high-quality graphs without
      knowing any R commands. Six kinds of graph are available:            histograms,
      box-and-whisker plots, bar plots, pie charts, curves and scatter plots. The
      complete            process is described with the examples of a bar plot and
      a scatter plot illustrating the legendary puzzle            of African and European
      swallows’ migrations.'
    pages:
    - 45
    - 53
    CRANpkgs:
    - JGR
    - playwith
    - GrapheR
    CTV_rev: Graphics
  - slug: RJ-2011-019
    old_slug: Lin~Shang
    title: 'rainbow: An R Package for Visualizing Functional Time Series'
    bibtitle: 'rainbow: An R Package for Visualizing Functional Time Series'
    author: Han Lin Shang
    bibauthor: Han Lin Shang
    landing: '2011'
    abstract: Recent advances in computer technology have tremendously increased the
      use of functional data, whose graphical representation can be infinite-dimensional
      curves, images or shapes. This article describes four methods for visualizing
      functional time series using an R add-on package. These methods are demonstrated
      using age-specific Australian fertility data from 1921 to 2006 and monthly sea
      surface temperatures from January 1950 to December 2006.
    pages:
    - 54
    - 59
  - slug: RJ-2011-020
    old_slug: Plummer
    title: Portable C++ for R Packages
    bibtitle: Portable C++ for R Packages
    author: Martyn Plummer
    bibauthor: Martyn Plummer
    landing: '2011'
    abstract: '  Abstract Package checking errors are more common on Solaris than
      Linux. In many cases, these errors            are due to non-portable C++ code.
      This article reviews some commonly recurring problems in C++            code
      found in R packages and suggests solutions.'
    pages:
    - 60
    - 63
    CRANpkgs: Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
  notes:
  - title: R's Participation in the Google Summer of Code 2011
    bibtitle: '{R}''s Participation in the {Google Summer of Code 2011}'
    page: 64
  - title: 'Conference Report: useR! 2011'
    bibtitle: 'Conference Report: {useR!} 2011'
    page: 68
  - title: 'Forthcoming Events: useR! 2012'
    bibtitle: 'Forthcoming Events: {useR!} 2012'
    page: 70
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 72
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 84
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 86
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 87
- issue: 2012-1
  volume: 4
  year: 2012
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2012-001
    old_slug: G~Barnett~et~al
    title: Analysing Seasonal Data
    bibtitle: Analysing Seasonal Data
    author:
    - Adrian G Barnett
    - Peter Baker
    - Annette J Dobson
    bibauthor: Adrian G Barnett and Peter Baker and Annette J Dobson
    landing: '2012'
    abstract: '  Abstract Many common diseases, such as the flu and cardiovascular
      disease, increase markedly in            winter and dip in summer. These seasonal
      patterns have been part of life for millennia and were            first noted
      in ancient Greece by both Hippocrates and Herodotus. Recent interest has focused
      on            climate change, and the concern that seasons will become more
      extreme with harsher winter and            summer weather. We describe a set
      of R functions designed to model seasonal patterns in disease.            We
      illustrate some simple descriptive and graphical methods, a more complex method
      that is able to            model non-stationary patterns, and the case-crossover
      to control for seasonal confounding.                 In this paper we illustrate
      some of the functions of the season package (Barnett et al., 2012), which            contains
      a range of functions for analysing seasonal health data. We were motivated by
      the great            interest in seasonality found in the health literature,
      and the relatively small number of seasonal tools            in R (or other
      software packages). The existing seasonal tools in R are:                • the
      baysea function of the timsac package and the decompose and stl functions of
      the stats                    package for decomposing a time series into a trend
      and season;                • the dynlm function of the dynlm package and the
      ssm function of the sspir package for fitting                    dynamic linear
      models with optional seasonal components;                • the arima function
      of the stats package and the Arima function of the forecast package for fitting                    seasonal
      components as part of an autoregressive integrated moving average (ARIMA) model;                    and                •
      the bfast package for detecting breaks in a seasonal pattern.            These
      tools are all useful, but most concern decomposing equally spaced time series
      data. Our package            includes models that can be applied to seasonal
      patterns in unequally spaced data. Such data are            common in observational
      studies when the timing of responses cannot be controlled (e.g. for a postal            survey).                 In
      the health literature much of the analysis of seasonal data uses simple methods
      such as com           paring rates of disease by month or using a cosinor regression
      model, which assumes a sinusoidal            seasonal pattern. We have created
      functions for these simple, but often very effective analyses, as we            describe
      below.                 More complex seasonal analyses examine non-stationary
      seasonal patterns that change over time.            Changing seasonal patterns
      in health are currently of great interest as global warming is predicted to            make
      seasonal changes in the weather more extreme. Hence there is a need for statistical
      tools that            can estimate whether a seasonal pattern has become more
      extreme over time or whether its phase has            changed.                 Ours
      is also the first R package that includes the case-crossover, a useful method
      for controlling for            seasonality.                 This paper illustrates
      just some of the functions of the season package. We show some descriptive            functions
      that give simple means or plots, and functions whose goal is inference based
      on generalised            linear models. The package was written as a companion
      to a book on seasonal analysis by Barnett and            Dobson (2010), which
      contains further details on the statistical methods and R code.'
    pages:
    - 5
    - 10
    CRANpkgs:
    - season
    - timsac
    - dynlm
    - sspir
    - forecast
    - bfast
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - Environmetrics
  - slug: RJ-2012-002
    old_slug: Holmes~et~al
    title: 'MARSS: Multivariate Autoregressive State-space Models for Analyzing Time-series
      Data'
    bibtitle: |-
      MARSS: Multivariate Autoregressive State-space Models for
                Analyzing Time-series Data
    author:
    - Elizabeth E. Holmes
    - Eric J. Ward
    - Kellie Wills
    bibauthor: Elizabeth E. Holmes and Eric J. Ward and Kellie Wills
    landing: '2012'
    abstract: '  Abstract MARSS is a package for fitting multivariate autoregressive
      state-space models to time-series            data. The MARSS package implements
      state-space models in a maximum likelihood framework. The            core functionality
      of MARSS is based on likelihood maximization using the Kalman filter/smoother,            combined
      with an EM algorithm. To make comparisons with other packages available, parameter            estimation
      is also permitted via direct search routines available in ’optim’. The MARSS
      package allows            data to contain missing values and allows a wide variety
      of model structures and constraints to be            specified (such as fixed
      or shared parameters). In addition to model-fitting, the package provides            bootstrap
      routines for simulating data and generating confidence intervals, and multiple
      options for            calculating model selection criteria (such as AIC).'
    pages:
    - 11
    - 19
    CRANpkgs:
    - MARSS
    - sspir
    - dlm
    - dse
    - KFAS
    - FKF
    CTV_rev:
    - TimeSeries
    - Finance
    - Bayesian
    - Environmetrics
  - slug: RJ-2012-003
    old_slug: Ropkins+Carslaw
    title: openair - Data Analysis Tools for the Air Quality Community
    bibtitle: openair - Data Analysis Tools for the Air Quality Community
    author:
    - Karl Ropkins
    - David C. Carslaw
    bibauthor: Karl Ropkins and David C. Carslaw
    landing: '2012'
    abstract: '  Abstract The openair package contains data analysis tools for the
      air quality community. This paper            provides an overview of data importers,
      main functions, and selected utilities and workhorse functions            within
      the package and the function output class, as of package version 0.4-14. It
      is intended as an            explanation of the rationale for the package and
      a technical description for those wishing to work            more interactively
      with the main functions or develop additional functions to support ‘higher level’            use
      of openair and R.                Large volumes of air quality data are routinely
      collected for regulatory purposes, but few of those            in local authorities
      and government bodies tasked with this responsibility have the time, expertise            or
      funds to comprehensively analyse this potential resource (Chow and Watson, 2008).
      Furthermore,            few of these institutions can routinely access the more
      powerful statistical methods typically required            to make the most
      effective use of such data without a suite of often expensive and niche-application            proprietary
      software products. This in turn places large cost and time burdens on both these
      institutions            and others (e.g. academic or commercial) wishing to
      contribute to this work. In addition, such            collaborative working
      practices can also become highly restricted and polarised if data analysis            undertaken
      by one partner cannot be validated or replicated by another because they lack
      access to            the same licensed products.                Being freely
      distributed under general licence, R has the obvious potential to act as a common            platform
      for those routinely collecting and archiving data and the wider air quality
      community.            This potential has already been proven in several other
      research areas, and commonly cited ex           amples include the Bioconductor
      project (Gentleman et al, 2004) and the Epitools collaboration            (http://www.medepi.com/epitools).
      However, what is perhaps most inspiring is the degree of trans           parency
      that has been demonstrated by the recent public analysis of climate change data
      in R and as           sociated open debate (http://chartsgraphs.wordpress.com/category/r-climate-data-analysis           tool/).
      Anyone affected by a policy decision, could potentially have unlimited access
      to scrutinise            both the tools and data used to shape that decision.'
    pages:
    - 20
    - 29
    CRANpkgs:
    - openair
    - openair
    - lattice
    - latticeExtra
    - hexbin
    - grDevices
    - mgcv
    - stats
    - grDevices
    - RColorBrewer
    CTV_rev:
    - Graphics
    - Environmetrics
    - SpatioTemporal
    - Bayesian
    - Econometrics
    - Multivariate
    - Pharmacokinetics
    - SocialSciences
    - Spatial
  - slug: RJ-2012-004
    old_slug: Adler
    title: Foreign Library Interface
    bibtitle: Foreign Library Interface
    author: Daniel Adler
    bibauthor: Daniel Adler
    landing: '2012'
    abstract: '  Abstract We present an improved Foreign Function Interface (FFI)
      for R to call arbitary native            functions without the need for C wrapper
      code. Further we discuss a dynamic linkage framework for            binding
      standard C libraries to R across platforms using a universal type information
      format. The            package rdyncall comprises the framework and an initial
      repository of cross-platform bindings for            standard libraries such
      as (legacy and modern) OpenGL, the family of SDL libraries and Expat. The            package
      enables system-level programming using the R language; sample applications are
      given in            the article. We outline the underlying automation tool-chain
      that extracts cross-platform bindings            from C headers, making the
      repository extendable and open for library developers.'
    pages:
    - 30
    - 40
    CRANpkgs:
    - rdyncall
    - Rffi
  - slug: RJ-2012-005
    old_slug: Lawson
    title: 'Vdgraph: A Package for Creating Variance Dispersion Graphs'
    bibtitle: 'Vdgraph: A Package for Creating Variance Dispersion Graphs'
    author: John Lawson
    bibauthor: John Lawson
    landing: '2012'
    abstract: '  Abstract This article introduces the package Vdgraph that is used
      for making variance dispersion            graphs of response surface designs.
      The package includes functions that make the variance dispersion            graph
      of one design or compare variance dispersion graphs of two designs, which are
      stored in data            frames or matrices. The package also contains several
      minimum run response surface designs (stored            as matrices) that are
      not available in other R packages.'
    pages:
    - 41
    - 44
    CRANpkgs:
    - Vdgraph
    - rsm
    CTV_rev: ExperimentalDesign
  - slug: RJ-2012-006
    old_slug: Anoke~et~al
    title: 'xgrid and R: Parallel Distributed Processing Using Heterogeneous Groups
      of Apple Computers'
    bibtitle: |-
      xgrid and R: Parallel Distributed Processing Using
                Heterogeneous Groups of Apple Computers
    author:
    - Sarah C. Anoke
    - Yuting Zhao
    - Rafael Jaeger
    - Nicholas J. Horton
    bibauthor: |-
      Sarah C. Anoke and Yuting Zhao and Rafael Jaeger and
                Nicholas J. Horton
    landing: '2012'
    abstract: '  Abstract The Apple Xgrid system provides access to groups (or grids)
      of computers that can be used            to facilitate parallel processing.
      We describe the xgrid package which facilitates access to this system            to
      undertake independent simulations or other long-running jobs that can be divided
      into replicate            runs within R. Detailed examples are provided to demonstrate
      the interface, along with results from a            simulation study of the
      performance gains using a variety of grids. Use of the grid for “embarassingly            parallel”
      independent jobs has the potential for major speedups in time to completion.
      Appendices            provide guidance on setting up the workflow, utilizing
      add-on packages, and constructing grids using            existing machines.'
    pages:
    - 45
    - 55
    CRANpkgs:
    - GridR
    - Rmpi
    - snow
    - multicore
    - xgrid
    - runjags
    - poLCA
    CTV_rev:
    - HighPerformanceComputing
    - Bayesian
    - Cluster
    - Multivariate
    - Psychometrics
  - slug: RJ-2012-007
    old_slug: Jurka
    title: 'maxent: An R Package for Low-memory Multinomial Logistic Regression with
      Support for Semi-automated Text Classification'
    bibtitle: |-
      maxent: An R Package for Low-memory Multinomial
                Logistic Regression with Support for Semi-automated Text
                Classification
    author: Timothy P. Jurka
    bibauthor: Timothy P. Jurka
    landing: '2012'
    abstract: '  Abstract maxent is a package with tools for data classification using
      multinomial logistic regression,            also known as maximum entropy. The
      focus of this maximum entropy classifier is to minimize memory            consumption
      on very large datasets, particularly sparse document-term matrices represented
      by the            tm text mining package.'
    pages:
    - 56
    - 59
    CRANpkgs:
    - nnet
    - mlogit
    - maxent
    - Rcpp
    - tm
    - Matrix
    - slam
    - SparseM
    CTV_rev:
    - Econometrics
    - NumericalMathematics
    - HighPerformanceComputing
    - Multivariate
    - NaturalLanguageProcessing
    - SocialSciences
    - MachineLearning
  - slug: RJ-2012-008
    old_slug: Bergsma+Smith
    title: 'Sumo: An Authenticating Web Application with an Embedded R Session'
    bibtitle: |-
      Sumo: An Authenticating Web Application with an Embedded R
                Session
    author:
    - Timothy T. Bergsma
    - Michael S. Smith
    bibauthor: Timothy T. Bergsma and Michael S. Smith
    landing: '2012'
    abstract: '  Abstract Sumo is a web application intended as a template for developers.
      It is distributed as a Java           ‘war’ file that deploys automatically
      when placed in a Servlet container’s ‘webapps’ directory. If a user            supplies
      proper credentials, Sumo creates a session-specific Secure Shell connection
      to the host and a            user-specific R session over that connection. Developers
      may write dynamic server pages that make            use of the persistent R
      session and user-specific file space. The supplied example plots a data set            conditional
      on preferences indicated by the user; it also displays some static text. A companion
      server            page allows the user to interact directly with the R session.
      Sumo’s novel feature set complements            previous efforts to supply R
      functionality over the internet.'
    pages:
    - 60
    - 63
    CRANpkgs:
    - Rpad
    - brew
    - R.rsp
    - Rook
    - Rserve
    - R2HTML
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
    - NumericalMathematics
  - slug: RJ-2012-009
    old_slug: Hornik~et~al
    title: Who Did What? The Roles of R Package Authors and How to Refer to Them
    bibtitle: |-
      Who Did What? The Roles of R Package Authors and How to
                Refer to Them
    author:
    - Kurt Hornik
    - Duncan Murdoch
    - Achim Zeileis
    bibauthor: Kurt Hornik and Duncan Murdoch and Achim Zeileis
    landing: '2012'
    abstract: '  Abstract Computational infrastructure for representing persons and
      citations has been available in R            for several years, but has been
      restructured through enhanced classes "person" and "bibentry" in            recent
      versions of R. The new features include support for the specification of the
      roles of package            authors (e.g. maintainer, author, contributor, translator,
      etc.) and more flexible formatting/printing            tools among various other
      improvements. Here, we introduce the new classes and their methods            and
      indicate how this functionality is employed in the management of R packages.
      Specifically, we            show how the authors of R packages can be specified
      along with their roles in package ‘DESCRIPTION’            and/or ‘CITATION’
      files and the citations produced from it.                 R packages are the
      result of scholarly activity and as such constitute scholarly resources which            must
      be clearly identifiable for the respective scientific communities and, more
      generally, today’s            information society. In particular, packages published
      by standard repositories can be regarded as            reliable sources which
      can and should be referenced (i.e. cited) by scientific works such as articles
      or            other packages. This requires conceptual frameworks and computational
      infrastructure for describing            bibliographic resources, general enough
      to encompass the needs of communities with an interest in R.            These
      needs include support for exporting bibliographic metadata in standardized formats
      such as            BIBTEX (Berry and Patashnik, 2010), but also facilitating
      bibliometric analyses and investigations of the            social fabric underlying
      the creation of scholarly knowledge.                 The latter requires a richer
      vocabulary than commonly employed by reference management            software
      such as BIBTEX, identifying persons and their roles in relation to bibliographic
      resources. For            example, a thesis typically has an author and advisors.
      Software can have an (original) author and a            translator to another
      language (such as from S to R). The maintainer of an R package is not necessarily            an
      author.                 In this paper, we introduce the base R infrastructure
      (as completely available in R since version            2.14.0) for representing
      and manipulating such scholarly data: objects of class "person" (hereafter,
      per           son objects) hold information about persons, possibly including
      their roles; objects of class "bibentry"            (hereafter, bibentry objects)
      hold bibliographic information in enhanced BIBTEX style, ideally using            person
      objects when referring to persons (such as authors or editors). Furthermore,
      we indicate how            this functionality is employed in the management
      of R packages, in particular in their ‘CITATION’ and           ‘DESCRIPTION’
      files.'
    pages:
    - 64
    - 69
    CRANpkgs:
    - boot
    - bibtex
    - XML
    CTV_rev:
    - Econometrics
    - Optimization
    - ReproducibleResearch
    - SocialSciences
    - Survival
    - TimeSeries
    - WebTechnologies
  notes:
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 70
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 96
- issue: 2012-2
  volume: 4
  year: 2012
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2012-016
    old_slug: Murrell
    title: What's in a Name?
    bibtitle: What's in a Name?
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2012'
    abstract: '  Abstract Any shape that is drawn using the grid graphics package
      can have a name associated            with it. If a name is provided, it is
      possible to access, query, and modify the shape after it has been            drawn.
      These facilities allow for very detailed customisations of plots and also for
      very general            transformations of plots that are drawn by packages
      based on grid.'
    pages:
    - 5
    - 12
  - slug: RJ-2012-017
    old_slug: Murrell2
    title: It's Not What You Draw,It's What You Don't Draw
    bibtitle: It's Not What You Draw,It's What You Don't Draw
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2012'
    abstract: '  Abstract The R graphics engine has new support for drawing complex
      paths via the functions            polypath() and grid.path(). This article
      explains what is meant by a complex path and demonstrates            the usefulness
      of complex paths in drawing non-trivial shapes, logos, customised data symbols,
      and            maps.                 One of the design goals of the R graphics
      system is to allow fine control over the small details            of plots.
      One way that the R graphics system does this is by providing access to low-level
      generic            graphics facilities, such as the ability to draw basic shapes
      and the ability to control apparently esoteric,            but still useful,
      features of those shapes, such as the line end style used for drawing lines.                 In
      R version 2.12.0, another low-level graphics facility was added to R: the ability
      to draw complex            paths (not just polygons).                 This article
      describes this new facility and presents some examples that show how complex
      paths            might be useful.'
    pages:
    - 13
    - 18
    CRANpkgs:
    - grImport
    - maptools
    - maps
    CTV_rev: Spatial
  - slug: RJ-2012-013
    old_slug: Murrell+Ly
    title: Debugging grid Graphics
    bibtitle: Debugging grid Graphics
    author:
    - Paul Murrell
    - Velvet Ly
    bibauthor: Paul Murrell and Velvet Ly
    landing: '2012'
    abstract: '  Abstract A graphical scene that has been produced using the grid
      graphics package consists of grobs            (graphical objects) and viewports.
      This article describes functions that allow the exploration and            inspection
      of the grobs and viewports in a grid scene, including several functions that
      are available in            a new package called gridDebug. The ability to explore
      the grobs and viewports in a grid scene is            useful for adding more
      drawing to a scene that was produced using grid and for understanding and            debugging
      the grid code that produced a scene.'
    pages:
    - 19
    - 27
    CRANpkgs:
    - ggplot2
    - gridDebug
    - graph
    - Rgraphviz
    - gridGraphviz
    - gridSVG
    - playwith
    CTV_rev:
    - Graphics
    - Phylogenetics
  - slug: RJ-2012-010
    old_slug: Do~Ha~et~al
    title: 'frailtyHL: A Package for Fitting Frailty Models with H-likelihood'
    bibtitle: |-
      frailtyHL: A Package for Fitting Frailty Models with H-
                likelihood
    author:
    - Il Do Ha
    - Maengseok Noh
    - Youngjo Lee
    bibauthor: Il Do Ha and Maengseok Noh and Youngjo Lee
    landing: '2012'
    abstract: '   Abstract We present the frailtyHL package for fitting semi-parametric
      frailty models using h            likelihood. This package allows lognormal
      or gamma frailties for random-effect distribution, and it             fits shared
      or multilevel frailty models for correlated survival data. Functions are provided
      to format             and summarize the frailtyHL results. The estimates of
      fixed effects and frailty parameters and their             standard errors are
      calculated. We illustrate the use of our package with three well-known data
      sets             and compare our results with various alternative R-procedures.'
    pages:
    - 28
    - 37
    CRANpkgs:
    - frailtyHL
    - survival
    - coxme
    - phmm
    - frailtypack
    - hglm
    - HGLMMM
    - dhglm
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - SocialSciences
  - slug: RJ-2012-011
    old_slug: Nieuwenhuis~et~al
    title: 'influence.ME: Tools for Detecting Influential Data in Mixed Effects Models'
    bibtitle: |-
      influence.ME: Tools for Detecting Influential Data in Mixed
                Effects Models
    author:
    - Rense Nieuwenhuis
    - Manfred te Grotenhuis
    - Ben Pelzer
    bibauthor: Rense Nieuwenhuis and Manfred te Grotenhuis and Ben Pelzer
    landing: '2012'
    abstract: '  Abstract influence.ME provides tools for detecting influential data
      in mixed effects models. The            application of these models has become
      common practice, but the development of diagnostic tools            has lagged
      behind. influence.ME calculates standardized measures of influential data for
      the point            estimates of generalized mixed effects models, such as
      DFBETAS, Cook’s distance, as well as percentile            change and a test
      for changing levels of significance. influence.ME calculates these measures
      of            influence while accounting for the nesting structure of the data.
      The package and measures of            influential data are introduced, a practical
      example is given, and strategies for dealing with influential            data
      are suggested.                 The application of mixed effects regression models
      has become common practice in the field of            social sciences. As used
      in the social sciences, mixed effects regression models take into account            that
      observations on individual respondents are nested within higher-level groups
      such as schools,            classrooms, states, and countries (Snijders and
      Bosker, 1999), and are often referred to as multilevel            regression
      models. Despite these models’ increasing popularity, diagnostic tools to evaluate
      fitted            models lag behind.                 We introduce influence.ME
      (Nieuwenhuis, Pelzer, and te Grotenhuis, 2012), an R-package that            provides
      tools for detecting influential cases in mixed effects regression models estimated
      with lme4            (Bates and Maechler, 2010). It is commonly accepted that
      tests for influential data should be performed            on regression models,
      especially when estimates are based on a relatively small number of cases.            However,
      most existing procedures do not account for the nesting structure of the data.
      As a result,            these existing procedures fail to detect that higher-level
      cases may be influential on estimates of            variables measured at specifically
      that level.                 In this paper, we outline the basic rationale on
      detecting influential data, describe standardized            measures of influence,
      provide a practical example of the analysis of students in 23 schools, and            discuss
      strategies for dealing with influential cases. Testing for influential cases
      in mixed effects            regression models is important, because influential
      data negatively influence the statistical fit and            generalizability
      of the model. In social science applications of mixed models the testing for
      influential            data is especially important, since these models are
      frequently based on large numbers of observations            at the individual
      level while the number of higher level groups is relatively small. For instance,
      Van der            Meer, te Grotenhuis, and Pelzer (2010) were unable to find
      any country-level comparative studies            involving more than 54 countries.
      With such a relatively low number of countries, a single country can            easily
      be overly influential on the parameter estimates of one or more of the country-level
      variables.'
    pages:
    - 38
    - 47
  - slug: RJ-2012-012
    old_slug: Nie+S~Racine
    title: 'The crs Package: Nonparametric Regression Splines for Continuous and Categorical
      Predictors'
    bibtitle: |-
      The crs Package: Nonparametric Regression Splines for
                Continuous and Categorical Predictors
    author:
    - Zhenghua Nie
    - Jeffrey S. Racine
    bibauthor: Zhenghua Nie and Jeffrey S. Racine
    landing: '2012'
    abstract: '  Abstract A new package crs is introduced for computing nonparametric
      regression (and quantile)            splines in the presence of both continuous
      and categorical predictors. B-splines are employed in the            regression
      model for the continuous predictors and kernel weighting is employed for the
      categorical            predictors. We also develop a simple R interface to NOMAD,
      which is a mixed integer optimization            solver used to compute optimal
      regression spline solutions.'
    pages:
    - 48
    - 56
    CRANpkgs:
    - crs
    - SemiPar
    - mgcv
    - gss
    - gam
    - MASS
    - rgl
    CTV_rev:
    - SocialSciences
    - Econometrics
    - Environmetrics
    - Multivariate
    - Bayesian
    - Distributions
    - Graphics
    - NumericalMathematics
    - Optimization
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SpatioTemporal
    - Survival
  - slug: RJ-2012-014
    old_slug: Kloke+McKean
    title: 'Rfit: Rank-based Estimation for Linear Models'
    bibtitle: 'Rfit: Rank-based Estimation for Linear Models'
    author:
    - John D. Kloke
    - Joseph W. McKean
    bibauthor: John D. Kloke and Joseph W. McKean
    landing: '2012'
    abstract: '  Abstract In the nineteen seventies, Jurečková and Jaeckel proposed
      rank estimation for linear models.            Since that time, several authors
      have developed inference and diagnostic methods for these estimators.            These
      rank-based estimators and their associated inference are highly efficient and
      are robust to            outliers in response space. The methods include estimation
      of standard errors, tests of general linear            hypotheses, confidence
      intervals, diagnostic procedures including studentized residuals, and measures            of
      influential cases. We have developed an R package, Rfit, for computing of these
      robust procedures.            In this paper we highlight the main features of
      the package. The package uses standard linear model            syntax and includes
      many of the main inference and diagnostic functions.'
    pages:
    - 57
    - 64
    CRANpkgs:
    - Rfit
    - Rfit
    - MASS
    - quantreg
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Robust
    - SocialSciences
    - Distributions
    - Multivariate
    - NumericalMathematics
    - Optimization
    - Pharmacokinetics
    - Psychometrics
    - ReproducibleResearch
    - Survival
  - slug: RJ-2012-015
    old_slug: Sadeghi+Marchetti
    title: Graphical Markov Models with Mixed Graphs in R
    bibtitle: Graphical Markov Models with Mixed Graphs in R
    author:
    - Kayvan Sadeghi
    - Giovanni M. Marchetti
    bibauthor: Kayvan Sadeghi and Giovanni M. Marchetti
    landing: '2012'
    abstract: '  Abstract In this paper we provide a short tutorial illustrating the
      new functions in the package ggm            that deal with ancestral, summary
      and ribbonless graphs. These are mixed graphs (containing three            types
      of edges) that are important because they capture the modified independence
      structure after            marginalisation over, and conditioning on, nodes
      of directed acyclic graphs. We provide functions to            verify whether
      a mixed graph implies that A is independent of B given C for any disjoint sets
      of nodes            and to generate maximal graphs inducing the same independence
      structure of non-maximal graphs.            Finally, we provide functions to
      decide on the Markov equivalence of two graphs with the same node            set
      but different types of edges.'
    pages:
    - 65
    - 73
    CRANpkgs:
    - gRain
    - ggm
    - ggm
    - igraph
    - gRbase
    CTV_rev:
    - gR
    - Graphics
    - Optimization
    - Spatial
  - slug: RJ-2012-018
    old_slug: Baaaath
    title: The State of Naming Conventions in R
    bibtitle: The State of Naming Conventions in R
    author: Rasmus Bååth
    bibauthor: Rasmus Bååth
    landing: '2012'
    abstract: '  Abstract Most programming language communities have naming conventions
      that are generally            agreed upon, that is, a set of rules that governs
      how functions and variables are named. This is not the            case with
      R, and a review of unofficial style guides and naming convention usage on CRAN
      shows            that a number of different naming conventions are currently
      in use. Some naming conventions are,            however, more popular than others
      and as a newcomer to the R community or as a developer of a new            package
      this could be useful to consider when choosing what naming convention to adopt.'
    pages:
    - 74
    - 75
  notes:
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 76
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2013-1
  year: 2013
  num: 1
  volume: 5
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Hadley Wickham
    slug: editorial
    pages:
    - 4
    - 5
  - heading: Contributed Research Articles
  - slug: RJ-2013-001
    old_slug: collingwood-jurka-boydstun-etal
    title: 'RTextTools: A Supervised Learning Package for Text Classification'
    bibtitle: |-
      RTextTools: A Supervised Learning Package for Text
                Classification
    author:
    - Timothy P. Jurka
    - Loren Collingwood
    - Amber E. Boydstun
    - Emiliano Grossman
    - Wouter van            Atteveldt
    bibauthor: |-
      Timothy P. Jurka and Loren Collingwood and Amber E. Boydstun
                and Emiliano Grossman and Wouter van Atteveldt
    landing: '2013'
    abstract: '  Abstract Social scientists have long hand-labeled texts to create
      datasets useful for studying topics            from congressional policymaking
      to media reporting. Many social scientists have begun to incorporate            machine
      learning into their toolkits. RTextTools was designed to make machine learning
      accessible            by providing a start-to-finish product in less than 10
      steps. After installing RTextTools, the initial            step is to generate
      a document term matrix. Second, a container object is created, which holds all            the
      objects needed for further analysis. Third, users can use up to nine algorithms
      to train their data.            Fourth, the data are classified. Fifth, the
      classification is summarized. Sixth, functions are available for            performance
      evaluation. Seventh, ensemble agreement is conducted. Eighth, users can cross-validate            their
      data. Finally, users write their data to a spreadsheet, allowing for further
      manual coding if            required.'
    pages:
    - 6
    - 12
    acknowledged: '2011-08-19'
    online: '2013-06-03'
    CRANpkgs:
    - RTextTools
    - glmnet
    - maxent
    - e1071
    - tm
    - ipred
    - caTools
    - randomForest
    - nnet
    - tree
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - NaturalLanguageProcessing
    - Survival
    - Cluster
    - Distributions
    - Econometrics
    - HighPerformanceComputing
    - Multivariate
    - Psychometrics
    - SocialSciences
  - slug: RJ-2013-002
    old_slug: xiang-gubian-suomela-etal
    title: 'Generalized Simulated Annealing for Global Optimization: The GenSA Package'
    bibtitle: |-
      Generalized Simulated Annealing for Global Optimization: The
                GenSA Package
    author:
    - Yang Xiang
    - Sylvain Gubian
    - Brian Suomela
    - Julia Hoeng
    bibauthor: |-
      Yang Xiang and Sylvain Gubian and Brian Suomela and Julia
                Hoeng
    landing: '2013'
    abstract: '  Abstract Many problems in statistics, finance, biology, pharmacology,
      physics, mathematics, eco           nomics, and chemistry involve determination
      of the global minimum of multidimensional functions.            R packages for
      different stochastic methods such as genetic algorithms and differential evolution            have
      been developed and successfully used in the R community. Based on Tsallis statistics,
      the R            package GenSA was developed for generalized simulated annealing
      to process complicated non-linear            objective functions with a large
      number of local minima. In this paper we provide a brief introduction            to
      the R package and demonstrate its utility by solving a non-convex portfolio
      optimization problem            in finance and the Thomson problem in physics.
      GenSA is useful and can serve as a complementary            tool to, rather
      than a replacement for, other widely used R packages for optimization.'
    pages:
    - 13
    - 28
    acknowledged: '2011-11-29'
    online: '2013-06-03'
    CRANpkgs:
    - DEoptim
    - rgenoud
    - likelihood
    - dclone
    - subselect
    - GenSA
    CTV_rev:
    - Optimization
    - HighPerformanceComputing
    - Bayesian
    - ChemPhys
    - gR
    - MachineLearning
  - slug: RJ-2013-003
    old_slug: kostov-becuebertaut-husson
    title: Multiple Factor Analysis for Contingency Tables in the FactoMineR Package
    bibtitle: |-
      Multiple Factor Analysis for Contingency Tables in the
                FactoMineR Package
    author:
    - Belchin Kostov
    - Mónica Bécue-Bertaut
    - François Husson
    bibauthor: Belchin Kostov and Mónica Bécue-Bertaut and François Husson
    landing: '2013'
    abstract: '  Abstract We present multiple factor analysis for contingency tables
      (MFACT) and its implementation            in the FactoMineR package. This method,
      through an option of the MFA function, allows us to deal            with multiple
      contingency or frequency tables, in addition to the categorical and quantitative
      multiple            tables already considered in previous versions of the package.
      Thanks to this revised function, either            a multiple contingency table
      or a mixed multiple table integrating quantitative, categorical and            frequency
      data can be tackled.                The FactoMineR package (Lê et al., 2008;
      Husson et al., 2011) offers the most commonly used            principal component
      methods: principal component analysis (PCA), correspondence analysis (CA;            Benzécri,
      1973), multiple correspondence analysis (MCA; Lebart et al., 2006) and multiple
      factor            analysis (MFA; Escofier and Pagès, 2008). Detailed presentations
      of these methods enriched by            numerous examples can be consulted at
      the website http://factominer.free.fr/.                An extension of the MFA
      function that considers contingency or frequency tables as proposed by            Bécue-Bertaut
      and Pagès (2004, 2008) is detailed in this article.                First, an
      example is presented in order to motivate the approach. Next, the mortality
      data used            to illustrate the method are introduced. Then we briefly
      describe multiple factor analysis (MFA)            and present the principles
      of its extension to contingency tables. A real example on mortality data            illustrates
      the handling of the MFA function to analyse these multiple tables and, finally,
      conclusions            are presented.'
    pages:
    - 29
    - 38
    acknowledged: '2011-12-14'
    online: '2013-06-03'
    CRANpkgs: FactoMineR
    CTV_rev:
    - Multivariate
    - Psychometrics
  - slug: RJ-2013-004
    old_slug: fox-friendly-weisberg
    title: Hypothesis Tests for Multivariate Linear Models Using the car Package
    bibtitle: |-
      Hypothesis Tests for Multivariate Linear Models Using the
                car Package
    author:
    - John Fox
    - Michael Friendly
    - Sanford Weisberg
    bibauthor: John Fox and Michael Friendly and Sanford Weisberg
    landing: '2013'
    abstract: '  Abstract The multivariate linear model is                                                     Y    =   X       B    +     E                                                   (n×m)    (n×
      p)( p×m)       (n×m)            The multivariate linear model can be fit with
      the lm function in R, where the left-hand side of the            model comprises
      a matrix of response variables, and the right-hand side is specified exactly
      as for            a univariate linear model (i.e., with a single response variable).
      This paper explains how to use the            Anova and linearHypothesis functions
      in the car package to perform convenient hypothesis tests for            parameters
      in multivariate linear models, including models for repeated-measures data.'
    pages:
    - 39
    - 52
    acknowledged: '2012-01-13'
    online: '2013-06-03'
    CRANpkgs:
    - car
    - lme4
    - nlme
    - survival
    - nnet
    - MASS
    - survey
    - heplots
    CTV_rev:
    - SocialSciences
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Psychometrics
    - Finance
    - Multivariate
    - Pharmacokinetics
    - SpatioTemporal
    - Survival
    - Bayesian
    - ChemPhys
    - ClinicalTrials
    - Distributions
    - MachineLearning
    - NumericalMathematics
    - Robust
    - Spatial
  - slug: RJ-2013-005
    old_slug: eugster-schlesinger
    title: 'osmar: OpenStreetMap and R'
    bibtitle: 'osmar: OpenStreetMap and R'
    author:
    - Manuel J. A. Eugster
    - Thomas Schlesinger
    bibauthor: Manuel J. A. Eugster and Thomas Schlesinger
    landing: '2013'
    abstract: '  Abstract OpenStreetMap provides freely accessible and editable geographic
      data. The osmar package            smoothly integrates the OpenStreetMap project
      into the R ecosystem. The osmar package provides            infrastructure to
      access OpenStreetMap data from different sources, to enable working with the
      OSM            data in the familiar R idiom, and to convert the data into objects
      based on classes provided by existing            R packages. This paper explains
      the package’s concept and shows how to use it. As an application we            present
      a simple navigation device.'
    pages:
    - 53
    - 63
    acknowledged: '2012-02-03'
    online: '2013-06-03'
    CRANpkgs:
    - osmar
    - osmar
    - OpenStreetMap
    - RgoogleMaps
    - ggmap
    - sp
    - igraph
    - geosphere
    - Rcpp
    CTV_rev:
    - Spatial
    - WebTechnologies
    - gR
    - Graphics
    - HighPerformanceComputing
    - NumericalMathematics
    - Optimization
    - SpatioTemporal
  - slug: RJ-2013-006
    old_slug: shang
    title: 'ftsa: An R Package for Analyzing Functional Time Series'
    bibtitle: 'ftsa: An R Package for Analyzing Functional Time Series'
    author: Han Lin Shang
    bibauthor: Han Lin Shang
    landing: '2013'
    abstract: '  Abstract Recent advances in computer recording and storing technology
      have tremendously increased            the presence of functional data, whose
      graphical representation can be infinite-dimensional curve,            image,
      or shape. When the same functional object is observed over a period of time,
      such data            are known as functional time series. This article makes
      first attempt to describe several techniques            (centered around functional
      principal component analysis) for modeling and forecasting functional            time
      series from a computational aspect, using a readily-available R addon package.
      These methods            are demonstrated using age-specific Australian fertility
      rate data from 1921 to 2006, and monthly sea            surface temperature
      data from January 1950 to December 2011.'
    pages:
    - 64
    - 72
    acknowledged: '2012-02-03'
    online: '2013-06-03'
    CRANpkgs: ftsa
  - slug: RJ-2013-007
    old_slug: godfrey
    title: Statistical Software from a Blind Person's Perspective
    bibtitle: Statistical Software from a Blind Person's Perspective
    author: A. Jonathan R. Godfrey
    bibauthor: A. Jonathan R. Godfrey
    landing: '2013'
    abstract: '  Abstract Blind people have experienced access issues to many software
      applications since the advent            of the Windows operating system; statistical
      software has proven to follow the rule and not be an            exception. The
      ability to use R within minutes of download with next to no adaptation has opened            doors
      for accessible production of statistical analyses for this author (himself blind)
      and blind students            around the world. This article shows how little
      is required to make R the most accessible statistical            software available
      today. There is any number of ramifications that this opportunity creates for
      blind            students, especially in terms of their future research and
      employment prospects. There is potential            for making R even better
      for blind users. The extensibility of R makes this possible through added            functionality
      being made available in an add-on package called BrailleR. Functions in this
      package            are intended to make graphical information available in text
      form.'
    pages:
    - 73
    - 79
    acknowledged: '2012-03-26'
    online: '2013-06-03'
    CRANpkgs:
    - Rcmdr
    - TeachingDemos
    - BrailleR
    - R2HTML
    CTV_rev:
    - Finance
    - ReproducibleResearch
  - slug: RJ-2013-008
    old_slug: zagaglia
    title: 'PIN: Measuring Asymmetric Information in Financial Markets with R'
    bibtitle: |-
      PIN: Measuring Asymmetric Information in Financial Markets
                with R
    author: Paolo Zagaglia
    bibauthor: Paolo Zagaglia
    landing: '2013'
    abstract: The package PIN computes a measure of asymmetric information in financial
      markets, the so-called probability of informed trading. This is obtained from
      a sequential trade model and is used to study the determinants of an asset price.
      Since the probability of informed trading depends on the number of buyand sell-initiated
      trades during a trading day, this paper discusses the entire modelling cycle,
      from data handling to the computation of the probability of informed trading
      and the estimation of parameters for the underlying theoretical model.
    pages:
    - 80
    - 86
    acknowledged: '2012-04-05'
    online: '2013-06-04'
    CRANpkgs:
    - PIN
    - highfrequency
    - IBrokers
    - orderbook
    CTV_rev: Finance
  - slug: RJ-2013-009
    old_slug: thiem-dusa
    title: 'QCA: A Package for Qualitative Comparative Analysis'
    bibtitle: 'QCA: A Package for Qualitative Comparative Analysis'
    author:
    - Alrik Thiem
    - Adrian Duşa
    bibauthor: Alrik Thiem and Adrian Duşa
    landing: '2013'
    abstract: ' Abstract We present QCA, a package for performing Qualitative Comparative
      Analysis (QCA). QCA           is becoming increasingly popular with social scientists,
      but none of the existing software alternatives           covers the full range
      of core procedures. This gap is now filled by QCA. After a mapping of the           method’s
      diffusion, we introduce some of the package’s main capabilities, including the
      calibration           of crisp and fuzzy sets, the analysis of necessity relations,
      the construction of truth tables and the           derivation of complex, parsimonious
      and intermediate solutions.'
    pages:
    - 87
    - 97
    acknowledged: '2012-04-20'
    online: '2013-06-03'
    CRANpkgs:
    - QCA
    - QCA3
    - VennDiagram
  - slug: RJ-2013-010
    old_slug: colleter-guitton-gascuel
    title: 'An Introduction to the EcoTroph R Package: Analyzing Aquatic Ecosystem
      Trophic Networks'
    bibtitle: |-
      An Introduction to the EcoTroph R Package: Analyzing Aquatic
                Ecosystem Trophic Networks
    author:
    - Mathieu Colléter
    - Jérôme Guitton
    - Didier Gascuel
    bibauthor: Mathieu Colléter and Jérôme Guitton and Didier Gascuel
    landing: '2013'
    abstract: '  Abstract Recent advances in aquatic ecosystem modelling have particularly
      focused on trophic            network analysis through trophodynamic models.
      We present here a R package devoted to a recently            developed model,
      EcoTroph. This model enables the analysis of aquatic ecological networks and
      the            related impacts of fisheries. It was available through a plug-in
      in the well-known Ecopath with Ecosim            software or through implementations
      in Excel sheets. The R package we developed simplifies the            access
      to the EcoTroph model and offers a new interfacing between two widely used software,
      Ecopath            and R.'
    pages:
    - 98
    - 107
    acknowledged: '2012-05-18'
    online: '2013-06-03'
    CRANpkgs:
    - EcoTroph
    - XML
    CTV_rev: WebTechnologies
  - slug: RJ-2013-011
    old_slug: valle-dellomodarme
    title: 'stellaR: A Package to Manage Stellar Evolution Tracks and Isochrones'
    bibtitle: |-
      stellaR: A Package to Manage Stellar Evolution Tracks and
                Isochrones
    author:
    - Matteo Dell’Omodarme
    - Giada Valle
    bibauthor: Matteo Dell’Omodarme and Giada Valle
    landing: '2013'
    abstract: '  Abstract We present the R package stellaR, which is designed to access
      and manipulate publicly            available stellar evolutionary tracks and
      isochrones from the Pisa low-mass database. The procedures            for extracting
      important stages in the evolution of a star from the database, for constructing
      isochrones            from stellar tracks and for interpolating among tracks
      are discussed and demonstrated.                 Due to the advance in the instrumentation,
      nowadays astronomers can deal with a huge amount            of high-quality
      observational data. In the last decade impressive improvements of spectroscopic
      and            photometric observational capabilities made available data which
      stimulated the research in the glob           ular clusters field. The theoretical
      effort of recovering the evolutionary history of the clusters benefits            from
      the computation of extensive databases of stellar tracks and isochrones, such
      as Pietrinferni et al.            (2006); Dotter et al. (2008); Bertelli et
      al. (2008). We recently computed a large data set of stellar tracks            and
      isochrones, “The Pisa low-mass database” (Dell’Omodarme et al., 2012), with
      up to date physical            and chemical inputs, and made available all the
      calculations to the astrophysical community at the            Centre de Données
      astronomiques de Strasbourg (CDS)1 , a data center dedicated to the collection
      and            worldwide distribution of astronomical data.                 In
      most databases, the management of the information and the extraction of the
      relevant evolu           tionary properties from libraries of tracks and/or
      isochrones is the responsibility of the end users.            Due to its extensive
      capabilities of data manipulation and analysis, however, R is an ideal choice
      for            these tasks. Nevertheless R is not yet well known in astrophysics;
      up to December 2012 only seven            astronomical or astrophysical-oriented
      packages have been published on CRAN (see the CRAN Task            View Chemometrics
      and Computational Physics).                 The package stellaR (Dell’Omodarme
      and Valle, 2012) is an effort to make available to the astro           physical
      community a basic tool set with the following capabilities: retrieve the required
      calculations            from CDS; plot the information in a suitable form; construct
      by interpolation tracks or isochrones of            compositions different to
      the ones available in the database; construct isochrones for age not included            in
      the database; extract relevant evolutionary points from tracks or isochrones.'
    pages:
    - 108
    - 116
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs: stellaR
    CTV_rev: ChemPhys
  - slug: RJ-2013-012
    old_slug: hofmann-unwin-cook
    title: Let Graphics Tell the Story - Datasets in R
    bibtitle: Let Graphics Tell the Story - Datasets in R
    author:
    - Antony Unwin
    - Heike Hofmann
    - Dianne Cook
    bibauthor: Antony Unwin and Heike Hofmann and Dianne Cook
    landing: '2013'
    abstract: ' Abstract Graphics are good for showing the information in datasets
      and for complementing modelling.           Sometimes graphics show information
      models miss, sometimes graphics help to make model results           more understandable,
      and sometimes models show whether information from graphics has statistical           support
      or not. It is the interplay of the two approaches that is valuable. Graphics
      could be used a lot           more in R examples and we explore this idea with
      some datasets available in R packages.'
    pages:
    - 117
    - 129
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs:
    - MASS
    - granova
    - ggplot2
    - vcd
    - knitr
    - HH
    CTV_rev:
    - Graphics
    - Multivariate
    - SocialSciences
    - ClinicalTrials
    - Distributions
    - Econometrics
    - Environmetrics
    - ExperimentalDesign
    - NumericalMathematics
    - Pharmacokinetics
    - Phylogenetics
    - Psychometrics
    - ReproducibleResearch
    - Robust
  - slug: RJ-2013-013
    old_slug: wilhelm-matos
    title: Estimating Spatial Probit Models in R
    bibtitle: Estimating Spatial Probit Models in R
    author:
    - Stefan Wilhelm
    - Miguel Godinho de Matos
    bibauthor: Stefan Wilhelm and Miguel Godinho de Matos
    landing: '2013'
    abstract: '  Abstract In this article we present the Bayesian estimation of spatial
      probit models in R and provide an            implementation in the package spatialprobit.
      We show that large probit models can be estimated with            sparse matrix
      representations and Gibbs sampling of a truncated multivariate normal distribution
      with            the precision matrix. We present three examples and point to
      ways to achieve further performance            gains through parallelization
      of the Markov Chain Monte Carlo approach.'
    pages:
    - 130
    - 143
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs:
    - spBayes
    - spatial
    - geoR
    - sgeostat
    - spdep
    - sphet
    - sna
    - network
    - Matrix
    - sparseM
    - spatialprobit
    - McSpatial
    - LearnBayes
    - tmvtnorm
    - mvtnorm
    - igraph
    CTV_rev:
    - Spatial
    - Bayesian
    - Distributions
    - Econometrics
    - SocialSciences
    - gR
    - Multivariate
    - Optimization
    - SpatioTemporal
    - Finance
    - Graphics
    - NumericalMathematics
    - Survival
  - slug: RJ-2013-014
    old_slug: kahle-wickham
    title: 'ggmap: Spatial Visualization with ggplot2'
    bibtitle: 'ggmap: Spatial Visualization with ggplot2'
    author:
    - David Kahle
    - Hadley Wickham
    bibauthor: David Kahle and Hadley Wickham
    landing: '2013'
    abstract: ' Abstract In spatial statistics the ability to visualize data and models
      superimposed with their basic           social landmarks and geographic context
      is invaluable. ggmap is a new tool which enables such           visualization
      by combining the spatial information of static maps from Google Maps, OpenStreetMap,           Stamen
      Maps or CloudMade Maps with the layered grammar of graphics implementation of
      ggplot2.           In addition, several new utility functions are introduced
      which allow the user to access the Google           Geocoding, Distance Matrix,
      and Directions APIs. The result is an easy, consistent and modular           framework
      for spatial graphics with several convenient tools for spatial data analysis.'
    pages:
    - 144
    - 161
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs:
    - sp
    - RgoogleMaps
    - ggplot2
    - ggmap
    - maps
    - maptools
    - DeducerSpatial
    - plyr
    - rjson
    - osmar
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Graphics
    - Phylogenetics
    - SpatioTemporal
  - slug: RJ-2013-015
    old_slug: kahle
    title: 'mpoly: Multivariate Polynomials in R'
    bibtitle: 'mpoly: Multivariate Polynomials in R'
    author: David Kahle
    bibauthor: David Kahle
    landing: '2013'
    abstract: '  Abstract The mpoly package is a general purpose collection of tools
      for symbolic computing with            multivariate polynomials in R. In addition
      to basic arithmetic, mpoly can take derivatives of polyno           mials, compute
      Gröbner bases of collections of polynomials, and convert polynomials into a
      functional            form to be evaluated. Among other things, it is hoped
      that mpoly will provide an R-based foundation            for the computational
      needs of algebraic statisticians.'
    pages:
    - 162
    - 170
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs:
    - mpoly
    - multipol
    - polynom
    - PolynomF
    - rSymPy
    CTV_rev: NumericalMathematics
  - slug: RJ-2013-016
    old_slug: forcheh-verbeke-kasim-etal
    title: 'beadarrayFilter: An R Package to Filter Beads'
    bibtitle: 'beadarrayFilter: An R Package to Filter Beads'
    author:
    - Anyiawung Chiara Forcheh
    - Geert Verbeke
    - Adetayo Kasim
    - Dan Lin
    - Ziv Shkedy
    - Willem Talloen
    - '           Hinrich W.H. Göhlmann'
    - Lieven Clement
    bibauthor: |-
      Anyiawung Chiara Forcheh and Geert Verbeke and Adetayo Kasim
                and Dan Lin and Ziv Shkedy and Willem Talloen and Hinrich
                W.H. Göhlmann and Lieven Clement
    landing: '2013'
    abstract: '  Abstract Microarrays enable the expression levels of thousands of
      genes to be measured simultane           ously. However, only a small fraction
      of these genes are expected to be expressed under different            experimental
      conditions. Nowadays, filtering has been introduced as a step in the microarray
      pre           processing pipeline. Gene filtering aims at reducing the dimensionality
      of data by filtering redundant            features prior to the actual statistical
      analysis. Previous filtering methods focus on the Affymetrix            platform
      and can not be easily ported to the Illumina platform. As such, we developed
      a filtering            method for Illumina bead arrays. We developed an R package,
      beadarrayFilter, to implement the            latter method. In this paper, the
      main functions in the package are highlighted and using many            examples,
      we illustrate how beadarrayFilter can be used to filter bead arrays.'
    pages:
    - 171
    - 180
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs: beadarrayFilter
  - slug: RJ-2013-017
    old_slug: mcdaniel-henderson-rathouz
    title: 'Fast Pure R Implementation of GEE: Application of the Matrix Package'
    bibtitle: |-
      Fast Pure R Implementation of GEE: Application of the Matrix
                Package
    author:
    - Lee S. McDaniel
    - Nicholas C. Henderson
    - Paul J. Rathouz
    bibauthor: |-
      Lee S. McDaniel and Nicholas C. Henderson and Paul J.
                Rathouz
    landing: '2013'
    abstract: '  Abstract Generalized estimating equation solvers in R only allow
      for a few pre-determined options            for the link and variance functions.
      We provide a package, geeM, which is implemented entirely in R            and
      allows for user specified link and variance functions. The sparse matrix representations
      provided            in the Matrix package enable a fast implementation. To gain
      speed, we make use of analytic inverses            of the working correlation
      when possible and a trick to find quick numeric inverses when an analytic            inverse
      is not available. Through three examples, we demonstrate the speed of geeM,
      which is not            much worse than C implementations like geepack and gee
      on small data sets and faster on large data            sets.'
    pages:
    - 181
    - 187
    acknowledged: '2012-10-17'
    online: '2013-06-03'
    CRANpkgs:
    - geepack
    - gee
    - geeM
    - Matrix
    CTV_rev:
    - Econometrics
    - SocialSciences
    - Multivariate
    - NumericalMathematics
  - slug: RJ-2013-018
    old_slug: bouchetvalat-bastin
    title: RcmdrPlugin.temis, a Graphical Integrated Text Mining Solution in R
    bibtitle: |-
      RcmdrPlugin.temis, a Graphical Integrated Text Mining
                Solution in R
    author:
    - Milan Bouchet-Valat
    - Gilles Bastin
    bibauthor: Milan Bouchet-Valat and Gilles Bastin
    landing: '2013'
    abstract: '  Abstract We present the package RcmdrPlugin.temis, a graphical user
      interface for user-friendly            text mining in R. Built as a plug-in
      to the R Commander provided by the Rcmdr package, it brings            together
      several existing packages and provides new features streamlining the process
      of importing,            managing and analyzing a corpus, in addition to saving
      results and plots to a report file. Beyond            common file formats, automated
      import of corpora from the Dow Jones Factiva content provider and            Twitter
      is supported. Featured analyses include vocabulary and dissimilarity tables,
      terms frequencies,            terms specific of levels of a variable, term co-occurrences,
      time series, correspondence analysis and            hierarchical clustering.'
    pages:
    - 188
    - 196
    acknowledged: '2012-10-29'
    online: '2013-06-03'
    CRANpkgs:
    - tm
    - RcmdrPlugin.temis
    - Rcmdr
    - RODBC
    - tm.plugin.factiva
    - twitteR
    - SnowballC
    - zoo
    - lattice
    - ca
    - R2HTML
    CTV_rev:
    - NaturalLanguageProcessing
    - Finance
    - Multivariate
    - Econometrics
    - Environmetrics
    - Graphics
    - HighPerformanceComputing
    - Pharmacokinetics
    - Psychometrics
    - ReproducibleResearch
    - TimeSeries
    - WebTechnologies
  - slug: RJ-2013-019
    old_slug: ooms
    title: Possible Directions for Improving Dependency Versioning in R
    bibtitle: Possible Directions for Improving Dependency Versioning in R
    author: Jeroen Ooms
    bibauthor: Jeroen Ooms
    landing: '2013'
    abstract: '  Abstract One of the most powerful features of R is its infrastructure
      for contributed code. The            built-in package manager and complementary
      repositories provide a great system for development            and exchange
      of code, and have played an important role in the growth of the platform towards
      the            de-facto standard in statistical computing that it is today.
      However, the number of packages on CRAN            and other repositories has
      increased beyond what might have been foreseen, and is revealing some            limitations
      of the current design. One such problem is the general lack of dependency versioning
      in            the infrastructure. This paper explores this problem in greater
      detail, and suggests approaches taken            by other open source communities
      that might work for R as well. Three use cases are defined that            exemplify
      the issue, and illustrate how improving this aspect of package management could
      increase            reliability while supporting further growth of the R community.'
    pages:
    - 197
    - 206
    acknowledged: '2013-01-17'
    online: '2013-06-03'
    CRANpkgs: CRAN
  - slug: RJ-2013-020
    old_slug: lebauer-dietze-bolker
    title: 'Translating Probability Density Functions: From R to BUGS and Back Again'
    bibtitle: |-
      Translating Probability Density Functions: From R to BUGS
                and Back Again
    author:
    - David S. LeBauer
    - Michael C. Dietze
    - Benjamin M. Bolker
    bibauthor: |-
      David S. LeBauer and Michael C. Dietze and Benjamin M.
                Bolker
    landing: '2013'
    abstract: '  Abstract The ability to implement statistical models in the BUGS
      language facilitates Bayesian in           ference by automating MCMC algorithms.
      Software packages that interpret the BUGS language            include OpenBUGS,
      WinBUGS, and JAGS. R packages that link BUGS software to the R environment,            including
      rjags and R2WinBUGS, are widely used in Bayesian analysis. Indeed, many packages
      in            the Bayesian task view on CRAN (http://cran.r-project.org/web/views/Bayesian.html)
      depend            on this integration. However, the R and BUGS languages use
      different representations of common            probability density functions,
      creating a potential for errors to occur in the implementation or interpre           tation
      of analyses that use both languages. Here we review different parameterizations
      used by the R            and BUGS languages, describe how to translate between
      the languages, and provide an R function,            r2bugs.distributions, that
      transforms parameterizations from R to BUGS and back again.'
    pages:
    - 207
    - 209
    acknowledged:
    - '2013-02-08'
    - '2013-02-15'
    online: '2013-06-17'
    CRANpkgs:
    - rjags
    - R2WinBUGS
    CTV_rev:
    - Bayesian
    - gR
    - Cluster
  - heading: News and Notes
  - title: 'Conference Review: The 6th Chinese R Conference'
    bibtitle: 'Conference Review: The 6th {C}hinese {R} Conference'
    author:
    - Jing Leng
    - Jingjing Guan
    slug: chinese-r-conf
    pages:
    - 210
    - 211
  - title: 'Conference Report: R/Finance 2013'
    bibtitle: 'Conference Report: {R/F}inance 2013'
    author: Joshua Ulrich
    slug: r-finance
    pages:
    - 212
    - 214
  - title: The R User Conference 2013
    bibtitle: The {R} {U}ser {C}onference 2013
    author: UseR 2013 Organising Committee
    bibauthor: '{UseR 2013 Organising Committee}'
    slug: user2013
    pages:
    - 215
    - 217
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 218
    - 219
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 220
    - 220
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 221
    - 238
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 239
    - 264
- issue: 2013-2
  year: 2013
  volume: 5
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Hadley Wickham
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2013-021
    old_slug: armstrong
    title: 'factorplot: Improving Presentation of Simple Contrasts in Generalized
      Linear Models'
    bibtitle: |-
      factorplot: Improving Presentation of Simple Contrasts in
                Generalized Linear Models
    author: David A. Armstrong II
    bibauthor: David A. Armstrong II
    landing: '2013'
    abstract: '  Abstract Recent statistical literature has paid attention to the
      presentation of pairwise comparisons            either from the point of view
      of the reference category problem in generalized linear models (GLMs)            or
      in terms of multiple comparisons. Both schools of thought are interested in
      the parsimonious            presentation of sufficient information to enable
      readers to evaluate the significance of contrasts            resulting from
      the inclusion of qualitative variables in GLMs. These comparisons also arise
      when            trying to interpret multinomial models where one category of
      the dependent variable is omitted as            a reference. While considerable
      advances have been made, opportunities remain to improve the            presentation
      of this information, especially in graphical form. The factorplot package provides
      new            functions for graphically and numerically presenting results
      of hypothesis tests related to pairwise            comparisons resulting from
      qualitative covariates in GLMs or coefficients in multinomial logistic            regression
      models.'
    pages:
    - 4
    - 15
    acknowledged: '2012-03-13'
    online: '2013-11-22'
    CRANpkgs:
    - multcomp
    - qvcalc
    - Epi
    - car
    - multcompView
    - factorplot
    CTV_rev:
    - SocialSciences
    - Survival
    - ClinicalTrials
    - Econometrics
    - Finance
    - Multivariate
  - slug: RJ-2013-022
    old_slug: sartore
    title: 'spMC: Modelling Spatial Random Fields with Continuous Lag Markov Chains'
    bibtitle: |-
      spMC: Modelling Spatial Random Fields with Continuous Lag
                Markov Chains
    author: Luca Sartore
    bibauthor: Luca Sartore
    landing: '2013'
    abstract: '  Abstract Currently, a part of the R statistical software is developed
      in order to deal with spatial models.            More specifically, some available
      packages allow the user to analyse categorical spatial random            patterns.
      However, only the spMC package considers a viewpoint based on transition probabilities            between
      locations. Through the use of this package it is possible to analyse the spatial
      variability of            data, make inference, predict and simulate the categorical
      classes in unobserved sites. An example is            presented by analysing
      the well-known Swiss Jura data set.'
    pages:
    - 16
    - 28
    acknowledged: '2012-08-27'
    online: '2013-09-27'
    CRANpkgs:
    - spMC
    - gstat
    - geoRglm
    - RandomFields
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Bayesian
  - slug: RJ-2013-023
    old_slug: michna-woods
    title: RNetCDF - A Package for Reading and Writing NetCDF Datasets
    bibtitle: RNetCDF - A Package for Reading and Writing NetCDF Datasets
    author:
    - Pavel Michna
    - Milton Woods
    bibauthor: Pavel Michna and Milton Woods
    landing: '2013'
    abstract: '  Abstract This paper describes the RNetCDF package (version 1.6),
      an interface for reading and            writing files in Unidata NetCDF format,
      and gives an introduction to the NetCDF file format. NetCDF            is a
      machine independent binary file format which allows storage of different types
      of array based            data, along with short metadata descriptions. The
      package presented here allows access to the most            important functions
      of the NetCDF C-interface for reading, writing, and modifying NetCDF datasets.            In
      this paper, we present a short overview on the NetCDF file format and show usage
      examples of the            package.'
    pages:
    - 29
    - 36
    acknowledged: '2012-08-27'
    online: '2013-10-14'
    CRANpkgs:
    - RNetCDF
    - ncdf
    - ncdf4
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2013-024
    old_slug: roediger-bohm-schimke
    title: Surface Melting Curve Analysis with R
    bibtitle: Surface Melting Curve Analysis with R
    author:
    - Stefan Rödiger
    - Alexander Böhm
    - Ingolf Schimke
    bibauthor: Stefan Rödiger and Alexander Böhm and Ingolf Schimke
    landing: '2013'
    abstract: ' Abstract Nucleic acid Melting Curve Analysis is a powerful method
      to investigate the interaction           of double stranded nucleic acids. Many
      researchers rely on closed source software which is not           ubiquitously
      available, and gives only little control over the computation and data presentation.           R
      in contrast, is open source, highly adaptable and provides numerous utilities
      for data import,           sophisticated statistical analysis and presentation
      in publication quality. This article covers methods,           implemented in
      the MBmca package, for DNA Melting Curve Analysis on microbead surfaces.           Particularly,
      the use of the second derivative melting peaks is suggested as an additional
      parameter to           characterize the melting behavior of DNA duplexes. Examples
      of microbead surface Melting Curve           Analysis on fragments of human
      genes are presented.'
    pages:
    - 37
    - 52
    acknowledged: '2012-09-04'
    online: '2013-08-26'
    CRANpkgs:
    - qpcR
    - MBmca
    - robustbase
    - stats
    - signal
    - zoo
    - delftfews
    - Hmisc
    - base
    - fda
    CTV_rev:
    - Econometrics
    - Multivariate
    - Bayesian
    - ClinicalTrials
    - Environmetrics
    - Finance
    - NumericalMathematics
    - OfficialStatistics
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - TimeSeries
  - slug: RJ-2013-025
    old_slug: lu-kane
    title: Performance Attribution for Equity Portfolios
    bibtitle: Performance Attribution for Equity Portfolios
    author:
    - Yang Lu
    - David Kane
    bibauthor: Yang Lu and David Kane
    landing: '2013'
    abstract: '  Abstract The pa package provides tools for conducting performance
      attribution for long-only, single            currency equity portfolios. The
      package uses two methods: the Brinson-Hood-Beebower model            (hereafter
      referred to as the Brinson model) and a regression-based analysis. The Brinson
      model takes            an ANOVA-type approach and decomposes the active return
      of any portfolio into asset allocation,            stock selection, and interaction
      effect. The regression-based analysis utilizes estimated coefficients,            based
      on a regression model, to attribute active return to different factors.'
    pages:
    - 53
    - 62
    acknowledged: '2012-10-11'
    online: '2013-09-23'
    CRANpkgs:
    - pa
    - portfolio
    - PerformanceAnalytics
    - portfolio
    CTV_rev: Finance
  - slug: RJ-2013-026
    old_slug: wang-shan
    title: 'ExactCIdiff: An R Package for Computing Exact Confidence Intervals for
      the Difference of Two Proportions'
    bibtitle: |-
      ExactCIdiff: An R Package for Computing Exact Confidence
                Intervals for the Difference of Two Proportions
    author:
    - Guogen Shan
    - Weizhen Wang
    bibauthor: Guogen Shan and Weizhen Wang
    landing: '2013'
    abstract: '  Abstract Comparing two proportions through the difference is a basic
      problem in statistics and has            applications in many fields. More than
      twenty confidence intervals (Newcombe, 1998a,b) have been            proposed.
      Most of them are approximate intervals with an asymptotic infimum coverage probability            much
      less than the nominal level. In addition, large sample may be costly in practice.
      So exact            optimal confidence intervals become critical for drawing
      valid statistical inference with accuracy and            precision. Recently,
      Wang (2010, 2012) derived the exact smallest (optimal) one-sided 1 − α confidence            intervals
      for the difference of two paired or independent proportions. His intervals,
      however, are            computer-intensive by nature. In this article, we provide
      an R package ExactCIdiff to implement the            intervals when the sample
      size is not large. This would be the first available package in R to calculate            the
      exact confidence intervals for the difference of proportions. Exact two-sided
      1 − α interval can be            easily obtained by taking the intersection
      of the lower and upper one-sided 1 − α/2 intervals. Readers            may jump
      to Examples 1 and 2 to obtain these intervals.'
    pages:
    - 62
    - 70
    acknowledged:
    - '2012-12-21'
    - '2013-02-15'
    online: '2013-08-16'
    CRANpkgs:
    - ExactCIdiff
    - Epi
    - PropCIs
    - exactci
    CTV_rev: Survival
  - slug: RJ-2013-027
    old_slug: bilgic-susmann
    title: 'rlme: An R Package for Rank-Based Estimation and Prediction in Random
      Effects Nested Models'
    bibtitle: |-
      rlme: An R Package for Rank-Based Estimation and Prediction
                in Random Effects Nested Models
    author:
    - Yusuf K. Bilgic
    - Herbert Susmann
    bibauthor: Yusuf K. Bilgic and Herbert Susmann
    landing: '2013'
    abstract: '  Abstract There is a lack of robust statistical analyses for random
      effects linear models. In practice,            statistical analyses, including
      estimation, prediction and inference, are not reliable when data are            unbalanced,
      of small size, contain outliers, or not normally distributed. It is fortunate
      that rank-based            regression analysis is a robust nonparametric alternative
      to likelihood and least squares analysis. We            propose an R package
      that calculates rank-based statistical analyses for twoand three-level random            effects
      nested designs. In this package, a new algorithm which recursively obtains robust
      predictions            for both scale and random effects is used, along with
      three rank-based fitting methods.'
    pages:
    - 71
    - 79
    acknowledged: '2013-02-04'
    online: '2013-10-25'
    CRANpkgs:
    - aa
    - Rfit
    - rlme
    - lme4
    CTV_rev:
    - Bayesian
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - SpatioTemporal
  - slug: RJ-2013-028
    old_slug: sax-steiner
    title: Temporal Disaggregation of Time Series
    bibtitle: Temporal Disaggregation of Time Series
    author:
    - Christoph Sax
    - Peter Steiner
    bibauthor: Christoph Sax and Peter Steiner
    landing: '2013'
    abstract: '  Abstract Temporal disaggregation methods are used to disaggregate
      low frequency time series to            higher frequency series, where either
      the sum, the average, the first or the last value of the resulting            high
      frequency series is consistent with the low frequency series. Temporal disaggregation
      can be            performed with or without one or more high frequency indicator
      series. The package tempdisagg is a            collection of several methods
      for temporal disaggregation.'
    pages:
    - 80
    - 87
    acknowledged: '2013-03-01'
    online: '2013-08-26'
    CRANpkgs: tempdisagg
    CTV_rev: TimeSeries
  - slug: RJ-2013-029
    old_slug: boehringer
    title: Dynamic Parallelization of R Functions
    bibtitle: Dynamic Parallelization of R Functions
    author: Stefan Böhringer
    bibauthor: Stefan Böhringer
    landing: '2013'
    abstract: '  Abstract R offers several extension packages that allow it to perform
      parallel computations. These            operate on fixed points in the program
      flow and make it difficult to deal with nested parallelism and            to
      organize parallelism in complex computations in general. In this article we
      discuss, first, of how to            detect parallelism in functions, and second,
      how to minimize user intervention in that process. We            present a solution
      that requires minimal code changes and enables to flexibly and dynamically choose            the
      degree of parallelization in the resulting computation. An implementation is
      provided by the R            package parallelize.dynamic and practical issues
      are discussed with the help of examples.'
    pages:
    - 88
    - 96
    acknowledged: '2013-03-29'
    online: '2013-12-27'
    CRANpkgs:
    - Rsge
    - foreach
    - boot
    - snow
    - parallelize.dynamic
    CTV_rev:
    - HighPerformanceComputing
    - Econometrics
    - Optimization
    - SocialSciences
    - Survival
    - TimeSeries
  - slug: RJ-2013-030
    old_slug: nadarajah-bakar
    title: 'CompLognormal: An R Package for Composite Lognormal Distributions'
    bibtitle: |-
      CompLognormal: An R Package for Composite Lognormal
                Distributions
    author:
    - S. Nadarajah
    - S. A. A. Bakar
    bibauthor: S. Nadarajah and S. A. A. Bakar
    landing: '2013'
    abstract: '  Abstract In recent years, composite models based on the lognormal
      distribution have become popular            in actuarial sciences and related
      areas. In this short note, we present a new R package for computing the            probability
      density function, cumulative density function, and quantile function, and for
      generating            random numbers of any composite model based on the lognormal
      distribution. The use of the package            is illustrated using a real
      data set.'
    pages:
    - 97
    - 103
    acknowledged: '2013-04-12'
    online: '2013-11-18'
    CRANpkgs:
    - CompLognormal
    - CRAN
    - poweRlaw
    - SMPracticals
    - MASS
    - fitdistrplus
    - distrMod
    CTV_rev:
    - Distributions
    - Survival
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2013-031
    old_slug: gaure
    title: 'lfe: Linear Group Fixed Effects'
    bibtitle: 'lfe: Linear Group Fixed Effects'
    author: Simen Gaure
    bibauthor: Simen Gaure
    landing: '2013'
    abstract: '  Abstract Linear models with fixed effects and many dummy variables
      are common in some fields.            Such models are straightforward to estimate
      unless the factors have too many levels. The R package            lfe solves
      this problem by implementing a generalization of the within transformation to
      multiple            factors, tailored for large problems.'
    pages:
    - 104
    - 116
    acknowledged:
    - '2013-04-12'
    - '2013-07-18'
    online: '2013-11-18'
    CRANpkgs:
    - Matrix
    - plm
    - lfe
    - igraph
    - multicore
    CTV_rev:
    - Econometrics
    - gR
    - Graphics
    - Multivariate
    - NumericalMathematics
    - Optimization
    - Spatial
    - SpatioTemporal
  - slug: RJ-2013-032
    old_slug: dietrich-zug-kaiser
    title: The R in Robotics
    bibtitle: The R in Robotics
    author:
    - André Dietrich
    - Sebastian Zug
    - Jörg Kaiser
    bibauthor: André Dietrich and Sebastian Zug and Jörg Kaiser
    landing: '2013'
    abstract: '  Abstract The aim of this contribution is to connect two previously
      separated worlds: robotic application            development with the Robot
      Operating System (ROS) and statistical programming with R. This            fruitful
      combination becomes apparent especially in the analysis and visualization of
      sensory data. We            therefore introduce a new language extension for
      ROS that allows to implement nodes in pure R. All            relevant aspects
      are described in a step-by-step development of a common sensor data transformation            node.
      This includes the reception of raw sensory data via the ROS network, message
      interpretation,            bag-file analysis, transformation and visualization,
      as well as the transmission of newly generated            messages back into
      the ROS network.'
    pages:
    - 117
    - 128
    acknowledged: '2013-04-12'
    online: '2013-12-13'
    CRANpkgs: Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
  - slug: RJ-2013-033
    old_slug: hofert
    title: On Sampling from the Multivariate t Distribution
    bibtitle: On Sampling from the Multivariate t Distribution
    author: Marius Hofert
    bibauthor: Marius Hofert
    landing: '2013'
    abstract: '  Abstract The multivariate normal and the multivariate t distributions
      belong to the most widely used            multivariate distributions in statistics,
      quantitative risk management, and insurance. In contrast to            the multivariate
      normal distribution, the parameterization of the multivariate t distribution
      does            not correspond to its moments. This, paired with a non-standard
      implementation in the R package            mvtnorm, provides traps for working
      with the multivariate t distribution. In this paper, common            traps
      are clarified and corresponding recent changes to mvtnorm are presented.'
    pages:
    - 129
    - 136
    acknowledged: '2013-04-29'
    online: '2013-11-04'
    CRANpkgs:
    - mvtnorm
    - MASS
    - evir
    - mnormt
    - QRM
    CTV_rev:
    - Distributions
    - Multivariate
    - Environmetrics
    - ExtremeValue
    - Econometrics
    - Finance
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2013-034
    old_slug: sucarrat
    title: 'betategarch: Simulation, Estimation and Forecasting of Beta-Skew-t-EGARCH
      Models'
    bibtitle: |-
      betategarch: Simulation, Estimation and Forecasting of Beta-
                Skew-t-EGARCH Models
    author: Genaro Sucarrat
    bibauthor: Genaro Sucarrat
    landing: '2013'
    abstract: '  Abstract This paper illustrates the usage of the betategarch package,
      a package for the simulation,            estimation and forecasting of Beta-Skew-t-EGARCH
      models. The Beta-Skew-t-EGARCH model is            a dynamic model of the scale
      or volatility of financial returns. The model is characterised by its            robustness
      to jumps or outliers, and by its exponential specification of volatility. The
      latter enables            richer dynamics, since parameters need not be restricted
      to be positive to ensure positivity of volatility.            In addition, the
      model also allows for heavy tails and skewness in the conditional return (i.e.
      scaled            return), and for leverage and a time-varying long-term component
      in the volatility specification. More            generally, the model can be
      viewed as a model of the scale of the error in a dynamic regression.'
    pages:
    - 137
    - 147
    acknowledged: '2013-06-04'
    online: '2013-12-23'
    CRANpkgs:
    - tseries
    - fGarch
    - rugarch
    - AutoSEARCH
    - zoo
    CTV_rev:
    - Finance
    - TimeSeries
    - Econometrics
    - Environmetrics
  - slug: RJ-2013-035
    old_slug: murrell
    title: Changes to grid for R 3.0.0
    bibtitle: Changes to grid for R 3.0.0
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2013'
    abstract: '  Abstract From R 3.0.0, there is a new recommended way to develop
      new grob classes in grid.            In a nutshell, two new “hook” functions,
      makeContext() and makeContent() have been added to            grid to provide
      an alternative to the existing hook functions preDrawDetails(), drawDetails(),
      and            postDrawDetails(). There is also a new function called grid.force().
      This article discusses why            these changes have been made, provides
      a simple demonstration of the use of the new functions, and            discusses
      some of the implications for packages that build on grid.'
    pages:
    - 148
    - 160
    acknowledged: '2013-06-04'
    online: '2013-09-27'
    CRANpkgs:
    - lattice
    - ggplot2
    - gtable
    - gridSVG
    - grImport
    - gridGraphviz
    - gridExtra
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
  - heading: News and Notes
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 161
    - 161
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 162
    - 163
  - title: 'Conference Report: Deuxièmes Rencontres R'
    bibtitle: 'Conference Report: Deuxi{\` e}mes Rencontres {R}'
    author:
    - Aurelie Siberchicot
    - Stephane Dray
    slug: siberchicot-dray
    pages:
    - 164
    - 165
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 166
    - 191
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 192
    - 198
- issue: 2014-1
  year: 2014
  volume: 6
  num: 1
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Deepayan Sarkar
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2014-001
    old_slug: sievert
    title: Taming PITCHf/x Data with XML2R and pitchRx
    bibtitle: Taming PITCHf/x Data with XML2R and pitchRx
    author: Carson Sievert
    bibauthor: Carson Sievert
    landing: '2014'
    abstract: '  Abstract XML2R is a framework that reduces the effort required to
      transform XML content into tables            in a way that preserves parent
      to child relationships. pitchRx applies XML2R’s grammar for XML            manipulation
      to Major League Baseball Advanced Media (MLBAM)’s Gameday data. With pitchRx,            one
      can easily obtain and store Gameday data in a remote database. The Gameday website
      hosts a            wealth of XML data, but perhaps most interesting is PITCHf/x.
      Among other things, PITCHf/x data            can be used to recreate a baseball’s
      flight path from a pitcher’s hand to home plate. With pitchRx, one            can
      easily create animations and interactive 3D scatterplots of the baseball’s flight
      path. PITCHf/x data            is also commonly used to generate a static plot
      of baseball locations at the moment they cross home            plate. These
      plots, sometimes called strike-zone plots, can also refer to a plot of event
      probabilities            over the same region. pitchRx provides an easy and
      robust way to generate strike-zone plots using            the ggplot2 package.'
    pages:
    - 5
    - 19
    acknowledged: '2013-01-17'
    online: '2014-03-03'
    CRANpkgs:
    - pitchRx
    - XML2R
    - ggplot2
    - rgl
    - dplyr
    - mgcv
    - knitr
    CTV_rev:
    - Graphics
    - Bayesian
    - Econometrics
    - Environmetrics
    - Multivariate
    - Phylogenetics
    - ReproducibleResearch
    - SocialSciences
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2014-002
    old_slug: nunes-taylor-eckley
    title: A Multiscale Test of Spatial Stationarity for Textured Images in R
    bibtitle: |-
      A Multiscale Test of Spatial Stationarity for Textured
                Images in R
    author:
    - Matthew A. Nunes
    - Sarah L. Taylor
    - Idris A. Eckley
    bibauthor: Matthew A. Nunes and Sarah L. Taylor and Idris A. Eckley
    landing: '2014'
    abstract: '  Abstract The ability to automatically identify areas of homogeneous
      texture present within a greyscale            image is an important feature
      of image processing algorithms. This article describes the R package            LS2Wstat
      which employs a recent wavelet-based test of stationarity for locally stationary
      random fields            to assess such spatial homogeneity. By embedding this
      test within a quadtree image segmentation            procedure we are also able
      to identify texture regions within an image.'
    pages:
    - 20
    - 30
    acknowledged: '2013-07-18'
    online: '2014-06-16'
    CRANpkgs:
    - LS2Wstat
    - LS2W
    - urca
    - CADFtest
    - locits
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
  - slug: RJ-2014-003
    old_slug: gu-shapiro-hughes-etal
    title: Stratified Weibull Regression Model for Interval-Censored Data
    bibtitle: |-
      Stratified Weibull Regression Model for Interval-Censored
                Data
    author:
    - Xiangdong Gu
    - David Shapiro
    - Michael D. Hughes
    - Raji Balasubramanian
    bibauthor: |-
      Xiangdong Gu and David Shapiro and Michael D. Hughes and
                Raji Balasubramanian
    landing: '2014'
    abstract: '  Abstract Interval censored outcomes arise when a silent event of
      interest is known to have occurred            within a specific time period
      determined by the times of the last negative and first positive diagnostic            tests.
      There is a rich literature on parametric and non-parametric approaches for the
      analysis of            interval-censored outcomes. A commonly used strategy
      is to use a proportional hazards (PH) model            with the baseline hazard
      function parameterized. The proportional hazards assumption can be relaxed            in
      stratified models by allowing the baseline hazard function to vary across strata
      defined by a subset of            explanatory variables. In this paper, we describe
      and implement a new R package straweib, for fitting            a stratified
      Weibull model appropriate for interval censored outcomes. We illustrate the
      R package            straweib by analyzing data from a longitudinal oral health
      study on the timing of the emergence of            permanent teeth in 4430 children.'
    pages:
    - 31
    - 40
    acknowledged: '2013-07-19'
    online: '2014-03-03'
    CRANpkgs:
    - survival
    - straweib
    CTV_rev:
    - ClinicalTrials
    - Econometrics
    - SocialSciences
    - Survival
  - slug: RJ-2014-004
    old_slug: muschelli-sweeney-crainiceanu
    title: 'brainR: Interactive 3 and 4D Images of High Resolution Neuroimage Data'
    bibtitle: |-
      brainR: Interactive 3 and 4D Images of High Resolution
                Neuroimage Data
    author:
    - John Muschelli
    - Elizabeth Sweeney
    - Ciprian Crainiceanu
    bibauthor: John Muschelli and Elizabeth Sweeney and Ciprian Crainiceanu
    landing: '2014'
    abstract: '  Abstract We provide software tools for displaying and publishing
      interactive 3-dimensional (3D) and            4-dimensional (4D) figures to
      html webpages, with examples of high-resolution brain imaging. Our            framework
      is based in the R statistical software using the rgl package, a 3D graphics
      library. We build            on this package to allow manipulation of figures
      including rotation and translation, zooming, coloring            of brain substructures,
      adjusting transparency levels, and addition/or removal of brain structures.            The
      need for better visualization tools of ultra high dimensional data is ever present;
      we are providing            a clean, simple, web-based option. We also provide
      a package (brainR) for users to readily implement            these tools.'
    pages:
    - 41
    - 48
    acknowledged: '2013-08-16'
    online: '2014-06-03'
    CRANpkgs:
    - rgl
    - knitr
    - Sweave
    - slidify
    - misc3d
    - brainR
    CTV_rev:
    - Graphics
    - Multivariate
    - MedicalImaging
    - ReproducibleResearch
    - SpatioTemporal
  - slug: RJ-2014-005
    old_slug: vandekerckhove-wabersich
    title: 'The RWiener Package: an R Package Providing Distribution Functions for
      the Wiener Diffusion Model'
    bibtitle: |-
      The RWiener Package: an R Package Providing Distribution
                Functions for the Wiener Diffusion Model
    author:
    - Dominik Wabersich
    - Joachim Vandekerckhove
    bibauthor: Dominik Wabersich and Joachim Vandekerckhove
    landing: '2014'
    abstract: '  Abstract We present the RWiener package that provides R functions
      for the Wiener diffusion model.            The core of the package are the four
      distribution functions dwiener, pwiener, qwiener and rwiener,            which
      use up-to-date methods, implemented in C, and provide fast and accurate computation
      of the            density, distribution, and quantile function, as well as a
      random number generator for the Wiener            diffusion model. We used the
      typical Wiener diffusion model with four parameters: boundary            separation,
      non-decision time, initial bias and drift rate parameter. Beyond the distribution
      functions,            we provide extended likelihood-based functions that can
      be used for parameter estimation and model            selection. The package
      can be obtained via CRAN.'
    pages:
    - 49
    - 56
    acknowledged: '2013-08-23'
    online: '2014-04-19'
    CRANpkgs: RWiener
  - slug: RJ-2014-006
    old_slug: qian
    title: 'PivotalR: A Package for Machine Learning on Big Data'
    bibtitle: 'PivotalR: A Package for Machine Learning on Big Data'
    author: Hai Qian
    bibauthor: Hai Qian
    landing: '2014'
    abstract: '  Abstract PivotalR is an R package that provides a front-end to PostgreSQL
      and all PostgreSQL-like            databases such as Pivotal Inc.’s Greenplum
      Database (GPDB) (Pivotal Inc., 2013a), HAWQ (Pivotal            Inc., 2013b).
      When running on the products of Pivotal Inc., PivotalR utilizes the full power
      of parallel            computation and distributive storage, and thus gives
      the normal R user access to big data. PivotalR            also provides the
      R wrapper for MADlib. MADlib is an open-source library for scalable in-database            analytics.
      It provides data-parallel implementations of mathematical, statistical and machine-learning            algorithms
      for structured and unstructured data. Thus PivotalR also enables the user to
      apply machine            learning algorithms onto big data.'
    pages:
    - 57
    - 67
    acknowledged: '2013-09-21'
    online: '2014-05-27'
    CRANpkgs:
    - PivotalR
    - RPostgreSQL
    - shiny
    CTV_rev: WebTechnologies
  - slug: RJ-2014-007
    old_slug: stanfill-hofmann-genschel
    title: 'rotations: An R Package for SO(3) Data'
    bibtitle: 'rotations: An R Package for SO(3) Data'
    author:
    - Bryan Stanfill
    - Heike Hofmann
    - Ulrike Genschel
    bibauthor: Bryan Stanfill and Heike Hofmann and Ulrike Genschel
    landing: '2014'
    abstract: '  Abstract In this article we introduce the rotations package which
      provides users with the ability to            simulate, analyze and visualize
      three-dimensional rotation data. More specifically it includes four            commonly
      used distributions from which to simulate data, four estimators of the central
      orientation,            six confidence region estimation procedures and two
      approaches to visualizing rotation data. All of            these features are
      available for two different parameterizations of rotations: three-by-three matrices            and
      quaternions. In addition, two datasets are included that illustrate the use
      of rotation data in            practice.'
    pages:
    - 68
    - 78
    acknowledged: '2013-09-21'
    online: '2014-04-19'
    CRANpkgs:
    - orientlib
    - onion
    - circular
    - SpherWave
    - rotations
    - ggplot2
    - sphereplot
    - Rcpp
    - RcppArmadillo
    CTV_rev:
    - NumericalMathematics
    - Graphics
    - Environmetrics
    - HighPerformanceComputing
    - Phylogenetics
  - slug: RJ-2014-008
    old_slug: menardi-lunardon-torelli
    title: 'ROSE: a Package for Binary Imbalanced Learning'
    bibtitle: 'ROSE: a Package for Binary Imbalanced Learning'
    author:
    - Nicola Lunardon
    - Giovanna Menardi
    - Nicola Torelli
    bibauthor: Nicola Lunardon and Giovanna Menardi and Nicola Torelli
    landing: '2014'
    abstract: '  Abstract The ROSE package provides functions to deal with binary
      classification problems in the            presence of imbalanced classes. Artificial
      balanced samples are generated according to a smoothed            bootstrap
      approach and allow for aiding both the phases of estimation and accuracy evaluation
      of a            binary classifier in the presence of a rare class. Functions
      that implement more traditional remedies for            the class imbalance
      and different metrics to evaluate accuracy are also provided. These are estimated            by
      holdout, bootstrap or cross-validation methods.'
    pages:
    - 79
    - 89
    acknowledged: '2013-09-21'
    online: '2014-06-16'
    CRANpkgs:
    - DMwR
    - caret
    - ROSE
    - ROSE
    - ROSE
    - class
    CTV_rev:
    - Multivariate
    - HighPerformanceComputing
    - MachineLearning
    - SocialSciences
  - slug: RJ-2014-009
    old_slug: greenwell-kabban
    title: 'investr: An R Package for Inverse Estimation'
    bibtitle: 'investr: An R Package for Inverse Estimation'
    author:
    - Brandon M. Greenwell
    - Christine M. Schubert Kabban
    bibauthor: Brandon M. Greenwell and Christine M. Schubert Kabban
    landing: '2014'
    abstract: '  Abstract Inverse estimation is a classical and well-known problem
      in regression. In simple terms, it            involves the use of an observed
      value of the response to make inference on the corresponding unknown            value
      of the explanatory variable. To our knowledge, however, statistical software
      is somewhat lacking            the capabilities for analyzing these types of
      problems. In this paper1 , we introduce investr (which            stands for
      inverse estimation in R), a package for solving inverse estimation problems
      in both linear            and nonlinear regression models.'
    pages:
    - 90
    - 100
    acknowledged: '2013-09-27'
    online: '2014-05-27'
    CRANpkgs:
    - investr
    - MASS
    - drc
    - car
    - boot
    CTV_rev:
    - Econometrics
    - SocialSciences
    - ChemPhys
    - Multivariate
    - Pharmacokinetics
    - Distributions
    - Environmetrics
    - Finance
    - NumericalMathematics
    - Optimization
    - Psychometrics
    - Robust
    - Survival
    - TimeSeries
  - slug: RJ-2014-010
    old_slug: jacques-grimonprez-biernacki
    title: 'Rankcluster: An R Package for Clustering Multivariate Partial Rankings'
    bibtitle: |-
      Rankcluster: An R Package for Clustering Multivariate
                Partial Rankings
    author:
    - Julien Jacques
    - Quentin Grimonprez
    - Christophe Biernacki
    bibauthor: |-
      Julien Jacques and Quentin Grimonprez and Christophe
                Biernacki
    landing: '2014'
    abstract: '  Abstract The Rankcluster package is the first R package proposing
      both modeling and clustering            tools for ranking data, potentially
      multivariate and partial. Ranking data are modeled by the Insertion            Sorting
      Rank (ISR) model, which is a meaningful model parametrized by a central ranking
      and a            dispersion parameter. A conditional independence assumption
      allows multivariate rankings to be            taken into account, and clustering
      is performed by means of mixtures of multivariate ISR models.            The
      parameters of the cluster (central rankings and dispersion parameters) help
      the practitioners            to interpret the clustering. Moreover, the Rankcluster
      package provides an estimate of the missing            ranking positions when
      rankings are partial. After an overview of the mixture of multivariate ISR            models,
      the Rankcluster package is described and its use is illustrated through the
      analysis of two            real datasets.'
    pages:
    - 101
    - 110
    acknowledged: '2013-10-04'
    online: '2014-03-03'
    CRANpkgs:
    - Rankcluster
    - pmr
    - RMallow
  - slug: RJ-2014-011
    old_slug: loo
    title: The stringdist Package for Approximate String Matching
    bibtitle: The stringdist Package for Approximate String Matching
    author: Mark P.J. van der Loo
    bibauthor: Mark P.J. van der Loo
    landing: '2014'
    abstract: '  Abstract Comparing text strings in terms of distance functions is
      a common and fundamental task in            many statistical text-processing
      applications. Thus far, string distance functionality has been somewhat            scattered
      around R and its extension packages, leaving users with inconistent interfaces
      and encoding            handling. The stringdist package was designed to offer
      a low-level interface to several popular string            distance algorithms
      which have been re-implemented in C for this purpose. The package offers            distances
      based on counting q-grams, edit-based distances, and some lesser known heuristic
      distance            functions. Based on this functionality, the package also
      offers inexact matching equivalents of R’s            native exact matching
      functions match and %in%.'
    pages:
    - 111
    - 122
    acknowledged: '2013-11-04'
    online: '2014-04-27'
    CRANpkgs:
    - kernlab
    - RecordLinkage
    - MiscPsycho
    - cba
    - Mkmisc
    - deducorrect
    - vwr
    - stringdist
    - textcat
    - TraMineR
    CTV_rev:
    - OfficialStatistics
    - Cluster
    - NaturalLanguageProcessing
    - Graphics
    - MachineLearning
    - Multivariate
    - Optimization
    - Survival
  - slug: RJ-2014-012
    old_slug: kaptein
    title: 'RStorm: Developing and Testing Streaming Algorithms in R'
    bibtitle: 'RStorm: Developing and Testing Streaming Algorithms in R'
    author: Maurits Kaptein
    bibauthor: Maurits Kaptein
    landing: '2014'
    abstract: '  Abstract Streaming data, consisting of indefinitely evolving sequences,
      are becoming ubiquitous in            many branches of science and in various
      applications. Computer scientists have developed streaming            applications
      such as Storm and the S4 distributed stream computing platform1 to deal with
      data            streams. However, in current production packages testing and
      evaluating streaming algorithms is            cumbersome. This paper presents
      RStorm for the development and evaluation of streaming algorithms            analogous
      to these production packages, but implemented fully in R. RStorm allows developers
      of            streaming algorithms to quickly test, iterate, and evaluate various
      implementations of streaming            algorithms. The paper provides both
      a canonical computer science example, the streaming word count,            and
      examples of several statistical applications of RStorm.'
    pages:
    - 123
    - 132
    acknowledged: '2013-11-18'
    online: '2014-03-18'
    CRANpkgs:
    - RStorm
    - stream
  - slug: RJ-2014-013
    old_slug: murrell-potter
    title: The gridSVG Package
    bibtitle: The gridSVG Package
    author:
    - Paul Murrell
    - Simon Potter
    bibauthor: Paul Murrell and Simon Potter
    landing: '2014'
    abstract: '  Abstract The gridSVG package can be used to generate a grid-based
      R plot in an SVG format, with            the ability to add special effects
      to the plot. The special effects include animation, interactivity, and            advanced
      graphical features, such as masks and filters. This article provides a basic
      introduction            to important functions in the gridSVG package and discusses
      the advantages and disadvantages of            gridSVG compared to similar R
      packages.'
    pages:
    - 133
    - 143
    acknowledged: '2013-11-18'
    online: '2014-06-02'
    CRANpkgs:
    - gridSVG
    - lattice
    - ggplot2
    - animation
    - RSVGTipsDevice
    - googleVis
    - shiny
    CTV_rev:
    - Graphics
    - WebTechnologies
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
    - ReproducibleResearch
    - SpatioTemporal
  - slug: RJ-2014-014
    old_slug: koziol-bilder
    title: 'MRCV: A Package for Analyzing Categorical Variables with Multiple Response
      Options'
    bibtitle: |-
      MRCV: A Package for Analyzing Categorical Variables with
                Multiple Response Options
    author:
    - Natalie A. Koziol
    - Christopher R. Bilder
    bibauthor: Natalie A. Koziol and Christopher R. Bilder
    landing: '2014'
    abstract: '  Abstract Multiple response categorical variables (MRCVs), also known
      as “pick any” or “choose            all that apply” variables, summarize survey
      questions for which respondents are allowed to select            more than one
      category response option. Traditional methods for analyzing the association
      between            categorical variables are not appropriate with MRCVs due
      to the within-subject dependence among            responses. We have developed
      the MRCV package as the first R package available to correctly analyze            MRCV
      data. Statistical methods offered by our package include counterparts to traditional
      Pearson            chi-square tests for independence and loglinear models, where
      bootstrap methods and Rao-Scott            adjustments are relied on to obtain
      valid inferences. We demonstrate the primary functions within the            package
      by analyzing data from a survey assessing the swine waste management practices
      of Kansas            farmers.'
    pages:
    - 144
    - 150
    acknowledged: '2013-11-22'
    online: '2014-04-19'
    CRANpkgs:
    - MRCV
    - geepack
    CTV_rev:
    - Econometrics
    - SocialSciences
  - slug: RJ-2014-015
    old_slug: leeper
    title: Archiving Reproducible Research with R and Dataverse
    bibtitle: Archiving Reproducible Research with R and Dataverse
    author: Thomas J. Leeper1
    bibauthor: Thomas J. Leeper1
    landing: '2014'
    abstract: '  Abstract Reproducible research and data archiving are increasingly
      important issues in research            involving statistical analyses of quantitative
      data. This article introduces the dvn package, which            allows R users
      to publicly archive datasets, analysis files, codebooks, and associated metadata
      in            Dataverse Network online repositories, an open-source data archiving
      project sponsored by Harvard            University. In this article I review
      the importance of data archiving in the context of reproducible            research,
      introduces the Dataverse Network, explain the implementation of the dvn package,
      and            provide example code for archiving and releasing data using the
      package.'
    pages:
    - 151
    - 158
    acknowledged: '2013-12-06'
    online: '2014-03-03'
    CRANpkgs:
    - dvn
    - knitr
    - rfigshare
    - RCurl
    - XML
    - rfigshare
    - rdryad
    - OAIHarvester
    CTV_rev:
    - WebTechnologies
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2014-018
    old_slug: bottomly-wilmot-mcweeney
    title: 'oligoMask: A Framework for Assessing and Removing the Effect of Genetic
      Variants on Microarray Probes'
    bibtitle: |-
      oligoMask: A Framework for Assessing and Removing the Effect
                of Genetic Variants on Microarray Probes
    author:
    - Daniel Bottomly
    - Beth Wilmot
    - Shannon K. McWeeney
    bibauthor: Daniel Bottomly and Beth Wilmot and Shannon K. McWeeney
    landing: '2014'
    abstract: '  Abstract As expression microarrays are typically designed relative
      to a reference genome, any            individual genetic variant that overlaps
      a probe’s genomic position can possibly cause a reduction            in hybridization
      due to the probe no longer being a perfect match to a given sample’s mRNA at            that
      locus. If the samples or groups used in a microarray study differ in terms of
      genetic variants,            the results of the microarray experiment can be
      negatively impacted. The oligoMask package is an            R/SQLite framework
      which can utilize publicly available genetic variants and works in conjunction            with
      the oligo package to read in the expression data and remove microarray probes
      which are likely            to impact a given microarray experiment prior to
      analysis. Tools are provided for creating an SQLite            database containing
      the probe and variant annotations and for performing the commonly used RMA            preprocessing
      procedure for Affymetrix microarrays. The oligoMask package is freely available
      at            https://github.com/dbottomly/oligoMask.'
    pages:
    - 159
    - 163
    acknowledged: '2014-03-06'
    online: '2014-05-27'
    BIOpkgs:
    - oligo
    - xps
    - maskBAD
    - VariantAnnotation
    - BSgenome
    - Biostrings
  - slug: RJ-2014-019
    old_slug: lombardi-pastore
    title: 'sgr: A Package for Simulating Conditional Fake Ordinal Data'
    bibtitle: 'sgr: A Package for Simulating Conditional Fake Ordinal Data'
    author:
    - Luigi Lombardi
    - Massimiliano Pastore
    bibauthor: Luigi Lombardi and Massimiliano Pastore
    landing: '2014'
    abstract: '  Abstract Many self-report measures of attitudes, beliefs, personality,
      and pathology include items that            can be easily manipulated by respondents.
      For example, an individual may deliberately attempt to            manipulate
      or distort responses to simulate grossly exaggerated physical or psychological
      symptoms            in order to reach specific goals such as, for example, obtaining
      financial compensation, avoiding being            charged with a crime, avoiding
      military duty, or obtaining drugs. This article introduces the package            sgr
      that can be used to perform fake data analysis according to the sample generation
      by replacement            approach. The package includes functions for making
      simple inferences about discrete/ordinal fake            data. The package allows
      to quantify uncertainty in inferences based on possible fake data as well as            to
      study the implications of fake data for empirical results.'
    pages:
    - 164
    - 177
    acknowledged: '2014-02-03'
    online: '2014-04-19'
    CRANpkgs:
    - sgr
    - polycor
    - MASS
    CTV_rev:
    - Multivariate
    - Psychometrics
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Pharmacokinetics
    - Robust
    - SocialSciences
  - heading: News and Notes
  - slug: RJ-2014-016
    old_slug: mair-chamberlain
    title: Web Technologies Task View
    bibtitle: Web Technologies Task View
    author:
    - Patrick Mair
    - Scott Chamberlain
    bibauthor: Patrick Mair and Scott Chamberlain
    landing: '2014'
    abstract: '  Abstract This article presents the CRAN Task View on Web Technologies.
      We describe the most            important aspects of Web Technologies and Web
      Scraping and list some of the packages that are            currently available
      on CRAN. Finally, we plot the network of Web Technology related package            dependencies.'
    pages:
    - 178
    - 181
    acknowledged: '2014-01-03'
    online: '2014-06-10'
    CRANpkgs:
    - XML
    - RCurl
    - rjson
    - RJSONIO
    - jsonlite
    - httr
    - ROAuth
    - shiny
    - rgbif
    - rfishbase
    - rfisheries
    - rsnps
    - rentrez
    - crn
    - RNCEP
    - WDI
    - TFX
    - anametrix
    - rpubchem
    - cimis
    - nhlscrapr
    - tm
    - translate
    - scholar
    - RgoogleMap
    - Rfacebook
    - twitteR
    - streamR
    - AWS.tools
    - MTurkR
    - GuardianR
    - igraph
    CTV_rev:
    - WebTechnologies
    - Spatial
    - ChemPhys
    - Finance
    - gR
    - Graphics
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - Optimization
  - slug: RJ-2014-017
    old_slug: godfrey-erhardt
    title: Addendum to ``Statistical Software from a Blind Person's Perspective''
    bibtitle: |-
      Addendum to ``Statistical Software from a Blind Person's
                Perspective''
    author:
    - A. Jonathan R. Godfrey
    - Robert Erhardt
    bibauthor: A. Jonathan R. Godfrey and Robert Erhardt
    landing: '2014'
    abstract: '  Abstract This short note explains a solution to a problem for blind
      users when using the R terminal            under Windows Vista or Windows 7,
      as identified in Godfrey (2013). We note the way the solution            was
      discovered and subsequent confirmatory experiments.                 As part
      of his preparations for teaching a blind student in a statistics course, the
      second author'
    pages:
    - 182
    - 182
    acknowledged: []
    online: '2014-03-03'
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 183
    - 183
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 184
    - 185
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 186
    - 220
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    bibauthor: '{The R Core Team}'
    pages:
    - 221
    - 235
- issue: 2014-2
  year: 2014
  volume: 6
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Deepayan Sarkar
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2014-020
    old_slug: stocco
    title: 'Coordinate-Based Meta-Analysis of fMRI Studies with R '
    bibtitle: Coordinate-Based Meta-Analysis of fMRI Studies with R
    author: Andrea Stocco
    bibauthor: Andrea Stocco
    landing: '2014'
    abstract: '  Abstract This paper outlines how to conduct a simple meta-analysis
      of neuroimaging foci of activation            in R. In particular, the first
      part of this paper reviews the nature of fMRI data, and briefly overviews            the
      existing packages that can be used to analyze fMRI data in R. The second part
      illustrates how            to handle fMRI data by showing how to visualize the
      results of different neuroimaging studies in a            so-called orthographic
      view, where the spatial distribution of the foci of activation from different
      fMRI            studies can be inspected visually.                 Functional
      MRI (fMRI) is one of the most important and powerful tools of neuroscientific
      research.            Although not as commonly used for fMRI analysis as some
      specific applications such as SPM (Friston            et al., 2006), AFNI (Cox
      and Hyde, 1997), or FSL (Smith et al., 2004), R does provide several packages            that
      can be employed in neuroimaging research. These packages deal with a variety
      of topics, ranging            from reading and manipulating fMRI datasets, to
      implementing sophisticated statistical models.                 The goal of this
      paper is to provide a brief introduction to fMRI analysis, and the various R            packages
      that can be used to carry it out. As an example, it will show how to use simple
      R commands            to read fMRI images and plot results from previous studies,
      which can then be visually compared. This            is a special form of meta-analysis,
      and a common way to compare results from the existing literature.'
    pages:
    - 5
    - 15
    acknowledged: '2013-03-01'
    online: '2014-11-13'
    CRANpkgs:
    - fmri
    - RNiftyReg
    - AnalyzeFMRI
    - RfmriVC
    - arf3DS4
    - BHMSMAfMRI
    - neuRosim
    - oro.nifti
    - spatstat
    CTV_rev:
    - MedicalImaging
    - ChemPhys
    - Spatial
    - SpatioTemporal
    - Survival
  - slug: RJ-2014-021
    old_slug: oh
    title: Automatic Conversion of Tables to LongForm Dataframes
    bibtitle: Automatic Conversion of Tables to LongForm Dataframes
    author: Jimmy Oh
    bibauthor: Jimmy Oh
    landing: '2014'
    abstract: '  Abstract TableToLongForm automatically converts hierarchical Tables
      intended for a human reader            into a simple LongForm dataframe that
      is machine readable, making it easier to access and use the data            for
      analysis. It does this by recognising positional cues present in the hierarchical
      Table (which would            normally be interpreted visually by the human
      brain) to decompose, then reconstruct the data into a            LongForm dataframe.
      The article motivates the benefit of such a conversion with an example Table,            followed
      by a short user manual, which includes a comparison between the simple one argument
      call            to TableToLongForm, with code for an equivalent manual conversion.
      The article then explores the            types of Tables the package can convert
      by providing a gallery of all recognised patterns. It finishes            with
      a discussion of available diagnostic methods and future work.'
    pages:
    - 16
    - 26
    acknowledged: '2013-11-04'
    online: '2014-09-26'
    CRANpkgs:
    - TableToLongForm
    - reshape2
    - plyr
  - slug: RJ-2014-022
    old_slug: zhang-etal
    title: Prinsimp
    bibtitle: Prinsimp
    author:
    - Jonathan Zhang
    - Nancy Heckman
    - Davor Cubranic
    - Joel G. Kingsolver
    - Travis Gaydos
    - J.S.            Marron
    bibauthor: |-
      Jonathan Zhang and Nancy Heckman and Davor Cubranic and Joel
                G. Kingsolver and Travis Gaydos and J.S. Marron
    landing: '2014'
    abstract: '  Abstract Principal Components Analysis (PCA) is a common way to study
      the sources of variation in            a high-dimensional data set. Typically,
      the leading principal components are used to understand the            variation
      in the data or to reduce the dimension of the data for subsequent analysis.
      The remaining            principal components are ignored since they explain
      little of the variation in the data. However, the            space spanned by
      the low variation principal components may contain interesting structure, structure            that
      PCA cannot find. Prinsimp is an R package that looks for interesting structure
      of low variability.           “Interesting” is defined in terms of a simplicity
      measure. Looking for interpretable structure in a low            variability
      space has particular importance in evolutionary biology, where such structure
      can signify            the existence of a genetic constraint.'
    pages:
    - 27
    - 42
    acknowledged: '2013-11-04'
    online: '2014-09-28'
    CRANpkgs: prinsimp
  - slug: RJ-2014-023
    old_slug: grayling
    title: 'phaseR: An R Package for Phase Plane Analysis of Autonomous ODE Systems'
    bibtitle: |-
      phaseR: An R Package for Phase Plane Analysis of Autonomous
                ODE Systems
    author: Michael J. Grayling
    bibauthor: Michael J. Grayling
    landing: '2014'
    abstract: '  Abstract When modelling physical systems, analysts will frequently
      be confronted by differential            equations which cannot be solved analytically.
      In this instance, numerical integration will usually be            the only
      way forward. However, for autonomous systems of ordinary differential equations
      (ODEs)            in one or two dimensions, it is possible to employ an instructive
      qualitative analysis foregoing this            requirement, using so-called
      phase plane methods. Moreover, this qualitative analysis can even prove            to
      be highly useful for systems that can be solved analytically, or will be solved
      numerically anyway.            The package phaseR allows the user to perform
      such phase plane analyses: determining the stability            of any equilibrium
      points easily, and producing informative plots.'
    pages:
    - 43
    - 51
    acknowledged: '2014-01-03'
    online: '2014-09-30'
    CRANpkgs:
    - deSolve
    - ReacTran
    - rootSolve
    - bvpSolve
    - sde
    - phaseR
    CTV_rev:
    - DifferentialEquations
    - Finance
    - Pharmacokinetics
    - TimeSeries
  - slug: RJ-2014-024
    old_slug: domelen-pittard
    title: Flexible R Functions for Processing Accelerometer Data, with Emphasis on
      NHANES 2003-2006
    bibtitle: |-
      Flexible R Functions for Processing Accelerometer Data, with
                Emphasis on NHANES 2003-2006
    author:
    - Dane R. Van Domelen
    - W. Stephen Pittard
    bibauthor: Dane R. Van Domelen and W. Stephen Pittard
    landing: '2014'
    abstract: '  Abstract Accelerometers are a valuable tool for measuring physical
      activity (PA) in epidemiological            studies. However, considerable processing
      is needed to convert time-series accelerometer data into            meaningful
      variables for statistical analysis. This article describes two recently developed
      R packages            for processing accelerometer data. The package accelerometry
      contains functions for performing            various data processing procedures,
      such as identifying periods of non-wear time and bouts of activity.            The
      functions are flexible, computationally efficient, and compatible with uniaxial
      or triaxial data.            The package nhanesaccel is specifically for processing
      data from the National Health and Nutrition            Examination Survey (NHANES),
      years 2003–2006. Its primary function generates measures of PA            volume,
      intensity, frequency, and patterns according to user-specified data processing
      methods. This            function can process the NHANES 2003-2006 dataset in
      under one minute, which is a drastic improve           ment over existing software.
      This article highlights important features of packages accelerometry and            nhanesaccel
      and demonstrates typical usage for PA researchers.'
    pages:
    - 52
    - 62
    acknowledged: '2014-03-15'
    online: '2015-01-04'
    CRANpkgs:
    - accelerometry
    - Rcpp
    - pawacc
    - PhysicalActivity
    - survey
    - GGIR
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    - OfficialStatistics
    - SocialSciences
    - Survival
  - slug: RJ-2014-025
    old_slug: alden-read-andrews-etal
    title: Applying spartan to Understand Parameter Uncertainty in Simulations
    bibtitle: |-
      Applying spartan to Understand Parameter Uncertainty in
                Simulations
    author:
    - Kieran Alden
    - Mark Read
    - Paul S Andrews
    - Jon Timmis
    - Mark Coles
    bibauthor: |-
      Kieran Alden and Mark Read and Paul S Andrews and Jon Timmis
                and Mark Coles
    landing: '2014'
    abstract: '  Abstract In attempts to further understand the dynamics of complex
      systems, the application of            computer simulation is becoming increasingly
      prevalent. Whereas a great deal of focus has been            placed in the development
      of software tools that aid researchers develop simulations, similar focus has            not
      been applied in the creation of tools that perform a rigorous statistical analysis
      of results generated            through simulation: vital in understanding how
      these results offer an insight into the captured            system. This encouraged
      us to develop spartan, a package of statistical techniques designed to assist            researchers
      in understanding the relationship between their simulation and the real system.
      Previously            we have described each technique within spartan in detail,
      with an accompanying immunology case            study examining the development
      of lymphoid tissue. Here we provide a practical introduction to            the
      package, demonstrating how each technique is run in R, to assist researchers
      in integrating this            package alongside their chosen simulation platform.'
    pages:
    - 63
    - 80
    acknowledged: '2014-04-08'
    online: '2014-09-30'
    CRANpkgs:
    - spartan
    - lhs
    - gplots
    - XML
    CTV_rev:
    - Distributions
    - ExperimentalDesign
    - Graphics
    - WebTechnologies
  - slug: RJ-2014-026
    old_slug: hughes
    title: 'ngspatial: A Package for Fitting the Centered Autologistic and Sparse
      Spatial Generalized Linear Mixed Models for Areal Data'
    bibtitle: |-
      ngspatial: A Package for Fitting the Centered Autologistic
                and Sparse Spatial Generalized Linear Mixed Models for Areal
                Data
    author: John Hughes
    bibauthor: John Hughes
    landing: '2014'
    abstract: '  Abstract Two important recent advances in areal modeling are the
      centered autologistic model and            the sparse spatial generalized linear
      mixed model (SGLMM), both of which are reparameterizations            of traditional
      models. The reparameterizations improve regression inference by alleviating
      spatial            confounding, and the sparse SGLMM also greatly speeds computing
      by reducing the dimension of the            spatial random effects. Package
      ngspatial (’ng’ = non-Gaussian) provides routines for fitting these            new
      models. The package supports composite likelihood and Bayesian inference for
      the centered            autologistic model, and Bayesian inference for the sparse
      SGLMM.'
    pages:
    - 81
    - 95
    acknowledged: '2014-04-18'
    online: '2015-01-04'
    CRANpkgs:
    - ngspatial
    - CARBayes
    - spdep
    - Rcpp
    - RcppArmadillo
    - batchmeans
    CTV_rev:
    - Spatial
    - NumericalMathematics
    - Econometrics
    - HighPerformanceComputing
  - slug: RJ-2014-027
    old_slug: conde-alvarez
    title: 'sgof: An R Package for Multiple Testing Problems'
    bibtitle: 'sgof: An R Package for Multiple Testing Problems'
    author:
    - Irene Castro-Conde
    - Jacobo de Uña-Álvarez
    bibauthor: Irene Castro-Conde and Jacobo de Uña-Álvarez
    landing: '2014'
    abstract: '  Abstract In this paper we present a new R package called sgof for
      multiple hypothesis testing. The            principal aim of this package is
      to implement SGoF-type multiple testing methods, known to be            more
      powerful than the classical false discovery rate (FDR) and family-wise error
      rate (FWER) based            methods in certain situations, particularly when
      the number of tests is large. This package includes Bi           nomial and
      Conservative SGoF and the Bayesian and Beta-Binomial SGoF multiple testing procedures,            which
      are adaptations of the original SGoF method to the Bayesian setting and to possibly
      correlated            tests, respectively. The sgof package also implements
      the Benjamini-Hochberg and Benjamini-Yekutieli            FDR controlling procedures.
      For each method the package provides (among other things) the number            of
      rejected null hypotheses, estimation of the corresponding FDR, and the set of
      adjusted p values.            Some automatic plots of interest are implemented
      too. Two real data examples are used to illustrate            how sgof works.'
    pages:
    - 96
    - 113
    acknowledged: '2014-04-18'
    online: '2014-11-24'
    CRANpkgs:
    - sgof
    - mutoss
    - multcomp
    BIOpkgs:
    - qvalue
    - HybridMTest
    - multtest
    CTV_rev:
    - ClinicalTrials
    - SocialSciences
    - Survival
  - slug: RJ-2014-028
    old_slug: rebora-salim-reilly
    title: 'bshazard: A Flexible Tool for Nonparametric Smoothing of the Hazard Function'
    bibtitle: |-
      bshazard: A Flexible Tool for Nonparametric Smoothing of the
                Hazard Function
    author:
    - Paola Rebora
    - Agus Salim
    - Marie Reilly
    bibauthor: Paola Rebora and Agus Salim and Marie Reilly
    landing: '2014'
    abstract: '  Abstract The hazard function is a key component in the inferential
      process in survival analysis and            relevant for describing the pattern
      of failures. However, it is rarely shown in research papers due            to
      the difficulties in nonparametric estimation. We developed the bshazard package
      to facilitate the            computation of a nonparametric estimate of the
      hazard function, with data-driven smoothing. The            method accounts
      for left truncation, right censoring and possible covariates. B-splines are
      used to            estimate the shape of the hazard within the generalized linear
      mixed models framework. Smoothness is            controlled by imposing an autoregressive
      structure on the baseline hazard coefficients. This perspective            allows
      an ’automatic’ smoothing by avoiding the need to choose the smoothing parameter,
      which is            estimated from the data as a dispersion parameter. A simulation
      study demonstrates the capability            of our software and an application
      to estimate the hazard of Non-Hodgkin’s lymphoma in Swedish            population
      data shows its potential.'
    pages:
    - 114
    - 122
    acknowledged: '2014-05-25'
    online: '2015-01-09'
    CRANpkgs:
    - muhaz
    - flexsurv
    - bshazard
    - Epi
    - survival
    - splines
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Distributions
    - Econometrics
    - SocialSciences
  - slug: RJ-2014-029
    old_slug: ferreira-batista
    title: 'SMR: An R package for computing the externally studentized normal midrange
      distribution'
    bibtitle: |-
      SMR: An R package for computing the externally studentized
                normal midrange distribution
    author:
    - Ben Dêivide Oliveira Batista
    - Daniel Furtado Ferreira
    bibauthor: Ben Dêivide Oliveira Batista and Daniel Furtado Ferreira
    landing: '2014'
    abstract: '  Abstract The main purpose of this paper is to present the main algorithms
      underlining the con           struction and implementation of the SMR package,
      whose aim to compute studentized normal            midrange distribution. Details
      on the externally studentized normal midrange and standardized            normal
      midrange distributions are also given. The package follows the same structure
      as the prob           ability functions implemented in R. That is: the probability
      density function (dSMR), the cumulative            distribution function (pSMR),
      the quantile function (qSMR) and the random number generating function            (rSMR).
      The pseudocodes and illustrative examples of how to use the package are presented.'
    pages:
    - 123
    - 136
    acknowledged: '2014-05-25'
    online: '2015-01-04'
    CRANpkgs: SMR
    CTV_rev: Distributions
  - slug: RJ-2014-030
    old_slug: hoff-gran-farewell
    title: 'Farewell''s Linear Increments Model for Missing Data: The FLIM package'
    bibtitle: |-
      Farewell's Linear Increments Model for Missing Data: The
                FLIM package
    author:
    - Rune Hoff
    - Jon Michael Gran
    - Daniel Farewell
    bibauthor: Rune Hoff and Jon Michael Gran and Daniel Farewell
    landing: '2014'
    abstract: '  Abstract Missing data is common in longitudinal studies. We present
      a package for Farewell’s Linear            Increments Model for Missing Data
      (the FLIM package), which can be used to fit linear models for            observed
      increments of longitudinal processes and impute missing data. The method is
      valid for            data with regular observation patterns. The end result
      is a list of fitted models and a hypothetical            complete dataset corresponding
      to the data we might have observed had individuals not been missing.            The
      FLIM package may also be applied to longitudinal studies for causal analysis,
      by considering            counterfactual data as missing data for instance to
      compare the effect of different treatments when            only data from observational
      studies are available. The aim of this article is to give an introduction to            the
      FLIM package and to demonstrate how the package can be applied.'
    pages:
    - 137
    - 150
    acknowledged: '2014-05-25'
    online: '2015-01-09'
    CRANpkgs: zoo
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Finance
    - TimeSeries
  - slug: RJ-2014-031
    old_slug: korkmaz-goksuluk-zararsiz
    title: 'MVN: An R Package for Assessing Multivariate Normality'
    bibtitle: 'MVN: An R Package for Assessing Multivariate Normality'
    author:
    - Selcuk Korkmaz
    - Dincer Goksuluk
    - Gokmen Zararsiz
    bibauthor: Selcuk Korkmaz and Dincer Goksuluk and Gokmen Zararsiz
    landing: '2014'
    abstract: '  Abstract Assessing the assumption of multivariate normality is required
      by many parametric mul           tivariate statistical methods, such as MANOVA,
      linear discriminant analysis, principal component            analysis, canonical
      correlation, etc. It is important to assess multivariate normality in order
      to proceed            with such statistical methods. There are many analytical
      methods proposed for checking multivariate            normality. However, deciding
      which method to use is a challenging process, since each method may            give
      different results under certain conditions. Hence, we may say that there is
      no best method, which            is valid under any condition, for normality
      checking. In addition to numerical results, it is very useful            to
      use graphical methods to decide on multivariate normality. Combining the numerical
      results from            several methods with graphical approaches can be useful
      and provide more reliable decisions. Here,            we present an R package,
      MVN, to assess multivariate normality. It contains the three most widely            used
      multivariate normality tests, including Mardia’s, Henze-Zirkler’s and Royston’s,
      and graphical            approaches, including chi-square Q-Q, perspective and
      contour plots. It also includes two multivariate            outlier detection
      methods, which are based on robust Mahalanobis distances. Moreover, this package            offers
      functions to check the univariate normality of marginal distributions through
      both tests and            plots. Furthermore, especially for non-R users, we
      provide a user-friendly web application of the            package. This application
      is available at http://www.biosoft.hacettepe.edu.tr/MVN/.'
    pages:
    - 151
    - 162
    acknowledged: '2014-06-10'
    online: '2015-01-04'
    CRANpkgs:
    - MASS
    - FactoMineR
    - psych
    - CCA
    - MVN
    - shiny
    CTV_rev:
    - Psychometrics
    - Multivariate
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Pharmacokinetics
    - Robust
    - SocialSciences
    - WebTechnologies
  - slug: RJ-2014-032
    old_slug: zabala
    title: 'qmethod: A Package to Explore Human Perspectives Using Q Methodology'
    bibtitle: |-
      qmethod: A Package to Explore Human Perspectives Using Q
                Methodology
    author: Aiora Zabala
    bibauthor: Aiora Zabala
    landing: '2014'
    abstract: '  Abstract Q is a methodology to explore the distinct subjective perspectives
      that exist within a group. It            is used increasingly across disciplines.
      The methodology is semi-qualitative and the data are analysed            using
      data reduction methods to discern the existing patterns of thought. This package
      is the first to            perform Q analysis in R, and it provides many advantages
      to the existing software: namely, it is fully            cross-platform, the
      algorithms can be transparently examined, it provides results in a clearly structured            and
      tabulated form ready for further exploration and modelling, it produces a graphical
      summary            of the results, and it generates a more concise report of
      the distinguishing and consensus statements.            This paper introduces
      the methodology and explains how to use the package, its advantages as well            as
      its limitations. I illustrate the main functions with a dataset on value patterns
      about democracy.'
    pages:
    - 163
    - 173
    acknowledged: '2014-07-28'
    online: '2015-01-04'
    CRANpkgs:
    - qmethod
    - psych
    - GPArotation
    - FactoMineR
    CTV_rev:
    - Psychometrics
    - Multivariate
  - slug: RJ-2014-033
    old_slug: liu
    title: 'gset: An R Package for Exact Sequential Test of Equivalence Hypothesis
      Based on Bivariate Non-Central t-Statistics'
    bibtitle: |-
      gset: An R Package for Exact Sequential Test of Equivalence
                Hypothesis Based on Bivariate Non-Central t-Statistics
    author: Fang Liu
    bibauthor: Fang Liu
    landing: '2014'
    abstract: '  Abstract The R package gset calculates equivalence and futility boundaries
      based on the exact            bivariate non-central t test statistics. It is
      the first R package that targets specifically at the group            sequential
      test of equivalence hypotheses. The exact test approach adopted by gset neither
      assumes            the large-sample normality of the test statistics nor ignores
      the contribution to the overall Type I error            rate from rejecting
      one out of the two one-sided hypotheses under a null value. The features of
      gset            include: error spending functions, computation of equivalence
      boundaries and futility boundaries,            either binding or nonbinding,
      depiction of stagewise boundary plots, and operating characteristics            of
      a given group sequential design including empirical Type I error rate, empirical
      power, expected            sample size, and probability of stopping at an interim
      look due to equivalence or futility.'
    pages:
    - 174
    - 184
    acknowledged: '2014-08-16'
    online: '2015-01-04'
    CRANpkgs:
    - gsDesign
    - GroupSeq
    - Hmisc
    - PwrGSD
    - AGSDest
    - clinfun
    CTV_rev:
    - ClinicalTrials
    - ExperimentalDesign
    - Bayesian
    - Econometrics
    - Multivariate
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
    - Survival
  - heading: News and Notes
  - title: 'Conference Report: R in Insurance 2014'
    bibtitle: 'Conference Report: {R} in Insurance 2014'
    slug: gesmann-tsanakas
    author:
    - Markus Gesmann
    - Andreas Tsanakas
    pages:
    - 185
    - 186
  - title: Conference Report Polish Academic R User Meeting
    bibtitle: 'Conference Report: {P}olish Academic {R} User Meeting'
    slug: beresewicz-szabelska-zyprychwalczak-etal
    author:
    - Maciej Beręsewicz
    - Alicja Szabelska
    - Joanna Zyprych-Walczak
    - Łukasz Wawrowski
    bibauthor:
    - Maciej Ber{\k e}sewicz
    - Alicja Szabelska
    - Joanna Zyprych-Walczak
    - \L{}ukasz Wawrowski
    pages:
    - 187
    - 189
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author:
    - Martin Mächler
    - Kurt Hornik
    slug: r-foundation
    bibauthor:
    - Martin M{\" a}chler
    - Kurt Hornik
    pages:
    - 190
    - 191
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 192
    - 223
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    bibauthor: '{The R Core Team}'
    pages:
    - 224
    - 226
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    bibauthor: '{The Bioconductor Team}'
    slug: bioconductor
    pages:
    - 227
    - 228
- issue: 2015-1
  year: 2015
  volume: 7
  num: 1
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Bettina Grün
    bibauthor: Bettina Gr{\" u}n
    slug: editorial
    pages: 3
  - heading: Contributed Research Articles
  - slug: RJ-2015-001
    old_slug: osorio-rondonvillarreal-torres
    title: 'Peptides: A Package for Data Mining of Antimicrobial Peptides'
    bibtitle: |-
      Peptides: A Package for Data Mining of Antimicrobial
                Peptides
    author:
    - Daniel Osorio
    - Paola Rondón-Villarreal
    - Rodrigo Torres
    bibauthor: Daniel Osorio and Paola Rondón-Villarreal and Rodrigo Torres
    landing: '2015'
    abstract: '  Abstract Antimicrobial peptides (AMP) are a promising source of antibiotics
      with a broad spectrum            activity against bacteria and low incidence
      of developing resistance. The mechanism by which an            AMP executes
      its function depends on a set of computable physicochemical properties from
      the amino            acid sequence. The Peptides package was designed to allow
      the quick and easy computation of ten            structural characteristics
      own of the antimicrobial peptides, with the aim of generating data to increase            the
      accuracy in classification and design of new amino acid sequences. Moreover,
      the options to read            and plot XVG output files from GROMACS molecular
      dynamics package are included.'
    pages:
    - 4
    - 14
    acknowledged: '2014-04-18'
    online: '2015-02-04'
    CRANpkgs:
    - Peptides
    - caret
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
    - Multivariate
  - slug: RJ-2015-002
    old_slug: abel
    title: 'fanplot: An R Package for Visualising Sequential Distributions'
    bibtitle: |-
      fanplot: An R Package for Visualising Sequential
                Distributions
    author: Guy J. Abel
    bibauthor: Guy J. Abel
    landing: '2015'
    abstract: '  Abstract Fan charts, first developed by the Bank of England in 1996,
      have become a standard method            for visualising forecasts with uncertainty.
      Using shading fan charts focus the attention towards the            whole distribution
      away from a single central measure. This article describes the basics of plotting            fan
      charts using an R add-on package alongside some additional methods for displaying
      sequential            distributions. Examples are based on distributions of
      both estimated parameters from a time series            model and future values
      with uncertainty.'
    pages:
    - 15
    - 23
    acknowledged: '2014-05-25'
    online: '2015-04-07'
    CRANpkgs:
    - vars
    - forecast
    - fanplot
    - R2OpenBUGS
    - zoo
    - tsbugs
    - RColorBrewer
    - shiny
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - Environmetrics
    - gR
    - Graphics
    - Spatial
    - WebTechnologies
  - slug: RJ-2015-003
    old_slug: templ-kowarik-meindl
    title: 'sparkTable: Generating Graphical Tables for Websites and Documents with
      R'
    bibtitle: |-
      sparkTable: Generating Graphical Tables for Websites and
                Documents with R
    author:
    - Alexander Kowarik
    - Bernhard Meindl
    - Matthias Templ
    bibauthor: Alexander Kowarik and Bernhard Meindl and Matthias Templ
    landing: '2015'
    abstract: '  Abstract                  Visual analysis of data is important to
      understand the main characteristics, main trends and            relationships
      in data sets and it can be used to assess the data quality. Using the R package
      sparkTable,            statistical tables holding quantitative information can
      be enhanced by including spark-type graphs            such as sparklines                and
      sparkbars              .                  These kind of graphics are well-known
      in literature and are considered as simple, intense and            illustrative
      graphs that are small enough to fit in a single line. Thus, they can easily
      enrich tables and            texts with additional information in a comprehensive
      visual way.                  The R package sparkTable uses a clean S4 class
      design and provides methods to create different            types of sparkgraphs
      that can be used in websites, presentations and documents. We also implemented            an
      easy way for non-experts to create highly complex tables. In this case, graphical
      parameters can be            interactively changed, variables can be sorted,
      graphs can be added and removed in an interactive            manner. Thereby
      it is possible to produce custom-tailored graphical tables – standard tables
      that are            enriched with graphs – that can be displayed in a browser
      and exported to various formats.'
    pages:
    - 24
    - 37
    acknowledged: '2014-06-23'
    online: '2015-05-29'
    CRANpkgs:
    - sparkTable
    - knitr
    - brew
    - xtable
    - shiny
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
  - slug: RJ-2015-004
    old_slug: cattaneo-calonico-titiunik
    title: 'rdrobust: An R Package for Robust Nonparametric Inference in Regression-Discontinuity
      Designs'
    bibtitle: |-
      rdrobust: An R Package for Robust Nonparametric Inference in
                Regression-Discontinuity Designs
    author:
    - Sebastian Calonico
    - Matias D. Cattaneo
    - Rocío Titiunik
    bibauthor: Sebastian Calonico and Matias D. Cattaneo and Rocío Titiunik
    landing: '2015'
    abstract: '  Abstract This article describes the R package rdrobust, which provides
      data-driven graphical and in           ference procedures for RD designs. The
      package includes three main functions: rdrobust, rdbwselect            and rdplot.
      The first function (rdrobust) implements conventional local-polynomial RD treatment            effect
      point estimators and confidence intervals, as well as robust bias-corrected
      confidence intervals,            for average treatment effects at the cutoff.
      This function covers sharp RD, sharp kink RD, fuzzy RD            and fuzzy
      kink RD designs, among other possibilities. The second function (rdbwselect)
      implements            several bandwidth selectors proposed in the RD literature.
      The third function (rdplot) provides            data-driven optimal choices
      of evenly-spaced and quantile-spaced partition sizes, which are used to            implement
      several data-driven RD plots.'
    pages:
    - 38
    - 51
    acknowledged:
    - '2014-07-28'
    - '2014-11-26'
    online: '2015-04-23'
    CRANpkgs: rdrobust
    CTV_rev: Econometrics
  - slug: RJ-2015-005
    old_slug: arcos-molina-ranalli-etal
    title: 'Frames2: A Package for Estimation in Dual Frame Surveys'
    bibtitle: 'Frames2: A Package for Estimation in Dual Frame Surveys'
    author:
    - Antonio Arcos
    - David Molina
    - Maria Giovanna Ranalli
    - María del Mar Rueda
    bibauthor: |-
      Antonio Arcos and David Molina and Maria Giovanna Ranalli
                and María del Mar Rueda
    landing: '2015'
    abstract: '  Abstract Data from complex survey designs require special consideration
      with regard to estimation            of finite population parameters and corresponding
      variance estimation procedures, as a consequence            of significant departures
      from the simple random sampling assumption. In the past decade a number            of
      statistical software packages have been developed to facilitate the analysis
      of complex survey            data. All these statistical software packages are
      able to treat samples selected from one sampling            frame containing
      all population units. Dual frame surveys are very useful when it is not possible
      to            guarantee a complete coverage of the target population and may
      result in considerable cost savings            over a single frame design with
      comparable precision. There are several estimators available in the            statistical
      literature but no existing software covers dual frame estimation procedures.
      This gap is now            filled by package Frames2. In this paper we highlight
      the main features of the package. The package            includes the main estimators
      in dual frame surveys and also provides interval confidence estimation.'
    pages:
    - 52
    - 72
    acknowledged: '2014-09-05'
    online: '2015-04-23'
    CRANpkgs:
    - survey
    - sampling
    - laeken
    - TeachingSampling
    - Frames2
    CTV_rev:
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
    - Survival
  - slug: RJ-2015-006
    old_slug: hankin
    title: The Complex Multivariate Gaussian Distribution
    bibtitle: The Complex Multivariate Gaussian Distribution
    author: Robin K. S. Hankin
    bibauthor: Robin K. S. Hankin
    landing: '2015'
    abstract: '  Abstract Here I introduce package cmvnorm, a complex generalization
      of the mvtnorm package. A            complex generalization of the Gaussian
      process is suggested and numerical results presented using the            package.
      An application in the context of approximating the Weierstrass σ-function using
      a complex            Gaussian process is given.'
    pages:
    - 73
    - 80
    acknowledged: '2014-09-18'
    online: '2015-04-23'
    CRANpkgs:
    - cmvnorm
    - mvtnorm
    - emulator
    CTV_rev:
    - Distributions
    - Finance
    - Multivariate
  - slug: RJ-2015-007
    old_slug: molina-marhuenda
    title: 'sae: An R Package for Small Area Estimation'
    bibtitle: 'sae: An R Package for Small Area Estimation'
    author:
    - Isabel Molina
    - Yolanda Marhuenda
    bibauthor: Isabel Molina and Yolanda Marhuenda
    landing: '2015'
    abstract: '  Abstract We describe the R package sae for small area estimation.
      This package can be used to            obtain model-based estimates for small
      areas based on a variety of models at the area and unit levels,            along
      with basic direct and indirect estimates. Mean squared errors are estimated
      by analytical            approximations in simple models and applying bootstrap
      procedures in more complex models. We            describe the package functions
      and show how to use them through examples.'
    pages:
    - 81
    - 98
    acknowledged: '2014-09-20'
    online: '2015-06-02'
    CRANpkgs:
    - sae
    - nlme
    - MASS
    - survey
    - sampling
    - rsae
    - JoSae
    - hbsae
    - mme
    - saery
    - sae2
    CTV_rev:
    - OfficialStatistics
    - SocialSciences
    - Econometrics
    - Environmetrics
    - Pharmacokinetics
    - Psychometrics
    - Bayesian
    - ChemPhys
    - Distributions
    - Finance
    - Multivariate
    - NumericalMathematics
    - Robust
    - Spatial
    - SpatioTemporal
    - Survival
    - TimeSeries
  - slug: RJ-2015-008
    old_slug: qiu
    title: 'showtext: Using System Fonts in R Graphics'
    bibtitle: 'showtext: Using System Fonts in R Graphics'
    author: Yixuan Qiu
    bibauthor: Yixuan Qiu
    landing: '2015'
    abstract: '  Abstract This article introduces the showtext package that makes
      it easy to use system fonts in R            graphics. Unlike other methods to
      embed fonts into graphics, showtext converts text into raster images            or
      polygons, and then adds them to the plot canvas. This method produces platform-independent            image
      files that do not rely on the fonts that create them. It supports a large number
      of font formats            and R graphics devices, and meanwhile provides convenient
      features such as using web fonts and            integrating with knitr. This
      article provides an elaborate introduction to the showtext package,            including
      its design, usage, and examples.'
    pages:
    - 99
    - 108
    acknowledged: '2014-10-26'
    online: '2015-05-29'
    CRANpkgs:
    - extrafont
    - showtext
    - knitr
    - Cairo
    - Rttf2pt1
    - sysfonts
    - RCurl
    - jsonlite
    - ggplot2
    - xkcd
    - RSvgDevice
    CTV_rev:
    - Graphics
    - WebTechnologies
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2015-010
    old_slug: kostov-becuebertaut-husson
    title: Correspondence Analysis on Generalised Aggregated Lexical Tables (CA-GALT)
      in the FactoMineR Package
    bibtitle: |-
      Correspondence Analysis on Generalised Aggregated Lexical
                Tables (CA-GALT) in the FactoMineR Package
    author:
    - Belchin Kostov
    - Mónica Bécue-Bertaut
    - François Husson
    bibauthor: Belchin Kostov and Mónica Bécue-Bertaut and François Husson
    landing: '2015'
    abstract: '  Abstract Correspondence analysis on generalised aggregated lexical
      tables (CA-GALT) is a method            that generalizes classical CA-ALT to
      the case of several quantitative, categorical and mixed variables.            It
      aims to establish a typology of the external variables and a typology of the
      events from their mutual            relationships. In order to do so, the influence
      of external variables on the lexical choices is untangled            cancelling
      the associations among them, and to avoid the instability issued from multicollinearity,
      they            are substituted by their principal components. The CaGalt function,
      implemented in the FactoMineR            package, provides numerous numerical
      and graphical outputs. Confidence ellipses are also provided            to validate
      and improve the representation of words and variables. Although this methodology
      was            developed mainly to give an answer to the problem of analyzing
      open-ended questions, it can be            applied to any kind of frequency/contingency
      table with external variables.'
    pages:
    - 109
    - 117
    acknowledged: '2014-11-04'
    online: '2015-06-02'
    CRANpkgs: FactoMineR
    CTV_rev:
    - Multivariate
    - Psychometrics
  - slug: RJ-2015-009
    old_slug: oneil
    title: Implementing Persistent O(1) Stacks and Queues in R
    bibtitle: Implementing Persistent O(1) Stacks and Queues in R
    author: Shawn T. O’Neil
    bibauthor: Shawn T. O’Neil
    landing: '2015'
    abstract: '  Abstract True to their functional roots, most R functions are side-effect-free,
      and users expect datatypes            to be persistent. However, these semantics
      complicate the creation of efficient and dynamic data            structures.
      Here, we describe the implementation of stack and queue data structures satisfying
      these            conditions in R, available in the CRAN package rstackdeque.
      Guided by important work in purely            functional languages, we look
      at both partiallyand fully-persistent versions of queues, comparing            their
      performance characteristics. Finally, we illustrate the usefulness of such dynamic
      structures with            examples of generating and solving mazes.'
    pages:
    - 118
    - 126
    acknowledged: '2014-12-16'
    online: '2015-06-24'
    CRANpkgs:
    - rstackdeque
    - dplyr
    - microbenchmark
    - ggplot2
    - hash
    - Rcpp
    CTV_rev:
    - Graphics
    - HighPerformanceComputing
    - NumericalMathematics
    - Phylogenetics
  - slug: RJ-2015-011
    old_slug: rodiger-burdukiewicz-blagodatskikh-etal
    title: R as an Environment for Reproducible Analysis of DNA Amplification Experiments
    bibtitle: |-
      R as an Environment for Reproducible Analysis of DNA
                Amplification Experiments
    author:
    - Stefan Rödiger
    - Michał Burdukiewicz
    - Konstantin Blagodatskikh
    - Michael Jahn
    - Peter Schierack
    bibauthor: |-
      Stefan Rödiger and Michał Burdukiewicz and Konstantin
                Blagodatskikh and Michael Jahn and Peter Schierack
    landing: '2015'
    abstract: '  Abstract There is an ever-increasing number of applications, which
      use quantitative PCR (qPCR) or            digital PCR (dPCR) to elicit fundamentals
      of biological processes. Moreover, quantitative isother           mal amplification
      (qIA) methods have become more prominent in life sciences and point-of-care           diagnostics.
      Additionally, the analysis of melting data is essential during many experiments.
      Several            software packages have been developed for the analysis of
      such datasets. In most cases, the software            is either distributed
      as closed source software or as monolithic block with little freedom to perform            highly
      customized analysis procedures. We argue, among others, that R is an excellent
      foundation            for reproducible and transparent data analysis in a highly
      customizable cross-platform environment.            However, for novices it
      is often challenging to master R or learn capabilities of the vast number            of
      packages available. In the paper, we describe exemplary workflows for the analysis
      of qPCR,            qIA or dPCR experiments including the analysis of melting
      curve data. Our analysis relies entirely            on R packages available
      from public repositories. Additionally, we provide information related to            standardized
      and reproducible research.'
    pages:
    - 127
    - 150
    acknowledged: '2014-11-30'
    online: '2015-06-25'
    CRANpkgs:
    - dpcR
    - kulife
    - MCMC.qpcr
    - qPCR.CT
    - DivMelt
    - qpcR
    - chipPCR
    - MBmca
    - RDML
    - RNetCDF
    - archivist
    - settings
    - shiny
    - rateratio.test
    BIOpkgs:
    - nondetects
    - qpcrNorm
    - HTqPCR
    - SLqPCR
    - ddCt
    - EasyqpcR
    - unifiedWMWqPCR
    - ReadqPCR
    - NormqPCR
    CTV_rev:
    - ReproducibleResearch
    - Spatial
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2015-012
    old_slug: murrell
    title: The gridGraphics Package
    bibtitle: The gridGraphics Package
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2015'
    abstract: '  Abstract The gridGraphics package provides a function, grid.echo(),
      that can be used to convert a            plot drawn with the graphics package
      to a visually identical plot drawn using grid. This conversion            provides
      access to a variety of grid tools for making customisations and additions to
      the plot that are            not possible with the graphics package.'
    pages:
    - 151
    - 162
    acknowledged: '2014-11-30'
    online: '2015-04-23'
    CRANpkgs:
    - gridGraphics
    - lattice
    - ggplot2
    - plotrix
    - maps
    - gridBase
    - gridSVG
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
    - Spatial
  - slug: RJ-2015-013
    old_slug: muschelli-sweeney-lindquist-etal
    title: 'fslr: Connecting the FSL Software with R'
    bibtitle: 'fslr: Connecting the FSL Software with R'
    author:
    - John Muschelli
    - Elizabeth Sweeney
    - Martin Lindquist
    - Ciprian Crainiceanu
    bibauthor: |-
      John Muschelli and Elizabeth Sweeney and Martin Lindquist
                and Ciprian Crainiceanu
    landing: '2015'
    abstract: '  Abstract We present the package fslr, a set of R functions that interface
      with FSL (FMRIB Software            Library), a commonly-used open-source software
      package for processing and analyzing neuroimaging            data. The fslr
      package performs operations on ‘nifti’ image objects in R using command-line            functions
      from FSL, and returns R objects back to the user. fslr allows users to develop
      image            processing and analysis pipelines based on FSL functionality
      while interfacing with the functionality            provided by R. We present
      an example of the analysis of structural magnetic resonance images,            which
      demonstrates how R users can leverage the functionality of FSL without switching
      to shell            commands.                                                          Glossary
      of acronyms                   MRI     Magnetic Resonance Imaging/Image          FSL     FMRIB
      Software Library                    PD     Proton Density                           FAST     FMRIB’s
      Automated Segmentation Tool                  FLAIR    Fluid-Attenuated Inversion
      Recovery      FLIRT    FMRIB’s Linear Image Registration Tool                   MS      Multiple
      Sclerosis                        BET     Brain Extraction Tool                  FMRIB    Functional
      MRI of the Brain Group       FNIRT     FMRIB’s Nonlinear Image Registration
      Tool                   MNI     Montreal Neurological Institute'
    pages:
    - 163
    - 175
    acknowledged: '2014-11-30'
    online: '2015-06-02'
    CRANpkgs:
    - AnalyzeFMRI
    - RNiftyReg
    - fmri
    - fslr
    - oro.nifti
    - ggplot2
    - ggplot2
    - mgcv
    BIOpkgs: EBImage
    CTV_rev:
    - MedicalImaging
    - ChemPhys
    - Graphics
    - Phylogenetics
    - Bayesian
    - Econometrics
    - Environmetrics
    - SocialSciences
  - slug: RJ-2015-014
    old_slug: baumgartner-thiem
    title: Identifying Complex Causal Dependencies in Configurational Data with Coincidence
      Analysis
    bibtitle: |-
      Identifying Complex Causal Dependencies in Configurational
                Data with Coincidence Analysis
    author:
    - Michael Baumgartner
    - Alrik Thiem
    bibauthor: Michael Baumgartner and Alrik Thiem
    landing: '2015'
    abstract: '  Abstract We present cna, a package for performing Coincidence Analysis
      (CNA). CNA is a config           urational comparative method for the identification
      of complex causal dependencies—in particular,            causal chains and common
      cause structures—in configurational data. After a brief introduction to the            method’s
      theoretical background and main algorithmic ideas, we demonstrate the use of
      the package            by means of an artificial and a real-life data set. Moreover,
      we outline planned enhancements of the            package that will further
      increase its applicability.'
    pages:
    - 176
    - 184
    acknowledged: '2014-12-17'
    online: '2015-03-30'
    CRANpkgs:
    - QCA
    - SetMethods
    - cna
  - slug: RJ-2015-015
    old_slug: hare-buja-hofmann
    title: Manipulation of Discrete Random Variables with discreteRV
    bibtitle: Manipulation of Discrete Random Variables with discreteRV
    author:
    - Eric Hare
    - Andreas Buja
    - Heike Hofmann
    bibauthor: Eric Hare and Andreas Buja and Heike Hofmann
    landing: '2015'
    abstract: '  Abstract A prominent issue in statistics education is the sometimes
      large disparity between the            theoretical and the computational coursework.
      discreteRV is an R package for manipulation of            discrete random variables
      which uses clean and familiar syntax similar to the mathematical notation in            introductory
      probability courses. The package offers functions that are simple enough for
      users with            little experience with statistical programming, but has
      more advanced features which are suitable for            a large number of more
      complex applications. In this paper, we introduce and motivate discreteRV,            describe
      its functionality, and provide reproducible examples illustrating its use.'
    pages:
    - 185
    - 194
    acknowledged: '2015-02-07'
    online: '2015-05-06'
    CRANpkgs:
    - discreteRV
    - devtools
  - slug: RJ-2015-016
    old_slug: lenth
    title: Estimability Tools for Package Developers
    bibtitle: Estimability Tools for Package Developers
    author: Russell V. Lenth
    bibauthor: Russell V. Lenth
    landing: '2015'
    abstract: '  Abstract When a linear model is rank-deficient, then predictions
      based on that model become            questionable because not all predictions
      are uniquely estimable. However, some of them are, and the            estimability
      package provides tools that package developers can use to tell which is which.
      With the            use of these tools, a model object’s predict method could
      return estimable predictions as-is while            flagging non-estimable ones
      in some way, so that the user can know which predictions to believe. The            estimability
      package also provides, as a demonstration, an estimability-enhanced epredict
      method            to use in place of predict for models fitted using the stats
      package.'
    pages:
    - 195
    - 199
    acknowledged: '2015-02-11'
    online: '2015-05-11'
    CRANpkgs: estimability
  - heading: News and Notes
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    bibauthor: Kurt Hornik
    slug: r-foundation
    pages: 200
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 201
    - 226
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 227
    - 238
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    bibauthor: '{The Bioconductor Team}'
    slug: bioconductor
    pages:
    - 239
    - 240
- issue: 2015-2
  year: 2015
  volume: 7
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Bettina Grün
    bibauthor: Bettina Gr{\" u}n
    slug: editorial
    pages: 4
  - heading: Contributed Research Articles
  - slug: RJ-2015-017
    old_slug: alam-ronnegard-shen
    title: Fitting Conditional and Simultaneous Autoregressive Spatial Models in hglm
    bibtitle: |-
      Fitting Conditional and Simultaneous Autoregressive Spatial
                Models in hglm
    author:
    - Moudud Alam
    - Lars Rönnegård
    - Xia Shen
    bibauthor: Moudud Alam and Lars Rönnegård and Xia Shen
    landing: '2015'
    abstract: '  Abstract We present a new version (> 2.0) of the hglm package for
      fitting hierarchical generalized            linear models (HGLMs) with spatially
      correlated random effects. CAR() and SAR() families for con           ditional
      and simultaneous autoregressive random effects were implemented. Eigen decomposition            of
      the matrix describing the spatial structure (e.g., the neighborhood matrix)
      was used to transform            the CAR/SAR random effects into an independent,
      but heteroscedastic, Gaussian random effect. A            linear predictor is
      fitted for the random effect variance to estimate the parameters in the CAR
      and SAR            models. This gives a computationally efficient algorithm
      for moderately sized problems.'
    pages:
    - 5
    - 18
    acknowledged: '2014-01-21'
    online: '2015-09-09'
    CRANpkgs:
    - hglm
    - spaMM
    - HGLMMM
    CTV_rev: Spatial
  - slug: RJ-2015-018
    old_slug: genuer-poggi-tuleaumalot
    title: 'VSURF: An R Package for Variable Selection Using Random Forests'
    bibtitle: |-
      VSURF: An R Package for Variable Selection Using Random
                Forests
    author:
    - Robin Genuer
    - Jean-Michel Poggi
    - Christine Tuleau-Malot
    bibauthor: |-
      Robin Genuer and Jean-Michel Poggi and Christine Tuleau-
                Malot
    landing: '2015'
    abstract: '  Abstract This paper describes the R package VSURF. Based on random
      forests, and for both regression            and classification problems, it
      returns two subsets of variables. The first is a subset of important            variables
      including some redundancy which can be relevant for interpretation, and the
      second one            is a smaller subset corresponding to a model trying to
      avoid redundancy focusing more closely on            the prediction objective.
      The two-stage strategy is based on a preliminary ranking of the explanatory            variables
      using the random forests permutation-based score of importance and proceeds
      using a            stepwise forward strategy for variable introduction. The
      two proposals can be obtained automatically            using data-driven default
      values, good enough to provide interesting results, but strategy can also            be
      tuned by the user. The algorithm is illustrated on a simulated example and its
      applications to real            datasets are presented.'
    pages:
    - 19
    - 33
    acknowledged: '2014-07-28'
    online: '2015-11-08'
    CRANpkgs:
    - VSURF
    - rpart
    - randomForest
    - party
    - ipred
    - Boruta
    - varSelRF
    - spikeSlabGAM
    - BioMark
    - mlbench
    - mixOmics
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - Survival
    - ChemPhys
    - Multivariate
    - Bayesian
    - HighPerformanceComputing
  - slug: RJ-2015-019
    old_slug: liu-kong
    title: 'zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One
      Inflated Beta Regression'
    bibtitle: |-
      zoib: An R Package for Bayesian Inference for Beta
                Regression and Zero/One Inflated Beta Regression
    author:
    - Fang Liu
    - Yunchuan Kong
    bibauthor: Fang Liu and Yunchuan Kong
    landing: '2015'
    abstract: ' Abstract The beta distribution is a versatile function that accommodates
      a broad range of probability           distribution shapes. Beta regression
      based on the beta distribution can be used to model a response           variable
      y that takes values in open unit interval (0, 1). Zero/one inflated beta (ZOIB)
      regression           models can be applied when y takes values from closed unit
      interval [0, 1]. The ZOIB model is based a           piecewise distribution
      that accounts for the probability mass at 0 and 1, in addition to the probability           density
      within (0, 1). This paper introduces an R package – zoib that provides Bayesian
      inferences for           a class of ZOIB models. The statistical methodology
      underlying the zoib package is discussed, the           functions covered by
      the package are outlined, and the usage of the package is illustrated with three           examples
      of different data and model types. The package is comprehensive and versatile
      in that it           can model data with or without inflation at 0 or 1, accommodate
      clustered and correlated data via           latent variables, perform penalized
      regression as needed, and allow for model comparison via the           computation
      of the DIC criterion.'
    pages:
    - 34
    - 51
    acknowledged: '2014-08-16'
    online: '2015-07-18'
    CRANpkgs:
    - betareg
    - Bayesianbetareg
    - zoib
    - coda
    - rjags
    CTV_rev:
    - Bayesian
    - gR
    - Cluster
    - Econometrics
    - Psychometrics
    - SocialSciences
  - slug: RJ-2015-020
    old_slug: nielsen
    title: 'apc: An R Package for Age-Period-Cohort Analysis'
    bibtitle: 'apc: An R Package for Age-Period-Cohort Analysis'
    author: Bent Nielsen
    bibauthor: Bent Nielsen
    landing: '2015'
    abstract: '  Abstract The apc package includes functions for age-period-cohort
      analysis based on the canonical            parametrisation of Kuang et al. (2008a).
      The package includes functions for organizing the data,            descriptive
      plots, a deviance table, estimation of (sub-models of) the age-period-cohort
      model, a plot            for specification testing, plots of estimated parameters,
      and sub-sample analysis.'
    pages:
    - 52
    - 64
    acknowledged: '2014-09-16'
    online: '2015-08-05'
    CRANpkgs:
    - apc
    - Epi
    CTV_rev: Survival
  - slug: RJ-2015-021
    old_slug: charlier-paindaveine-saracco
    title: 'QuantifQuantile: An R Package for Performing Quantile Regression Through
      Optimal Quantization'
    bibtitle: |-
      QuantifQuantile: An R Package for Performing Quantile
                Regression Through Optimal Quantization
    author:
    - Isabelle Charlier
    - Davy Paindaveine
    - Jérôme Saracco
    bibauthor: Isabelle Charlier and Davy Paindaveine and Jérôme Saracco
    landing: '2015'
    abstract: '  Abstract In quantile regression, various quantiles of a response
      variable Y are modelled as func           tions of covariates (rather than its
      mean). An important application is the construction of reference            curves/surfaces
      and conditional prediction intervals for Y. Recently, a nonparametric quantile
      regres           sion method based on the concept of optimal quantization was
      proposed. This method competes very            well with k-nearest neighbor,
      kernel, and spline methods. In this paper, we describe an R package,            called
      QuantifQuantile, that allows to perform quantization-based quantile regression.
      We describe            the various functions of the package and provide examples.'
    pages:
    - 65
    - 80
    acknowledged: '2014-09-28'
    online: '2015-10-30'
    CRANpkgs:
    - quantreg
    - quantregGrowth
    - QuantifQuantile
    - rgl
    - quantregGrowth
    CTV_rev:
    - Environmetrics
    - Econometrics
    - Graphics
    - Multivariate
    - Optimization
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - SpatioTemporal
    - Survival
  - slug: RJ-2015-022
    old_slug: hankin
    title: Numerical Evaluation of the Gauss Hypergeometric Function with the hypergeo
      Package
    bibtitle: |-
      Numerical Evaluation of the Gauss Hypergeometric Function
                with the hypergeo Package
    author: Robin K. S. Hankin
    bibauthor: Robin K. S. Hankin
    landing: '2015'
    abstract: '  Abstract This paper introduces the hypergeo package of R routines
      for numerical calculation of            hypergeometric functions. The package
      is focussed on efficient and accurate evaluation of the Gauss            hypergeometric
      function over the whole of the complex plane within the constraints of fixed-precision            arithmetic.
      The hypergeometric series is convergent only within the unit circle, so analytic
      continuation            must be used to define the function outside the unit
      circle. This short document outlines the numerical            and conceptual
      methods used in the package; and justifies the package philosophy, which is
      to            maintain transparent and verifiable links between the software
      and Abramowitz and Stegun (1965).            Most of the package functionality
      is accessed via the single function hypergeo(), which dispatches to            one
      of several methods depending on the value of its arguments. The package is demonstrated
      in the            context of game theory.'
    pages:
    - 81
    - 88
    acknowledged: '2014-12-16'
    online: '2015-11-18'
    CRANpkgs:
    - gsl
    - appell
    - hypergeo
    CTV_rev:
    - NumericalMathematics
    - Optimization
  - slug: RJ-2015-023
    old_slug: villacorta-saez
    title: 'SRCS: Statistical Ranking Color Scheme for Visualizing Parameterized Multiple
      Pairwise Comparisons with R'
    bibtitle: |-
      SRCS: Statistical Ranking Color Scheme for Visualizing
                Parameterized Multiple Pairwise Comparisons with R
    author:
    - Pablo J. Villacorta
    - José A. Sáez
    bibauthor: Pablo J. Villacorta and José A. Sáez
    landing: '2015'
    abstract: '  Abstract The problem of comparing a new solution method against existing
      ones to find statistically            significant differences arises very often
      in sciences and engineering. When the problem instance being            solved
      is defined by several parameters, assessing a number of methods with respect
      to many problem            configurations simultaneously becomes a hard task.
      Some visualization technique is required for            presenting a large number
      of statistical significance results in an easily interpretable way. Here we            review
      an existing color-based approach called Statistical Ranking Color Scheme (SRCS)
      for displaying            the results of multiple pairwise statistical comparisons
      between several methods assessed separately on            a number of problem
      configurations. We introduce an R package implementing SRCS, which performs            all
      the pairwise statistical tests from user data and generates customizable plots.
      We demonstrate            its applicability on two examples from the areas of
      dynamic optimization and machine learning, in            which several algorithms
      are compared on many problem instances, each defined by a combination of            parameters.'
    pages:
    - 89
    - 104
    acknowledged: '2015-01-02'
    online: '2015-07-29'
    CRANpkgs:
    - factorplot
    - SRCS
    - e1071
    - RWeka
    BIOpkgs: paircompviz
    CTV_rev:
    - MachineLearning
    - Cluster
    - Distributions
    - Environmetrics
    - Multivariate
    - NaturalLanguageProcessing
    - Psychometrics
  - slug: RJ-2015-024
    old_slug: vegabayo
    title: 'An R Package for the Panel Approach Method for Program Evaluation: pampe'
    bibtitle: |-
      An R Package for the Panel Approach Method for Program
                Evaluation: pampe
    author: Ainhoa Vega-Bayo
    bibauthor: Ainhoa Vega-Bayo
    landing: '2015'
    abstract: '  Abstract The pampe package for R implements the panel data approach
      method for program evalua           tion designed to estimate the causal effects
      of political interventions or treatments. This procedure            exploits
      the dependence among cross-sectional units to construct a counterfactual of
      the treated unit(s),            and it is an appropriate method for research
      events that occur at an aggregate level like countries or            regions
      and that affect only one or a small number of units. The implementation of the
      pampe package            is illustrated using data from Hong Kong and 24 other
      units, by examining the economic impact of the            political and economic
      integration of Hong Kong with mainland China in 1997 and 2004 respectively.'
    pages:
    - 105
    - 121
    acknowledged: '2015-02-04'
    online: '2015-11-10'
    CRANpkgs:
    - pampe
    - leaps
    - xtable
    CTV_rev:
    - ChemPhys
    - Econometrics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2015-025
    old_slug: lee-chen
    title: 'BSGS: Bayesian Sparse Group Selection'
    bibtitle: 'BSGS: Bayesian Sparse Group Selection'
    author:
    - Kuo-Jung Lee
    - Ray-Bing Chen
    bibauthor: Kuo-Jung Lee and Ray-Bing Chen
    landing: '2015'
    abstract: '  Abstract An R package BSGS is provided for the integration of Bayesian
      variable and sparse group            selection separately proposed by Chen et
      al. (2011) and Chen et al. (in press) for variable selection            problems,
      even in the cases of large p and small n. This package is designed for variable
      selection            problems including the identification of the important
      groups of variables and the active variables            within the important
      groups. This article introduces the functions in the BSGS package that can be            used
      to perform sparse group selection as well as variable selection through simulation
      studies and            real data.'
    pages:
    - 122
    - 133
    acknowledged: '2015-02-16'
    online: '2015-08-05'
    CRANpkgs: BSGS
  - slug: RJ-2015-026
    old_slug: vigneau-chen-qannari
    title: 'ClustVarLV: An R Package for the Clustering of Variables Around Latent
      Variables'
    bibtitle: |-
      ClustVarLV: An R Package for the Clustering of Variables
                Around Latent Variables
    author:
    - Evelyne Vigneau
    - Mingkun Chen
    - El Mostafa Qannari
    bibauthor: Evelyne Vigneau and Mingkun Chen and El Mostafa Qannari
    landing: '2015'
    abstract: '  Abstract The clustering of variables is a strategy for deciphering
      the underlying structure of a data            set. Adopting an exploratory data
      analysis point of view, the Clustering of Variables around Latent            Variables
      (CLV) approach has been proposed by Vigneau and Qannari (2003). Based on a family
      of            optimization criteria, the CLV approach is adaptable to many situations.
      In particular, constraints may            be introduced in order to take account
      of additional information about the observations and/or the            variables.
      In this paper, the CLV method is depicted and the R package ClustVarLV including
      a set of            functions developed so far within this framework is introduced.
      Considering successively different            types of situations, the underlying
      CLV criteria are detailed and the various functions of the package            are
      illustrated using real case studies.'
    pages:
    - 134
    - 148
    acknowledged: '2015-03-04'
    online: '2015-10-23'
    CRANpkgs:
    - cluster
    - ClustVarLV
    - ClustOfVar
    - clere
    - biclust
    - pvclust
    - Hmisc
    - FactoMineR
    - plsgenomics
    - Rcpp
    - ClustVarLV
    CTV_rev:
    - Multivariate
    - Cluster
    - Psychometrics
    - Environmetrics
    - HighPerformanceComputing
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - Graphics
    - NumericalMathematics
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2015-027
    old_slug: charte-charte
    title: 'Working with Multilabel Datasets in R: The mldr Package'
    bibtitle: 'Working with Multilabel Datasets in R: The mldr Package'
    author:
    - Francisco Charte
    - David Charte
    bibauthor: Francisco Charte and David Charte
    landing: '2015'
    abstract: '  Abstract Most classification algorithms deal with datasets which
      have a set of input features, the            variables to be used as predictors,
      and only one output class, the variable to be predicted. However,            in
      late years many scenarios in which the classifier has to work with several outputs
      have come to            life. Automatic labeling of text documents, image annotation
      or protein classification are among            them. Multilabel datasets are
      the product of these new needs, and they have many specific traits.            The
      mldr package allows the user to load datasets of this kind, obtain their characteristics,
      produce            specialized plots, and manipulate them. The goal is to provide
      the exploratory tools needed to analyze            multilabel datasets, as well
      as the transformation and manipulation functions that will make possible            to
      apply binary and multiclass classification models to this data or the development
      of new multilabel            classifiers. Thanks to its integrated user interface,
      the exploratory functions will be available even to            non-specialized
      R users.'
    pages:
    - 149
    - 162
    acknowledged: '2015-03-09'
    online: '2015-09-16'
    CRANpkgs:
    - RWeka
    - mldr
    - shiny
    - Rcmdr
    - rattle
    - XML
    - circlize
    - devtools
    - pROC
    - shiny
    CTV_rev:
    - WebTechnologies
    - MachineLearning
    - Finance
    - NaturalLanguageProcessing
  - slug: RJ-2015-028
    old_slug: valliant-dever-kreuter
    title: 'PracTools: Computations for Design of Finite Population Samples'
    bibtitle: |-
      PracTools: Computations for Design of Finite Population
                Samples
    author:
    - Richard Valliant
    - Jill A. Dever
    - Frauke Kreuter
    bibauthor: Richard Valliant and Jill A. Dever and Frauke Kreuter
    landing: '2015'
    abstract: '  Abstract PracTools is an R package with functions that compute sample
      sizes for various types of            finite population sampling designs when
      totals or means are estimated. One-, two-, and three-stage            designs
      are covered as well as allocations for stratified sampling and probability proportional
      to size            sampling. Sample allocations can be computed that minimize
      the variance of an estimator subject to a            budget constraint or that
      minimize cost subject to a precision constraint. The package also contains            some
      specialized functions for estimating variance components and design effects.
      Several finite            populations are included that are useful for classroom
      instruction.'
    pages:
    - 163
    - 176
    acknowledged: '2015-03-18'
    online: '2015-06-30'
    CRANpkgs:
    - pps
    - sampling
    - samplingbook
    - simFrame
    - survey
    - PracTools
    - stratification
    - alabama
    - Rsolnp
    - SamplingStrata
    CTV_rev:
    - OfficialStatistics
    - Optimization
    - SocialSciences
    - Survival
  - slug: RJ-2015-029
    old_slug: seo-pan
    title: 'ALTopt: An R Package for Optimal Experimental Design of Accelerated Life
      Testing'
    bibtitle: |-
      ALTopt: An R Package for Optimal Experimental Design of
                Accelerated Life Testing
    author:
    - Kangwon Seo
    - Rong Pan
    bibauthor: Kangwon Seo and Rong Pan
    landing: '2015'
    abstract: '  Abstract The R package ALTopt has been developed with the aim of
      creating and evaluating optimal            experimental designs of censored
      accelerated life tests (ALTs). This package takes the generalized            linear
      model approach to ALT planning, because this approach can easily handle censoring
      plans and            derive information matrices for evaluating designs. Three
      types of optimality criteria are considered:            D-optimality for model
      parameter estimation, U-optimality for reliability prediction at a single use            condition,
      and I-optimality for reliability prediction over a region of use conditions.
      The Weibull            distribution is assumed for failure time data and more
      than one stress factor can be specified in the            package. Several graphical
      evaluation tools are also provided for the comparison of different ALT test            plans.'
    pages:
    - 177
    - 188
    acknowledged: '2015-03-18'
    online: '2015-09-29'
    CRANpkgs: ALTopt
    CTV_rev: ExperimentalDesign
  - slug: RJ-2015-030
    old_slug: nunes-prangle
    title: 'abctools: An R Package for Tuning Approximate Bayesian Computation Analyses'
    bibtitle: |-
      abctools: An R Package for Tuning Approximate Bayesian
                Computation Analyses
    author:
    - Matthew A. Nunes
    - Dennis Prangle
    bibauthor: Matthew A. Nunes and Dennis Prangle
    landing: '2015'
    abstract: '  Abstract Approximate Bayesian computation (ABC) is a popular family
      of algorithms which perform            approximate parameter inference when
      numerical evaluation of the likelihood function is not possible            but
      data can be simulated from the model. They return a sample of parameter values
      which produce            simulations close to the observed dataset. A standard
      approach is to reduce the simulated and            observed datasets to vectors
      of summary statistics and accept when the difference between these is            below
      a specified threshold. ABC can also be adapted to perform model choice.                 In
      this article, we present a new software package for R, abctools which provides
      methods for            tuning ABC algorithms. This includes recent dimension
      reduction algorithms to tune the choice            of summary statistics, and
      coverage methods to tune the choice of threshold. We provide several            illustrations
      of these routines on applications taken from the ABC literature.'
    pages:
    - 189
    - 205
    acknowledged: '2015-03-25'
    online: '2015-07-29'
    CRANpkgs:
    - abctools
    - abc
    - easyABC
    - MASS
    CTV_rev:
    - Bayesian
    - Distributions
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2015-031
    old_slug: wang-faivre-richard-etal
    title: 'mtk: A General-Purpose and Extensible R Environment for Uncertainty and
      Sensitivity Analyses of Numerical Experiments'
    bibtitle: |-
      mtk: A General-Purpose and Extensible R Environment
                for Uncertainty and Sensitivity Analyses of Numerical
                Experiments
    author:
    - Juhui Wang
    - Robert Faivre
    - Hervé Richard
    - Hervé Monod
    bibauthor: |-
      Juhui Wang and Robert Faivre and Hervé Richard and Hervé
                Monod
    landing: '2015'
    abstract: '  Abstract Along with increased complexity of the models used for scientific
      activities and engineering            come diverse and greater uncertainties.
      Today, effectively quantifying the uncertainties contained            in a model
      appears to be more important than ever. Scientific fellows know how serious
      it is to            calibrate their model in a robust way, and decision-makers
      describe how critical it is to keep the best            effort to reduce the
      uncertainties about the model. Effectively accessing the uncertainties about
      the            model requires mastering all the tasks involved in the numerical
      experiments, from optimizing the            experimental design to managing
      the very time consuming aspect of model simulation and choosing            the
      adequate indicators and analysis methods.                 In this paper, we
      present an open framework for organizing the complexity associated with            numerical
      model simulation and analyses. Named mtk (Mexico Toolkit), the developed system
      aims            at providing practitioners from different disciplines with a
      systematic and easy way to compare and            to find the best method to
      effectively uncover and quantify the uncertainties contained in the model            and
      further to evaluate their impact on the performance of the model. Such requirements
      imply that            the system must be generic, universal, homogeneous, and
      extensible. This paper discusses such an            implementation using the
      R scientific computing platform and demonstrates its functionalities with            examples
      from agricultural modeling.                 The package mtk is of general purpose
      and easy to extend. Numerous methods are already            available in the
      actual release version, including Fast, Sobol, Morris, Basic Monte-Carlo, Regression,            LHS
      (Latin Hypercube Sampling), PLMM (Polynomial Linear metamodel). Most of them
      are compiled            from available R packages with extension tools delivered
      by package mtk.'
    pages:
    - 206
    - 226
    acknowledged: '2015-03-30'
    online: '2015-10-01'
    CRANpkgs:
    - sensitivity
    - spartan
    - diceDesign
    - planor
    - mtk
    - ff
    CTV_rev:
    - Environmetrics
    - ExperimentalDesign
    - HighPerformanceComputing
  - slug: RJ-2015-032
    old_slug: buttrey-whitaker
    title: 'treeClust: An R Package for Tree-Based Clustering Dissimilarities'
    bibtitle: |-
      treeClust: An R Package for Tree-Based Clustering
                Dissimilarities
    author:
    - Samuel E. Buttrey
    - Lyn R. Whitaker
    bibauthor: Samuel E. Buttrey and Lyn R. Whitaker
    landing: '2015'
    abstract: '  Abstract This paper describes treeClust, an R package that produces
      dissimilarities useful for cluster           ing. These dissimilarities arise
      from a set of classification or regression trees, one with each variable in            the
      data acting in turn as a the response, and all others as predictors. This use
      of trees produces dissim           ilarities that are insensitive to scaling,
      benefit from automatic variable selection, and appear to perform            well.
      The software allows a number of options to be set, affecting the set of objects
      returned in the call;            the user can also specify a clustering algorithm
      and, optionally, return only the clustering vector. The            package can
      also generate a numeric data set whose inter-point distances relate to the treeClust
      ones;            such a numeric data set can be much smaller than the vector
      of inter-point dissimilarities, a useful            feature in big data sets.'
    pages:
    - 227
    - 236
    acknowledged: '2015-04-07'
    online: '2015-09-16'
    CRANpkgs:
    - treeClust
    - cluster
    - rpart
    - tree
    CTV_rev:
    - Cluster
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Survival
  - slug: RJ-2015-033
    old_slug: hino-takano-murata
    title: 'mmpp: A Package for Calculating Similarity and Distance Metrics for Simple
      and Marked Temporal Point Processes'
    bibtitle: |-
      mmpp: A Package for Calculating Similarity and Distance
                Metrics for Simple and Marked Temporal Point Processes
    author:
    - Hideitsu Hino
    - Ken Takano
    - Noboru Murata
    bibauthor: Hideitsu Hino and Ken Takano and Noboru Murata
    landing: '2015'
    abstract: '  Abstract A simple temporal point process (SPP) is an important class
      of time series, where the sample            realization of the process is solely
      composed of the times at which events occur. Particular examples            of
      point process data are neuronal spike patterns or spike trains, and a large
      number of distance and            similarity metrics for those data have been
      proposed. A marked point process (MPP) is an extension            of a simple
      temporal point process, in which a certain vector valued mark is associated
      with each of            the temporal points in the SPP. Analyses of MPPs are
      of practical importance because instances of            MPPs include recordings
      of natural disasters such as earthquakes and tornadoes. In this paper, we            introduce
      the R package mmpp, which implements a number of distance and similarity metrics
      for            SPPs, and also extends those metrics for dealing with MPPs.'
    pages:
    - 237
    - 248
    acknowledged: '2015-04-17'
    online: '2015-09-29'
    CRANpkgs:
    - splancs
    - spatstat
    - PtProcess
    - stpp
    - mmpp
    - SAPP
    - etasFLP
    CTV_rev:
    - SpatioTemporal
    - Spatial
    - Survival
  - slug: RJ-2015-034
    old_slug: koohafkan-younis
    title: Open-Channel Computation with R
    bibtitle: Open-Channel Computation with R
    author:
    - Michael C. Koohafkan
    - Bassam A. Younis
    bibauthor: Michael C. Koohafkan and Bassam A. Younis
    landing: '2015'
    abstract: '  Abstract The rivr package provides a computational toolset for simulating
      steady and unsteady one           dimensional flows in open channels. It is
      designed primarily for use by instructors of undergraduate           and graduate-level
      open-channel hydrodynamics courses in such diverse fields as river engineering,            physical
      geography and geophysics. The governing equations used to describe open-channel
      flows            are briefly presented, followed by example applications. These
      include the computation of gradually           varied flows and two examples
      of unsteady flows in channels—namely, the tracking of the evolution            of
      a flood wave in a channel and the prediction of extreme variation in the water-surface
      profile            that results when a sluice gate is abruptly closed. Model
      results for the unsteady flow examples            are validated against standard
      benchmarks. The article concludes with a discussion of potential            modifications
      and extensions to the package.'
    pages:
    - 249
    - 262
    acknowledged: '2015-04-19'
    online: '2015-11-28'
    CRANpkgs:
    - rivr
    - knitr
    - shiny
    - Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    - ReproducibleResearch
    - WebTechnologies
  - slug: RJ-2015-035
    old_slug: morina-higueras-puig-etal
    title: Generalized Hermite Distribution Modelling with the R Package hermite
    bibtitle: |-
      Generalized Hermite Distribution Modelling with the R
                Package hermite
    author:
    - David Moriña
    - Manuel Higueras
    - Pedro Puig
    - María Oliveira
    bibauthor: |-
      David Moriña and Manuel Higueras and Pedro Puig and María
                Oliveira
    landing: '2015'
    abstract: '  Abstract The Generalized Hermite distribution (and the Hermite distribution
      as a particular case) is            often used for fitting count data in the
      presence of overdispersion or multimodality. Despite this, to            our
      knowledge, no standard software packages have implemented specific functions
      to compute basic            probabilities and make simple statistical inference
      based on these distributions. We present here a set            of computational
      tools that allows the user to face these difficulties by modelling with the
      Generalized            Hermite distribution using the R package hermite. The
      package can also be used to generate random            deviates from a Generalized
      Hermite distribution and to use basic functions to compute probabilities            (density,
      cumulative density and quantile functions are available), to estimate parameters
      using the            maximum likelihood method and to perform the likelihood
      ratio test for Poisson assumption against a            Generalized Hermite alternative.
      In order to improve the density and quantile functions performance            when
      the parameters are large, Edgeworth and Cornish-Fisher expansions have been
      used. Hermite            regression is also a useful tool for modeling inflated
      count data, so its inclusion to a commonly used            software like R will
      make this tool available to a wide range of potential users. Some examples of            usage
      in several fields of application are also given.'
    pages:
    - 263
    - 274
    acknowledged: '2015-04-27'
    online: '2015-12-10'
    CRANpkgs:
    - maxLik
    - radir
    CTV_rev: Optimization
  - slug: RJ-2015-036
    old_slug: rubio-villar
    title: 'Code Profiling in R: A Review of Existing Methods and an Introduction
      to Package GUIProfiler'
    bibtitle: |-
      Code Profiling in R: A Review of Existing Methods and an
                Introduction to Package GUIProfiler
    author:
    - Angel Rubio
    - Fernando de Villar
    bibauthor: Angel Rubio and Fernando de Villar
    landing: '2015'
    abstract: '  Abstract Code analysis tools are crucial to understand program behavior.
      Profile tools use the results            of time measurements in the execution
      of a program to gain this understanding and thus help in the            optimization
      of the code. In this paper, we review the different available packages to profile
      R code            and show the advantages and disadvantages of each of them.
      In additon, we present GUIProfiler, a            package that fulfills some
      unmet needs.                 Package GUIProfiler generates an HTML report with
      the timing for each code line and the            relationships between different
      functions. This package mimics the behavior of the MATLAB profiler.            The
      HTML report includes information on the time spent on each of the lines of the
      profiled code            (the slowest code is highlighted). If the package is
      used within the RStudio environment, the user            can navigate across
      the bottlenecks in the code and open the editor to modify the lines of code
      where            more time is spent. It is also possible to edit the code using
      Notepad++ (a free editor for Windows) by            simply clicking on the corresponding
      line. The graphical user interface makes it easy to identify the            specific
      lines which slow down the code.                 The integration in RStudio and
      the generation of an HTML report makes GUIProfiler a very            convenient
      tool to perform code optimization.'
    pages:
    - 275
    - 287
    acknowledged: '2015-05-04'
    online: '2015-11-18'
    CRANpkgs:
    - aprof
    - proftools
    - profr
    - microbenchmark
    - Nozzle.R1
    - knitr
    - GUIProfiler
    - stringr
    - plyr
    - devtools
    - shiny
    BIOpkgs:
    - Rgraphviz
    - graph
    CTV_rev:
    - HighPerformanceComputing
    - ReproducibleResearch
    - WebTechnologies
  - heading: News and Notes
  - title: The R Consortium and the R Foundation
    bibtitle: The {R} Consortium and the {R} Foundation
    slug: plummer
    author: Martyn Plummer
    pages: 288
  - title: 'Conference Report: useR! 2015'
    bibtitle: 'Conference Report: {useR!} 2015'
    slug: tvedebrink
    author: Torben Tvedebrink
    pages:
    - 289
    - 290
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    slug: bioconductor
    pages:
    - 291
    - 292
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    pages:
    - 293
    - 297
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 298
    - 339
- issue: 2016-1
  year: 2016
  volume: 8
  num: 1
  month: Aug.
  bibmonth: aug
  articles:
  - title: Editorial
    author: Michael Lawrence
    slug: editorial
    pages:
    - 4
    - 4
  - heading: Contributed Research Articles
  - slug: RJ-2016-001
    old_slug: beath
    title: 'metaplus: An R Package for the Analysis of Robust Meta-Analysis and Meta-Regression'
    bibtitle: |-
      metaplus: An R Package for the Analysis of Robust Meta-
                Analysis and Meta-Regression
    author: Ken J. Beath
    bibauthor: Ken J. Beath
    landing: '2016'
    abstract: '  Abstract The metaplus package is described with examples of its use
      for fitting meta-analysis and            meta-regression. For either meta-analysis
      or meta-regression it is possible to fit one of three models:            standard
      normal random effect, t-distribution random effect or mixture of normal random
      effects. The            latter two models allow for robustness by allowing for
      a random effect distribution with heavier tails            than the normal distribution,
      and for both robust models the presence of outliers may be tested using            the
      parametric bootstrap. For the mixture of normal random effects model the outlier
      studies may be            identified through their posterior probability of
      membership in the outlier component of the mixture.            Plots allow the
      results of the different models to be compared. The package is demonstrated
      on three            examples: a meta-analysis with no outliers, a meta-analysis
      with an outlier and a meta-regression with            an outlier.'
    pages:
    - 5
    - 16
    acknowledged: '2015-02-17'
    online: '2016-06-13'
    CRANpkgs:
    - metaplus
    - metafor
    - bbmle
    - forestplot
    - extrafont
    CTV_rev:
    - MetaAnalysis
    - ClinicalTrials
    - Phylogenetics
  - slug: RJ-2016-002
    old_slug: wais
    title: Gender Prediction Methods Based on First Names with genderizeR
    bibtitle: |-
      Gender Prediction Methods Based on First Names with
                genderizeR
    author: Kamil Wais
    bibauthor: Kamil Wais
    landing: '2016'
    abstract: '  Abstract In recent years, there has been increased interest in methods
      for gender prediction based on            first names that employ various open
      data sources. These methods have applications from bibliometric            studies
      to customizing commercial offers for web users. Analysis of gender disparities
      in science based            on such methods are published in the most prestigious
      journals, although they could be improved            by choosing the most suited
      prediction method with optimal parameters and performing validation            studies
      using the best data source for a given purpose. There is also a need to monitor
      and report how            well a given prediction method works in comparison
      to others. In this paper, the author recommends            a set of tools (including
      one dedicated to gender prediction, the R package called genderizeR), data            sources
      (including the genderize.io API), and metrics that could be fully reproduced
      and tested in            order to choose the optimal approach suitable for different
      gender analyses.'
    pages:
    - 17
    - 37
    acknowledged: '2015-12-17'
    online: '2016-07-23'
    CRANpkgs:
    - genderizeR
    - qdap
    - gender
    - babynames
    - sortinghat
    - stringr
    - tm
    - ROCR
    - verification
    - data.table
    - dplyr
    CTV_rev:
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - Finance
    - MachineLearning
    - Multivariate
    - WebTechnologies
  - slug: RJ-2016-003
    old_slug: sophie-brouste-istas
    title: Conditional Fractional Gaussian Fields with the Package FieldSim
    bibtitle: |-
      Conditional Fractional Gaussian Fields with the Package
                FieldSim
    author:
    - Alexandre Brouste
    - Jacques Istas
    - Sophie Lambert-Lacroix
    bibauthor: |-
      Alexandre Brouste and Jacques Istas and Sophie Lambert-
                Lacroix
    landing: '2016'
    abstract: '  Abstract We propose an effective and fast method to simulate multidimensional
      conditional fractional            Gaussian fields with the package FieldSim.
      Our method is valid not only for conditional simulations            associated
      to fractional Brownian fields, but to any Gaussian field and on any (non regular)
      grid of            points.'
    pages:
    - 38
    - 47
    acknowledged: '2015-03-06'
    online: '2016-04-03'
    CRANpkgs:
    - FieldSim
    - RandomFields
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2016-004
    old_slug: demirhan
    title: 'rTableICC: An R Package for Random Generation of 22K and RC Contingency
      Tables'
    bibtitle: |-
      rTableICC: An R Package for Random Generation of 22K and RC
                Contingency Tables
    author: Haydar Demirhan
    bibauthor: Haydar Demirhan
    landing: '2016'
    abstract: '  Abstract In this paper, we describe the R package rTableICC that
      provides an interface for random            generation of 2×2×K and R×C contingency
      tables constructed over either intraclass-correlated or            uncorrelated
      individuals. Intraclass correlations arise in studies where sampling units include
      more            than one individual and these individuals are correlated. The
      package implements random generation            of contingency tables over individuals
      with or without intraclass correlations under various sampling            plans.
      The package include two functions for the generation of K 2×2 tables over product-multinomial            sampling
      schemes and that of 2×2×K tables under Poisson or multinomial sampling plans.
      It also            contains two functions that generate R×C tables under product-multinomial,
      multinomial or Poisson            sampling plans with or without intraclass
      correlations. The package also includes a function for            random number
      generation from a given probability distribution. In addition to the contingency
      table            format, the package also provides raw data required for further
      estimation purposes.'
    pages:
    - 48
    - 63
    acknowledged: '2015-03-24'
    online: '2016-04-02'
    CRANpkgs:
    - rTableICC
    - partitions
    CTV_rev: NumericalMathematics
  - slug: RJ-2016-005
    old_slug: brown
    title: Maps, Coordinate Reference Systems and Visualising Geographic Data with
      mapmisc
    bibtitle: |-
      Maps, Coordinate Reference Systems and Visualising
                Geographic Data with mapmisc
    author: Patrick E. Brown
    bibauthor: Patrick E. Brown
    landing: '2016'
    abstract: '  Abstract The mapmisc package provides functions for visualising geospatial
      data, including fetching            background map layers, producing colour
      scales and legends, and adding scale bars and orientation            arrows
      to plots. Background maps are returned in the coordinate reference system of
      the dataset            supplied, and inset maps and direction arrows reflect
      the map projection being plotted. This is a “light            weight” package
      having an emphasis on simplicity and ease of use.'
    pages:
    - 64
    - 91
    acknowledged: '2015-03-25'
    online: '2016-07-28'
    CRANpkgs:
    - sp
    - raster
    - mapmisc
    - rgdal
    - RColorBrewer
    - classInt
    - rgeos
    - geosphere
    - dismo
    - maptools
    - R.utils
    - geostatsp
    - knitr
    - ggplot2
    - leaflet
    CTV_rev:
    - Spatial
    - Graphics
    - SpatioTemporal
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2016-006
    old_slug: jacques-yengo-biernacki-etal
    title: 'Variable Clustering in High-Dimensional Linear Regression: The R Package
      clere'
    bibtitle: |-
      Variable Clustering in High-Dimensional Linear Regression:
                The R Package clere
    author:
    - Loïc Yengo
    - Julien Jacques
    - Christophe Biernacki
    - Mickael Canouil
    bibauthor: |-
      Loïc Yengo and Julien Jacques and Christophe Biernacki and
                Mickael Canouil
    landing: '2016'
    abstract: '  Abstract Dimension reduction is one of the biggest challenges in
      high-dimensional regression models.            We recently introduced a new
      methodology based on variable clustering as a means to reduce dimen           sionality.
      We present here the R package clere that implements some refinements of this
      methodology.            An overview of the package functionalities as well as
      examples to run an analysis are described.            Numerical experiments
      on real data were performed to illustrate the good predictive performance of            our
      parsimonious method compared to standard dimension reduction approaches.'
    pages:
    - 92
    - 106
    acknowledged: '2015-03-26'
    online: '2016-04-03'
    CRANpkgs:
    - glmnet
    - spikeslab
    - clere
    - Rcpp
    - RcppEigen
    - lasso2
    - flare
    CTV_rev:
    - MachineLearning
    - NumericalMathematics
    - Bayesian
    - HighPerformanceComputing
    - Survival
  - slug: RJ-2016-007
    old_slug: eder-rybicki-kestemont
    title: 'Stylometry with R: A Package for Computational Text Analysis'
    bibtitle: 'Stylometry with R: A Package for Computational Text Analysis'
    author:
    - Maciej Eder
    - Jan Rybicki
    - Mike Kestemont
    bibauthor: Maciej Eder and Jan Rybicki and Mike Kestemont
    landing: '2016'
    abstract: '  Abstract This software paper describes ‘Stylometry with R’ (stylo),
      a flexible R package for the high           level analysis of writing style
      in stylometry. Stylometry (computational stylistics) is concerned with the            quantitative
      study of writing style, e.g. authorship verification, an application which has
      considerable            potential in forensic contexts, as well as historical
      research. In this paper we introduce the possibilities            of stylo for
      computational text analysis, via a number of dummy case studies from English
      and French            literature. We demonstrate how the package is particularly
      useful in the exploratory statistical analysis            of texts, e.g. with
      respect to authorial writing style. Because stylo provides an attractive graphical
      user            interface for high-level exploratory analyses, it is especially
      suited for an audience of novices, without            programming skills (e.g.
      from the Digital Humanities). More experienced users can benefit from our            implementation
      of a series of standard pipelines for text processing, as well as a number of
      similarity            metrics.'
    pages:
    - 107
    - 121
    acknowledged: '2015-04-07'
    online: '2015-12-22'
    CRANpkgs: stylo
  - slug: RJ-2016-008
    old_slug: linares-na
    title: 'quickpsy: An R Package to Fit Psychometric Functions for Multiple Groups'
    bibtitle: |-
      quickpsy: An R Package to Fit Psychometric Functions for
                Multiple Groups
    author:
    - Daniel Linares
    - Joan López-Moliner
    bibauthor: Daniel Linares and Joan López-Moliner
    landing: '2016'
    abstract: '  Abstract quickpsy is a package to parametrically fit psychometric
      functions. In comparison with            previous R packages, quickpsy was built
      to easily fit and plot data for multiple groups. Here,            we describe
      the standard parametric model used to fit psychometric functions and the standard            estimation
      of its parameters using maximum likelihood. We also provide examples of usage
      of            quickpsy, including how allowing the lapse rate to vary can sometimes
      eliminate the bias in parameter            estimation, but not in general. Finally,
      we describe some implementation details, such as how to avoid            the
      problems associated to round-off errors in the maximisation of the likelihood
      or the use of closures            and non-standard evaluation functions.'
    pages:
    - 122
    - 131
    acknowledged: '2015-05-12'
    online: '2015-11-08'
    CRANpkgs:
    - quickpsy
    - psyphy
    - modelfree
    - MPDiR
    - gridExtra
    - dplyr
    - ggplot2
    CTV_rev:
    - Psychometrics
    - Graphics
    - Phylogenetics
  - slug: RJ-2016-009
    old_slug: sestelo-villanueva-meiramachado-etal
    title: 'FWDselect: An R Package for Variable Selection in Regression Models'
    bibtitle: |-
      FWDselect: An R Package for Variable Selection in Regression
                Models
    author:
    - Marta Sestelo
    - Nora M. Villanueva
    - Luis Meira-Machado
    - Javier Roca-Pardiñas
    bibauthor: |-
      Marta Sestelo and Nora M. Villanueva and Luis Meira-Machado
                and Javier Roca-Pardiñas
    landing: '2016'
    abstract: '  Abstract In multiple regression models, when there are a large number
      (p) of explanatory variables            which may or may not be relevant for
      predicting the response, it is useful to be able to reduce the model.            To
      this end, it is necessary to determine the best subset of q (q ≤ p) predictors
      which will establish            the model with the best prediction capacity.
      FWDselect package introduces a new forward stepwise           based selection
      procedure to select the best model in different regression frameworks (parametric            or
      nonparametric). The developed methodology, which can be equally applied to linear
      models,            generalized linear models or generalized additive models,
      aims to introduce solutions to the following            two topics: i) selection
      of the best combination of q variables by using a step-by-step method; and,            perhaps,
      most importantly, ii) search for the number of covariates to be included in
      the model based            on bootstrap resampling techniques. The software
      is illustrated using real and simulated data.'
    pages:
    - 132
    - 148
    acknowledged: '2015-05-18'
    online: '2016-04-20'
    CRANpkgs:
    - meifly
    - leaps
    - subselect
    - leaps
    - subselect
    - lars
    - glmnet
    - glmulti
    - bestglm
    - mgcv
    - FWDselect
    CTV_rev:
    - ChemPhys
    - SocialSciences
    - MachineLearning
    - Bayesian
    - Econometrics
    - Environmetrics
    - Survival
  - slug: RJ-2016-010
    old_slug: joblin-mauerer
    title: An Interactive Survey Application for Validating Social Network Analysis
      Techniques
    bibtitle: |-
      An Interactive Survey Application for Validating Social
                Network Analysis Techniques
    author:
    - Mitchell Joblin
    - Wolfgang Mauerer
    bibauthor: Mitchell Joblin and Wolfgang Mauerer
    landing: '2016'
    abstract: '  Abstract Social network analysis is extremely well supported by the
      R community and is routinely            used for studying the relationships
      between people engaged in collaborative activities. While there            has
      been rapid development of new approaches and metrics in this field, the challenging
      question            of validity (how well insights derived from social networks
      agree with reality) is often difficult to            address. We propose the
      use of several R packages to generate interactive surveys that are specifically            well
      suited for validating social network analyses. Using our web-based survey application,
      we were            able to validate the results of applying community-detection
      algorithms to infer the organizational            structure of software developers
      contributing to open-source projects.'
    pages:
    - 149
    - 158
    acknowledged: '2015-05-18'
    online: '2015-11-04'
    CRANpkgs:
    - igraph
    - sna
    - twitteR
    - Rfacebook
    - shiny
    BIOpkgs: graph
    CTV_rev:
    - WebTechnologies
    - Optimization
    - Bayesian
    - gR
    - Graphics
    - SocialSciences
    - Spatial
  - slug: RJ-2016-011
    old_slug: franck-osborne
    title: Exploring Interaction Effects in Two-Factor Studies using the hiddenf Package
      in R.
    bibtitle: |-
      Exploring Interaction Effects in Two-Factor Studies using
                the hiddenf Package in R.
    author:
    - Christopher T. Franck
    - Jason A. Osborne
    bibauthor: Christopher T. Franck and Jason A. Osborne
    landing: '2016'
    abstract: '  Abstract In crossed, two-factor studies with one observation per
      factor-level combination, interaction            effects between factors can
      be hard to detect and can make the choice of a suitable statistical model            difficult.
      This article describes hiddenf, an R package that enables users to quantify
      and characterize a            certain form of interaction in two-factor layouts.
      When effects of one factor (a) fall into two groups            depending on
      the level of another factor, and (b) are constant within these groups, the interaction            pattern
      is deemed "hidden additivity" because within groups, the effects of the two
      factors are additive,            while between groups the factors are allowed
      to interact. The hiddenf software can be used to estimate,            test,
      and report an appropriate factorial effects model corresponding to hidden additivity,
      which is            intermediate between the unavailable full factorial model
      and the overly-simplistic additive model.            Further, the software also
      conducts five statistical tests for interaction proposed between 1949 and            2014.
      A collection of 17 datasets is used for illustration.'
    pages:
    - 159
    - 172
    acknowledged: '2015-05-27'
    online: '2016-04-03'
    CRANpkgs:
    - hiddenf
    - additivityTests
  - slug: RJ-2016-012
    old_slug: messner-mayr-zeileis
    title: Heteroscedastic Censored and Truncated Regression with crch
    bibtitle: Heteroscedastic Censored and Truncated Regression with crch
    author:
    - Jakob W. Messner
    - Georg J. Mayr
    - Achim Zeileis
    bibauthor: Jakob W. Messner and Georg J. Mayr and Achim Zeileis
    landing: '2016'
    abstract: '  Abstract The crch package provides functions for maximum likelihood
      estimation of censored            or truncated regression models with conditional
      heteroscedasticity along with suitable standard            methods to summarize
      the fitted models and compute predictions, residuals, etc. The supported            distributions
      include leftor right-censored or truncated Gaussian, logistic, or student-t
      distributions            with potentially different sets of regressors for modeling
      the conditional location and scale. The models            and their R implementation
      are introduced and illustrated by numerical weather prediction tasks            using
      precipitation data for Innsbruck (Austria).'
    pages:
    - 173
    - 181
    acknowledged: '2015-06-28'
    online: '2015-10-14'
    CRANpkgs:
    - dglm
    - glmx
    - gamlss
    - betareg
    - crch
    - Formula
    - gamlss.cens
    - gamlss.tr
    - sampleSelection
    - mhurdle
    CTV_rev:
    - Econometrics
    - Psychometrics
    - SocialSciences
    - Survival
  - slug: RJ-2016-013
    old_slug: pritikin-schmidt
    title: Model Builder for Item Factor Analysis with OpenMx
    bibtitle: Model Builder for Item Factor Analysis with OpenMx
    author:
    - Joshua N. Pritikin
    - Karen M. Schmidt
    bibauthor: Joshua N. Pritikin and Karen M. Schmidt
    landing: '2016'
    abstract: '  Abstract We introduce a shiny web application to facilitate the construction
      of Item Factor Analysis            (a.k.a. Item Response Theory) models using
      the OpenMx package. The web application assists with            importing data,
      outcome recoding, and model specification. However, the app does not conduct
      any            analysis but, rather, generates an analysis script. Generated
      Rmarkdown output serves dual purposes:            to analyze a data set and
      demonstrate good programming practices. The app can be used as a teaching            tool
      or as a starting point for custom analysis scripts.'
    pages:
    - 182
    - 203
    acknowledged: '2015-07-21'
    online: '2016-04-03'
    CRANpkgs:
    - OpenMx
    - shiny
    - Rmarkdown
    - ifaTools
    - rpf
    CTV_rev:
    - Psychometrics
    - WebTechnologies
  - slug: RJ-2016-014
    old_slug: na-pebesma-heuvelink
    title: Spatio-Temporal Interpolation using gstat
    bibtitle: Spatio-Temporal Interpolation using gstat
    author:
    - Benedikt Gräler
    - Edzer Pebesma
    - Gerard Heuvelink
    bibauthor: Benedikt Gräler and Edzer Pebesma and Gerard Heuvelink
    landing: '2016'
    abstract: '  Abstract We present new spatio-temporal geostatistical modelling
      and interpolation capabilities of            the R package gstat. Various spatio-temporal
      covariance models have been implemented, such as the            separable, product-sum,
      metric and sum-metric models. In a real-world application we compare spatio           temporal
      interpolations using these models with a purely spatial kriging approach. The
      target variable            of the application is the daily mean PM10 concentration
      measured at rural air quality monitoring            stations across Germany
      in 2005. R code for variogram fitting and interpolation is presented in            this
      paper to illustrate the workflow of spatio-temporal interpolation using gstat.
      We conclude            that the system works properly and that the extension
      of gstat facilitates and eases spatio-temporal            geostatistical modelling
      and prediction for R users.'
    pages:
    - 204
    - 218
    acknowledged: '2015-07-24'
    online: '2016-06-13'
    CRANpkgs:
    - spacetime
    - gstat
    - RandomFields
    - spTimer
    - spBayes
    - spate
    - FNN
    CTV_rev:
    - SpatioTemporal
    - Spatial
    - Bayesian
    - TimeSeries
  - slug: RJ-2016-015
    old_slug: beck
    title: 'SWMPr: An R Package for Retrieving, Organizing, and Analyzing Environmental
      Data for Estuaries'
    bibtitle: |-
      SWMPr: An R Package for Retrieving, Organizing, and
                Analyzing Environmental Data for Estuaries
    author: Marcus W Beck
    bibauthor: Marcus W Beck
    landing: '2016'
    abstract: '  Abstract The System-Wide Monitoring Program (SWMP) was implemented
      in 1995 by the US National            Estuarine Research Reserve System. This
      program has provided two decades of continuous monitoring            data at
      over 140 fixed stations in 28 estuaries. However, the increasing quantity of
      data provided by the            monitoring network has complicated broad-scale
      comparisons between systems and, in some cases,            prevented simple
      trend analysis of water quality parameters at individual sites. This article
      describes            the SWMPr package that provides several functions that
      facilitate data retrieval, organization, and            analysis of time series
      data in the reserve estuaries. Previously unavailable functions for estuaries
      are            also provided to estimate rates of ecosystem metabolism using
      the open-water method. The SWMPr            package has facilitated a cross-reserve
      comparison of water quality trends and links quantitative            information
      with analysis tools that have use for more generic applications to environmental
      time            series.'
    pages:
    - 219
    - 232
    acknowledged: '2015-09-04'
    online: '2016-04-03'
    CRANpkgs:
    - SWMPr
    - shiny
    - cents
    - wq
    - ggmap
    - StreamMetabolism
    CTV_rev:
    - WebTechnologies
    - Environmetrics
    - Spatial
    - TimeSeries
  - slug: RJ-2016-016
    old_slug: demirhan-bitirim
    title: 'CryptRndTest: An R Package for Testing the Cryptographic Randomness'
    bibtitle: |-
      CryptRndTest: An R Package for Testing the Cryptographic
                Randomness
    author:
    - Haydar Demirhan
    - Nihan Bitirim
    bibauthor: Haydar Demirhan and Nihan Bitirim
    landing: '2016'
    abstract: '  Abstract In this article, we introduce the R package CryptRndTest
      that performs eight statistical            randomness tests on cryptographic
      random number sequences. The purpose of the package is to            provide
      software implementing recently proposed cryptographic randomness tests utilizing
      goodness           of-fit tests superior to the usual chi-square test in terms
      of statistical performance. Most of the tests            included in package
      CryptRndTest are not available in other software packages such as the R package            RDieHarder
      or the C library TestU01. Chi-square, Anderson-Darling, Kolmogorov-Smirnov,
      and            Jarque-Bera goodness-of-fit procedures are provided along with
      cryptographic randomness tests.            CryptRndTest utilizes multiple precision
      floating numbers for sequences longer than 64-bit based            on the package
      Rmpfr. By this way, included tests are applied precisely for higher bit-lengths.
      In            addition CryptRndTest provides a user friendly interface to these
      cryptographic randomness tests.            As an illustrative application, CryptRndTest
      is used to test available random number generators in R.'
    pages:
    - 233
    - 247
    acknowledged: '2015-09-10'
    online: '2016-04-03'
    CRANpkgs:
    - RDieHarder
    - randtests
    - DescTools
    - CryptRndTest
    - Rmpfr
    - kSamples
    - tseries
    - copula
    - gmp
    CTV_rev:
    - Distributions
    - Finance
    - NumericalMathematics
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - Multivariate
    - TimeSeries
  - slug: RJ-2016-017
    old_slug: calvo-na
    title: 'scmamp: Statistical Comparison of Multiple Algorithms in Multiple Problems'
    bibtitle: |-
      scmamp: Statistical Comparison of Multiple Algorithms in
                Multiple Problems
    author:
    - Borja Calvo
    - Guzmán Santafé
    bibauthor: Borja Calvo and Guzmán Santafé
    landing: '2016'
    abstract: '  Abstract Comparing the results obtained by two or more algorithms
      in a set of problems is a central            task in areas such as machine learning
      or optimization. Drawing conclusions from these comparisons            may require
      the use of statistical tools such as hypothesis testing. There are some interesting
      papers            that cover this topic. In this manuscript we present scmamp,
      an R package aimed at being a tool            that simplifies the whole process
      of analyzing the results obtained when comparing algorithms, from            loading
      the data to the production of plots and tables.                 Comparing the
      performance of different algorithms is an essential step in many research and            practical
      computational works. When new algorithms are proposed, they have to be compared
      with            the state of the art. Similarly, when an algorithm is used for
      a particular problem, its performance with            different sets of parameters
      has to be compared, in order to tune them for the best results.                 When
      the differences are very clear (e.g., when an algorithm is the best in all the
      problems used in            the comparison), the direct comparison of the results
      may be enough. However, this is an unusual            situation and, thus, in
      most situations a direct comparison may be misleading and not enough to draw            sound
      conclusions; in those cases, the statistical assessment of the results is advisable.                 The
      statistical comparison of algorithms in the context of machine learning has
      been covered in            several papers. In particular, the tools implemented
      in this package are those presented in Demšar            (2006); García and
      Herrera (2008); García et al. (2010). Another good review that covers, among
      other            aspects, the statistical assessment of the results in the context
      of supervised classification can be found            in Santafé et al. (2015).'
    pages:
    - 248
    - 256
    acknowledged: '2015-09-28'
    online: '2015-11-26'
    CRANpkgs: scmamp
  - slug: RJ-2016-018
    old_slug: an-liu
    title: 'keyplayer: An R Package for Locating Key Players in Social Networks'
    bibtitle: |-
      keyplayer: An R Package for Locating Key Players in Social
                Networks
    author:
    - Weihua An
    - Yu-Hsin Liu
    bibauthor: Weihua An and Yu-Hsin Liu
    landing: '2016'
    abstract: '  Abstract Interest in social network analysis has exploded in the
      past few years, partly thanks to            the advancements in statistical
      methods and computing for network analysis. A wide range of the            methods
      for network analysis is already covered by existent R packages. However, no
      comprehensive            packages are available to calculate group centrality
      scores and to identify key players (i.e., those players            who constitute
      the most central group) in a network. These functionalities are important because,            for
      example, many social and health interventions rely on key players to facilitate
      the intervention.            Identifying key players is challenging because
      players who are individually the most central are not            necessarily
      the most central as a group due to redundancy in their connections. In this
      paper we            develop methods and tools for computing group centrality
      scores and for identifying key players in            social networks. We illustrate
      the methods using both simulated and empirical examples. The package            keyplayer
      providing the presented methods is available from Comprehensive R Archive Network            (CRAN).'
    pages:
    - 257
    - 268
    acknowledged:
    - '2015-10-16'
    - '2015-10-17'
    online: '2016-05-01'
    CRANpkgs:
    - network
    - sna
    - igraph
    - statnet
    - RSiena
    - keyplayer
    - influenceR
    CTV_rev:
    - SocialSciences
    - gR
    - Optimization
    - Bayesian
    - Graphics
    - Spatial
  - slug: RJ-2016-019
    old_slug: north
    title: 'SchemaOnRead: A Package for Schema-on-Read in R'
    bibtitle: 'SchemaOnRead: A Package for Schema-on-Read in R'
    author: Michael J. North
    bibauthor: Michael J. North
    landing: '2016'
    abstract: '  Abstract SchemaOnRead is a CRAN package that provides an extensible
      mechanism for importing a            wide range of file types into R as well
      as support for the emerging schema-on-read paradigm in R. The            schema-on-read
      tools within the package include a single function call that recursively reads
      folders            with text, comma separated value, raster image, R data, HDF5,
      NetCDF, spreadsheet, Weka, Epi Info,            Pajek network, R network, HTML,
      SPSS, Systat, and Stata files. It also recursively reads folders (e.g.,            schemaOnRead("folder")),
      returning a nested list of the contained elements. The provided tools can            be
      used as-is or easily customized to implement tool chains in R. This paper’s
      contribution is that it            introduces and describes the SchemaOnRead
      package and compares it to related R packages.'
    pages:
    - 269
    - 275
    acknowledged: '2015-10-27'
    online: '2016-04-03'
    CRANpkgs:
    - SchemaOnRead
    - rio
    - readbitmap
    - foreign
    - testthat
    CTV_rev:
    - OfficialStatistics
    - WebTechnologies
  - slug: RJ-2016-020
    old_slug: leeper
    title: Crowdsourced Data Preprocessing with R and Amazon Mechanical Turk
    bibtitle: |-
      Crowdsourced Data Preprocessing with R and Amazon Mechanical
                Turk
    author: Thomas J. Leeper
    bibauthor: Thomas J. Leeper
    landing: '2016'
    abstract: '  Abstract This article introduces the use of the Amazon Mechanical
      Turk (MTurk) crowdsourcing            platform as a resource for R users to
      leverage crowdsourced human intelligence for preprocessing           “messy”
      data into a form easily analyzed within R. The article first describes MTurk
      and the MTurkR            package, then outlines how to use MTurkR to gather
      and manage crowdsourced data with MTurk            using some of the package’s
      core functionality. Potential applications of MTurkR include construction            of
      manually coded training sets, human transcription and translation, manual data
      scraping from            scanned documents, content analysis, image classification,
      and the completion of online survey            questionnaires, among others.
      As an example of massive data preprocessing, the article describes an            image
      rating task involving 225 crowdsourced workers and more than 5500 images using
      just three            MTurkR function calls.'
    pages:
    - 276
    - 288
    acknowledged: '2015-10-30'
    online: '2016-06-13'
    CRANpkgs:
    - MTurkR
    - MTurkRGUI
    - tcltk
    - curl
    - XML
    CTV_rev: WebTechnologies
  - slug: RJ-2016-021
    old_slug: scrucca-fop-murphy-etal
    title: 'mclust 5: Clustering, Classification and Density Estimation Using Gaussian
      Finite Mixture Models'
    bibtitle: |-
      mclust 5: Clustering, Classification and Density Estimation
                Using Gaussian Finite Mixture Models
    author:
    - Luca Scrucca
    - Michael Fop
    - T. Brendan Murphy
    - Adrian E. Raftery
    bibauthor: |-
      Luca Scrucca and Michael Fop and T. Brendan Murphy and
                Adrian E. Raftery
    landing: '2016'
    abstract: '  Abstract Finite mixture models are being used increasingly to model
      a wide variety of random            phenomena for clustering, classification
      and density estimation. mclust is a powerful and popular            package
      which allows modelling of data as a Gaussian finite mixture with different covariance            structures
      and different numbers of mixture components, for a variety of purposes of analysis.
      Recently,            version 5 of the package has been made available on CRAN.
      This updated version adds new covariance            structures, dimension reduction
      capabilities for visualisation, model selection criteria, initialisation            strategies
      for the EM algorithm, and bootstrap-based inference, making it a full-featured
      R package            for data analysis via finite mixture modelling.'
    pages:
    - 289
    - 317
    acknowledged: '2015-11-11'
    online: '2016-06-13'
    CRANpkgs:
    - mclust
    - cranlogs
    - Rmixmod
    - mixture
    - EMCluster
    - mixtools
    - bgmm
    - flexmix
    - igraph
    - gclus
    - rrcov
    - tourr
    - fpc
    CTV_rev:
    - Cluster
    - Multivariate
    - Distributions
    - Environmetrics
    - Graphics
    - gR
    - Optimization
    - Psychometrics
    - Robust
    - Spatial
  - slug: RJ-2016-022
    old_slug: szkaliczki
    title: 'clustering.sc.dp: Optimal Clustering with Sequential Constraint by Using
      Dynamic Programming'
    bibtitle: |-
      clustering.sc.dp: Optimal Clustering with Sequential
                Constraint by Using Dynamic Programming
    author: Tibor Szkaliczki
    bibauthor: Tibor Szkaliczki
    landing: '2016'
    abstract: '  Abstract The general clustering algorithms do not guarantee optimality
      because of the hardness of the            problem. Polynomial-time methods can
      find the clustering corresponding to the exact optimum only            in special
      cases. For example, the dynamic programming algorithm can solve the one-dimensional            clustering
      problem, i.e., when the items to be clustered can be characterised by only one
      scalar            number. Optimal one-dimensional clustering is provided by
      package Ckmeans.1d.dp in R. The paper            shows a possible generalisation
      of the method implemented in this package to multidimensional            data:
      the dynamic programming method can be applied to find the optimum clustering
      of vectors            when only subsequent items may form a cluster. Sequential
      data are common in various fields            including telecommunication, bioinformatics,
      marketing, transportation etc. The proposed algorithm            can determine
      the optima for a range of cluster numbers in order to support the case when
      the number            of clusters is not known in advance.'
    pages:
    - 318
    - 327
    acknowledged: '2015-12-09'
    online: '2016-05-01'
    CRANpkgs:
    - Ckmeans.1d.dp
    - clustering.sc.dp
  - slug: RJ-2016-023
    old_slug: hu-qutub
    title: 'progenyClust: an R package for Progeny Clustering'
    bibtitle: 'progenyClust: an R package for Progeny Clustering'
    author:
    - Chenyue W. Hu
    - Amina A. Qutub
    bibauthor: Chenyue W. Hu and Amina A. Qutub
    landing: '2016'
    abstract: '  Abstract Identifying the optimal number of clusters is a common problem
      faced by data scientists            in various research fields and industry
      applications. Though many clustering evaluation techniques            have been
      developed to solve this problem, the recently developed algorithm Progeny Clustering            is
      a much faster alternative and one that is relevant to biomedical applications.
      In this paper, we            introduce an R package progenyClust that implements
      and extends the original Progeny Clustering            algorithm for evaluating
      clustering stability and identifying the optimal cluster number. We illustrate            its
      applicability using two examples: a simulated test dataset for proof-of-concept,
      and a cell imaging            dataset for demonstrating its application potential
      in biomedical research. The progenyClust package            is versatile in
      that it offers great flexibility for picking methods and tuning parameters.
      In addition,            the default parameter setting as well as the plot and
      summary methods offered in the package make            the application of Progeny
      Clustering straightforward and coherent.'
    pages:
    - 328
    - 338
    acknowledged: '2016-01-01'
    online: '2016-05-01'
    CRANpkgs:
    - cclust
    - clusterSim
    - cluster
    - Nbclust
    - fpc
    - progenyClust
    - stat
    - Hmisc
    CTV_rev:
    - Cluster
    - Multivariate
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2016-024
    old_slug: giner-smyth
    title: 'statmod: Probability Calculations for the Inverse Gaussian Distribution'
    bibtitle: |-
      statmod: Probability Calculations for the Inverse Gaussian
                Distribution
    author:
    - Göknur Giner
    - Gordon K. Smyth
    bibauthor: Göknur Giner and Gordon K. Smyth
    landing: '2016'
    abstract: '  Abstract The inverse Gaussian distribution (IGD) is a well known
      and often used probability dis           tribution for which fully reliable
      numerical algorithms have not been available. We develop fast,            reliable
      basic probability functions (dinvgauss, pinvgauss, qinvgauss and rinvgauss)
      for the IGD            that work for all possible parameter values and which
      achieve close to full machine accuracy. The            most challenging task
      is to compute quantiles for given cumulative probabilities and we develop            a
      simple but elegant mathematical solution to this problem. We show that Newton’s
      method for            finding the quantiles of a IGD always converges monotonically
      when started from the mode of the            distribution. Simple Taylor series
      expansions are used to improve accuracy on the log-scale. The            IGD
      probability functions provide the same options and obey the same conventions
      as do probability            functions provided in the stats package.'
    pages:
    - 339
    - 351
    acknowledged: '2016-01-05'
    online: '2016-07-27'
    CRANpkgs:
    - SuppDists
    - STAR
    - statmod
    CTV_rev:
    - Distributions
    - HighPerformanceComputing
    - NumericalMathematics
  - slug: RJ-2016-025
    old_slug: wright
    title: Using DECIPHER v2.0 to Analyze Big Biological Sequence Data in R
    bibtitle: |-
      Using DECIPHER v2.0 to Analyze Big Biological Sequence Data
                in R
    author: Erik S. Wright
    bibauthor: Erik S. Wright
    landing: '2016'
    abstract: '  Abstract In recent years, the cost of DNA sequencing has decreased
      at a rate that has outpaced            improvements in memory capacity. It is
      now common to collect or have access to many gigabytes            of biological
      sequences. This has created an urgent need for approaches that analyze sequences
      in            subsets without requiring all of the sequences to be loaded into
      memory at one time. It has also opened            opportunities to improve the
      organization and accessibility of information acquired in sequencing            projects.
      The DECIPHER package offers solutions to these problems by assisting in the
      curation of            large sets of biological sequences stored in compressed
      format inside a database. This approach has            many practical advantages
      over standard bioinformatics workflows, and enables large analyses that            would
      otherwise be prohibitively time consuming.'
    pages:
    - 352
    - 359
    acknowledged: '2016-01-29'
    online: '2016-05-01'
    CRANpkgs: RSQLite
    BIOpkgs:
    - Biostrings
    - DECIPHER
  - slug: RJ-2016-026
    old_slug: keyes-rudis-jacobs
    title: R Packages to Aid in Handling Web Access Logs
    bibtitle: R Packages to Aid in Handling Web Access Logs
    author:
    - Oliver Keyes
    - Bob Rudis
    - Jay Jacobs
    bibauthor: Oliver Keyes and Bob Rudis and Jay Jacobs
    landing: '2016'
    abstract: '  Abstract Web access logs contain information on HTTP(S) requests
      and form a key part of both            industry and academic explorations of
      human behaviour on the internet. But the preparation (reading,            parsing
      and manipulation) of that data is just unique enough to make generalized tools
      unfit for the            task, both in programming time and processing time
      which are compounded when dealing with large            data sets common with
      web access logs. In this paper we explain and demonstrate a series of packages            designed
      to efficiently read in, parse and munge access log data, allowing researchers
      to handle URLs            and IP addresses easily. These packages are substantially
      faster than existing R methods from a            3-500% speedup for file reading
      to a 57,000% speedup in URL parsing.'
    pages:
    - 360
    - 366
    acknowledged: '2016-01-29'
    online: '2016-06-13'
    CRANpkgs:
    - httr
    - ApacheLogProcessor
    - webreadr
    - readr
    - microbenchmark
    - urltools
    - httr
    - XML
    - lubridate
    - iptools
    - rgeolocate
    - Rcpp
    CTV_rev:
    - WebTechnologies
    - HighPerformanceComputing
    - NumericalMathematics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-027
    old_slug: feys
    title: Nonparametric Tests for the Interaction in Two-way Factorial Designs Using
      R
    bibtitle: |-
      Nonparametric Tests for the Interaction in Two-way Factorial
                Designs Using R
    author: Jos Feys
    bibauthor: Jos Feys
    landing: '2016'
    abstract: '  Abstract An increasing number of R packages include nonparametric
      tests for the interaction in            two-way factorial designs. This paper
      briefly describes the different methods of testing and reports            the
      resulting p-values of such tests on datasets for four types of designs: between,
      within, mixed, and            pretest-posttest designs. Potential users are
      advised only to apply tests they are quite familiar with            and not
      be guided by p-values for selecting packages and tests.'
    pages:
    - 367
    - 378
    acknowledged: '2016-02-28'
    online: '2016-07-27'
    CRANpkgs:
    - WRS2
    - nparLD
    - coin
    - lmPerm
    - perm
    - ez
    - boot
    - ART
    - ARTool
    - npIntFactRep
    - Rfit
    - StatMethRank
    - outliers
    - npsm
    - cocor
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - ExperimentalDesign
    - Optimization
    - Psychometrics
    - Robust
    - SocialSciences
    - TimeSeries
  - slug: RJ-2016-028
    old_slug: yozgatligil-dag
    title: 'GMDH: An R Package for Short Term Forecasting via GMDH-Type Neural Network
      Algorithms'
    bibtitle: |-
      GMDH: An R Package for Short Term Forecasting via GMDH-Type
                Neural Network Algorithms
    author:
    - Osman Dag
    - Ceylan Yozgatligil
    bibauthor: Osman Dag and Ceylan Yozgatligil
    landing: '2016'
    abstract: '  Abstract Group Method of Data Handling (GMDH)-type neural network
      algorithms are the heuristic            self organization method for the modelling
      of complex systems. GMDH algorithms are utilized            for a variety of
      purposes, examples include identification of physical laws, the extrapolation
      of            physical fields, pattern recognition, clustering, the approximation
      of multidimensional processes,            forecasting without models, etc. In
      this study, the R package GMDH is presented to make short term            forecasting
      through GMDH-type neural network algorithms. The GMDH package has options to
      use            different transfer functions (sigmoid, radial basis, polynomial,
      and tangent functions) simultaneously            or separately. Data on cancer
      death rate of Pennsylvania from 1930 to 2000 are used to illustrate the            features
      of the GMDH package. The results based on ARIMA models and exponential smoothing            methods
      are included for comparison.'
    pages:
    - 379
    - 386
    acknowledged: '2016-03-10'
    online: '2016-06-13'
    CRANpkgs:
    - glarma
    - ftsa
    - MARSS
    - ensembleBMA
    - ProbForecastGOP
    - forecast
    CTV_rev:
    - TimeSeries
    - Bayesian
    - Econometrics
    - Environmetrics
    - Finance
  - slug: RJ-2016-029
    old_slug: winslow-chamberlain-appling-etal
    title: 'sbtools: A Package Connecting R to Cloud-based Data for Collaborative
      Online Research'
    bibtitle: |-
      sbtools: A Package Connecting R to Cloud-based Data for
                Collaborative Online Research
    author:
    - Luke A Winslow
    - Scott Chamberlain
    - Alison P Appling
    - Jordan S Read
    bibauthor: |-
      Luke A Winslow and Scott Chamberlain and Alison P Appling
                and Jordan S Read
    landing: '2016'
    abstract: '  Abstract The adoption of high-quality tools for collaboration and
      reproducibile research such as R            and Github is becoming more common
      in many research fields. While Github and other version            management
      systems are excellent resources, they were originally designed to handle code
      and scale            poorly to large text-based or binary datasets. A number
      of scientific data repositories are coming            online and are often focused
      on dataset archival and publication. To handle collaborative workflows            using
      large scientific datasets, there is increasing need to connect cloud-based online
      data storage to            R. In this article, we describe how the new R package
      sbtools enables direct access to the advanced            online data functionality
      provided by ScienceBase, the U.S. Geological Survey’s online scientific data            storage
      platform.'
    pages:
    - 387
    - 398
    acknowledged: '2016-04-30'
    online: '2016-07-23'
  - heading: News and Notes
  - title: 'Conference Report: useR! 2016'
    author: Joe Rickert
    slug: user2016
    bibtitle: 'Conference Report: {useR}! 2016'
    pages:
    - 399
    - 401
  - title: Changes on CRAN
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    bibtitle: Changes on {CRAN}
    pages:
    - 402
    - 403
  - title: News from the Bioconductor Project
    author: The Bioconductor Team
    slug: bioconductor
    pages:
    - 404
    - 405
  - title: Changes in R
    author: The R Core Team
    slug: r-changes
    bibtitle: Changes in {R}
    pages:
    - 406
    - 415
- issue: 2016-2
  year: 2016
  volume: 8
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Michael Lawrence
    slug: editorial
    pages:
    - 4
    - 4
  - heading: Contributed Research Articles
  - slug: RJ-2016-030
    old_slug: stoer-samuelsen
    title: 'multipleNCC: Inverse Probability Weighting of Nested Case-Control Data'
    bibtitle: |-
      multipleNCC: Inverse Probability Weighting of Nested Case-
                Control Data
    author:
    - Nathalie C. Støer
    - Sven Ove Samuelsen
    bibauthor: Nathalie C. Støer and Sven Ove Samuelsen
    landing: '2016'
    abstract: '  Abstract Reuse of controls from nested case-control designs can increase
      efficiency in many situations,            for instance with competing risks
      or in other multiple endpoints situations. The matching between            cases
      and controls must be broken when controls are to be used for other endpoints.
      A weighted            analysis can then be performed to take care of the biased
      sampling from the cohort. We present the            R package multipleNCC for
      reuse of controls in nested case-control studies by inverse probability            weighting
      of the partial likelihood. The package handles right-censored, left-truncated
      and additionally            matched data, and varying numbers of sampled controls
      and the whole analysis is carried out using            one simple command. Four
      weight estimators are presented and variance estimation is explained.            The
      package is illustrated by analyzing health survey data from three counties in
      Norway for two            causes of death: cardiovascular disease and death
      from alcohol abuse, liver disease, and accidents and            violence. The
      data set is included in the package.'
    pages:
    - 5
    - 18
    acknowledged: '2015-08-23'
    online: '2016-08-11'
    CRANpkgs:
    - multipleNCC
    - survival
    - mgcv
    - ipw
    - MatchIt
    - NestedCohort
    - survey
    - Epi
    - gam
    CTV_rev:
    - SocialSciences
    - Survival
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Bayesian
    - ClinicalTrials
  - slug: RJ-2016-031
    old_slug: moore-stieha-nolting-etal
    title: 'QPot: An R Package for Stochastic Differential Equation Quasi-Potential
      Analysis'
    bibtitle: |-
      QPot: An R Package for Stochastic Differential Equation
                Quasi-Potential Analysis
    author:
    - Christopher M. Moore
    - Christopher R. Stieha
    - Ben C. Nolting
    - Maria K. Cameron
    - Karen C.            Abbott
    bibauthor: |-
      Christopher M. Moore and Christopher R. Stieha and Ben C.
                Nolting and Maria K. Cameron and Karen C. Abbott
    landing: '2016'
    abstract: '  Abstract QPot (pronounced kyoo + p ät) is an R package for analyzing
      two-dimensional systems of            stochastic differential equations. It
      provides users with a wide range of tools to simulate, analyze,            and
      visualize the dynamics of these systems. One of QPot’s key features is the computation
      of the            quasi-potential, an important tool for studying stochastic
      systems. Quasi-potentials are particularly            useful for comparing the
      relative stabilities of equilibria in systems with alternative stable states.
      This            paper describes QPot’s primary functions, and explains how quasi-potentials
      can yield insights about            the dynamics of stochastic systems. Three
      worked examples guide users through the application of            QPot’s functions.'
    pages:
    - 19
    - 38
    acknowledged: '2015-10-22'
    online: '2016-09-09'
    CRANpkgs:
    - QPot
    - rootSolve
    - deSolve
    - phaseR
    - Sim.DiffProc
    - yuima
    - viridis
    - plot3D
    - rgl
    CTV_rev:
    - DifferentialEquations
    - TimeSeries
    - Finance
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - SpatioTemporal
  - slug: RJ-2016-032
    old_slug: ramazzotti-antoniotti-caravagna-etal
    title: Design of the TRONCO BioConductor Package for TRanslational ONCOlogy
    bibtitle: |-
      Design of the TRONCO BioConductor Package for TRanslational
                ONCOlogy
    author:
    - Marco Antoniotti
    - Giulio Caravagna
    - Luca De Sano
    - Alex Graudenzi
    - Giancarlo Mauri
    - Bud            Mishra
    - Daniele Ramazzotti
    bibauthor: |-
      Marco Antoniotti and Giulio Caravagna and Luca De Sano
                and Alex Graudenzi and Giancarlo Mauri and Bud Mishra and
                Daniele Ramazzotti
    landing: '2016'
    abstract: '  Abstract Models of cancer progression provide insights on the order
      of accumulation of genetic            alterations during cancer development.
      Algorithms to infer such models from the currently available            mutational
      profiles collected from different cancer patients (cross-sectional data) have
      been defined in            the literature since late the 90s. These algorithms
      differ in the way they extract a graphical model of the            events modelling
      the progression, e.g., somatic mutations or copy-number alterations.                  TRONCO
      is an R package for TRanslational ONcology which provides a series of functions            to
      assist the user in the analysis of cross-sectional genomic data and, in particular,
      it implements            algorithms that aim to model cancer progression by
      means of the notion of selective advantage. These            algorithms are
      proved to outperform the current state-of-the-art in the inference of cancer
      progression            models. TRONCO also provides functionalities to load
      input cross-sectional data, set up the execution            of the algorithms,
      assess the statistical confidence in the results, and visualize the models.            Availability.
      Freely available at http://www.bioconductor.org/ under GPL license; project
      hosted            at http://bimib.disco.unimib.it/ and https://github.com/BIMIB-DISCo/TRONCO.            Contact.
      tronco@disco.unimib.it'
    pages:
    - 39
    - 59
    acknowledged: '2015-10-22'
    online: '2016-10-21'
    BIOpkgs: TRONCO
  - slug: RJ-2016-033
    old_slug: guevara-hartmann-mendoza
    title: 'diverse: an R Package to Analyze Diversity in Complex Systems'
    bibtitle: |-
      diverse: an R Package to Analyze Diversity in Complex
                Systems
    author:
    - Miguel R. Guevara
    - Dominik Hartmann
    - Marcelo Mendoza
    bibauthor: Miguel R. Guevara and Dominik Hartmann and Marcelo Mendoza
    landing: '2016'
    abstract: '  Abstract The package diverse provides an easy-to-use interface to
      calculate and visualize different            aspects of diversity in complex
      systems. In recent years, an increasing number of research projects in            social
      and interdisciplinary sciences, including fields like innovation studies, scientometrics,
      economics,            and network science have emphasized the role of diversification
      and sophistication of socioeconomic            systems. However, so far no dedicated
      package exists that covers the needs of these emerging fields            and
      interdisciplinary teams. Most packages about diversity tend to be created according
      to the            demands and terminology of particular areas of natural and
      biological sciences. The package diverse            uses interdisciplinary concepts
      of diversity—like variety, disparity and balance— as well as ubiquity            and
      revealed comparative advantages, that are relevant to many fields of science,
      but are in particular            useful for interdisciplinary research on diversity
      in socioeconomic systems. The package diverse            provides a toolkit
      for social scientists, interdisciplinary researcher, and beginners in ecology
      to (i)            import data, (ii) calculate different data transformations
      and normalization like revealed comparative            advantages, (iii) calculate
      different diversity measures, and (iv) connect diverse to other specialized
      R            packages on similarity measures, data visualization techniques,
      and statistical significance tests. The            comprehensiveness of the
      package, from matrix import and transformations options, over similarity            and
      diversity measures, to data visualization methods, makes it a useful package
      to explore different            dimensions of diversity in complex systems.'
    pages:
    - 60
    - 78
    acknowledged: '2015-11-10'
    online: '2016-12-12'
    CRANpkgs:
    - entropart
    - vegan
    - biodiversityR
    - Blaunet
    - diveRsity
    - divo
    - FD
    - hierDiversity
    - simboot
    - treescape
    - SYNCSA
    - diverse
    - proxy
    - pheatmap
    - treemap
    - igraph
    - foreign
    - spadeR
    CTV_rev:
    - Environmetrics
    - Multivariate
    - OfficialStatistics
    - Phylogenetics
    - Spatial
    - gR
    - Graphics
    - Optimization
    - Psychometrics
  - slug: RJ-2016-034
    old_slug: touloumis
    title: 'Simulating Correlated Binary and Multinomial Responses under Marginal
      Model Specification: The SimCorMultRes Package'
    bibtitle: |-
      Simulating Correlated Binary and Multinomial Responses under
                Marginal Model Specification: The SimCorMultRes Package
    author: Anestis Touloumis
    bibauthor: Anestis Touloumis
    landing: '2016'
    abstract: '  Abstract We developed the R package SimCorMultRes to facilitate simulation
      of correlated categori           cal (binary and multinomial) responses under
      a desired marginal model specification. The simulated            correlated
      categorical responses are obtained by applying threshold approaches to correlated
      contin           uous responses of underlying regression models and the dependence
      structure is parametrized in            terms of the correlation matrix of the
      latent continuous responses. This article provides an elaborate            introduction
      to the SimCorMultRes package demonstrating its design and usage via three examples.            The
      package can be obtained via CRAN.'
    pages:
    - 79
    - 91
    acknowledged: '2015-12-14'
    online: '2016-09-09'
    CRANpkgs:
    - SimCorMultRes
    - GenOrd
    - MultiOrd
    - mvtBinaryEP
    - multgee
    CTV_rev:
    - Distributions
    - SocialSciences
  - slug: RJ-2016-035
    old_slug: collingwood-oskooii-garciarios-etal
    title: 'eiCompare: Comparing Ecological Inference Estimates across EI and EI:RC'
    bibtitle: |-
      eiCompare: Comparing Ecological Inference Estimates across
                EI and EI:RC
    author:
    - Loren Collingwood
    - Kassra Oskooii
    - Sergio Garcia-Rios
    - Matt Barreto
    bibauthor: |-
      Loren Collingwood and Kassra Oskooii and Sergio Garcia-Rios
                and Matt Barreto
    landing: '2016'
    abstract: '  Abstract Social scientists and statisticians often use aggregate
      data to predict individual-level behavior            because the latter are
      not always available. Various statistical techniques have been developed to            make
      inferences from one level (e.g., precinct) to another level (e.g., individual
      voter) that minimize            errors associated with ecological inference.
      While ecological inference has been shown to be highly            problematic
      in a wide array of scientific fields, many political scientists and analysis
      employ the            techniques when studying voting patterns. Indeed, federal
      voting rights lawsuits now require such            an analysis, yet expert reports
      are not consistent in which type of ecological inference is used. This            is
      especially the case in the analysis of racially polarized voting when there
      are multiple candidates            and multiple racial groups. The eiCompare
      package was developed to easily assess two of the more            common ecological
      inference methods: EI and EI:R×C. The package facilitates a seamless comparison            between
      these methods so that scholars and legal practitioners can easily assess the
      two methods and            whether they produce similar or disparate findings.'
    pages:
    - 92
    - 101
    acknowledged: '2016-01-06'
    online: '2016-09-09'
    CRANpkgs:
    - ei
    - eiPack
    - eiCompare
  - slug: RJ-2016-036
    old_slug: vitolo-fry-buytaert
    title: 'rnrfa: An R package to Retrieve, Filter and Visualize Data from the UK
      National River Flow Archive'
    bibtitle: |-
      rnrfa: An R package to Retrieve, Filter and Visualize Data
                from the UK National River Flow Archive
    author:
    - Claudia Vitolo
    - Matthew Fry
    - Wouter Buytaert
    bibauthor: Claudia Vitolo and Matthew Fry and Wouter Buytaert
    landing: '2016'
    abstract: '  Abstract The UK National River Flow Archive (NRFA) stores several
      types of hydrological data and            metadata: daily river flow and catchment
      rainfall time series, gauging station and catchment informa           tion.
      Data are served through the NRFA web services via experimental RESTful APIs.
      Obtaining NRFA            data can be unwieldy due to complexities in handling
      HTTP GET requests and parsing responses in            JSON and XML formats.
      The rnrfa package provides a set of functions to programmatically access,            filter,
      and visualize NRFA data using simple R syntax. This paper describes the structure
      of the rnrfa            package, including examples using the main functions
      gdf() and cmr() for flow and rainfall data,            respectively. Visualization
      examples are also provided with a shiny web application and functions            provided
      in the package. Although this package is regional specific, the general framework
      and            structure could be applied to similar databases.'
    pages:
    - 102
    - 116
    acknowledged: '2016-01-29'
    online: '2017-01-03'
    CRANpkgs:
    - rnrfa
    - rnoaa
    - waterData
    - RNCEP
    - shiny
    - leaflet
    - rmarkdown
    - DT
    - dplyr
    - cowplot
    - plyr
    - httr
    - xml2
    - stringr
    - xts
    - rjson
    - ggmap
    - ggplot2
    - rgdal
    - sp
    - ggrepel
    - devtools
    - microbenchmark
    - cranlogs
    - evd
    - outliers
    - spacetime
    - sos4R
    CTV_rev:
    - WebTechnologies
    - Spatial
    - SpatioTemporal
    - ReproducibleResearch
    - Distributions
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - Finance
    - Graphics
    - Phylogenetics
    - TimeSeries
  - slug: RJ-2016-037
    old_slug: geraci
    title: 'Qtools: A Collection of Models and Tools for Quantile Inference'
    bibtitle: |-
      Qtools: A Collection of Models and Tools for Quantile
                Inference
    author: Marco Geraci
    bibauthor: Marco Geraci
    landing: '2016'
    abstract: '  Abstract Quantiles play a fundamental role in statistics. The quantile
      function defines the distribution            of a random variable and, thus,
      provides a way to describe the data that is specular but equivalent            to
      that given by the corresponding cumulative distribution function. There are
      many advantages in            working with quantiles, starting from their properties.
      The renewed interest in their usage seen in the            last years is due
      to the theoretical, methodological, and software contributions that have broadened            their
      applicability. This paper presents the R package Qtools, a collection of utilities
      for unconditional            and conditional quantiles.'
    pages:
    - 117
    - 138
    acknowledged: '2016-09-15'
    online: '2016-12-12'
    CRANpkgs:
    - quantreg
    - bayesQR
    - BSquare
    - lqmm
    - Qtools
    - boot
    - Rearrangement
    - mice
    CTV_rev:
    - SocialSciences
    - Bayesian
    - Econometrics
    - Optimization
    - Robust
    - Survival
    - Environmetrics
    - Multivariate
    - OfficialStatistics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-038
    old_slug: bacci-bartolucci
    title: Two-Tier Latent Class IRT Models in R
    bibtitle: Two-Tier Latent Class IRT Models in R
    author:
    - Silvia Bacci
    - Francesco Bartolucci
    bibauthor: Silvia Bacci and Francesco Bartolucci
    landing: '2016'
    abstract: '  Abstract In analyzing data deriving from the administration of a
      questionnaire to a group of individu           als, Item Response Theory (IRT)
      models provide a flexible framework to account for several aspects            involved
      in the response process, such as the existence of multiple latent traits. In
      this paper, we focus            on a class of semi-parametric multidimensional
      IRT models, in which these traits are represented            through one or
      more discrete latent variables; these models allow us to cluster individuals
      into homo           geneous latent classes and, at the same time, to properly
      study item characteristics. In particular, we            follow a within-item
      multidimensional formulation similar to that adopted in the two-tier models,            with
      each item measuring one or two latent traits. The proposed class of models may
      be estimated            through the package MLCIRTwithin, whose functioning
      is illustrated in this paper with examples            based on data about quality-of-life
      measurement and about the propensity to commit a crime.'
    pages:
    - 139
    - 166
    acknowledged: '2016-02-28'
    online: '2016-09-09'
    CRANpkgs:
    - MLCIRTwithin
    - MultiLCIRT
    - CDM
    - mirt
    - flirt
    - covLCA
    - lavaan
    - OpenMx
    - LMest
    CTV_rev:
    - Psychometrics
    - Econometrics
    - OfficialStatistics
  - slug: RJ-2016-039
    old_slug: lombardo-beh
    title: Variants of Simple Correspondence Analysis
    bibtitle: Variants of Simple Correspondence Analysis
    author:
    - Rosaria Lombardo
    - Eric J. Beh
    bibauthor: Rosaria Lombardo and Eric J. Beh
    landing: '2016'
    abstract: '  Abstract This paper presents the R package CAvariants (Lombardo and
      Beh, 2017). The package            performs six variants of correspondence analysis
      on a two-way contingency table. The main function            that shares the
      same name as the package – CAvariants – allows the user to choose (via a series
      of            input parameters) from six different correspondence analysis procedures.
      These include the classical            approach to (symmetrical) correspondence
      analysis, singly ordered correspondence analysis, doubly            ordered
      correspondence analysis, non symmetrical correspondence analysis, singly ordered
      non            symmetrical correspondence analysis and doubly ordered non symmetrical
      correspondence analysis.            The code provides the flexibility for constructing
      either a classical correspondence plot or a biplot            graphical display.
      It also allows the user to consider other important features that allow to assess
      the            reliability of the graphical representations, such as the inclusion
      of algebraically derived elliptical            confidence regions. This paper
      provides R functions that elaborates more fully on the code presented            in
      Beh and Lombardo (2014).'
    pages:
    - 167
    - 184
    acknowledged: '2016-02-28'
    online: '2016-10-21'
    CRANpkgs:
    - MASS
    - ca
    - anacor
    - FactoMineR
    - cabootcrs
    - CAinterprTools
    - homals
    - dualScale
    - ExPosition
    - vegan
    - ade4
    - cncaGUI
    - PTAk
    - CAvariants
    CTV_rev:
    - Psychometrics
    - Multivariate
    - Environmetrics
    - ChemPhys
    - Spatial
    - Distributions
    - Econometrics
    - Graphics
    - MedicalImaging
    - NumericalMathematics
    - Pharmacokinetics
    - Phylogenetics
    - Robust
    - SocialSciences
  - slug: RJ-2016-040
    old_slug: spindler-chernozhukov-hansen
    title: 'hdm: High-Dimensional Metrics'
    bibtitle: 'hdm: High-Dimensional Metrics'
    author:
    - Victor Chernozhukov
    - Chris Hansen
    - Martin Spindler
    bibauthor: Victor Chernozhukov and Chris Hansen and Martin Spindler
    landing: '2016'
    abstract: '  Abstract In this article the package High-dimensional Metrics hdm
      is introduced. It is a collection of            statistical methods for estimation
      and quantification of uncertainty in high-dimensional approximately            sparse
      models. It focuses on providing confidence intervals and significance testing
      for (possibly many)            low-dimensional subcomponents of the high-dimensional
      parameter vector. Efficient estimators and            uniformly valid confidence
      intervals for regression coefficients on target variables (e.g., treatment or            policy
      variable) in a high-dimensional approximately sparse regression model, for average
      treatment            effect (ATE) and average treatment effect for the treated
      (ATET), as well for extensions of these param           eters to the endogenous
      setting are provided. Theory grounded, data-driven methods for selecting            the
      penalization parameter in Lasso regressions under heteroscedastic and non-Gaussian
      errors are            implemented. Moreover, joint/ simultaneous confidence
      intervals for regression coefficients of a            high-dimensional sparse
      regression are implemented. Data sets which have been used in the literature            and
      might be useful for classroom demonstration and for testing new estimators are
      included.'
    pages:
    - 185
    - 199
    acknowledged: '2016-02-28'
    online: '2016-09-09'
    CRANpkgs:
    - glmnet
    - lars
    - hdm
    CTV_rev:
    - MachineLearning
    - Survival
  - slug: RJ-2016-041
    old_slug: young
    title: Normal Tolerance Interval Procedures in the tolerance Package
    bibtitle: |-
      Normal Tolerance Interval Procedures in the tolerance
                Package
    author: Derek S. Young
    bibauthor: Derek S. Young
    landing: '2016'
    abstract: '  Abstract Statistical tolerance intervals are used for a broad range
      of applications, such as quality            control, engineering design tests,
      environmental monitoring, and bioequivalence testing. tolerance            is
      the only R package devoted to procedures for tolerance intervals and regions.
      Perhaps the most            commonly-employed functions of the package involve
      normal tolerance intervals. A number of new            procedures for this setting
      have been included in recent versions of tolerance. In this paper, we discuss            and
      illustrate the functions that implement these normal tolerance interval procedures,
      one of which            is a new, novel type of operating characteristic curve.'
    pages:
    - 200
    - 212
    acknowledged: '2016-02-28'
    online: '2017-01-03'
    CRANpkgs:
    - tolerance
    - cranlogs
    - rgl
    CTV_rev:
    - Distributions
    - Graphics
    - Multivariate
    - SpatioTemporal
  - slug: RJ-2016-042
    old_slug: goksuluk-korkmaz-zararsiz-etal
    title: 'easyROC: An Interactive Web-tool for ROC Curve Analysis Using R Language
      Environment'
    bibtitle: |-
      easyROC: An Interactive Web-tool for ROC Curve Analysis
                Using R Language Environment
    author:
    - Dincer Goksuluk
    - Selcuk Korkmaz
    - Gokmen Zararsiz
    - A. Ergun Karaagaoglu
    bibauthor: |-
      Dincer Goksuluk and Selcuk Korkmaz and Gokmen Zararsiz and
                A. Ergun Karaagaoglu
    landing: '2016'
    abstract: '  Abstract ROC curve analysis is a fundamental tool for evaluating
      the performance of a marker in a            number of research areas, e.g.,
      biomedicine, bioinformatics, engineering etc., and is frequently used            for
      discriminating cases from controls. There are a number of analysis tools which
      are used to guide            researchers through their analysis. Some of these
      tools are commercial and provide basic methods            for ROC curve analysis
      while others offer advanced analysis techniques and a command-based user            interface,
      such as the R environment. The R environmentg includes comprehensive tools for
      ROC curve            analysis; however, using a command-based interface might
      be challenging and time consuming when a            quick evaluation is desired;
      especially for non-R users, physicians etc. Hence, a quick, comprehensive,            free
      and easy-to-use analysis tool is required. For this purpose, we developed a
      user-friendly web           tool based on the R language. This tool provides
      ROC statistics, graphical tools, optimal cutpoint            calculation, comparison
      of several markers, and sample size estimation to support researchers in their            decisions
      without writing R codes. easyROC can be used via any device with an internet
      connection            independently of the operating system. The web interface
      of easyROC is constructed with the R            package shiny. This tool is
      freely available through www.biosoft.hacettepe.edu.tr/easyROC.'
    pages:
    - 213
    - 230
    acknowledged: '2016-02-28'
    online: '2016-12-23'
    CRANpkgs:
    - ROCR
    - pROC
    - OptimalCutpoints
    - shiny
    - plotROC
    - plyr
    BIOpkgs: ROC
    CTV_rev:
    - MachineLearning
    - Multivariate
    - WebTechnologies
  - slug: RJ-2016-043
    old_slug: walker
    title: 'tigris: An R Package to Access and Work with Geographic Data from the
      US Census Bureau'
    bibtitle: |-
      tigris: An R Package to Access and Work with Geographic Data
                from the US Census Bureau
    author: Kyle Walker
    bibauthor: Kyle Walker
    landing: '2016'
    abstract: '  Abstract TIGER/Line shapefiles from the United States Census Bureau
      are commonly used for the            mapping and analysis of US demographic
      trends. The tigris package provides a uniform interface            for R users
      to download and work with these shapefiles. Functions in tigris allow R users
      to request            Census geographic datasets using familiar geographic identifiers
      and return those datasets as objects            of class "Spatial*DataFrame".
      In turn, tigris ensures consistent and high-quality spatial data for R            users’
      cartographic and spatial analysis projects that involve US Census data. This
      article provides            an overview of the functionality of the tigris package,
      and concludes with an applied example of a            geospatial workflow using
      data retrieved with tigris.'
    pages:
    - 231
    - 242
    acknowledged: '2016-02-28'
    online: '2016-08-11'
    CRANpkgs:
    - tigris
    - rgdal
    - sp
    - UScensus2010
    - USABoundaries
    - choroplethr
    - ggplot2
    - sp
    - rappdirs
    - dplyr
    - tmap
    - shiny
    - leaflet
    - devtools
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Graphics
    - OfficialStatistics
    - Phylogenetics
    - WebTechnologies
  - slug: RJ-2016-044
    old_slug: schloerke-wickham-cook-etal
    title: Escape from Boxland
    bibtitle: Escape from Boxland
    author:
    - Barret Schloerke
    - Hadley Wickham
    - Dianne Cook
    - Heike Hofmann
    bibauthor: |-
      Barret Schloerke and Hadley Wickham and Dianne Cook and
                Heike Hofmann
    landing: '2016'
    abstract: '  Abstract A library of common geometric shapes can be used to train
      our brains for understanding data            structure in high-dimensional Euclidean
      space. This article describes the methods for producing cubes,            spheres,
      simplexes, and tori in multiple dimensions. It also describes new ways to define
      and generate            high-dimensional tori. The algorithms are described,
      critical code chunks are given, and a large            collection of generated
      data are provided. These are available in the R package geozoo, and selected            movies
      and images, are available on the GeoZoo web site (http://schloerke.github.io/geozoo/).'
    pages:
    - 243
    - 257
    acknowledged: '2016-03-10'
    online: '2016-11-21'
    CRANpkgs:
    - geozoo
    - tourr
    - bitops
    - geozoo
    - geozoo
    CTV_rev: Multivariate
  - slug: RJ-2016-045
    old_slug: some-wansouwe-kokonendji
    title: 'Ake: An R Package for Discrete and Continuous Associated Kernel Estimations'
    bibtitle: |-
      Ake: An R Package for Discrete and Continuous Associated
                Kernel Estimations
    author:
    - Wanbitching E. Wansouwé
    - Sobom M. Somé
    - Célestin C. Kokonendji
    bibauthor: |-
      Wanbitching E. Wansouwé and Sobom M. Somé and Célestin C.
                Kokonendji
    landing: '2016'
    abstract: '  Abstract Kernel estimation is an important technique in exploratory
      data analysis. Its utility relies            on its ease of interpretation,
      especially based on graphical means. The Ake package is introduced            for
      univariate density or probability mass function estimation and also for continuous
      and discrete            regression functions using associated kernel estimators.
      These associated kernels have been proposed            due to their specific
      features of variables of interest. The package focuses on associated kernel
      methods            appropriate for continuous (bounded, positive) or discrete
      (count, categorical) data often found in            applied settings. Furthermore,
      optimal bandwidths are selected by cross-validation for any associated            kernel
      and by Bayesian methods for the binomial kernel. Other Bayesian methods for
      selecting            bandwidths with other associated kernels will complete
      this package in its future versions; particularly,            a Bayesian adaptive
      method for gamma kernel estimation of density functions is developed. Some            practical
      and theoretical aspects of the normalizing constant in both density and probability
      mass            functions estimations are given.'
    pages:
    - 258
    - 276
    acknowledged: '2016-03-10'
    online: '2016-12-12'
    CRANpkgs: Ake
  - slug: RJ-2016-046
    old_slug: sachs-gabriel
    title: An Introduction to Principal Surrogate Evaluation with the pseval Package
    bibtitle: |-
      An Introduction to Principal Surrogate Evaluation with the
                pseval Package
    author:
    - Michael C. Sachs
    - Erin E. Gabriel
    bibauthor: Michael C. Sachs and Erin E. Gabriel
    landing: '2016'
    abstract: '  Abstract We describe a new package called pseval that implements
      the core methods for the evaluation            of principal surrogates in a
      single clinical trial. It provides a flexible interface for defining models
      for            the risk given treatment and the surrogate, the models for integration
      over the missing counterfactual            surrogate responses, and the estimation
      methods. Estimated maximum likelihood and pseudo-score            can be used
      for estimation, and the bootstrap for inference. A variety of post-estimation
      methods are            provided, including print, summary, plot, and testing.
      We summarize the main statistical methods            that are implemented in
      the package and illustrate its use from the perspective of a novice R user.'
    pages:
    - 277
    - 292
    acknowledged: '2016-03-19'
    online: '2016-11-21'
    CRANpkgs:
    - pseval
    - survival
    - survey
    - ggplot2
    - lattice
    - Surrogate
    CTV_rev:
    - Graphics
    - SocialSciences
    - Survival
    - ClinicalTrials
    - Econometrics
    - Multivariate
    - OfficialStatistics
    - Pharmacokinetics
    - Phylogenetics
  - slug: RJ-2016-047
    old_slug: deveau-barillot-boeva-etal
    title: Calculating Biological Module Enrichment or Depletion and Visualizing Data
      on Large-scale Molecular Maps with ACSNMineR and RNaviCell Packages
    bibtitle: |-
      Calculating Biological Module Enrichment or Depletion
                and Visualizing Data on Large-scale Molecular Maps with
                ACSNMineR and RNaviCell Packages
    author:
    - Paul Deveau
    - Emmanuel Barillot
    - Valentina Boeva
    - Andrei Zinovyev
    - Eric Bonnet
    bibauthor: |-
      Paul Deveau and Emmanuel Barillot and Valentina Boeva and
                Andrei Zinovyev and Eric Bonnet
    landing: '2016'
    abstract: '  Abstract Biological pathways or modules represent sets of interactions
      or functional relationships            occurring at the molecular level in living
      cells. A large body of knowledge on pathways is organized in            public
      databases such as the KEGG, Reactome, or in more specialized repositories, the
      Atlas of Cancer            Signaling Network (ACSN) being an example. All these
      open biological databases facilitate analyses,            improving our understanding
      of cellular systems. We hereby describe ACSNMineR for calculation of            enrichment
      or depletion of lists of genes of interest in biological pathways. ACSNMineR
      integrates            ACSN molecular pathways gene sets, but can use any gene
      set encoded as a GMT file, for instance            sets of genes available in
      the Molecular Signatures Database (MSigDB). We also present RNaviCell,            that
      can be used in conjunction with ACSNMineR to visualize different data types
      on web-based,            interactive ACSN maps. We illustrate the functionalities
      of the two packages with biological data            taken from large-scale cancer
      datasets.'
    pages:
    - 293
    - 306
    acknowledged: '2016-04-02'
    online: '2016-10-21'
    CRANpkgs:
    - ACSNMineR
    - RNaviCell
    - ggplot2
    BIOpkgs:
    - GOstats
    - clusterProfiler
    CTV_rev:
    - Graphics
    - Phylogenetics
  - slug: RJ-2016-048
    old_slug: na-charte-na-etal
    title: 'Subgroup Discovery with Evolutionary Fuzzy Systems in R: The SDEFSR Package'
    bibtitle: |-
      Subgroup Discovery with Evolutionary Fuzzy Systems in R: The
                SDEFSR Package
    author:
    - Ángel M. García
    - Francisco Charte
    - Pedro González
    - Cristóbal J. Carmona
    - María J. del Jesus
    bibauthor: |-
      Ángel M. García and Francisco Charte and Pedro González and
                Cristóbal J. Carmona and María J. del Jesus
    landing: '2016'
    abstract: '  Abstract Subgroup discovery is a data mining task halfway between
      descriptive and predictive data            mining. Nowadays it is very relevant
      for researchers due to the fact that the knowledge extracted            is simple
      and interesting. For this task, evolutionary fuzzy systems are well suited algorithms            because
      they can find a good trade-off between multiple objectives in large search spaces.
      In fact, this            paper presents the SDEFSR package, which contains all
      the evolutionary fuzzy systems for subgroup            discovery presented throughout
      the literature. It is a package without dependencies on other software,            providing
      functions with recommended default parameters. In addition, it brings a graphical
      user            interface to avoid the user having to know all the parameters
      of the algorithms.'
    pages:
    - 307
    - 323
    acknowledged: []
    online: '2016-09-09'
    CRANpkgs:
    - rsubgroup
    - SDEFSR
    - devtools
    - mldr
  - slug: RJ-2016-049
    old_slug: pitsillou-fokianos
    title: 'dCovTS: Distance Covariance/Correlation for Time Series'
    bibtitle: 'dCovTS: Distance Covariance/Correlation for Time Series'
    author:
    - Maria Pitsillou
    - Konstantinos Fokianos
    bibauthor: Maria Pitsillou and Konstantinos Fokianos
    landing: '2016'
    abstract: '  Abstract The distance covariance function is a new measure of dependence
      between random vectors.            We drop the assumption of iid data to introduce
      distance covariance for time series. The R package            dCovTS provides
      functions that compute and plot distance covariance and correlation functions            for
      both univariate and multivariate time series. Additionally it includes functions
      for testing serial            independence based on distance covariance. This
      paper describes the theoretical background of            distance covariance
      methodology in time series and discusses in detail the implementation of these            methods
      with the R package dCovTS.'
    pages:
    - 324
    - 340
    acknowledged: '2016-04-18'
    online: '2016-10-21'
    CRANpkgs:
    - energy
    - doParallel
    - portes
    - MTS
    CTV_rev:
    - TimeSeries
    - Multivariate
  - slug: RJ-2016-050
    old_slug: schweiker
    title: 'comf: An R Package for Thermal Comfort Studies'
    bibtitle: 'comf: An R Package for Thermal Comfort Studies'
    author: Marcel Schweiker
    bibauthor: Marcel Schweiker
    landing: '2016'
    abstract: '  Abstract The field of thermal comfort generated a number of thermal
      comfort indices. Their code            implementation needs to be done by individual
      researchers. This paper presents the R package, comf,            which includes
      functions for common and new thermal comfort indices. Additional functions allow            comparisons
      between the predictive performance of these indices. This paper reviews existing
      thermal            comfort indices and available code implementations. This
      is followed by the description of the R            package and an example how
      to use the R package for the comparison of different thermal comfort            indices
      on data from a thermal comfort study.'
    pages:
    - 341
    - 351
    acknowledged: '2016-04-18'
    online: '2016-10-21'
    CRANpkgs: comf
  - slug: RJ-2016-051
    old_slug: olmedo-ortegafarias-delafuentesaiz-etal
    title: 'water: Tools and Functions to Estimate Actual Evapotranspiration Using
      Land Surface Energy Balance Models in R'
    bibtitle: |-
      water: Tools and Functions to Estimate Actual
                Evapotranspiration Using Land Surface Energy Balance Models
                in R
    author:
    - Guillermo Federico Olmedo
    - Samuel Ortega-Farías
    - Daniel de la Fuente-Sáiz
    - David Fonseca-            Luego
    - Fernando Fuentes-Peñailillo
    bibauthor: |-
      Guillermo Federico Olmedo and Samuel Ortega-Farías and
                Daniel de la Fuente-Sáiz and David Fonseca- Luego and
                Fernando Fuentes-Peñailillo
    landing: '2016'
    abstract: '  Abstract The crop water requirement is a key factor in the agricultural
      process. It is usually estimated            throughout actual evapotranspiration
      (ETa ). This parameter is the key to develop irrigation strategies,            to
      improve water use efficiency and to understand hydrological, climatic, and ecosystem
      processes.            Currently, it is calculated with classical methods, which
      are difficult to extrapolate, or with land surface            energy balance
      models (LSEB), such as METRIC and SEBAL, which are based on remote sensing data.            This
      paper describes water, an open implementation of LSEB. The package provides
      several functions            to estimate the parameters of the LSEB equation
      from satellite data and proposes a new object class            to handle weather
      station data. One of the critical steps in METRIC is the selection of “cold”
      and           “hot” pixels, which water solves with an automatic method. The
      water package can process a batch            of satellite images and integrates
      most of the already published sub-models for METRIC. Although            water
      implements METRIC, it will be expandable to SEBAL and others in the near future.
      Finally, two            different procedures are demonstrated using data that
      is included in water package.'
    pages:
    - 352
    - 369
    acknowledged: '2016-04-30'
    online: '2016-12-12'
    CRANpkgs:
    - raster
    - raster
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2016-052
    old_slug: lipsitz-belloni-chernozhukov-etal
    title: 'quantreg.nonpar: An R Package for Performing Nonparametric Series Quantile
      Regression'
    bibtitle: |-
      quantreg.nonpar: An R Package for Performing Nonparametric
                Series Quantile Regression
    author:
    - Michael Lipsitz
    - Alexandre Belloni
    - Victor Chernozhukov
    - Iván Fernández-Val
    bibauthor: |-
      Michael Lipsitz and Alexandre Belloni and Victor
                Chernozhukov and Iván Fernández-Val
    landing: '2016'
    abstract: '  Abstract The R package quantreg.nonpar implements nonparametric quantile
      regression methods            to estimate and make inference on partially linear
      quantile models. quantreg.nonpar obtains point            estimates of the conditional
      quantile function and its derivatives based on series approximations to            the
      nonparametric part of the model. It also provides pointwise and uniform confidence
      intervals            over a region of covariate values and/or quantile indices
      for the same functions using analytical            and resampling methods. This
      paper serves as an introduction to the package and displays basic            functionality
      of the functions contained within.'
    pages:
    - 370
    - 381
    acknowledged: '2016-04-30'
    online: '2016-11-21'
    CRANpkgs:
    - quantreg.nonpar
    - quantreg
    - QuantifQuantile
    - quantregGrowth
    - fda
    CTV_rev:
    - Environmetrics
    - Econometrics
    - Optimization
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - Survival
  - slug: RJ-2016-053
    old_slug: koitka-friedrich
    title: 'nmfgpu4R: GPU-Accelerated Computation of the Non-Negative Matrix Factorization
      (NMF) Using CUDA Capable Hardware'
    bibtitle: |-
      nmfgpu4R: GPU-Accelerated Computation of the Non-Negative
                Matrix Factorization (NMF) Using CUDA Capable Hardware
    author:
    - Sven Koitka
    - Christoph M. Friedrich
    bibauthor: Sven Koitka and Christoph M. Friedrich
    landing: '2016'
    abstract: '  Abstract In this work, a novel package called nmfgpu4R is presented,
      which offers the computation            of Non-negative Matrix Factorization
      (NMF) on Compute Unified Device Architecture (CUDA) platforms            within
      the R environment. Benchmarks show a remarkable speed-up in terms of time per
      iteration            by utilizing the parallelization capabilities of modern
      graphics cards. Therefore the application of            NMF gets more attractive
      for real-world sized problems because the time to compute a factorization is            reduced
      by an order of magnitude.'
    pages:
    - 382
    - 392
    acknowledged: '2016-04-30'
    online: '2016-11-21'
    CRANpkgs:
    - NMF
    - NMFN
    - nmfgpu4R
    - Matrix
    - SparseM
    CTV_rev:
    - Econometrics
    - Multivariate
    - NumericalMathematics
  - slug: RJ-2016-054
    old_slug: roocks
    title: Computing Pareto Frontiers and Database Preferences with the rPref Package
    bibtitle: |-
      Computing Pareto Frontiers and Database Preferences with the
                rPref Package
    author: Patrick Roocks
    bibauthor: Patrick Roocks
    landing: '2016'
    abstract: ' Abstract The concept of Pareto frontiers is well-known in economics.
      Within the database community           there exist many different solutions
      for the specification and calculation of Pareto frontiers, also called           Skyline
      queries in the database context. Slight generalizations like the combination
      of the Pareto           operator with the lexicographical order have been established
      under the term database preferences. In           this paper we present the
      rPref package which allows to efficiently deal with these concepts within           R.
      With its help, database preferences can be specified in a very similar way as
      in a state-of-the-art           database management system. Our package provides
      algorithms for an efficient calculation of the           Pareto-optimal set
      and further functionalities for visualizing and analyzing the induced preference           order.'
    pages:
    - 393
    - 404
    acknowledged: '2016-05-10'
    online: '2017-01-03'
    CRANpkgs:
    - rPref
    - emoa
    - mco
    - TunePareto
    - dplyr
    - lazyeval
    - RcppParallel
    - igraph
    - ggplot2
    BIOpkgs: Rgraphviz
    CTV_rev:
    - Graphics
    - Optimization
    - gR
    - HighPerformanceComputing
    - Phylogenetics
    - Spatial
  - slug: RJ-2016-055
    old_slug: fachada-rodrigues-lopes-etal
    title: 'micompr: An R Package for Multivariate Independent Comparison of Observations'
    bibtitle: |-
      micompr: An R Package for Multivariate Independent
                Comparison of Observations
    author:
    - Nuno Fachada
    - João Rodrigues
    - Vitor V. Lopes
    - Rui C. Martins
    - Agostinho C. Rosa
    bibauthor: |-
      Nuno Fachada and João Rodrigues and Vitor V. Lopes and Rui
                C. Martins and Agostinho C. Rosa
    landing: '2016'
    abstract: '  Abstract The R package micompr implements a procedure for assessing
      if two or more multivariate            samples are drawn from the same distribution.
      The procedure uses principal component analysis to            convert multivariate
      observations into a set of linearly uncorrelated statistical measures, which
      are then            compared using a number of statistical methods. This technique
      is independent of the distributional            properties of samples and automatically
      selects features that best explain their differences. The            procedure
      is appropriate for comparing samples of time series, images, spectrometric measures
      or            similar high-dimension multivariate observations.'
    pages:
    - 405
    - 420
    acknowledged: '2016-05-10'
    online: '2016-11-21'
    CRANpkgs:
    - micompr
    - vegan
    - Blossom
    - energy
    - crossmatch
    - cramer
    - ks
    - ChemoSpec
    - biotools
    - MVN
    - testthat
    - knitr
    - roxygen2
    - deseasonalize
    CTV_rev:
    - Multivariate
    - ChemPhys
    - Environmetrics
    - Phylogenetics
    - Psychometrics
    - ReproducibleResearch
    - Spatial
    - TimeSeries
  - slug: RJ-2016-056
    old_slug: zhu-chen
    title: 'mixtox: An R Package for Mixture Toxicity Assessment'
    bibtitle: 'mixtox: An R Package for Mixture Toxicity Assessment'
    author:
    - Xiang-Wei Zhu
    - Jian-Yi Chen
    bibauthor: Xiang-Wei Zhu and Jian-Yi Chen
    landing: '2016'
    abstract: '  Abstract Mixture toxicity assessment is indeed necessary for humans
      and ecosystems that are contin           ually exposed to a variety of chemical
      mixtures. This paper describes an R package, called mixtox,            which
      offers a general framework of curve fitting, mixture experimental design, and
      mixture toxicity            prediction for practitioners in toxicology. The
      unique features of mixtox include: (1) constructing a            uniform table
      for mixture experimental design; and (2) predicting toxicity of a mixture with
      multiple            components based on reference models such as concentration
      addition, independent action, and            generalized concentration addition.
      We describe the various functions of the package and provide            examples
      to illustrate their use and show the collaboration of mixtox with other existing
      packages            (e.g., drc) in predicting toxicity of chemical mixtures.'
    pages:
    - 421
    - 433
    acknowledged: '2016-05-10'
    online: '2016-10-21'
  - slug: RJ-2016-057
    old_slug: sola-irigoien-mestres-etal
    title: 'Weighted Distance Based Discriminant Analysis: The R Package WeDiBaDis'
    bibtitle: |-
      Weighted Distance Based Discriminant Analysis: The R Package
                WeDiBaDis
    author:
    - Itziar Irigoien
    - Francesc Mestres
    - Concepcion Arenas
    bibauthor: Itziar Irigoien and Francesc Mestres and Concepcion Arenas
    landing: '2016'
    abstract: '  Abstract The WeDiBaDis package provides a user friendly environment
      to perform discriminant            analysis (supervised classification). WeDiBaDis
      is an easy to use package addressed to the biological            and medical
      communities, and in general, to researchers interested in applied studies. It
      can be            suitable when the user is interested in the problem of constructing
      a discriminant rule on the basis            of distances between a relatively
      small number of instances or units of known unbalanced-class            membership
      measured on many (possibly thousands) features of any type. This is a current
      situation            when analyzing genetic biomedical data. This discriminant
      rule can then be used both, as a means of            explaining differences
      among classes, but also in the important task of assigning the class membership            for
      new unlabeled units. Our package implements two discriminant analysis procedures
      in an R            environment: the well-known distance-based discriminant analysis
      (DB-discriminant) and a weighted           distance-based discriminant (WDB-discriminant),
      a novel classifier rule that we introduce. This new            procedure is
      based on an improvement of the DB rule taking into account the statistical depth
      of the            units. This article presents both classifying procedures and
      describes the implementation of each in            detail. We illustrate the
      use of the package using an ecological and a genetic experimental example.            Finally,
      we illustrate the effectiveness of the new proposed procedure (WDB), as compared
      with DB.            This comparison is carried out using thirty-eight, high-dimensional,
      class-unbalanced, cancer data            sets, three of which include clinical
      features.'
    pages:
    - 434
    - 450
    acknowledged: '2016-05-29'
    online: '2017-01-03'
    CRANpkgs:
    - cluster
    - ICGE
    - vegan
    CTV_rev:
    - Environmetrics
    - Multivariate
    - Cluster
    - Phylogenetics
    - Psychometrics
    - Spatial
  - slug: RJ-2016-058
    old_slug: mori-mori-mendiburu-etal
    title: 'Distance Measures for Time Series in R: The TSdist Package'
    bibtitle: 'Distance Measures for Time Series in R: The TSdist Package'
    author:
    - Usue Mori
    - Alexander Mendiburu
    - Jose A. Lozano
    bibauthor: Usue Mori and Alexander Mendiburu and Jose A. Lozano
    landing: '2016'
    abstract: '  Abstract The definition of a distance measure between time series
      is crucial for many time series data            mining tasks, such as clustering
      and classification. For this reason, a vast portfolio of time series            distance
      measures has been published in the past few years. In this paper, the TSdist
      package is            presented, a complete tool which provides a unified framework
      to calculate the largest variety of            time series dissimilarity measures
      available in R at the moment, to the best of our knowledge. The            package
      implements some popular distance measures which were not previously available
      in R, and            moreover, it also provides wrappers for measures already
      included in other R packages. Additionally,            the application of these
      distance measures to clustering and classification tasks is also supported            in
      TSdist, directly enabling the evaluation and comparison of their performance
      within these two            frameworks.'
    pages:
    - 451
    - 459
    acknowledged: '2016-05-29'
    online: '2016-09-09'
    CRANpkgs:
    - TSdist
    - dtw
    - pdc
    - proxy
    - longitudinalData
    - TSclust
    - zoo
    - xts
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - Environmetrics
    - Multivariate
    - SpatioTemporal
  - slug: RJ-2016-059
    old_slug: meiramachado-sestelo
    title: 'condSURV: An R Package for the Estimation of the Conditional Survival
      Function for Ordered Multivariate Failure Time Data'
    bibtitle: |-
      condSURV: An R Package for the Estimation of the Conditional
                Survival Function for Ordered Multivariate Failure Time Data
    author:
    - Luis Meira-Machado
    - Marta Sestelo
    bibauthor: Luis Meira-Machado and Marta Sestelo
    landing: '2016'
    abstract: '  Abstract One major goal in clinical applications of time-to-event
      data is the estimation of survival            with censored data. The usual
      nonparametric estimator of the survival function is the time-honored            Kaplan-Meier
      product-limit estimator. Though this estimator has been implemented in several
      R            packages, the development of the condSURV R package has been motivated
      by recent contributions            that allow the estimation of the survival
      function for ordered multivariate failure time data. The            condSURV
      package provides three different approaches all based on the Kaplan-Meier estimator.            In
      one of these approaches these quantities are estimated conditionally on current
      or past covariate            measures. Illustration of the software usage is
      included using real data.'
    pages:
    - 460
    - 473
    acknowledged: '2016-05-29'
    online: '2017-01-03'
    CRANpkgs:
    - survival
    - prodlim
    - condSURV
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - SocialSciences
  - slug: RJ-2016-060
    old_slug: tang-horikoshi-li
    title: 'ggfortify: Unified Interface to Visualize Statistical Results of Popular
      R Packages'
    bibtitle: |-
      ggfortify: Unified Interface to Visualize Statistical
                Results of Popular R Packages
    author:
    - Yuan Tang
    - Masaaki Horikoshi
    - Wenxuan Li
    bibauthor: Yuan Tang and Masaaki Horikoshi and Wenxuan Li
    landing: '2016'
    abstract: '  Abstract The ggfortify package provides a unified interface that
      enables users to use one line of code            to visualize statistical results
      of many R packages using ggplot2 idioms. With the help of ggfortify,            statisticians,
      data scientists, and researchers can avoid the sometimes repetitive work of
      using the            ggplot2 syntax to achieve what they need.'
    pages:
    - 474
    - 485
    acknowledged: '2016-05-29'
    online: '2016-09-10'
    CRANpkgs:
    - lattice
    - ggplot2
    - ggfortify
    - cluster
    - lfda
    - zoo
    - xts
    - timeSeries
    - forecast
    - changepoint
    - strucchange
    - dlm
    - dplyr
    - tidyr
    - gridExtra
    - scales
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - Environmetrics
    - Graphics
    - Multivariate
    - Bayesian
    - Cluster
    - Pharmacokinetics
    - Phylogenetics
    - SpatioTemporal
  - slug: RJ-2016-061
    old_slug: pebesma-mailund-hiebert
    title: Measurement Units in R
    bibtitle: Measurement Units in R
    author:
    - Edzer Pebesma
    - Thomas Mailund
    - James Hiebert
    bibauthor: Edzer Pebesma and Thomas Mailund and James Hiebert
    landing: '2016'
    abstract: ' Abstract We briefly review SI units, and discuss R packages that deal
      with measurement units,           their compatibility and conversion. Built
      upon udunits2 and the UNIDATA udunits library, we           introduce the package
      units that provides a class for maintaining unit metadata. When used in           expression,
      it automatically converts units, and simplifies units of results when possible;
      in case of           incompatible units, errors are raised. The class flexibly
      allows expansion beyond predefined units.           Using units may eliminate
      a whole class of potential scientific programming mistakes. We discuss           the
      potential and limitations of computing with explicit units.'
    pages:
    - 486
    - 494
    acknowledged: '2016-07-12'
    online: '2016-12-12'
    CRANpkgs:
    - lubridate
    - sp
    - measurements
    - NISTunits
    - udunits2
    - units
    - ggplot2
    - spacetime
    - h5
    - RNetCDF
    - sos4R
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Graphics
    - Phylogenetics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-062
    old_slug: imdadullah-aslam-altaf
    title: 'mctest: An R Package for Detection of Collinearity among Regressors'
    bibtitle: |-
      mctest: An R Package for Detection of Collinearity among
                Regressors
    author:
    - Muhammad Imdadullah
    - Muhammad Aslam
    - Saima Altaf
    bibauthor: Muhammad Imdadullah and Muhammad Aslam and Saima Altaf
    landing: '2016'
    abstract: '  Abstract It is common for linear regression models to be plagued
      with the problem of multicollinearity            when two or more regressors
      are highly correlated. This problem results in unstable estimates of            regression
      coefficients and causes some serious problems in validation and interpretation
      of the model.            Different diagnostic measures are used to detect multicollinearity
      among regressors. Many statistical            software and R packages provide
      few diagnostic measures for the judgment of multicollinearity. Most            widely
      used diagnostic measures in these software are: coefficient of determination
      (R2 ), variance            inflation factor/tolerance limit (VIF/TOL), eigenvalues,
      condition number (CN) and condition index            (CI) etc. In this manuscript,
      we present an R package, mctest, that computes popular and widely used            multicollinearity
      diagnostic measures. The package also indicates which regressors may be the
      reason            of collinearity among regressors.'
    pages:
    - 495
    - 505
    acknowledged: '2016-07-12'
    online: '2016-12-12'
    CRANpkgs:
    - mctest
    - perturb
    - HH
    - car
    - fmsb
    - rms
    - faraway
    - usdm
    - VIF
    - leaps
    - bestglm
    - glmulti
    - meifly
    CTV_rev:
    - SocialSciences
    - Econometrics
    - ChemPhys
    - ClinicalTrials
    - Finance
    - Multivariate
    - ReproducibleResearch
    - Survival
  - heading: News and Notes
  - title: R Foundation News
    author: by Torsten Hothorn
    slug: foundation
    bibauthor: by Torsten Hothorn
    pages:
    - 506
    - 506
  - title: Changes on CRAN
    author: by Kurt Hornik and Achim Zeileis
    slug: cran
    bibtitle: Changes on {CRAN}
    bibauthor: by Kurt Hornik and Achim Zeileis
    pages:
    - 507
    - 509
  - title: News from the Bioconductor Project
    author: by Bioconductor Core Team
    slug: bioc
    bibauthor: by Bioconductor Core Team
    pages:
    - 510
    - 510
  - title: Changes in R
    author: by the R Core Team
    slug: ch
    bibtitle: Changes in {R}
    bibauthor: by the R Core Team
    pages:
    - 511
    - 514

