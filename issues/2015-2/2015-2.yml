issue: 2015-2
year: 2015
volume: 7
num: 2
month: Dec.
bibmonth: dec
articles:
- title: Editorial
  author: Bettina Grün
  bibauthor: Bettina Gr{\" u}n
  slug: editorial
  pages: 4
- heading: Contributed Research Articles
- slug: RJ-2015-017
  old_slug: alam-ronnegard-shen
  title: Fitting Conditional and Simultaneous Autoregressive Spatial Models in hglm
  bibtitle: |-
    Fitting Conditional and Simultaneous Autoregressive Spatial
              Models in hglm
  author:
  - Moudud Alam
  - Lars Rönnegård
  - Xia Shen
  bibauthor: Moudud Alam and Lars Rönnegård and Xia Shen
  landing: '2015'
  abstract: '  Abstract We present a new version (> 2.0) of the hglm package for fitting
    hierarchical generalized            linear models (HGLMs) with spatially correlated
    random effects. CAR() and SAR() families for con           ditional and simultaneous
    autoregressive random effects were implemented. Eigen decomposition            of
    the matrix describing the spatial structure (e.g., the neighborhood matrix) was
    used to transform            the CAR/SAR random effects into an independent, but
    heteroscedastic, Gaussian random effect. A            linear predictor is fitted
    for the random effect variance to estimate the parameters in the CAR and SAR            models.
    This gives a computationally efficient algorithm for moderately sized problems.'
  pages:
  - 5
  - 18
  acknowledged: '2014-01-21'
  online: '2015-09-09'
  CRANpkgs:
  - hglm
  - spaMM
  - HGLMMM
  CTV_rev: Spatial
- slug: RJ-2015-018
  old_slug: genuer-poggi-tuleaumalot
  title: 'VSURF: An R Package for Variable Selection Using Random Forests'
  bibtitle: |-
    VSURF: An R Package for Variable Selection Using Random
              Forests
  author:
  - Robin Genuer
  - Jean-Michel Poggi
  - Christine Tuleau-Malot
  bibauthor: |-
    Robin Genuer and Jean-Michel Poggi and Christine Tuleau-
              Malot
  landing: '2015'
  abstract: '  Abstract This paper describes the R package VSURF. Based on random
    forests, and for both regression            and classification problems, it returns
    two subsets of variables. The first is a subset of important            variables
    including some redundancy which can be relevant for interpretation, and the second
    one            is a smaller subset corresponding to a model trying to avoid redundancy
    focusing more closely on            the prediction objective. The two-stage strategy
    is based on a preliminary ranking of the explanatory            variables using
    the random forests permutation-based score of importance and proceeds using a            stepwise
    forward strategy for variable introduction. The two proposals can be obtained
    automatically            using data-driven default values, good enough to provide
    interesting results, but strategy can also            be tuned by the user. The
    algorithm is illustrated on a simulated example and its applications to real            datasets
    are presented.'
  pages:
  - 19
  - 33
  acknowledged: '2014-07-28'
  online: '2015-11-08'
  CRANpkgs:
  - VSURF
  - rpart
  - randomForest
  - party
  - ipred
  - Boruta
  - varSelRF
  - spikeSlabGAM
  - BioMark
  - mlbench
  - mixOmics
  CTV_rev:
  - MachineLearning
  - Environmetrics
  - Survival
  - ChemPhys
  - Multivariate
  - Bayesian
  - HighPerformanceComputing
- slug: RJ-2015-019
  old_slug: liu-kong
  title: 'zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One
    Inflated Beta Regression'
  bibtitle: |-
    zoib: An R Package for Bayesian Inference for Beta
              Regression and Zero/One Inflated Beta Regression
  author:
  - Fang Liu
  - Yunchuan Kong
  bibauthor: Fang Liu and Yunchuan Kong
  landing: '2015'
  abstract: ' Abstract The beta distribution is a versatile function that accommodates
    a broad range of probability           distribution shapes. Beta regression based
    on the beta distribution can be used to model a response           variable y
    that takes values in open unit interval (0, 1). Zero/one inflated beta (ZOIB)
    regression           models can be applied when y takes values from closed unit
    interval [0, 1]. The ZOIB model is based a           piecewise distribution that
    accounts for the probability mass at 0 and 1, in addition to the probability           density
    within (0, 1). This paper introduces an R package – zoib that provides Bayesian
    inferences for           a class of ZOIB models. The statistical methodology underlying
    the zoib package is discussed, the           functions covered by the package
    are outlined, and the usage of the package is illustrated with three           examples
    of different data and model types. The package is comprehensive and versatile
    in that it           can model data with or without inflation at 0 or 1, accommodate
    clustered and correlated data via           latent variables, perform penalized
    regression as needed, and allow for model comparison via the           computation
    of the DIC criterion.'
  pages:
  - 34
  - 51
  acknowledged: '2014-08-16'
  online: '2015-07-18'
  CRANpkgs:
  - betareg
  - Bayesianbetareg
  - zoib
  - coda
  - rjags
  CTV_rev:
  - Bayesian
  - gR
  - Cluster
  - Econometrics
  - Psychometrics
  - SocialSciences
- slug: RJ-2015-020
  old_slug: nielsen
  title: 'apc: An R Package for Age-Period-Cohort Analysis'
  bibtitle: 'apc: An R Package for Age-Period-Cohort Analysis'
  author: Bent Nielsen
  bibauthor: Bent Nielsen
  landing: '2015'
  abstract: '  Abstract The apc package includes functions for age-period-cohort analysis
    based on the canonical            parametrisation of Kuang et al. (2008a). The
    package includes functions for organizing the data,            descriptive plots,
    a deviance table, estimation of (sub-models of) the age-period-cohort model, a
    plot            for specification testing, plots of estimated parameters, and
    sub-sample analysis.'
  pages:
  - 52
  - 64
  acknowledged: '2014-09-16'
  online: '2015-08-05'
  CRANpkgs:
  - apc
  - Epi
  CTV_rev: Survival
- slug: RJ-2015-021
  old_slug: charlier-paindaveine-saracco
  title: 'QuantifQuantile: An R Package for Performing Quantile Regression Through
    Optimal Quantization'
  bibtitle: |-
    QuantifQuantile: An R Package for Performing Quantile
              Regression Through Optimal Quantization
  author:
  - Isabelle Charlier
  - Davy Paindaveine
  - Jérôme Saracco
  bibauthor: Isabelle Charlier and Davy Paindaveine and Jérôme Saracco
  landing: '2015'
  abstract: '  Abstract In quantile regression, various quantiles of a response variable
    Y are modelled as func           tions of covariates (rather than its mean). An
    important application is the construction of reference            curves/surfaces
    and conditional prediction intervals for Y. Recently, a nonparametric quantile
    regres           sion method based on the concept of optimal quantization was
    proposed. This method competes very            well with k-nearest neighbor, kernel,
    and spline methods. In this paper, we describe an R package,            called
    QuantifQuantile, that allows to perform quantization-based quantile regression.
    We describe            the various functions of the package and provide examples.'
  pages:
  - 65
  - 80
  acknowledged: '2014-09-28'
  online: '2015-10-30'
  CRANpkgs:
  - quantreg
  - quantregGrowth
  - QuantifQuantile
  - rgl
  - quantregGrowth
  CTV_rev:
  - Environmetrics
  - Econometrics
  - Graphics
  - Multivariate
  - Optimization
  - ReproducibleResearch
  - Robust
  - SocialSciences
  - SpatioTemporal
  - Survival
- slug: RJ-2015-022
  old_slug: hankin
  title: Numerical Evaluation of the Gauss Hypergeometric Function with the hypergeo
    Package
  bibtitle: |-
    Numerical Evaluation of the Gauss Hypergeometric Function
              with the hypergeo Package
  author: Robin K. S. Hankin
  bibauthor: Robin K. S. Hankin
  landing: '2015'
  abstract: '  Abstract This paper introduces the hypergeo package of R routines for
    numerical calculation of            hypergeometric functions. The package is focussed
    on efficient and accurate evaluation of the Gauss            hypergeometric function
    over the whole of the complex plane within the constraints of fixed-precision            arithmetic.
    The hypergeometric series is convergent only within the unit circle, so analytic
    continuation            must be used to define the function outside the unit circle.
    This short document outlines the numerical            and conceptual methods used
    in the package; and justifies the package philosophy, which is to            maintain
    transparent and verifiable links between the software and Abramowitz and Stegun
    (1965).            Most of the package functionality is accessed via the single
    function hypergeo(), which dispatches to            one of several methods depending
    on the value of its arguments. The package is demonstrated in the            context
    of game theory.'
  pages:
  - 81
  - 88
  acknowledged: '2014-12-16'
  online: '2015-11-18'
  CRANpkgs:
  - gsl
  - appell
  - hypergeo
  CTV_rev:
  - NumericalMathematics
  - Optimization
- slug: RJ-2015-023
  old_slug: villacorta-saez
  title: 'SRCS: Statistical Ranking Color Scheme for Visualizing Parameterized Multiple
    Pairwise Comparisons with R'
  bibtitle: |-
    SRCS: Statistical Ranking Color Scheme for Visualizing
              Parameterized Multiple Pairwise Comparisons with R
  author:
  - Pablo J. Villacorta
  - José A. Sáez
  bibauthor: Pablo J. Villacorta and José A. Sáez
  landing: '2015'
  abstract: '  Abstract The problem of comparing a new solution method against existing
    ones to find statistically            significant differences arises very often
    in sciences and engineering. When the problem instance being            solved
    is defined by several parameters, assessing a number of methods with respect to
    many problem            configurations simultaneously becomes a hard task. Some
    visualization technique is required for            presenting a large number of
    statistical significance results in an easily interpretable way. Here we            review
    an existing color-based approach called Statistical Ranking Color Scheme (SRCS)
    for displaying            the results of multiple pairwise statistical comparisons
    between several methods assessed separately on            a number of problem
    configurations. We introduce an R package implementing SRCS, which performs            all
    the pairwise statistical tests from user data and generates customizable plots.
    We demonstrate            its applicability on two examples from the areas of
    dynamic optimization and machine learning, in            which several algorithms
    are compared on many problem instances, each defined by a combination of            parameters.'
  pages:
  - 89
  - 104
  acknowledged: '2015-01-02'
  online: '2015-07-29'
  CRANpkgs:
  - factorplot
  - SRCS
  - e1071
  - RWeka
  BIOpkgs: paircompviz
  CTV_rev:
  - MachineLearning
  - Cluster
  - Distributions
  - Environmetrics
  - Multivariate
  - NaturalLanguageProcessing
  - Psychometrics
- slug: RJ-2015-024
  old_slug: vegabayo
  title: 'An R Package for the Panel Approach Method for Program Evaluation: pampe'
  bibtitle: |-
    An R Package for the Panel Approach Method for Program
              Evaluation: pampe
  author: Ainhoa Vega-Bayo
  bibauthor: Ainhoa Vega-Bayo
  landing: '2015'
  abstract: '  Abstract The pampe package for R implements the panel data approach
    method for program evalua           tion designed to estimate the causal effects
    of political interventions or treatments. This procedure            exploits the
    dependence among cross-sectional units to construct a counterfactual of the treated
    unit(s),            and it is an appropriate method for research events that occur
    at an aggregate level like countries or            regions and that affect only
    one or a small number of units. The implementation of the pampe package            is
    illustrated using data from Hong Kong and 24 other units, by examining the economic
    impact of the            political and economic integration of Hong Kong with
    mainland China in 1997 and 2004 respectively.'
  pages:
  - 105
  - 121
  acknowledged: '2015-02-04'
  online: '2015-11-10'
  CRANpkgs:
  - pampe
  - leaps
  - xtable
  CTV_rev:
  - ChemPhys
  - Econometrics
  - ReproducibleResearch
  - SocialSciences
- slug: RJ-2015-025
  old_slug: lee-chen
  title: 'BSGS: Bayesian Sparse Group Selection'
  bibtitle: 'BSGS: Bayesian Sparse Group Selection'
  author:
  - Kuo-Jung Lee
  - Ray-Bing Chen
  bibauthor: Kuo-Jung Lee and Ray-Bing Chen
  landing: '2015'
  abstract: '  Abstract An R package BSGS is provided for the integration of Bayesian
    variable and sparse group            selection separately proposed by Chen et
    al. (2011) and Chen et al. (in press) for variable selection            problems,
    even in the cases of large p and small n. This package is designed for variable
    selection            problems including the identification of the important groups
    of variables and the active variables            within the important groups.
    This article introduces the functions in the BSGS package that can be            used
    to perform sparse group selection as well as variable selection through simulation
    studies and            real data.'
  pages:
  - 122
  - 133
  acknowledged: '2015-02-16'
  online: '2015-08-05'
  CRANpkgs: BSGS
- slug: RJ-2015-026
  old_slug: vigneau-chen-qannari
  title: 'ClustVarLV: An R Package for the Clustering of Variables Around Latent Variables'
  bibtitle: |-
    ClustVarLV: An R Package for the Clustering of Variables
              Around Latent Variables
  author:
  - Evelyne Vigneau
  - Mingkun Chen
  - El Mostafa Qannari
  bibauthor: Evelyne Vigneau and Mingkun Chen and El Mostafa Qannari
  landing: '2015'
  abstract: '  Abstract The clustering of variables is a strategy for deciphering
    the underlying structure of a data            set. Adopting an exploratory data
    analysis point of view, the Clustering of Variables around Latent            Variables
    (CLV) approach has been proposed by Vigneau and Qannari (2003). Based on a family
    of            optimization criteria, the CLV approach is adaptable to many situations.
    In particular, constraints may            be introduced in order to take account
    of additional information about the observations and/or the            variables.
    In this paper, the CLV method is depicted and the R package ClustVarLV including
    a set of            functions developed so far within this framework is introduced.
    Considering successively different            types of situations, the underlying
    CLV criteria are detailed and the various functions of the package            are
    illustrated using real case studies.'
  pages:
  - 134
  - 148
  acknowledged: '2015-03-04'
  online: '2015-10-23'
  CRANpkgs:
  - cluster
  - ClustVarLV
  - ClustOfVar
  - clere
  - biclust
  - pvclust
  - Hmisc
  - FactoMineR
  - plsgenomics
  - Rcpp
  - ClustVarLV
  CTV_rev:
  - Multivariate
  - Cluster
  - Psychometrics
  - Environmetrics
  - HighPerformanceComputing
  - Bayesian
  - ClinicalTrials
  - Econometrics
  - Graphics
  - NumericalMathematics
  - OfficialStatistics
  - ReproducibleResearch
  - SocialSciences
- slug: RJ-2015-027
  old_slug: charte-charte
  title: 'Working with Multilabel Datasets in R: The mldr Package'
  bibtitle: 'Working with Multilabel Datasets in R: The mldr Package'
  author:
  - Francisco Charte
  - David Charte
  bibauthor: Francisco Charte and David Charte
  landing: '2015'
  abstract: '  Abstract Most classification algorithms deal with datasets which have
    a set of input features, the            variables to be used as predictors, and
    only one output class, the variable to be predicted. However,            in late
    years many scenarios in which the classifier has to work with several outputs
    have come to            life. Automatic labeling of text documents, image annotation
    or protein classification are among            them. Multilabel datasets are the
    product of these new needs, and they have many specific traits.            The
    mldr package allows the user to load datasets of this kind, obtain their characteristics,
    produce            specialized plots, and manipulate them. The goal is to provide
    the exploratory tools needed to analyze            multilabel datasets, as well
    as the transformation and manipulation functions that will make possible            to
    apply binary and multiclass classification models to this data or the development
    of new multilabel            classifiers. Thanks to its integrated user interface,
    the exploratory functions will be available even to            non-specialized
    R users.'
  pages:
  - 149
  - 162
  acknowledged: '2015-03-09'
  online: '2015-09-16'
  CRANpkgs:
  - RWeka
  - mldr
  - shiny
  - Rcmdr
  - rattle
  - XML
  - circlize
  - devtools
  - pROC
  - shiny
  CTV_rev:
  - WebTechnologies
  - MachineLearning
  - Finance
  - NaturalLanguageProcessing
- slug: RJ-2015-028
  old_slug: valliant-dever-kreuter
  title: 'PracTools: Computations for Design of Finite Population Samples'
  bibtitle: |-
    PracTools: Computations for Design of Finite Population
              Samples
  author:
  - Richard Valliant
  - Jill A. Dever
  - Frauke Kreuter
  bibauthor: Richard Valliant and Jill A. Dever and Frauke Kreuter
  landing: '2015'
  abstract: '  Abstract PracTools is an R package with functions that compute sample
    sizes for various types of            finite population sampling designs when
    totals or means are estimated. One-, two-, and three-stage            designs
    are covered as well as allocations for stratified sampling and probability proportional
    to size            sampling. Sample allocations can be computed that minimize
    the variance of an estimator subject to a            budget constraint or that
    minimize cost subject to a precision constraint. The package also contains            some
    specialized functions for estimating variance components and design effects. Several
    finite            populations are included that are useful for classroom instruction.'
  pages:
  - 163
  - 176
  acknowledged: '2015-03-18'
  online: '2015-06-30'
  CRANpkgs:
  - pps
  - sampling
  - samplingbook
  - simFrame
  - survey
  - PracTools
  - stratification
  - alabama
  - Rsolnp
  - SamplingStrata
  CTV_rev:
  - OfficialStatistics
  - Optimization
  - SocialSciences
  - Survival
- slug: RJ-2015-029
  old_slug: seo-pan
  title: 'ALTopt: An R Package for Optimal Experimental Design of Accelerated Life
    Testing'
  bibtitle: |-
    ALTopt: An R Package for Optimal Experimental Design of
              Accelerated Life Testing
  author:
  - Kangwon Seo
  - Rong Pan
  bibauthor: Kangwon Seo and Rong Pan
  landing: '2015'
  abstract: '  Abstract The R package ALTopt has been developed with the aim of creating
    and evaluating optimal            experimental designs of censored accelerated
    life tests (ALTs). This package takes the generalized            linear model
    approach to ALT planning, because this approach can easily handle censoring plans
    and            derive information matrices for evaluating designs. Three types
    of optimality criteria are considered:            D-optimality for model parameter
    estimation, U-optimality for reliability prediction at a single use            condition,
    and I-optimality for reliability prediction over a region of use conditions. The
    Weibull            distribution is assumed for failure time data and more than
    one stress factor can be specified in the            package. Several graphical
    evaluation tools are also provided for the comparison of different ALT test            plans.'
  pages:
  - 177
  - 188
  acknowledged: '2015-03-18'
  online: '2015-09-29'
  CRANpkgs: ALTopt
  CTV_rev: ExperimentalDesign
- slug: RJ-2015-030
  old_slug: nunes-prangle
  title: 'abctools: An R Package for Tuning Approximate Bayesian Computation Analyses'
  bibtitle: |-
    abctools: An R Package for Tuning Approximate Bayesian
              Computation Analyses
  author:
  - Matthew A. Nunes
  - Dennis Prangle
  bibauthor: Matthew A. Nunes and Dennis Prangle
  landing: '2015'
  abstract: '  Abstract Approximate Bayesian computation (ABC) is a popular family
    of algorithms which perform            approximate parameter inference when numerical
    evaluation of the likelihood function is not possible            but data can
    be simulated from the model. They return a sample of parameter values which produce            simulations
    close to the observed dataset. A standard approach is to reduce the simulated
    and            observed datasets to vectors of summary statistics and accept when
    the difference between these is            below a specified threshold. ABC can
    also be adapted to perform model choice.                 In this article, we present
    a new software package for R, abctools which provides methods for            tuning
    ABC algorithms. This includes recent dimension reduction algorithms to tune the
    choice            of summary statistics, and coverage methods to tune the choice
    of threshold. We provide several            illustrations of these routines on
    applications taken from the ABC literature.'
  pages:
  - 189
  - 205
  acknowledged: '2015-03-25'
  online: '2015-07-29'
  CRANpkgs:
  - abctools
  - abc
  - easyABC
  - MASS
  CTV_rev:
  - Bayesian
  - Distributions
  - Econometrics
  - Environmetrics
  - Multivariate
  - NumericalMathematics
  - Pharmacokinetics
  - Psychometrics
  - Robust
  - SocialSciences
- slug: RJ-2015-031
  old_slug: wang-faivre-richard-etal
  title: 'mtk: A General-Purpose and Extensible R Environment for Uncertainty and
    Sensitivity Analyses of Numerical Experiments'
  bibtitle: |-
    mtk: A General-Purpose and Extensible R Environment
              for Uncertainty and Sensitivity Analyses of Numerical
              Experiments
  author:
  - Juhui Wang
  - Robert Faivre
  - Hervé Richard
  - Hervé Monod
  bibauthor: |-
    Juhui Wang and Robert Faivre and Hervé Richard and Hervé
              Monod
  landing: '2015'
  abstract: '  Abstract Along with increased complexity of the models used for scientific
    activities and engineering            come diverse and greater uncertainties.
    Today, effectively quantifying the uncertainties contained            in a model
    appears to be more important than ever. Scientific fellows know how serious it
    is to            calibrate their model in a robust way, and decision-makers describe
    how critical it is to keep the best            effort to reduce the uncertainties
    about the model. Effectively accessing the uncertainties about the            model
    requires mastering all the tasks involved in the numerical experiments, from optimizing
    the            experimental design to managing the very time consuming aspect
    of model simulation and choosing            the adequate indicators and analysis
    methods.                 In this paper, we present an open framework for organizing
    the complexity associated with            numerical model simulation and analyses.
    Named mtk (Mexico Toolkit), the developed system aims            at providing
    practitioners from different disciplines with a systematic and easy way to compare
    and            to find the best method to effectively uncover and quantify the
    uncertainties contained in the model            and further to evaluate their
    impact on the performance of the model. Such requirements imply that            the
    system must be generic, universal, homogeneous, and extensible. This paper discusses
    such an            implementation using the R scientific computing platform and
    demonstrates its functionalities with            examples from agricultural modeling.                 The
    package mtk is of general purpose and easy to extend. Numerous methods are already            available
    in the actual release version, including Fast, Sobol, Morris, Basic Monte-Carlo,
    Regression,            LHS (Latin Hypercube Sampling), PLMM (Polynomial Linear
    metamodel). Most of them are compiled            from available R packages with
    extension tools delivered by package mtk.'
  pages:
  - 206
  - 226
  acknowledged: '2015-03-30'
  online: '2015-10-01'
  CRANpkgs:
  - sensitivity
  - spartan
  - diceDesign
  - planor
  - mtk
  - ff
  CTV_rev:
  - Environmetrics
  - ExperimentalDesign
  - HighPerformanceComputing
- slug: RJ-2015-032
  old_slug: buttrey-whitaker
  title: 'treeClust: An R Package for Tree-Based Clustering Dissimilarities'
  bibtitle: |-
    treeClust: An R Package for Tree-Based Clustering
              Dissimilarities
  author:
  - Samuel E. Buttrey
  - Lyn R. Whitaker
  bibauthor: Samuel E. Buttrey and Lyn R. Whitaker
  landing: '2015'
  abstract: '  Abstract This paper describes treeClust, an R package that produces
    dissimilarities useful for cluster           ing. These dissimilarities arise
    from a set of classification or regression trees, one with each variable in            the
    data acting in turn as a the response, and all others as predictors. This use
    of trees produces dissim           ilarities that are insensitive to scaling,
    benefit from automatic variable selection, and appear to perform            well.
    The software allows a number of options to be set, affecting the set of objects
    returned in the call;            the user can also specify a clustering algorithm
    and, optionally, return only the clustering vector. The            package can
    also generate a numeric data set whose inter-point distances relate to the treeClust
    ones;            such a numeric data set can be much smaller than the vector of
    inter-point dissimilarities, a useful            feature in big data sets.'
  pages:
  - 227
  - 236
  acknowledged: '2015-04-07'
  online: '2015-09-16'
  CRANpkgs:
  - treeClust
  - cluster
  - rpart
  - tree
  CTV_rev:
  - Cluster
  - Environmetrics
  - MachineLearning
  - Multivariate
  - Survival
- slug: RJ-2015-033
  old_slug: hino-takano-murata
  title: 'mmpp: A Package for Calculating Similarity and Distance Metrics for Simple
    and Marked Temporal Point Processes'
  bibtitle: |-
    mmpp: A Package for Calculating Similarity and Distance
              Metrics for Simple and Marked Temporal Point Processes
  author:
  - Hideitsu Hino
  - Ken Takano
  - Noboru Murata
  bibauthor: Hideitsu Hino and Ken Takano and Noboru Murata
  landing: '2015'
  abstract: '  Abstract A simple temporal point process (SPP) is an important class
    of time series, where the sample            realization of the process is solely
    composed of the times at which events occur. Particular examples            of
    point process data are neuronal spike patterns or spike trains, and a large number
    of distance and            similarity metrics for those data have been proposed.
    A marked point process (MPP) is an extension            of a simple temporal point
    process, in which a certain vector valued mark is associated with each of            the
    temporal points in the SPP. Analyses of MPPs are of practical importance because
    instances of            MPPs include recordings of natural disasters such as earthquakes
    and tornadoes. In this paper, we            introduce the R package mmpp, which
    implements a number of distance and similarity metrics for            SPPs, and
    also extends those metrics for dealing with MPPs.'
  pages:
  - 237
  - 248
  acknowledged: '2015-04-17'
  online: '2015-09-29'
  CRANpkgs:
  - splancs
  - spatstat
  - PtProcess
  - stpp
  - mmpp
  - SAPP
  - etasFLP
  CTV_rev:
  - SpatioTemporal
  - Spatial
  - Survival
- slug: RJ-2015-034
  old_slug: koohafkan-younis
  title: Open-Channel Computation with R
  bibtitle: Open-Channel Computation with R
  author:
  - Michael C. Koohafkan
  - Bassam A. Younis
  bibauthor: Michael C. Koohafkan and Bassam A. Younis
  landing: '2015'
  abstract: '  Abstract The rivr package provides a computational toolset for simulating
    steady and unsteady one           dimensional flows in open channels. It is designed
    primarily for use by instructors of undergraduate           and graduate-level
    open-channel hydrodynamics courses in such diverse fields as river engineering,            physical
    geography and geophysics. The governing equations used to describe open-channel
    flows            are briefly presented, followed by example applications. These
    include the computation of gradually           varied flows and two examples of
    unsteady flows in channels—namely, the tracking of the evolution            of
    a flood wave in a channel and the prediction of extreme variation in the water-surface
    profile            that results when a sluice gate is abruptly closed. Model results
    for the unsteady flow examples            are validated against standard benchmarks.
    The article concludes with a discussion of potential            modifications
    and extensions to the package.'
  pages:
  - 249
  - 262
  acknowledged: '2015-04-19'
  online: '2015-11-28'
  CRANpkgs:
  - rivr
  - knitr
  - shiny
  - Rcpp
  CTV_rev:
  - HighPerformanceComputing
  - NumericalMathematics
  - ReproducibleResearch
  - WebTechnologies
- slug: RJ-2015-035
  old_slug: morina-higueras-puig-etal
  title: Generalized Hermite Distribution Modelling with the R Package hermite
  bibtitle: |-
    Generalized Hermite Distribution Modelling with the R
              Package hermite
  author:
  - David Moriña
  - Manuel Higueras
  - Pedro Puig
  - María Oliveira
  bibauthor: |-
    David Moriña and Manuel Higueras and Pedro Puig and María
              Oliveira
  landing: '2015'
  abstract: '  Abstract The Generalized Hermite distribution (and the Hermite distribution
    as a particular case) is            often used for fitting count data in the presence
    of overdispersion or multimodality. Despite this, to            our knowledge,
    no standard software packages have implemented specific functions to compute basic            probabilities
    and make simple statistical inference based on these distributions. We present
    here a set            of computational tools that allows the user to face these
    difficulties by modelling with the Generalized            Hermite distribution
    using the R package hermite. The package can also be used to generate random            deviates
    from a Generalized Hermite distribution and to use basic functions to compute
    probabilities            (density, cumulative density and quantile functions are
    available), to estimate parameters using the            maximum likelihood method
    and to perform the likelihood ratio test for Poisson assumption against a            Generalized
    Hermite alternative. In order to improve the density and quantile functions performance            when
    the parameters are large, Edgeworth and Cornish-Fisher expansions have been used.
    Hermite            regression is also a useful tool for modeling inflated count
    data, so its inclusion to a commonly used            software like R will make
    this tool available to a wide range of potential users. Some examples of            usage
    in several fields of application are also given.'
  pages:
  - 263
  - 274
  acknowledged: '2015-04-27'
  online: '2015-12-10'
  CRANpkgs:
  - maxLik
  - radir
  CTV_rev: Optimization
- slug: RJ-2015-036
  old_slug: rubio-villar
  title: 'Code Profiling in R: A Review of Existing Methods and an Introduction to
    Package GUIProfiler'
  bibtitle: |-
    Code Profiling in R: A Review of Existing Methods and an
              Introduction to Package GUIProfiler
  author:
  - Angel Rubio
  - Fernando de Villar
  bibauthor: Angel Rubio and Fernando de Villar
  landing: '2015'
  abstract: '  Abstract Code analysis tools are crucial to understand program behavior.
    Profile tools use the results            of time measurements in the execution
    of a program to gain this understanding and thus help in the            optimization
    of the code. In this paper, we review the different available packages to profile
    R code            and show the advantages and disadvantages of each of them. In
    additon, we present GUIProfiler, a            package that fulfills some unmet
    needs.                 Package GUIProfiler generates an HTML report with the timing
    for each code line and the            relationships between different functions.
    This package mimics the behavior of the MATLAB profiler.            The HTML report
    includes information on the time spent on each of the lines of the profiled code            (the
    slowest code is highlighted). If the package is used within the RStudio environment,
    the user            can navigate across the bottlenecks in the code and open the
    editor to modify the lines of code where            more time is spent. It is
    also possible to edit the code using Notepad++ (a free editor for Windows) by            simply
    clicking on the corresponding line. The graphical user interface makes it easy
    to identify the            specific lines which slow down the code.                 The
    integration in RStudio and the generation of an HTML report makes GUIProfiler
    a very            convenient tool to perform code optimization.'
  pages:
  - 275
  - 287
  acknowledged: '2015-05-04'
  online: '2015-11-18'
  CRANpkgs:
  - aprof
  - proftools
  - profr
  - microbenchmark
  - Nozzle.R1
  - knitr
  - GUIProfiler
  - stringr
  - plyr
  - devtools
  - shiny
  BIOpkgs:
  - Rgraphviz
  - graph
  CTV_rev:
  - HighPerformanceComputing
  - ReproducibleResearch
  - WebTechnologies
- heading: News and Notes
- title: The R Consortium and the R Foundation
  bibtitle: The {R} Consortium and the {R} Foundation
  slug: plummer
  author: Martyn Plummer
  pages: 288
- title: 'Conference Report: useR! 2015'
  bibtitle: 'Conference Report: {useR!} 2015'
  slug: tvedebrink
  author: Torben Tvedebrink
  pages:
  - 289
  - 290
- title: News from the Bioconductor Project
  bibtitle: News from the {B}ioconductor Project
  author: The Bioconductor Team
  slug: bioconductor
  pages:
  - 291
  - 292
- title: Changes in R
  bibtitle: Changes in {R}
  author: The R Core Team
  slug: r-changes
  pages:
  - 293
  - 297
- title: Changes on CRAN
  bibtitle: Changes on {CRAN}
  author:
  - Kurt Hornik
  - Achim Zeileis
  slug: cran
  pages:
  - 298
  - 339
