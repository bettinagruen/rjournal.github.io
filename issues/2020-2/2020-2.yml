issue: 2020-2
year: 2020
volume: 12
num: 2
month: Dec.
bibmonth: dec
articles:
- slug: editorial
  cat: Editorial
  author: Michael J. Kane
  title: Editorial
  bibtitle: Editorial
  bibauthor: Michael J. Kane
  pages:
  - '4'
  - '5'
- heading: Contributed Research Articles
- slug: RJ-2021-001
  title: 'The biglasso Package: A Memory- and Computation-Efficient Solver for Lasso
    Model Fitting with Big Data in R'
  bibtitle: |-
    The biglasso Package: A Memory- and Computation-Efficient
              Solver for Lasso Model Fitting with Big Data in R
  author:
  - Yaohui Zeng
  - Patrick Breheny
  bibauthor: Yaohui Zeng and Patrick Breheny
  abstract: '  Abstract Penalized regression models such as the lasso have been extensively
    applied to analyzing            high-dimensional data sets. However, due to memory
    limitations, existing R packages like glmnet            and ncvreg are not capable
    of fitting lasso-type models for ultrahigh-dimensional, multi-gigabyte            data
    sets that are increasingly seen in many areas such as genetics, genomics, biomedical
    imaging,            and high-frequency finance. In this research, we implement
    an R package called biglasso that tackles            this challenge. biglasso
    utilizes memory-mapped files to store the massive data on the disk, only            reading
    data into memory when necessary during model fitting, and is thus able to handle
    out-of           core computation seamlessly. Moreover, it’s equipped with newly
    proposed, more efficient feature            screening rules, which substantially
    accelerate the computation. Benchmarking experiments show            that our
    biglasso package, as compared to existing popular ones like glmnet, is much more
    memory           and computation-efficient. We further analyze a 36 GB simulated
    GWAS data set on a laptop with only            16 GB RAM to demonstrate the out-of-core
    computation capability of biglasso in analyzing massive            data sets that
    cannot be accommodated by existing R packages.'
  acknowledged: '2018-12-07'
  online: '2021-01-14'
  CRANpkgs:
  - glmnet
  - ncvreg
  - biglasso
  - picasso
  - bigmemory
  - parallel
  CTV_rev:
  - MachineLearning
  - HighPerformanceComputing
  - Survival
  suppl: 418 bytes
  landing: '2021'
  pages:
  - '6'
  - '19'
- slug: RJ-2021-002
  title: Comparing Multiple Survival Functions with Crossing Hazards in R
  bibtitle: |-
    Comparing Multiple Survival Functions with Crossing Hazards
              in R
  author:
  - Hsin-wen Chang
  - Pei-Yuan Tsai
  - Jen-Tse Kao
  - Guo-You Lan
  bibauthor: |-
    Hsin-wen Chang and Pei-Yuan Tsai and Jen-Tse Kao and Guo-You
              Lan
  abstract: ' Abstract It is frequently of interest in time-to-event analysis to compare
    multiple survival functions           nonparametrically. However, when the hazard
    functions cross, tests in existing R packages do not           perform well. To
    address the issue, we introduce the package survELtest, which provides tests for           comparing
    multiple survival functions with possibly crossing hazards. Due to its powerful
    likelihood           ratio formulation, this is the only R package to date that
    works when the hazard functions cross. We           illustrate the use of the
    procedures in survELtest by applying them to data from randomized clinical           trials
    and simulated datasets. We show that these methods lead to more significant results
    than those           obtained by existing R packages.'
  acknowledged: '2019-07-01'
  online: '2021-01-14'
  CRANpkgs:
  - survival
  - YPmodel
  - survRM2
  - survELtest
  - emplik
  - emplik2
  - ELYP
  - FHtest
  - clinfun
  - LogrankA
  - coin
  - maxstat
  - boot
  - muhaz
  CTVs: Survival
  CTV_rev:
  - Survival
  - ClinicalTrials
  - Econometrics
  - SocialSciences
  - Optimization
  - TimeSeries
  suppl: unknown
  landing: '2021'
  pages:
  - '20'
  - '42'
- slug: RJ-2021-003
  title: 'A Unified Algorithm for the Non-Convex Penalized Estimation: The ncpen Package'
  bibtitle: |-
    A Unified Algorithm for the Non-Convex Penalized Estimation:
              The ncpen Package
  author:
  - Dongshin Kim
  - Sangin Lee
  - Sunghoon Kwon
  bibauthor: Dongshin Kim and Sangin Lee and Sunghoon Kwon
  abstract: '  Abstract Various R packages have been developed for the non-convex
    penalized estimation but they            can only be applied to the smoothly clipped
    absolute deviation (SCAD) or minimax concave penalty            (MCP). We develop
    an R package, entitled ncpen, for the non-convex penalized estimation in order            to
    make data analysts to experience other non-convex penalties. The package ncpen
    implements a            unified algorithm based on the convex concave procedure
    and modified local quadratic approximation            algorithm, which can be
    applied to a broader range of non-convex penalties, including the SCAD and            MCP
    as special examples. Many user-friendly functionalities such as generalized information
    criteria,            cross-validation and ridge regularization are provided also.'
  acknowledged: '2019-02-25'
  online: '2021-01-14'
  CRANpkgs:
  - lars
  - glmpath
  - glmnet
  - plus
  - sparsenet
  - cvplogit
  - ncvreg
  - ncpen
  - spls
  - Rcpp
  CTV_rev:
  - MachineLearning
  - Survival
  - ChemPhys
  - HighPerformanceComputing
  - NumericalMathematics
  suppl: 4 Kb
  landing: '2021'
  pages:
  - '43'
  - '60'
- slug: RJ-2021-025
  title: 'TULIP: A Toolbox for Linear Discriminant Analysis with Penalties'
  bibtitle: |-
    TULIP: A Toolbox for Linear Discriminant Analysis with
              Penalties
  author:
  - Yuqing Pan
  - Qing Mai
  - Xin Zhang
  bibauthor: Yuqing Pan and Qing Mai and Xin Zhang
  abstract: '  Abstract Linear discriminant analysis (LDA) is a powerful tool in building
    classifiers with easy            computation and interpretation. Recent advancements
    in science technology have led to the popularity            of datasets with high
    dimensions, high orders and complicated structure. Such datasetes motivate the            generalization
    of LDA in various research directions. The R package TULIP integrates several
    popular            high-dimensional LDA-based methods and provides a comprehensive
    and user-friendly toolbox for            linear, semi-parametric and tensor-variate
    classification. Functions are included for model fitting, cross            validation
    and prediction. In addition, motivated by datasets with diverse sources of predictors,
    we            further include functions for covariate adjustment. Our package
    is carefully tailored for low storage            and high computation efficiency.
    Moreover, our package is the first R package for many of these            methods,
    providing great convenience to researchers in this area.'
  acknowledged: '2020-05-06'
  online: '2021-01-20'
  CRANpkgs:
  - TULIP
  - msda
  - sparseLDA
  - MASS
  - Matrix
  - tensr
  - glmnet
  CTV_rev:
  - Econometrics
  - Multivariate
  - NumericalMathematics
  - Distributions
  - Environmetrics
  - MachineLearning
  - Psychometrics
  - Robust
  - SocialSciences
  - Survival
  - TeachingStatistics
  suppl: 4.4 Kb
  landing: '2021'
  pages:
  - '61'
  - '81'
- slug: RJ-2021-005
  title: fitzRoy - An R Package to Encourage Reproducible Sports Analysis
  bibtitle: |-
    fitzRoy - An R Package to Encourage Reproducible Sports
              Analysis
  author:
  - Robert Nguyen
  - James Day
  - David Warton
  - Oscar Lane
  bibauthor: Robert Nguyen and James Day and David Warton and Oscar Lane
  abstract: '  Abstract The importance of reproducibility, and the related issue of
    open access to data, has received            a lot of recent attention. Momentum
    on these issues is gathering in the sports analytics community.            While
    Australian Rules football (AFL) is the leading commercial sport in Australia,
    unlike popular            international sports, there has been no mechanism for
    the public to access comprehensive statistics            on players and teams.
    Expert commentary currently relies heavily on data that isn’t made readily            accessible
    and this produces an unnecessary barrier for the development of an inclusive sports
    analytics            community. We present the R package fitzRoy to provide easy
    access to AFL statistics.'
  acknowledged: '2019-07-02'
  online: '2021-01-14'
  CRANpkgs:
  - fitzRoy
  - Rvest
  - dplyr
  - purrr
  - XML
  CTV_rev:
  - Databases
  - ModelDeployment
  - WebTechnologies
  suppl: unknown
  landing: '2021'
  pages:
  - '82'
  - '106'
- slug: RJ-2021-006
  title: Assembling Pharmacometric Datasets in R - The puzzle Package
  bibtitle: Assembling Pharmacometric Datasets in R - The puzzle Package
  author:
  - Mario González-Sales
  - Olivier Barrière
  - Pierre Olivier Tremblay
  - Guillaume Bonnefois
  - Julie            Desrochers
  - Fahima Nekka
  bibauthor: |-
    Mario González-Sales and Olivier Barrière and Pierre
              Olivier Tremblay and Guillaume Bonnefois and Julie
              Desrochers and Fahima Nekka
  abstract: '  Abstract                Pharmacometric analyses are integral components
    of the drug development process. The core of            each pharmacometric analysis
    is a dataset. The time required to construct a pharmacometrics dataset            can
    sometimes be higher than the effort required for the modeling per se. To simplify
    the process, the            puzzle R package has been developed aimed at simplifying
    and facilitating the time consuming and            error prone task of assembling
    pharmacometrics datasets.                Puzzle consist of a series of functions
    written in R. These functions create, from tabulated files,            datasets
    that are compatible with the formatting requirements of the gold standard non-linear
    mixed            effects modeling software.                With only one function,
    puzzle(), complex pharmacometrics databases can easily be assembled.            Users
    are able to select from different absorption processes such as zeroand first-order,
    or a com           bination of both. Furthermore, datasets containing data from
    one or more analytes, and/or one or            more responses, and/or time dependent
    and/or independent covariates, and/or urine data can be            simultaneously
    assembled.                The puzzle package is a powerful and efficient tool
    that helps modelers, programmers and            pharmacometricians through the
    challenging process of assembling pharmacometrics datasets.'
  acknowledged: '2019-07-19'
  online: '2021-01-14'
  CRANpkgs:
  - puzzle
  - saemix
  - nlmixr
  - tidyverse
  suppl: 448.3 Kb
  landing: '2021'
  pages:
  - '107'
  - '119'
- slug: RJ-2021-007
  title: 'RNGforGPD: An R Package for Generation of Univariate and Multivariate Generalized
    Poisson Data'
  bibtitle: |-
    RNGforGPD: An R Package for Generation of Univariate and
              Multivariate Generalized Poisson Data
  author:
  - Hesen Li
  - Hakan Demirtas
  - Ruizhe Chen
  bibauthor: Hesen Li and Hakan Demirtas and Ruizhe Chen
  abstract: '  Abstract This article describes the R package RNGforGPD, which is designed
    for the generation of            univariate and multivariate generalized Poisson
    data. Some illustrative examples are given, the utility            and functionality
    of the package are demonstrated; and its performance is assessed via simulations            that
    are devised around both artificial and real data.'
  acknowledged: '2019-07-26'
  online: '2021-01-14'
  CRANpkgs:
  - RNGforGPD
  - mvtnorm
  - corpcor
  - Matrix
  - ggplot2
  - robustbase
  - MixAll
  CTV_rev:
  - Multivariate
  - Cluster
  - Distributions
  - Econometrics
  - Finance
  - Graphics
  - NumericalMathematics
  - Phylogenetics
  - Robust
  - TeachingStatistics
  suppl: 7 Kb
  landing: '2021'
  pages:
  - '120'
  - '133'
- slug: RJ-2021-008
  title: Testing the equality of normal distributed and independent groups' means
    under unequal variances by doex package
  bibtitle: |-
    Testing the equality of normal distributed and independent
              groups' means under unequal variances by doex
              package
  author:
  - Mustafa Cavus
  - Berna Yazıcı
  bibauthor: Mustafa Cavus and Berna Yazıcı
  abstract: '  Abstract In this paper, we present the doex package contains the tests
    for equality of normal dis           tributed and independent group means under
    unequal variances such as Cochran F, Welch-Aspin,            Welch, Box, Scott-Smith,
    Brown-Forsythe, Johansen F, Approximate F, Alexander-Govern, Generalized            F,
    Modified Brown-Forsythe, Permutation F, Adjusted Welch, B2, Parametric Bootstrap,
    Fiducial            Approach, and Alvandi Generalized F-test. Most of these tests
    are not available in any package. Thus,            doex is easy to use for researchers
    in multidisciplinary studies. In this study, an extensive Monte-Carlo            simulation
    study is conducted to investigate the performance of the the tests for equality
    of normal            distributed group means under unequal variances in terms
    of Type I error probability and penalized            power. In the case of Type
    I error probability of the compared tests are different, the penalized power            is
    used which allows fair power comparisons. In this way, we conclude the performance
    of the tests by            taking into account two possible errors in hypothesis
    testing.'
  acknowledged: '2019-07-31'
  online: '2021-01-14'
  CRANpkgs:
  - doex
  - asbio
  - coin
  - lawstat
  - onewaytests
  - welchADF
  - WRS2
  - car
  - rstatix
  - inferr
  CTV_rev:
  - Survival
  - ClinicalTrials
  - Econometrics
  - Finance
  - Multivariate
  - Robust
  - SocialSciences
  - TeachingStatistics
  suppl: unknown
  landing: '2021'
  pages:
  - '134'
  - '154'
- slug: RJ-2021-004
  title: Six Years of Shiny in Research - Collaborative Development of Web Tools in
    R
  bibtitle: |-
    Six Years of Shiny in Research - Collaborative Development
              of Web Tools in R
  author:
  - Peter Kasprzak
  - Lachlan Mitchell
  - Olena Kravchuk
  - Andy Timmins
  bibauthor: |-
    Peter Kasprzak and Lachlan Mitchell and Olena Kravchuk and
              Andy Timmins
  abstract: Abstract The use of Shiny in research publications is investigated over
    the six and          a half years since the appearance of this popular web application
    framework for R,          which has been utilised in many varied research areas.
    While it is demonstrated          that the complexity of Shiny applications is
    limited by the background architecture,          and real security concerns exist
    for novice app developers, the collaborative benefits          are worth attention
    from the wider research community. Shiny simplifies the          use of complex
    methodologies for people of different specialities, at the level of          proficiency
    appropriate for the end user. This enables a diverse community of users          to
    interact efficiently, and utilise cutting edge methodologies. The literature reviewed          demonstrates
    that complex methodologies can be put into practice without insisting          on
    investment in professional training, for a comprehensive understanding from all          participants.
    It appears that Shiny opens up concurrent benefits in communication          between
    those who analyse data and other disciplines, that would enrich much of          the
    peer-reviewed research.
  acknowledged: '2019-10-20'
  online: '2021-01-14'
  CRANpkgs:
  - Shiny
  - ggplot2
  - Reactlog
  - ShinyTester
  - rHyperSpec
  - ShinyStan
  CTV_rev:
  - Graphics
  - Phylogenetics
  - TeachingStatistics
  landing: '2021'
  pages:
  - '155'
  - '162'
- slug: RJ-2021-010
  title: A Fast and Scalable Implementation Method for Competing Risks Data with the
    R Package fastcmprsk
  bibtitle: |-
    A Fast and Scalable Implementation Method for Competing
              Risks Data with the R Package fastcmprsk
  author:
  - Eric S. Kawaguchi
  - Jenny I. Shen
  - Gang Li
  - Marc A. Suchard
  bibauthor: |-
    Eric S. Kawaguchi and Jenny I. Shen and Gang Li and Marc A.
              Suchard
  abstract: '  Abstract Advancements in medical informatics tools and high-throughput
    biological experimentation            make large-scale biomedical data routinely
    accessible to researchers. Competing risks data are typical            in biomedical
    studies where individuals are at risk to more than one cause (type of event) which
    can            preclude the others from happening. The Fine and Gray (1999) proportional
    subdistribution hazards            model is a popular and well-appreciated model
    for competing risks data and is currently implemented            in a number of
    statistical software packages. However, current implementations are not computation           ally
    scalable for large-scale competing risks data. We have developed an R package,
    fastcmprsk, that            uses a novel forward-backward scan algorithm to significantly
    reduce the computational complexity            for parameter estimation by exploiting
    the structure of the subject-specific risk sets. Numerical studies            compare
    the speed and scalability of our implementation to current methods for unpenalized
    and            penalized Fine-Gray regression and show impressive gains in computational
    efficiency.'
  acknowledged: '2020-01-16'
  online: '2021-01-14'
  CRANpkgs:
  - fastcmprsk
  - cmprsk
  - riskRegression
  - timereg
  - survival
  - crrSC
  - crrstep
  - crrp
  - glmnet
  - ncvreg
  - Cyclops
  - doParallel
  CTV_rev:
  - Survival
  - MachineLearning
  - ClinicalTrials
  - Econometrics
  - SocialSciences
  suppl: 1.4 Kb
  landing: '2021'
  pages:
  - '163'
  - '172'
- slug: RJ-2021-011
  title: 'ordinalClust: An R Package to Analyze Ordinal Data'
  bibtitle: 'ordinalClust: An R Package to Analyze Ordinal Data'
  author:
  - Margot Selosse
  - Julien Jacques
  - Christophe Biernacki
  bibauthor: Margot Selosse and Julien Jacques and Christophe Biernacki
  abstract: '  Abstract Ordinal data are used in many domains, especially when measurements
    are collected            from people through observations, tests, or questionnaires.
    ordinalClust is an innovative R package            dedicated to ordinal data that
    provides tools for modeling, clustering, co-clustering and classifying            such
    data. Ordinal data are modeled using the BOS distribution, which is a model with
    two meaningful            parameters referred to as "position" and "precision".
    The former indicates the mode of the distribution            and the latter describes
    how scattered the data are around the mode: the user is able to easily interpret            the
    distribution of their data when given these two parameters. The package is based
    on the co           clustering framework (when rows and columns are simultaneously
    clustered). The co-clustering            approach uses the Latent Block Model
    (LBM) and the SEM-Gibbs algorithm for parameter inference.            On the other
    hand, the clustering and the classification methods follow on from simplified
    versions            of the SEM-Gibbs algorithm. For the classification process,
    two approaches are proposed. In the            first one, the BOS parameters are
    estimated from the training dataset in the conventional way. In the            second
    approach, parsimony is introduced by estimating the parameters and column-clusters
    from the            training dataset. We empirically show that this approach can
    yield better results. For the clustering            and co-clustering processes,
    the ICL-BIC criterion is used for model selection purposes. An overview            of
    these methods is given, and the way to use them with the ordinalClust package
    is described using            real datasets. The latest stable package version
    is available on the Comprehensive R Archive Network            (CRAN).'
  acknowledged: '2019-09-27'
  online: '2021-01-14'
  CRANpkgs:
  - ordinalClust
  - MASS
  - VGAM
  - rms
  - brms
  - ordinal
  - ordinalForest
  - monmlp
  - ocapis
  - clustMD
  - ordinalLBM
  - CUB
  - mclust
  CTV_rev:
  - Econometrics
  - Distributions
  - Environmetrics
  - Multivariate
  - Psychometrics
  - SocialSciences
  - Survival
  - Bayesian
  - Cluster
  - ExtremeValue
  - NumericalMathematics
  - Phylogenetics
  - ReproducibleResearch
  - Robust
  - TeachingStatistics
  suppl: 1.5 Kb
  landing: '2021'
  pages:
  - '173'
  - '188'
- slug: RJ-2021-012
  title: 'KSPM: A Package For Kernel Semi-Parametric Models'
  bibtitle: 'KSPM: A Package For Kernel Semi-Parametric Models'
  author:
  - Catherine Schramm
  - Sébastien Jacquemont
  - Karim Oualkacha
  - Aurélie Labbe
  - Celia M.T.            Greenwood
  bibauthor: |-
    Catherine Schramm and Sébastien Jacquemont and Karim
              Oualkacha and Aurélie Labbe and Celia M.T.
              Greenwood
  abstract: '  Abstract Kernel semi-parametric models and their equivalence with linear
    mixed models provide            analysts with the flexibility of machine learning
    methods and a foundation for inference and tests of            hypothesis. These
    models are not impacted by the number of predictor variables, since the kernel            trick
    transforms them to a kernel matrix whose size only depends on the number of subjects.
    Hence,            methods based on this model are appealing and numerous, however
    only a few R programs are            available and none includes a complete set
    of features. Here, we present the KSPM package to fit            the kernel semi-parametric
    model and its extensions in a unified framework. KSPM allows multiple            kernels
    and unlimited interactions in the same model. It also includes predictions, statistical
    tests,            variable selection procedure and graphical tools for diagnostics
    and interpretation of variable effects.            Currently KSPM is implemented
    for continuous dependent variables but could be extended to binary            or
    survival outcomes.'
  acknowledged: '2020-05-31'
  online: '2021-01-14'
  CRANpkgs:
  - KSPM
  - coxme
  - SKAT
  - KRLS
  - e1071
  - SPA3G
  - np
  - mgcv
  - lme4
  - nlme
  - DEoptim
  - adegenet
  - CompQuadForm
  CTV_rev:
  - Econometrics
  - Environmetrics
  - SocialSciences
  - Psychometrics
  - Bayesian
  - Distributions
  - OfficialStatistics
  - SpatioTemporal
  - ChemPhys
  - Cluster
  - Finance
  - Genetics
  - MachineLearning
  - Multivariate
  - Optimization
  - Spatial
  - Survival
  suppl: 20.3 Kb
  landing: '2021'
  pages:
  - '189'
  - '208'
- slug: RJ-2021-013
  title: 'AQuadtree: an R Package for Quadtree Anonymization of Point Data'
  bibtitle: |-
    AQuadtree: an R Package for Quadtree Anonymization of Point
              Data
  author:
  - Raymond Lagonigro
  - Ramon Oller
  - Joan Carles Martori
  bibauthor: Raymond Lagonigro and Ramon Oller and Joan Carles Martori
  abstract: ' Abstract The demand for precise data for analytical purposes grows rapidly
    among the research           community and decision makers as more geographic
    information is being collected. Laws protecting           data privacy are being
    enforced to prevent data disclosure. Statistical institutes and agencies need           methods
    to preserve confidentiality while maintaining accuracy when disclosing geographic
    data.           In this paper we present the AQuadtree package, a software intended
    to produce and deal with           official spatial data making data privacy and
    accuracy compatible. The lack of specific methods in           R to anonymize
    spatial data motivated the development of this package, providing an automatic           aggregation
    tool to anonymize point data. We propose a methodology based on hierarchical           geographic
    data structures to create a varying size grid adapted to local area population
    densities.           This article gives insights and hints for implementation
    and usage. We hope this new tool may be           helpful for statistical offices
    and users of official spatial data.'
  acknowledged: '2020-05-01'
  online: '2021-01-14'
  CRANpkgs:
  - anonymizer
  - SciencePo
  - sdcMicro
  - AQuadtree
  - sp
  - dplyr
  - rgeos
  - rgdal
  CTV_rev:
  - Spatial
  - Databases
  - ModelDeployment
  - SpatioTemporal
  suppl: 2.4 Kb
  landing: '2021'
  pages:
  - '209'
  - '225'
- slug: RJ-2021-014
  title: 'miWQS: Multiple Imputation Using Weighted Quantile Sum Regression'
  bibtitle: |-
    miWQS: Multiple Imputation Using Weighted Quantile Sum
              Regression
  author:
  - Paul M. Hargarten
  - David C. Wheeler
  bibauthor: Paul M. Hargarten and David C. Wheeler
  abstract: '  Abstract The miWQS package in the Comprehensive R Archive Network (CRAN)
    utilizes weighted            quantile sum regression (WQS) in the multiple imputation
    (MI) framework. The data analyzed is a            set/mixture of continuous and
    correlated components/chemicals that are reasonable to combine in            an
    index and share a common outcome. These components are also interval-censored
    between zero            and upper thresholds, or detection limits, which may differ
    among the components. This type of data            is found in areas such as chemical
    epidemiological studies, sociology, and genomics. The miWQS            package
    can be run using complete or incomplete data, which may be placed in the first
    quantile,            or imputed using bootstrap or Bayesian approach. This article
    provides a stepwise and hands-on            approach to handle uncertainty due
    to values below the detection limit in correlated component            mixture
    problems.'
  acknowledged: '2020-04-04'
  online: '2021-01-14'
  CRANpkgs:
  - miWQS
  - wqs
  - gWQS
  - mice
  - norm
  - mi
  - coda
  - Rsolnp
  - glm2
  - rlist
  - Hmisc
  - tidyr
  - ggplot2
  - survival
  - invgamma
  - truncnorm
  - purrr
  - GGally
  - rticles
  CTV_rev:
  - MissingData
  - SocialSciences
  - OfficialStatistics
  - Bayesian
  - ClinicalTrials
  - Econometrics
  - Multivariate
  - Distributions
  - gR
  - Graphics
  - Optimization
  - Phylogenetics
  - ReproducibleResearch
  - Survival
  - TeachingStatistics
  suppl: 3.7 Kb
  landing: '2021'
  pages:
  - '226'
  - '250'
- slug: RJ-2021-015
  title: 'Kuhn-Tucker and Multiple Discrete-Continuous Extreme Value Model Estimation
    and Simulation in R: The rmdcev Package'
  bibtitle: |-
    Kuhn-Tucker and Multiple Discrete-Continuous Extreme Value
              Model Estimation and Simulation in R: The rmdcev
              Package
  author: Patrick Lloyd-Smith
  bibauthor: Patrick Lloyd-Smith
  abstract: '  Abstract This paper introduces the package rmdcev in R for estimation
    and simulation of Kuhn           Tucker demand models with individual heterogeneity.
    The models supported by rmdcev are the            multiple-discrete continuous
    extreme value (MDCEV) model and Kuhn-Tucker specification common            in
    the environmental economics literature on recreation demand. Latent class and
    random parameters            specifications can be implemented and the models
    are fit using maximum likelihood estimation            or Bayesian estimation.
    The rmdcev package also implements demand forecasting and welfare            calculation
    for policy simulation. The purpose of this paper is to describe the model estimation
    and            simulation framework and to demonstrate the functionalities of
    rmdcev using real datasets.'
  acknowledged: '2020-04-01'
  online: '2021-01-15'
  CRANpkgs:
  - rmdcev
  - apollo
  - mlogit
  - gmnl
  - Formula
  - rstan
  - bayesplot
  - shinystan
  - parallel
  CTV_rev:
  - Econometrics
  - Bayesian
  - SocialSciences
  suppl: 1.6 Kb
  landing: '2021'
  pages:
  - '251'
  - '265'
- slug: RJ-2021-016
  title: 'NTS: An R Package for Nonlinear Time Series Analysis'
  bibtitle: 'NTS: An R Package for Nonlinear Time Series Analysis'
  author:
  - Xialu Liu
  - Rong Chen
  - Ruey Tsay
  bibauthor: Xialu Liu and Rong Chen and Ruey Tsay
  abstract: '  Abstract Linear time series models are commonly used in analyzing dependent
    data and in forecasting.            On the other hand, real phenomena often exhibit
    nonlinear behavior and the observed data show            nonlinear dynamics. This
    paper introduces the R package NTS that offers various computational            tools
    and nonlinear models for analyzing nonlinear dependent data. The package fills
    the gaps of            several outstanding R packages for nonlinear time series
    analysis. Specifically, the NTS package            covers the implementation of
    threshold autoregressive (TAR) models, autoregressive conditional mean            models
    with exogenous variables (ACMx), functional autoregressive models, and state-space
    models.            Users can also evaluate and compare the performance of different
    models and select the best one for            prediction. Furthermore, the package
    implements flexible and comprehensive sequential Monte Carlo            methods
    (also known as particle filters) for modeling non-Gaussian or nonlinear processes.
    Several            examples are used to demonstrate the capabilities of the NTS
    package.'
  acknowledged: '2020-04-05'
  online: '2021-01-15'
  CRANpkgs:
  - NTS
  - nonlinearTseries
  - NlinTS
  - nlts
  - sm
  - tree
  - randomForest
  - TAR
  - tsDyn
  - tscount
  - ftsa
  - SMC
  CTV_rev:
  - TimeSeries
  - MachineLearning
  - MissingData
  - Econometrics
  - Environmetrics
  - Finance
  - FunctionalData
  - SocialSciences
  suppl: 3 Kb
  landing: '2021'
  pages:
  - '266'
  - '292'
- slug: RJ-2021-017
  title: 'Species Distribution Modeling using Spatial Point Processes: a Case Study
    of Sloth Occurrence in Costa Rica'
  bibtitle: |-
    Species Distribution Modeling using Spatial Point Processes:
              a Case Study of Sloth Occurrence in Costa Rica
  author: Paula Moraga
  bibauthor: Paula Moraga
  abstract: '  Abstract                Species distribution models are widely used
    in ecology for conservation management of species            and their environments.
    This paper demonstrates how to fit a log-Gaussian Cox process model to            predict
    the intensity of sloth occurrence in Costa Rica, and assess the effect of climatic
    factors on spatial            patterns using the R-INLA package. Species occurrence
    data are retrieved using spocc, and spatial            climatic variables are
    obtained with raster. Spatial data and results are manipulated and visualized
    by            means of several packages such as raster and tmap. This paper provides
    an accessible illustration of            spatial point process modeling that can
    be used to analyze data that arise in a wide range of fields            including
    ecology, epidemiology and the environment.'
  acknowledged: '2019-12-20'
  online: '2021-01-15'
  CRANpkgs:
  - spocc
  - raster
  - tmap
  - ggplot2
  - leaflet
  - mapview
  - sp
  - rnaturalearth
  - rgeos
  BIOpkgs:
  - graph
  - Rgraphviz
  CTV_rev:
  - Spatial
  - SpatioTemporal
  - Graphics
  - OfficialStatistics
  - Phylogenetics
  - TeachingStatistics
  suppl: 1.8 Kb
  landing: '2021'
  pages:
  - '293'
  - '310'
- slug: RJ-2021-018
  title: 'A Graphical EDA Tool with ggplot2: brinton'
  bibtitle: 'A Graphical EDA Tool with ggplot2: brinton'
  author:
  - Pere Millán-Martínez
  - Ramon Oller
  bibauthor: Pere Millán-Martínez and Ramon Oller
  abstract: '  Abstract We present brinton package, which we developed for graphical
    exploratory data analysis in            R. Based on ggplot2, gridExtra and rmarkdown,
    brinton package introduces wideplot() graphics for            exploring the structure
    of a dataset through a grid of variables and graphic types. It also introduces            longplot()
    graphics, which present the entire catalog of available graphics for representing
    a particular            variable using a grid of graphic types and variations
    on these types. Finally, it introduces the plotup()            function, which
    complements the previous two functions in that it presents a particular graphic
    for a            specific variable of a dataset. This set of functions is useful
    for understanding the structure of a data            set, discovering unexpected
    properties in the data, evaluating different graphic representations of            these
    properties, and selecting a particular graphic for display on the screen.'
  acknowledged: '2020-01-19'
  online: '2021-01-15'
  CRANpkgs:
  - brinton
  - ggplot2
  - gridExtra
  - rmarkdown
  - GGobi
  - Mondrian
  - lattice
  - survminer
  - tabplot
  - visdat
  - inspectdf
  - xray
  - DataExplorer
  - SmartEDA
  - dataMaid
  - summarytools
  - ExPanDaR
  - dlookr
  - explore
  - shinydashboard
  - flexdashboard
  - cowplot
  - patchwork
  - KMsurv
  - Stat2Data
  - Ecdat
  CTV_rev:
  - Graphics
  - Survival
  - Econometrics
  - MissingData
  - Multivariate
  - Phylogenetics
  - ReproducibleResearch
  - TeachingStatistics
  - TimeSeries
  landing: '2021'
  pages:
  - '311'
  - '320'
- slug: RJ-2021-019
  title: 'MoTBFs: An R Package for Learning Hybrid Bayesian Networks Using Mixtures
    of Truncated Basis Functions'
  bibtitle: |-
    MoTBFs: An R Package for Learning Hybrid Bayesian Networks
              Using Mixtures of Truncated Basis Functions
  author:
  - Inmaculada Pérez-Bernabé
  - Ana D. Maldonado
  - Antonio Salmerón
  - Thomas D. Nielsen
  bibauthor: |-
    Inmaculada Pérez-Bernabé and Ana D. Maldonado and Antonio
              Salmerón and Thomas D. Nielsen
  abstract: '  Abstract This paper introduces MoTBFs, an R package for manipulating
    mixtures of truncated            basis functions. This class of functions allows
    the representation of joint probability distributions            involving discrete
    and continuous variables simultaneously, and includes mixtures of truncated            exponentials
    and mixtures of polynomials as special cases. The package implements functions
    for            learning the parameters of univariate, multivariate, and conditional
    distributions, and provides            support for parameter learning in Bayesian
    networks with both discrete and continuous variables.            Probabilistic
    inference using forward sampling is also implemented. Part of the functionality
    of the            MoTBFs package relies on the bnlearn package, which includes
    functions for learning the structure            of a Bayesian network from a data
    set. Leveraging this functionality, the MoTBFs package supports            learning
    of MoTBF-based Bayesian networks over hybrid domains. We give a brief introduction
    to            the methodological context and algorithms implemented in the package.
    An extensive illustrative            example is used to describe the package,
    its functionality, and its usage.'
  acknowledged: '2020-04-05'
  online: '2021-01-15'
  CRANpkgs:
  - MoTBFs
  - bnlearn
  - deal
  - pcalg
  - HydeNet
  - abn
  CTV_rev:
  - gR
  - Bayesian
  - HighPerformanceComputing
  suppl: 1.9 Kb
  landing: '2021'
  pages:
  - '321'
  - '341'
- slug: RJ-2021-020
  title: Analyzing Basket Trials under Multisource Exchangeability Assumptions
  bibtitle: |-
    Analyzing Basket Trials under Multisource Exchangeability
              Assumptions
  author:
  - Michael J. Kane
  - Nan Chen
  - Alexander M. Kaizer
  - Xun Jiang
  - H. Amy Xia
  - Brian P. Hobbs
  bibauthor: |-
    Michael J. Kane and Nan Chen and Alexander M. Kaizer and Xun
              Jiang and H. Amy Xia and Brian P. Hobbs
  abstract: '  Abstract Basket designs are prospective clinical trials that are devised
    with the hypothesis that the            presence of selected molecular features
    determine a patient’s subsequent response to a particular           “targeted”
    treatment strategy. Basket trials are designed to enroll multiple clinical subpopulations
    to            which it is assumed that the therapy in question offers beneficial
    efficacy in the presence of the targeted            molecular profile. The treatment,
    however, may not offer acceptable efficacy to all subpopulations            enrolled.
    Moreover, for rare disease settings, such as oncology wherein these trials have
    become            popular, marginal measures of statistical evidence are difficult
    to interpret for sparsely enrolled            subpopulations. Consequently, basket
    trials pose challenges to the traditional paradigm for trial            design,
    which assumes inter-patient exchangeability. The package basket for the R programmming            environment
    (R Core Team, 2019) facilitates the analysis of basket trials by implementing
    multi           source exchangeability models. By evaluating all possible pairwise
    exchangeability relationships, this            hierarchical modeling framework
    facilitates Bayesian posterior shrinkage among a collection of discrete            and
    pre-specified subpopulations. Analysis functions are provided to implement posterior
    inference            of the response rates and all possible exchangeability relationships
    between subpopulations. In            addition, the package can identify “poolable”
    subsets of and report their response characteristics. The            functionality
    of the package is demonstrated using data from an oncology study with subpopulations            defined
    by tumor histology.                 Keywords: Bayesian analysis, basket design,
    hierarchical model, master protocol, oncology, patient            heterogeneity'
  acknowledged: '2020-05-01'
  online: '2021-01-15'
  CRANpkgs:
  - basket
  - igraph
  CTV_rev:
  - gR
  - Graphics
  - Optimization
  - Spatial
  suppl: 452 bytes
  landing: '2021'
  pages:
  - '342'
  - '358'
- slug: RJ-2021-021
  title: 'OpenLand: Software for Quantitative Analysis and Visualization of Land Use
    and Cover Change'
  bibtitle: |-
    OpenLand: Software for Quantitative Analysis and
              Visualization of Land Use and Cover Change
  author:
  - Reginal Exavier
  - Peter Zeilhofer
  bibauthor: Reginal Exavier and Peter Zeilhofer
  abstract: '  Abstract There is an increasing availability of spatially explicit,
    freely available land use and cover            (LUC) time series worldwide. Because
    of the enormous amount of data this represents, the continuous            updates
    and improvements in spatial and temporal resolution and category differentiation,
    as well            as increasingly dynamic and complex changes made, manual data
    extraction and analysis is highly            time consuming, and making software
    tools available to automatize LUC data assessment is becom           ing imperative.
    This paper presents a software developed in R, which combines LUC raster time            series
    data and their transitions, calculates state-of-the-art LUC change indicators,
    and creates spatio           temporal visualizations, all in a coherent workflow.
    The functionality of the application developed is            demonstrated using
    an LUC dataset of the Pantanal floodplain contribution area in Central Brazil.'
  acknowledged: '2020-04-26'
  online: '2021-01-15'
  CRANpkgs:
  - intensity.analysis
  - lulcc
  - OpenLand
  - raster
  - dplyr
  - tidyr
  - ggplot2
  - circlize
  - gridExtra
  - networkD3
  CTV_rev:
  - Databases
  - Graphics
  - Hydrology
  - ModelDeployment
  - Phylogenetics
  - Spatial
  - SpatioTemporal
  - TeachingStatistics
  suppl: 2 Kb
  landing: '2021'
  pages:
  - '359'
  - '371'
- slug: RJ-2021-023
  title: 'FarmTest: An R Package for Factor-Adjusted Robust Multiple Testing'
  bibtitle: |-
    FarmTest: An R Package for Factor-Adjusted Robust Multiple
              Testing
  author:
  - Koushiki Bose
  - Jianqing Fan
  - Yuan Ke
  - Xiaoou Pan
  - Wen-Xin Zhou
  bibauthor: |-
    Koushiki Bose and Jianqing Fan and Yuan Ke and Xiaoou Pan
              and Wen-Xin Zhou
  abstract: '  Abstract We provide a publicly available library FarmTest in the R
    programming system. This            library implements a factor-adjusted robust
    multiple testing principle proposed by Fan et al. (2019) for            large-scale
    simultaneous inference on mean effects. We use a multi-factor model to explicitly
    capture            the dependence among a large pool of variables. Three types
    of factors are considered: observable,            latent, and a mixture of observable
    and latent factors. The non-factor case, which corresponds to            standard
    multiple mean testing under weak dependence, is also included. The library implements
    a            series of adaptive Huber methods integrated with fast data-driven
    tuning schemes to estimate model            parameters and to construct test statistics
    that are robust against heavy-tailed and asymmetric error            distributions.
    Extensions to two-sample multiple mean testing problems are also discussed. The            results
    of some simulation experiments and a real data analysis are reported.'
  acknowledged: '2020-06-03'
  online: '2021-01-15'
  CRANpkgs:
  - FarmTest
  - Rcpp
  - multcomp
  - mutoss
  - rstiefel
  BIOpkgs:
  - qvalue
  - multtest
  CTV_rev:
  - Bayesian
  - ClinicalTrials
  - HighPerformanceComputing
  - NumericalMathematics
  - SocialSciences
  - Survival
  suppl: 429.6 Kb
  landing: '2021'
  pages:
  - '372'
  - '387'
- slug: RJ-2021-024
  title: User-Specified General-to-Specific and Indicator Saturation Methods
  bibtitle: |-
    User-Specified General-to-Specific and Indicator Saturation
              Methods
  author: Genaro Sucarrat
  bibauthor: Genaro Sucarrat
  abstract: '  Abstract General-to-Specific (GETS) modelling provides a comprehensive,
    systematic and cumulative            approach to modelling that is ideally suited
    for conditional forecasting and counterfactual analysis,            whereas Indicator
    Saturation (ISAT) is a powerful and flexible approach to the detection and estimation            of
    structural breaks (e.g. changes in parameters), and to the detection of outliers.
    To these ends, multi           path backwards elimination, single and multiple
    hypothesis tests on the coefficients, diagnostics tests            and goodness-of-fit
    measures are combined to produce a parsimonious final model. In many situations            a
    specific model or estimator is needed, a specific set of diagnostics tests may
    be required, or a specific            fit criterion is preferred. In these situations,
    if the combination of estimator/model, diagnostics tests            and fit criterion
    is not offered in a pre-programmed way by publicly available software, then the            implementation
    of user-specified GETS and ISAT methods puts a large programming-burden on the            user.
    Generic functions and procedures that facilitate the implementation of user-specified
    GETS            and ISAT methods for specific problems can therefore be of great
    benefit. The R package gets is the            first software – both inside and
    outside the R universe – to provide a complete set of facilities for            user-specified
    GETS and ISAT methods: User-specified model/estimator, user-specified diagnostics            and
    user-specified goodness-of-fit criteria. The aim of this article is to illustrate
    how user-specified            GETS and ISAT methods can be implemented with the
    R package gets.'
  acknowledged: '2020-06-03'
  online: '2021-01-15'
  CRANpkgs:
  - gets
  - AutoSEARCH
  - Matrix
  CTV_rev:
  - Econometrics
  - Finance
  - Multivariate
  - NumericalMathematics
  suppl: 2.6 Kb
  landing: '2021'
  pages:
  - '388'
  - '401'
- heading: News and Notes
- slug: core
  author:
  - Tomas Kalibera
  - Sebastian Meyer
  - Kurt Hornik
  title: Changes in R 3.6–4.0
  bibtitle: Changes in R 3.6–4.0
  bibauthor: Tomas Kalibera and Sebastian Meyer and Kurt Hornik
  pages:
  - '402'
  - '406'
- slug: cran
  author:
  - Kurt Hornik
  - Uwe Ligges
  - Achim Zeileis
  title: Changes on CRAN
  bibtitle: Changes on CRAN
  bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
  pages:
  - '407'
  - '409'
- slug: bioc
  author: Bioconductor Core Team
  title: News from the Bioconductor Project
  bibtitle: News from the Bioconductor Project
  bibauthor: Bioconductor Core Team
  pages:
  - '410'
  - '410'
- slug: forwards-news
  author: Heather Turner
  title: News from the Forwards Taskforce
  bibtitle: News from the Forwards Taskforce
  bibauthor: Heather Turner
  pages:
  - '411'
  - '412'
- slug: foundation
  author: Torsten Hothorn
  title: R Foundation News
  bibtitle: R Foundation News
  bibauthor: Torsten Hothorn
  pages:
  - '413'
  - '415'
- slug: erum
  author:
  - Mariachiara Fortuna
  - Francesca Vitalini
  - Mirko Signorelli
  - Emanuela Furfaro
  - Federico Marini
  - Gert Janssenswillen'
  - Riccardo Porreca
  - Riccardo L. Rossi
  - Andrea Guzzo
  - Roberta Sirovich
  - Andrea
  title: 'e-Rum2020: how we turned a physical conference into a successful virtual
    event'
  bibtitle: 'e-Rum2020: how we turned a physical conference into a successful virtual
    event'
  bibauthor: |-
    Mariachiara Fortuna and Francesca Vitalini and Mirko
              Signorelli and Emanuela Furfaro and Federico
              Marini and Gert Janssenswillen and Riccardo
              Porreca and Riccardo L. Rossi and Andrea Guzzo and
              Roberta Sirovich and Andrea
  pages: '416'
