issue: 2018-1
year: 2018
volume: 10
num: 1
month: Jul
bibmonth: july
articles:
- slug: editorial
  cat: Editorial
  author: John Verzani
  title: Editorial
  bibtitle: Editorial
  bibauthor: John Verzani
  pages:
  - 4
  - 4
- heading: Contributed Research Articles
- slug: RJ-2018-001
  title: A System for an Accountable Data Analysis Process in R
  bibtitle: A System for an Accountable Data Analysis Process in R
  author:
  - Jonathan Gelfond
  - Martin Goros
  - Brian Hernandez
  - Alex Bokov
  bibauthor: |-
    Jonathan Gelfond and Martin Goros and Brian Hernandez and
              Alex Bokov
  abstract: '  Abstract Efficiently producing transparent analyses may be difficult
    for beginners or tedious for the            experienced. This implies a need for
    computing systems and environments that can efficiently satisfy            reproducibility
    and accountability standards. To this end, we have developed a system, R package,            and
    R Shiny application called adapr (Accountable Data Analysis Process in R) that
    is built on the            principle of accountable units. An accountable unit
    is a data file (statistic, table or graphic) that            can be associated
    with a provenance, meaning how it was created, when it was created and who            created
    it, and this is similar to the ’verifiable computational results’ (VCR) concept
    proposed by            Gavish and Donoho. Both accountable units and VCRs are
    version controlled, sharable, and can            be incorporated into a collaborative
    project. However, accountable units use file hashes and do not            involve
    watermarking or public repositories like VCRs. Reproducing collaborative work
    may be highly            complex, requiring repeating computations on multiple
    systems from multiple authors; however,            determining the provenance
    of each unit is simpler, requiring only a search using file hashes and            version
    control systems.'
  acknowledged: '2016-09-30'
  online: '2018-05-15'
  CRANpkgs:
  - knitr
  - rmarkdown
  - cacher
  - archivist
  - adapr
  - packrat
  CTV_rev: ReproducibleResearch
  landing: '2018'
  pages:
  - 6
  - 21
- slug: RJ-2018-033
  title: 'RealVAMS: An R Package for Fitting a Multivariate Value-added Model (VAM)'
  bibtitle: |-
    RealVAMS: An R Package for Fitting a Multivariate Value-
              added Model (VAM)
  author:
  - Jennifer Broatch
  - Jennifer Green
  - Andrew Karl
  bibauthor: Jennifer Broatch and Jennifer Green and Andrew Karl
  abstract: '  Abstract We present RealVAMS, an R package for fitting a generalized
    linear mixed model to            multimembership data with partially crossed and
    partially nested random effects. RealVAMS utilizes            a multivariate generalized
    linear mixed model with pseudo-likelihood approximation for fitting            normally
    distributed continuous response(s) jointly with a binary outcome. In an educational
    context,            the model is referred to as a multidimensional value-added
    model, which extends previous theory to            estimate the relationships
    between potential teacher contributions toward different student outcomes            and
    to allow the consideration of a binary, real-world outcome such as graduation.
    The simultaneous            joint modeling of continuous and binary outcomes was
    not available prior to RealVAMS due to            computational difficulties.
    In this paper, we discuss the multidimensional model, describe RealVAMS,            and
    demonstrate the use of this package and its modeling options with an educational
    data set.'
  acknowledged: '2017-03-03'
  online: '2018-05-22'
  CRANpkgs:
  - RealVAMS
  - lme4
  CTV_rev:
  - Bayesian
  - Econometrics
  - Environmetrics
  - OfficialStatistics
  - Psychometrics
  - SocialSciences
  - SpatioTemporal
  suppl: 1.4 Kb
  landing: '2018'
  pages:
  - 22
  - 30
- slug: RJ-2018-013
  title: 'InfoTrad: An R package for estimating the probability of informed trading'
  bibtitle: |-
    InfoTrad: An R package for estimating the probability of
              informed trading
  author:
  - Duygu Çelik
  - Murat Tiniç
  bibauthor: Duygu Çelik and Murat Tiniç
  abstract: '  Abstract The purpose of this paper is to introduce the R package InfoTrad
    for estimating the proba           bility of informed trading (PIN) initially
    proposed by Easley et al. (1996). PIN is a popular information            asymmetry
    measure that proxies the proportion of informed traders in the market. This study
    provides            a short survey on alternative estimation techniques for the
    PIN. There are many problems documented            in the existing literature
    in estimating PIN. InfoTrad package aims to address two problems. First,            the
    sequential trading structure proposed by Easley et al. (1996) and later extended
    by Easley et al.            (2002) is prone to sample selection bias for stocks
    with large trading volumes, due to floating point            exception. This problem
    is solved by different factorizations provided by Easley et al. (2010) (EHO            factorization)
    and Lin and Ke (2011) (LK factorization). Second, the estimates are prone to bias
    due to            boundary solutions. A grid-search algorithm (YZ algorithm) is
    proposed by Yan and Zhang (2012) to            overcome the bias introduced due
    to boundary estimates. In recent years, clustering algorithms have            become
    popular due to their flexibility in quickly handling large data sets. Gan et al.
    (2015) propose            an algorithm (GAN algorithm) to estimate PIN using hierarchical
    agglomerative clustering which is            later extended by Ersan and Alici
    (2016) (EA algorithm). The package InfoTrad offers LK and EHO            factorizations
    given an input matrix and initial parameter vector. In addition, these factorizations
    can            be used to estimate PIN through YZ algorithm, GAN algorithm and
    EA algorithm.'
  acknowledged: '2017-03-05'
  online: '2018-05-16'
  CRANpkgs:
  - InfoTrad
  - FinAsym
  - PIN
  - nloptr
  CTV_rev:
  - Finance
  - Optimization
  suppl: 4.3 Kb
  landing: '2018'
  pages:
  - 31
  - 42
- slug: RJ-2018-035
  title: 'RatingScaleReduction package: stepwise rating scale item reduction without
    predictability loss'
  bibtitle: |-
    RatingScaleReduction package: stepwise rating scale item
              reduction without predictability loss
  author:
  - Waldemar W. Koczkodaj
  - Feng Li
  - Alicja Wolny–Dominiak
  bibauthor: Waldemar W. Koczkodaj and Feng Li and Alicja Wolny–Dominiak
  abstract: '  Abstract This study presents an innovative method for reducing the
    number of rating scale items            without predictability loss. The “area
    under the receiver operator curve” method (AUC ROC) is used            for the
    stepwise method of reducing items of a rating scale. RatingScaleReduction R package
    contains            the presented implementation. Differential evolution (a metaheuristic
    for optimization) was applied            to one of the analyzed datasets to illustrate
    that the presented stepwise method can be used with other            classifiers
    to reduce the number of rating scale items (variables). The targeted areas of
    application are            decision making, data mining, machine learning, and
    psychometrics.            Keywords: rating scale, receiver operator characteristic,
    ROC, AUC, scale reduction.'
  acknowledged: '2017-03-20'
  online: '2018-06-01'
  CRANpkgs:
  - pROC
  - ROCR
  - RatingScaleReduction
  - DEoptim
  CTV_rev:
  - MachineLearning
  - Multivariate
  - Optimization
  suppl: unknown
  landing: '2018'
  pages:
  - 43
  - 55
- slug: RJ-2018-038
  title: 'mmpf: Monte-Carlo Methods for Prediction Functions'
  bibtitle: 'mmpf: Monte-Carlo Methods for Prediction Functions'
  author: Zachary M. Jones
  bibauthor: Zachary M. Jones
  abstract: '  Abstract Machine learning methods can often learn high-dimensional
    functions which generalize            well but are not human interpretable. The
    mmpf package marginalizes prediction functions using            Monte-Carlo methods,
    allowing users to investigate the behavior of these learned functions, as on a            lower
    dimensional subset of input features: partial dependence and variations thereof.
    This makes            machine learning methods more useful in situations where
    accurate prediction is not the only goal,            such as in the social sciences
    where linear models are commonly used because of their interpretability.                 Many
    methods for estimating prediction functions produce estimated functions which
    are not            directly human-interpretable because of their complexity: for
    example, they may include high           dimensional interactions and/or complex
    nonlinearities. While a learning method’s capacity to            automatically
    learn interactions and nonlinearities is attractive when the goal is prediction,
    there            are many cases where users want good predictions and the ability
    to understand how predictions            depend on the features. mmpf implements
    general methods for interpreting prediction functions            using Monte-Carlo
    methods. These methods allow any function which generates predictions to be be            interpreted.
    mmpf is currently used in other packages for machine learning like edarf and mlr
    (Jones            and Linder, 2016; Bischl et al., 2016).'
  acknowledged: '2017-04-17'
  online: '2018-06-29'
  CRANpkgs:
  - mmpf
  - edarf
  landing: '2018'
  pages:
  - 56
  - 60
- slug: RJ-2018-014
  title: Generalized Additive Model Multiple Imputation by Chained Equations With
    Package ImputeRobust
  bibtitle: |-
    Generalized Additive Model Multiple Imputation by Chained
              Equations With Package ImputeRobust
  author:
  - Daniel Salfran
  - Martin Spiess
  bibauthor: Daniel Salfran and Martin Spiess
  abstract: '  Abstract Data analysis, common to all empirical sciences, often requires
    complete data sets. Unfortu           nately, real world data collection will
    usually result in data values not being observed. We present a            package
    for robust multiple imputation (the ImputeRobust package) that allows the use
    of generalized            additive models for location, scale, and shape in the
    context of chained equations. The paper describes            the basics of the
    imputation technique which builds on a semi-parametric regression model (GAMLSS)            and
    the algorithms and functions provided with the corresponding package. Furthermore,
    some            illustrative examples are provided.'
  acknowledged: '2017-05-02'
  online: '2018-05-16'
  CRANpkgs:
  - ImputeRobust
  - mice
  - gamlss
  CTV_rev:
  - Econometrics
  - Multivariate
  - OfficialStatistics
  - SocialSciences
  suppl: 1.2 Kb
  landing: '2018'
  pages:
  - 61
  - 72
- slug: RJ-2018-015
  title: 'MGLM: An R Package for Multivariate Categorical Data Analysis'
  bibtitle: |-
    MGLM: An R Package for Multivariate Categorical Data
              Analysis
  author:
  - Juhyun Kim
  - Yiwen Zhang
  - Joshua Day
  - Hua Zhou
  bibauthor: Juhyun Kim and Yiwen Zhang and Joshua Day and Hua Zhou
  abstract: '  Abstract Data with multiple responses is ubiquitous in modern applications.
    However, few tools are            available for regression analysis of multivariate
    counts. The most popular multinomial-logit model            has a very restrictive
    mean-variance structure, limiting its applicability to many data sets. This article            introduces
    an R package MGLM, short for multivariate response generalized linear models,
    that            expands the current tools for regression analysis of polytomous
    data. Distribution fitting, random            number generation, regression, and
    sparse regression are treated in a unifying framework. The            algorithm,
    usage, and implementation details are discussed.'
  acknowledged: '2017-05-09'
  online: '2018-05-16'
  CRANpkgs:
  - MGLM
  - VGAM
  - glmnet
  - dirmult
  - parallel
  - isoform
  - glmc
  CTV_rev:
  - Distributions
  - Survival
  - Econometrics
  - Environmetrics
  - ExtremeValue
  - MachineLearning
  - Multivariate
  - Psychometrics
  - SocialSciences
  suppl: 1.7 Kb
  landing: '2018'
  pages:
  - 73
  - 90
- slug: RJ-2018-016
  title: 'ArCo: An R package to Estimate Artificial Counterfactuals'
  bibtitle: 'ArCo: An R package to Estimate Artificial Counterfactuals'
  author:
  - Yuri R. Fonseca
  - Ricardo P. Masini
  - Marcelo C. Medeiros
  - Gabriel F. R. Vasconcelos
  bibauthor: |-
    Yuri R. Fonseca and Ricardo P. Masini and Marcelo C.
              Medeiros and Gabriel F. R. Vasconcelos
  abstract: '  Abstract In this paper we introduce the ArCo package for R which consists
    of a set of functions            to implement the the Artificial Counterfactual
    (ArCo) methodology to estimate causal effects of an            intervention (treatment)
    on aggregated data and when a control group is not necessarily available.            The
    ArCo method is a two-step procedure, where in the first stage a counterfactual
    is estimated from a            large panel of time series from a pool of untreated
    peers. In the second-stage, the average treatment            effect over the post-intervention
    sample is computed. Standard inferential procedures are available.            The
    package is illustrated with both simulated and real datasets.'
  acknowledged: '2017-05-09'
  online: '2018-05-16'
  CRANpkgs:
  - ArCo
  - boot
  - glmnet
  - Synth
  CTV_rev:
  - Survival
  - Econometrics
  - MachineLearning
  - Optimization
  - SocialSciences
  - TimeSeries
  suppl: 2.9 Kb
  landing: '2018'
  pages:
  - 91
  - 108
- slug: RJ-2018-018
  title: 'PanJen: An R package for Ranking Transformations in a Linear Regression'
  bibtitle: |-
    PanJen: An R package for Ranking Transformations in a Linear
              Regression
  author:
  - Cathrine Ulla Jensen
  - Toke Emil Panduro
  bibauthor: Cathrine Ulla Jensen and Toke Emil Panduro
  abstract: '  Abstract PanJen is an R-package for ranking transformations in linear
    regressions. It provides users            with the ability to explore the relationship
    between a dependent variable and its independent variables.            The package
    offers an easy and data-driven way to choose a functional form in multiple linear            regression
    models by comparing a range of parametric transformations. The parametric functional            forms
    are benchmarked against each other and a non-parametric transformation. The package            allows
    users to generate plots that show the relation between a covariate and the dependent
    variable.            Furthermore, PanJen will enable users to specify specific
    functional transformations, driven by a            priori and theory-based hypotheses.
    The package supplies both model fits and plots that allow users            to
    make informed choices on the functional forms in their regression. We show that
    the ranking            in PanJen outperforms the Box-Tidwell transformation, especially
    in the presence of inefficiency,            heteroscedasticity or endogeneity.'
  acknowledged: '2017-05-12'
  online: '2018-05-21'
  CRANpkgs:
  - PanJen
  - mgcv
  CTV_rev:
  - Bayesian
  - Econometrics
  - Environmetrics
  - SocialSciences
  suppl: 1 Kb
  landing: '2018'
  pages:
  - 109
  - 121
- slug: RJ-2018-019
  title: Tackling Uncertainties of Species Distribution Model Projections with Package
    mopa
  bibtitle: |-
    Tackling Uncertainties of Species Distribution Model
              Projections with Package mopa
  author:
  - M. Iturbide
  - J. Bedia
  - J.M. Gutiérrez
  bibauthor: M. Iturbide and J. Bedia and J.M. Gutiérrez
  abstract: '  Abstract Species Distribution Models (SDMs) constitute an important
    tool to assist decision-making            in environmental conservation and planning
    in the context of climate change. Nevertheless, SDM pro           jections are
    affected by a wide range of uncertainty factors (related to training data, climate
    projections            and SDM techniques), which limit their potential value
    and credibility. The new package mopa pro           vides tools for designing
    comprehensive multi-factor SDM ensemble experiments, combining multiple            sources
    of uncertainty (e.g. baseline climate, pseudo-absence realizations, SDM techniques,
    future            projections) and allowing to assess their contribution to the
    overall spread of the ensemble projection.            In addition, mopa is seamlessly
    integrated with the climate4R bundle and allows straightforward            retrieval
    and post-processing of state-of-the-art climate datasets (including observations
    and climate            change projections), thus facilitating the proper analysis
    of key uncertainty factors related to climate            data.'
  acknowledged: '2017-05-29'
  online: '2018-05-21'
  CRANpkgs:
  - mopa
  - sdm
  - biomod2
  - dismo
  - SDMTools
  - raster
  - sp
  - e1071
  - stats
  - ranger
  - earth
  - tree
  - rpart
  - caret
  CTV_rev:
  - MachineLearning
  - Multivariate
  - Environmetrics
  - Spatial
  - SpatioTemporal
  - Survival
  - Cluster
  - Distributions
  - HighPerformanceComputing
  - Psychometrics
  suppl: 2.2 Kb
  landing: '2018'
  pages:
  - 122
  - 139
- slug: RJ-2018-020
  title: 'FHDI: An R Package for Fractional Hot Deck Imputation'
  bibtitle: 'FHDI: An R Package for Fractional Hot Deck Imputation'
  author:
  - Jongho Im
  - In Ho Cho
  - Jae Kwang Kim
  bibauthor: Jongho Im and In Ho Cho and Jae Kwang Kim
  abstract: '  Abstract Fractional hot deck imputation (FHDI), proposed by Kalton
    and Kish (1984) and investigated            by Kim and Fuller (2004), is a tool
    for handling item nonresponse in survey sampling. In FHDI,            each missing
    item is filled with multiple observed values yielding a single completed data
    set for            subsequent analyses. An R package FHDI is developed to perform
    FHDI and also the fully efficient            fractional imputation (FEFI) method
    of (Fuller and Kim, 2005) to impute multivariate missing data            with
    arbitrary missing patterns. FHDI substitutes missing items with a few observed
    values jointly            obtained from a set of donors whereas the FEFI uses
    all the possible donors. This paper introduces            FHDI as a tool for implementing
    the multivariate version of fractional hot deck imputation discussed            in
    Im et al. (2015) as well as FEFI. For variance estimation of FHDI and FEFI, the
    Jackknife method is            implemented, and replicated weights are provided
    as a part of the output.'
  acknowledged: '2017-06-02'
  online: '2018-05-21'
  CRANpkgs:
  - mice
  - mi
  - Amelia
  - VIM
  - FHDI
  CTV_rev:
  - OfficialStatistics
  - SocialSciences
  - Multivariate
  suppl: 984 bytes
  landing: '2018'
  pages:
  - 140
  - 154
- slug: RJ-2018-021
  title: Bayesian Testing, Variable Selection and Model Averaging in Linear Models
    using R with BayesVarSel
  bibtitle: |-
    Bayesian Testing, Variable Selection and Model Averaging in
              Linear Models using R with BayesVarSel
  author:
  - Gonzalo Garcia-Donato
  - Anabel Forte
  bibauthor: Gonzalo Garcia-Donato and Anabel Forte
  abstract: '  Abstract In this paper, objective Bayesian methods for hypothesis testing
    and variable selection in            linear models are considered. The focus is
    on BayesVarSel, an R package that computes posterior            probabilities
    of hypotheses/models and provides a suite of tools to properly summarize the results.
    We            introduce the usage of specific functions to compute several types
    of model averaging estimations and            predictions weighted by posterior
    probabilities. BayesVarSel contains exact algorithms to perform            fast
    computations in problems of small to moderate size and heuristic sampling methods
    to solve            large problems. We illustrate the functionalities of the package
    with several data examples.'
  acknowledged: '2017-06-14'
  online: '2018-05-21'
  CRANpkgs:
  - BayesVarSel
  - faraway
  - BayesFactor
  - BMS
  - mombf
  - BAS
  - BMA
  CTV_rev:
  - Bayesian
  - Econometrics
  - SocialSciences
  - Survival
  suppl: 4.4 Kb
  landing: '2018'
  pages:
  - 155
  - 174
- slug: RJ-2018-022
  title: 'onewaytests: An R Package for One-Way Tests in Independent Groups Designs'
  bibtitle: |-
    onewaytests: An R Package for One-Way Tests in Independent
              Groups Designs
  author:
  - Osman Dag
  - Anil Dolgun
  - Naime Meric Konar
  bibauthor: Osman Dag and Anil Dolgun and Naime Meric Konar
  abstract: '  Abstract One-way tests in independent groups designs are the most commonly
    utilized statistical            methods with applications on the experiments in
    medical sciences, pharmaceutical research, agri           culture, biology, engineering,
    social sciences and so on. In this paper, we present the onewaytests            package
    to investigate treatment effects on the dependent variable. The package offers
    the one-way            tests in independent groups designs, which include ANOVA,
    Welch’s heteroscedastic F test, Welch’s            heteroscedastic F test with
    trimmed means and Winsorized variances, Brown-Forsythe test, Alexander           Govern
    test, James second order test and Kruskal-Wallis test. The package also provides
    pairwise            comparisons, graphical approaches, and assesses variance homogeneity
    and normality of data in each            group via tests and plots. A simulation
    study is also conducted to give recommendations for applied            researchers
    on the selection of appropriate one-way tests under assumption violations. Furthermore,            especially
    for non-R users, a user-friendly web application of the package is provided. This
    application            is available at http://www.softmed.hacettepe.edu.tr/onewaytests.'
  acknowledged: '2017-06-14'
  online: '2018-05-21'
  CRANpkgs:
  - onewaytests
  - onewaytests
  - stats
  suppl: 1.1 Kb
  landing: '2018'
  pages:
  - 175
  - 199
- slug: RJ-2018-023
  title: 'Inventorymodel: an R Package for Centralized Inventory Problems'
  bibtitle: |-
    Inventorymodel: an R Package for Centralized Inventory
              Problems
  author: Alejandro Saavedra-Nieves
  bibauthor: Alejandro Saavedra-Nieves
  abstract: '  Abstract Inventory management of goods is an integral part of logistics
    systems; common to various            economic sectors such as industry, agriculture
    and trade; and independent of production volume. In            general, as companies
    seek to minimize economic losses, studies on problems of multi-agent inventory            have
    increased in recent years. A multi-agent inventory problem is a situation in which
    several            agents face individual inventory problems and agree to coordinate
    their orders with the objective of            reducing their costs. The R package
    Inventorymodel allows the determination of both the optimal            policy
    for some inventory situations with deterministic demands and the allocation of
    costs from a            game-theoretic perspective. The required calculations
    may be computed for any number of agents            although the computational
    complexity of this class of problems when the involved agents enlarge is            not
    reduced. In this work, the different possibilities that the package offers are
    described and some            examples of usage are also demonstrated.'
  acknowledged: '2017-06-14'
  online: '2018-05-21'
  CRANpkgs:
  - Inventorymodel
  - e1071
  - GameTheoryAllocation
  CTV_rev:
  - Cluster
  - Distributions
  - Environmetrics
  - MachineLearning
  - Multivariate
  - Psychometrics
  suppl: 687 bytes
  landing: '2018'
  pages:
  - 200
  - 217
- slug: RJ-2018-024
  title: R Package imputeTestbench to Compare Imputation Methods for Univariate Time
    Series
  bibtitle: |-
    R Package imputeTestbench to Compare Imputation Methods for
              Univariate Time Series
  author:
  - Marcus W Beck
  - Neeraj Bokde
  - Gualberto Asencio-Cortés
  - Kishore Kulat
  bibauthor: |-
    Marcus W Beck and Neeraj Bokde and Gualberto Asencio-Cortés
              and Kishore Kulat
  abstract: '  Abstract Missing observations are common in time series data and several
    methods are available to            impute these values prior to analysis. Variation
    in statistical characteristics of univariate time series            can have a
    profound effect on characteristics of missing observations and, therefore, the
    accuracy of            different imputation methods. The imputeTestbench package
    can be used to compare the prediction            accuracy of different methods
    as related to the amount and type of missing data for a user-supplied            dataset.
    Missing data are simulated by removing observations completely at random or in
    blocks of            different sizes depending on characteristics of the data.
    Several imputation algorithms are included            with the package that vary
    from simple replacement with means to more complex interpolation            methods.
    The testbench is not limited to the default functions and users can add or remove
    methods            as needed. Plotting functions also allow comparative visualization
    of the behavior and effectiveness of            different algorithms. We present
    example applications that demonstrate how the package can be used            to
    understand differences in prediction accuracy between methods as affected by characteristics
    of a            dataset and the nature of missing data.'
  acknowledged: '2017-06-29'
  online: '2018-05-21'
  CRANpkgs:
  - imputeTestbench
  - dplyr
  - reshape2
  - tidyr
  - ggplot2
  - forecast
  - imputeTS
  - zoo
  - stats
  - datasets
  - Rcpp
  - matlabr
  CTV_rev:
  - TimeSeries
  - Econometrics
  - Environmetrics
  - Finance
  - Graphics
  - HighPerformanceComputing
  - ModelDeployment
  - NumericalMathematics
  - Phylogenetics
  suppl: 3.8 Kb
  landing: '2018'
  pages:
  - 218
  - 233
- slug: RJ-2018-034
  title: 'ICSOutlier: Unsupervised Outlier Detection for Low-Dimensional Contamination
    Structure'
  bibtitle: |-
    ICSOutlier: Unsupervised Outlier Detection for Low-
              Dimensional Contamination Structure
  author:
  - Aurore Archimbaud
  - Klaus Nordhausen
  - Anne Ruiz-Gazen
  bibauthor: Aurore Archimbaud and Klaus Nordhausen and Anne Ruiz-Gazen
  abstract: '  Abstract Detecting outliers in a multivariate and unsupervised context
    is an important and ongoing            problem notably for quality control. Many
    statistical methods are already implemented in R and            are briefly surveyed
    in the present paper. But only a few lead to the accurate identification of            potential
    outliers in the case of a small level of contamination. In this particular context,
    the Invariant            Coordinate Selection (ICS) method shows remarkable properties
    for identifying outliers that lie on            a low-dimensional subspace in
    its first invariant components. It is implemented in the ICSOutlier            package.
    The main function of the package, ics.outlier, offers the possibility of labelling
    potential            outliers in a completely automated way. Four examples, including
    two real examples in quality control,            illustrate the use of the function.
    Comparing with several other approaches, it appears that ICS is            generally
    as efficient as its competitors and shows an advantage in the context of a small
    proportion of            outliers lying in a low-dimensional subspace. In quality
    control, the method may help in properly            identifying some defective
    products while not detecting too many false positives.'
  acknowledged: '2017-06-29'
  online: '2018-05-30'
  CRANpkgs:
  - mvoutlier
  - CerioliOutlierDetection
  - rrcovHD
  - faoutlier
  - abodOutlier
  - HighDimOut
  - alphaOutlier
  - extremevalues
  - HDoutliers
  - outliers
  - DMwR2
  - ldbod
  - Rlof
  - depth
  - REPPlab
  - OutlierDC
  - pcadapt
  - rrcov
  - ICSOutlier
  - ICS
  - robustbase
  CTV_rev:
  - Robust
  - Multivariate
  - OfficialStatistics
  - Psychometrics
  - Survival
  suppl: 3.1 Kb
  landing: '2018'
  pages:
  - 234
  - 250
- slug: RJ-2018-025
  title: 'rpostgis: Linking R with a PostGIS Spatial Database'
  bibtitle: 'rpostgis: Linking R with a PostGIS Spatial Database'
  author:
  - David Bucklin
  - Mathieu Basille
  bibauthor: David Bucklin and Mathieu Basille
  abstract: '  Abstract With the proliferation of sensors and the ease of data collection
    from online sources, large            datasets have become the norm in many scientific
    disciplines, and efficient data storage, management,            and retrival is
    imperative for large research projects. Relational databases provide a solution,
    but            in order to be useful, must be able to be linked to analysis and
    visualization tools, such as R. Here,            we present a package intended
    to facilitate integration of R with the open-source database software            PostgreSQL,
    with a focus on its spatial extension, PostGIS. The package rpostgis (version
    1.4.1)            provides methods for spatial data handling (vector and raster)
    between PostGIS-enabled databases            and R, methods for R "data.frame"s
    storage in PostgreSQL, and a set of convenient wrappers for            common
    database procedures. We thus expect rpostgis to be useful for both (1) existing
    users of            spatial data in R and/or PostGIS, and (2) R users who have
    yet to adopt relational databases for their            projects.'
  acknowledged: '2017-07-07'
  online: '2018-05-21'
  CRANpkgs:
  - rgdal
  - maptools
  - raster
  - RPostgreSQL
  - DBI
  - rpostgis
  - sp
  - rgeos
  - wkb
  - sf
  - rpostgisLT
  - adehabitatLT
  CTVs: Spatial
  CTV_rev:
  - Spatial
  - SpatioTemporal
  suppl: 1.7 Kb
  landing: '2018'
  pages:
  - 251
  - 268
- slug: RJ-2018-026
  title: 'lba: An R Package for Latent Budget Analysis'
  bibtitle: 'lba: An R Package for Latent Budget Analysis'
  author:
  - Enio G. Jelihovschi
  - Ivan Bezerra Allaman
  bibauthor: Enio G. Jelihovschi and Ivan Bezerra Allaman
  abstract: '  Abstract The latent budget model is a mixture model for compositional
    data sets in which the entries,            a contingency table, may be either
    realizations from a product multinomial distribution or distribution            free.
    Based on this model, the latent budget analysis considers the interactions of
    two variables; the ex           planatory (row) and the response (column) variables.
    The package lba uses expectation-maximization            and active constraints
    method (ACM) to carry out, respectively, the maximum likelihood and the least            squares
    estimation of the model parameters. It contains three main functions, lba which
    performs            the analysis, goodnessfit for model selection and goodness
    of fit and the plotting functions plotcorr            and plotlba used as a help
    in the interpretation of the results.'
  acknowledged: '2017-07-12'
  online: '2018-05-21'
  CRANpkgs:
  - lba
  - alabama
  - plotrix
  - scatterplot3d
  - rgl
  - MASS
  CTV_rev:
  - Graphics
  - Multivariate
  - Psychometrics
  - Distributions
  - Econometrics
  - Environmetrics
  - NumericalMathematics
  - Optimization
  - Robust
  - SocialSciences
  - SpatioTemporal
  suppl: 1.1 Kb
  landing: '2018'
  pages:
  - 269
  - 287
- slug: RJ-2018-027
  title: Semiparametric Generalized Linear Models with the gldrm Package
  bibtitle: |-
    Semiparametric Generalized Linear Models with the gldrm
              Package
  author:
  - Michael J. Wurm
  - Paul J. Rathouz
  bibauthor: Michael J. Wurm and Paul J. Rathouz
  abstract: '  Abstract This paper introduces a new algorithm to estimate and perform
    inferences on a recently            proposed and developed semiparametric generalized
    linear model (glm). Rather than selecting a            particular parametric exponential
    family model, such as the Poisson distribution, this semiparametric            glm
    assumes that the response is drawn from the more general exponential tilt family.
    The regression            coefficients and unspecified reference distribution
    are estimated by maximizing a semiparametric like           lihood. The new algorithm
    incorporates several computational stability and efficiency improvements            over
    the algorithm originally proposed. In particular, the new algorithm performs well
    for either small            or large support for the nonparametric response distribution.
    The algorithm is implemented in a new            R package called gldrm.'
  acknowledged: '2017-07-23'
  online: '2018-05-21'
  CRANpkgs: gldrm
  landing: '2018'
  pages:
  - 288
  - 307
- slug: RJ-2018-028
  title: 'LP Algorithms for Portfolio Optimization: The PortfolioOptim Package'
  bibtitle: |-
    LP Algorithms for Portfolio Optimization: The PortfolioOptim
              Package
  author: Andrzej Palczewski
  bibauthor: Andrzej Palczewski
  abstract: '  Abstract The paper describes two algorithms for financial portfolio
    optimization with the following            risk measures: CVaR, MAD, LSAD and
    dispersion CVaR. These algorithms can be applied to discrete            distributions
    of asset returns since then the optimization problems can be reduced to linear
    programs.            The first algorithm solves a simple recourse problem as described
    by Haneveld using Benders de           composition method. The second algorithm
    finds an optimal portfolio with the smallest distance            to a given benchmark
    portfolio and is an adaptation of the least norm solution (called also normal            solution)
    of linear programs due to Zhao and Li. The algorithms are implemented in R in
    the package            PortfolioOptim.'
  acknowledged: '2017-07-23'
  online: '2018-05-21'
  CRANpkgs:
  - fPortfolio
  - PortfolioAnalytics
  - Rglpk
  - quadprog
  - DEoptim
  - GenSA
  - psoptim
  - parma
  - nloptr
  - PortfolioOptim
  CTV_rev:
  - Optimization
  - Finance
  suppl: 1.4 Kb
  landing: '2018'
  pages:
  - 308
  - 327
- slug: RJ-2018-029
  title: 'Welfare, Inequality and Poverty Analysis with rtip: An Approach Based on
    Stochastic Dominance'
  bibtitle: |-
    Welfare, Inequality and Poverty Analysis with rtip: An
              Approach Based on Stochastic Dominance
  author:
  - Angel Berihuete
  - Carmen D. Ramos
  - Miguel A. Sordo
  bibauthor: Angel Berihuete and Carmen D. Ramos and Miguel A. Sordo
  abstract: '  Abstract Disparities in economic welfare, inequality and poverty across
    and within countries are            of great interest to sociologists, economists,
    researchers, social organizations and political scientists.            Information
    about these topics is commonly based on surveys. We present a package called rtip
    that            implements techniques based on stochastic dominance to make unambiguous
    comparisons, in terms            of welfare, poverty and inequality, among income
    distributions. Besides providing point estimates            and confidence intervals
    for the most commonly used indicators of these characteristics, the package            rtip
    estimates the usual Lorenz curve, the generalized Lorenz curve, the TIP (Three
    I’s of Poverty)            curve and allows to test statistically whether one
    curve is dominated by another.'
  acknowledged: '2017-07-25'
  online: '2018-05-21'
  CRANpkgs:
  - rtip
  - IC2
  - ineq
  - laeken
  - boot
  CTV_rev:
  - OfficialStatistics
  - Econometrics
  - Optimization
  - SocialSciences
  - Survival
  - TimeSeries
  suppl: 2.2 Kb
  landing: '2018'
  pages:
  - 328
  - 341
- slug: RJ-2018-039
  title: dimRed and coRanking - Unifying Dimensionality Reduction in R
  bibtitle: dimRed and coRanking---Unifying Dimensionality Reduction in R
  author:
  - Guido Kraemer
  - Markus Reichstein
  - Miguel D. Mahecha
  bibauthor: Guido Kraemer and Markus Reichstein and Miguel D. Mahecha
  abstract: '  Abstract “Dimensionality reduction” (DR) is a widely used approach
    to find low dimensional and            interpretable representations of data that
    are natively embedded in high-dimensional spaces. DR can be            realized
    by a plethora of methods with different properties, objectives, and, hence, (dis)advantages.
    The            resulting low-dimensional data embeddings are often difficult to
    compare with objective criteria. Here,            we introduce the dimRed and
    coRanking packages for the R language. These open source software            packages
    enable users to easily access multiple classical and advanced DR methods using
    a common            interface. The packages also provide quality indicators for
    the embeddings and easy visualization of            high dimensional data. The
    coRanking package provides the functionality for assessing DR methods            in
    the co-ranking matrix framework. In tandem, these packages allow for uncovering
    complex            structures high dimensional data. Currently 15 DR methods are
    available in the package, some of            which were not previously available
    to R users. Here, we outline the dimRed and coRanking packages            and
    make the implemented methods understandable to the interested reader.'
  acknowledged: '2017-08-14'
  online: '2018-06-29'
  CRANpkgs:
  - dimRed
  - coRanking
  - kernlab
  - vegan
  - RANN
  - igraph
  - lle
  - diffusionMap
  - MASS
  - igraph
  - Rtsne
  - fastICA
  - DRR
  BIOpkgs: pcaMethods
  CTV_rev:
  - Multivariate
  - Optimization
  - Psychometrics
  - Spatial
  - Environmetrics
  - gR
  - Graphics
  - ChemPhys
  - Cluster
  - Distributions
  - Econometrics
  - MachineLearning
  - NaturalLanguageProcessing
  - NumericalMathematics
  - Phylogenetics
  - Robust
  - SocialSciences
  landing: '2018'
  pages:
  - 342
  - 358
- slug: RJ-2018-002
  title: 'GrpString: An R Package for Analysis of Groups of Strings'
  bibtitle: 'GrpString: An R Package for Analysis of Groups of Strings'
  author:
  - Hui Tang
  - Elizabeth L. Day
  - Molly B. Atkinson
  - Norbert J. Pienta
  bibauthor: |-
    Hui Tang and Elizabeth L. Day and Molly B. Atkinson and
              Norbert J. Pienta
  abstract: '  Abstract The R package GrpString was developed as a comprehensive toolkit
    for quantitatively            analyzing and comparing groups of strings. It offers
    functions for researchers and data analysts to            prepare strings from
    event sequences, extract common patterns from strings, and compare patterns be           tween
    string vectors. The package also finds transition matrices and complexity of strings,
    determines            clusters in a string vector, and examines the statistical
    difference between two groups of strings.'
  acknowledged: '2017-08-16'
  online: '2018-05-15'
  CRANpkgs:
  - stringr
  - stringb
  - stringi
  - gsubfn
  - uniqtag
  - stringdist
  - TraMineR
  - informR
  - GrpString
  - entropy
  CTV_rev:
  - NaturalLanguageProcessing
  - OfficialStatistics
  - Survival
  suppl: 984 bytes
  landing: '2018'
  pages:
  - 359
  - 369
- slug: RJ-2018-003
  title: 'Epistemic Game Theory: Putting Algorithms to Work'
  bibtitle: 'Epistemic Game Theory: Putting Algorithms to Work'
  author:
  - Bilge Başer
  - Nalan Cinemre
  bibauthor: Bilge Başer and Nalan Cinemre
  abstract: '  Abstract The aim of this study is to construct an epistemic model in
    which each rational choice under            common belief in rationality is supplemented
    by a type which expresses such a belief. In practice, the            finding of
    type depends on manual solution approach with some mathematical operations in
    scope of            the theory. This approach becomes less convenient with the
    growth of the size of the game. To solve            this difficulty, a linear
    programming model is constructed for two-player, static and non-cooperative            games
    to find the type that is supporting that player’s rational choice is optimal under
    common            belief in rationality and maximizing the utility of the game.
    Since the optimal choice would only            be made from rational choices,
    it is first necessary to eliminate all strictly dominated choices. In            real
    life, the games are usually large sized. Therefore, the elimination process should
    be performed            in a computer environment. Since software related to game
    theory was mostly prepared with a            result-oriented approach for some
    types of games, it was necessary to develop software to execute            the
    iterated elimination method. With this regard, a program has been developed that
    determines            the choices that are strictly dominated by pure and randomized
    choices in two-player games. Two            functions named “esdc” and “type”
    are created by using R statistical programming language for the            operations
    performed in both parts, and these functions are added to the content of an R
    package after            its creation with the name EpistemicGameTheory.'
  acknowledged: '2017-09-13'
  online: '2018-05-15'
  CRANpkgs:
  - EpistemicGameTheory
  - roxygen2
  - lpSolve
  CTV_rev: Optimization
  suppl: 631 bytes
  landing: '2018'
  pages:
  - 370
  - 380
- slug: RJ-2018-004
  title: 'Residuals and Diagnostics for Binary and Ordinal Regression Models: An Introduction
    to the sure Package'
  bibtitle: |-
    Residuals and Diagnostics for Binary and Ordinal Regression
              Models: An Introduction to the sure Package
  author:
  - Brandon M. Greenwell
  - Andrew J. McCarthy
  - Bradley C. Boehmke
  - Dungang Liu
  bibauthor: |-
    Brandon M. Greenwell and Andrew J. McCarthy and Bradley C.
              Boehmke and Dungang Liu
  abstract: '  Abstract Residual diagnostics is an important topic in the classroom,
    but it is less often used in practice            by Brandon M. Greenwell, Andrew
    J. McCarthy, Bradley C. Boehmke, and Dungang Liu            Introduction to the
    sure Package            Ordinal Regression Models: An'
  acknowledged: '2017-09-21'
  online: '2018-05-15'
  CRANpkgs:
  - MASS
  - VGAM
  - ordinal
  - rms
  - PResiduals
  - sure
  - ggplot2
  CTV_rev:
  - Econometrics
  - Psychometrics
  - SocialSciences
  - Distributions
  - Environmetrics
  - Multivariate
  - Survival
  - ExtremeValue
  - Graphics
  - NumericalMathematics
  - Phylogenetics
  - ReproducibleResearch
  - Robust
  suppl: 2 Kb
  landing: '2018'
  pages:
  - 381
  - 394
- slug: RJ-2018-017
  title: Advanced Bayesian Multilevel Modeling with the R Package brms
  bibtitle: |-
    Advanced Bayesian Multilevel Modeling with the R Package
              brms
  author: Paul-Christian Bürkner
  bibauthor: Paul-Christian Bürkner
  abstract: '  Abstract The brms package allows R users to easily specify a wide range
    of Bayesian single-level            and multilevel models which are fit with the
    probabilistic programming language Stan behind the            scenes. Several
    response distributions are supported, of which all parameters (e.g., location,
    scale, and            shape) can be predicted. Non-linear relationships may be
    specified using non-linear predictor terms            or semi-parametric approaches
    such as splines or Gaussian processes. Multivariate models can be fit            as
    well. To make all of these modeling options possible in a multilevel framework,
    brms provides an            intuitive and powerful formula syntax, which extends
    the well known formula syntax of lme4. The            purpose of the present paper
    is to introduce this syntax in detail and to demonstrate its usefulness            with
    four examples, each showing relevant aspects of the syntax.'
  acknowledged: '2017-10-01'
  online: '2018-05-18'
  CRANpkgs:
  - brms
  - lme4
  - rstanarm
  - MCMCglmm
  - mgcv
  - nlme
  - afex
  - loo
  - gamlss.data
  - bridgesampling
  CTV_rev:
  - Bayesian
  - SocialSciences
  - Econometrics
  - Environmetrics
  - Psychometrics
  - OfficialStatistics
  - SpatioTemporal
  - ChemPhys
  - Finance
  - Phylogenetics
  - Spatial
  - Survival
  landing: '2018'
  pages:
  - 395
  - 411
- slug: RJ-2018-005
  title: Support Vector Machines for Survival Analysis with R
  bibtitle: Support Vector Machines for Survival Analysis with R
  author:
  - Césaire J. K. Fouodo
  - Inke R. König
  - Claus Weihs
  - Andreas Ziegler
  - Marvin N. Wright
  bibauthor: |-
    Césaire J. K. Fouodo and Inke R. König and Claus Weihs and
              Andreas Ziegler and Marvin N. Wright
  abstract: '  Abstract This article introduces the R package survivalsvm, implementing
    support vector machines            for survival analysis. Three approaches are
    available in the package: The regression approach takes            censoring into
    account when formulating the inequality constraints of the support vector problem.            In
    the ranking approach, the inequality constraints set the objective to maximize
    the concordance            index for comparable pairs of observations. The hybrid
    approach combines the regression and ranking            constraints in a single
    model. We describe survival support vector machines and their implementation,            provide
    examples and compare the prediction performance with the Cox proportional hazards
    model,            random survival forests and gradient boosting using several
    real datasets. On these datasets, survival            support vector machines
    perform on par with the reference methods.'
  acknowledged: '2017-10-01'
  online: '2018-05-16'
  CRANpkgs:
  - survivalsvm
  - kernlab
  - pracma
  - quadprog
  - Matrix
  - randomForestSRC
  - mboost
  - mlr
  - ggplot2
  - tikzDevice
  CTV_rev:
  - MachineLearning
  - Multivariate
  - NumericalMathematics
  - Optimization
  - Survival
  - Cluster
  - DifferentialEquations
  - Econometrics
  - Graphics
  - HighPerformanceComputing
  - NaturalLanguageProcessing
  - Phylogenetics
  - ReproducibleResearch
  suppl: 11.2 Kb
  landing: '2018'
  pages:
  - 412
  - 423
- slug: RJ-2018-008
  title: Nonparametric Independence Tests and k-sample Tests for Large Sample Sizes
    Using Package HHG
  bibtitle: |-
    Nonparametric Independence Tests and k-sample Tests for
              Large Sample Sizes Using Package HHG
  author:
  - Barak Brill
  - Yair Heller
  - Ruth Heller
  bibauthor: Barak Brill and Yair Heller and Ruth Heller
  abstract: '  Abstract Nonparametric tests of independence and k-sample tests are
    ubiquitous in modern applica           tions, but they are typically computationally
    expensive. We present a family of nonparametric tests            that are computationally
    efficient and powerful for detecting any type of dependence between a pair            of
    univariate random variables. The computational complexity of the suggested tests
    is sub-quadratic            in sample size, allowing calculation of test statistics
    for millions of observations. We survey both            algorithms and the HHG
    package in which they are implemented, with usage examples showing            the
    implementation of the proposed tests for both the independence case and the k-sample
    problem.            The tests are compared to existing nonparametric tests via
    several simulation studies comparing both            runtime and power. Special
    focus is given to the design of data structures used in implementation of            the
    tests. These data structures can be useful for developers of nonparametric distribution-free
    tests.'
  acknowledged: '2017-10-23'
  online: '2018-05-16'
  CRANpkgs:
  - Hmisc
  - infotheo
  - entropy
  - minerva
  - dHSIC
  - energy
  - HHG
  - kernlab
  - dslice
  - rbenchmark
  - doRNG
  BIOpkgs: minet
  CTV_rev:
  - Multivariate
  - Bayesian
  - ClinicalTrials
  - Cluster
  - Econometrics
  - HighPerformanceComputing
  - MachineLearning
  - NaturalLanguageProcessing
  - OfficialStatistics
  - Optimization
  - ReproducibleResearch
  - SocialSciences
  suppl: 20.8 Kb
  landing: '2018'
  pages:
  - 424
  - 438
- slug: RJ-2018-009
  title: 'Simple Features for R: Standardized Support for Spatial Vector Data'
  bibtitle: |-
    Simple Features for R: Standardized Support for Spatial
              Vector Data
  author: Edzer Pebesma
  bibauthor: Edzer Pebesma
  abstract: '  Abstract Simple features are a standardized way of encoding spatial
    vector data (points, lines,            polygons) in computers. The sf package
    implements simple features in R, and has roughly the same            capacity
    for spatial vector data as packages sp, rgeos, and rgdal. We describe the need
    for this package,            its place in the R package ecosystem, and its potential
    to connect R to other computer systems. We            illustrate this with examples
    of its use.'
  acknowledged: '2017-11-05'
  online: '2018-05-16'
  CRANpkgs:
  - sf
  - sp
  - rgdal
  - rgeos
  - tidyverse
  - dplyr
  - ggplot2
  - lwgeom
  - geosphere
  - s2
  - raster
  - Rcpp
  CTV_rev:
  - Spatial
  - SpatioTemporal
  - Graphics
  - HighPerformanceComputing
  - ModelDeployment
  - NumericalMathematics
  - Phylogenetics
  suppl: 775 bytes
  landing: '2018'
  pages:
  - 439
  - 446
- slug: RJ-2018-010
  title: 'Pstat: An R Package to Assess Population Differentiation in Phenotypic Traits'
  bibtitle: |-
    Pstat: An R Package to Assess Population Differentiation in
              Phenotypic Traits
  author:
  - Stéphane Blondeau Da Silva
  - Anne Da Silva
  bibauthor: Stéphane Blondeau Da Silva and Anne Da Silva
  abstract: '  Abstract The package Pstat calculates PST values to assess differentiation
    among populations from            a set of quantitative traits and provides bootstrapped
    distributions and confidence intervals for PST .            Variations of PST
    as a function of the parameter c/h2 are studied as well. The package implements            different
    transformations of the measured phenotypic traits to eliminate variation resulting
    from            allometric growth, including calculation of residuals from linear
    regression, Reist standardization, and            the Aitchison transformation.'
  acknowledged: '2017-11-05'
  online: '2018-05-16'
  CRANpkgs:
  - Pstat
  - diveRsity
  - hierfstat
  CTV_rev: Genetics
  suppl: 4 Kb
  landing: '2018'
  pages:
  - 447
  - 454
- slug: RJ-2018-037
  title: 'Collections in R: Review and Proposal'
  bibtitle: 'Collections in R: Review and Proposal'
  author: Timothy Barry
  bibauthor: Timothy Barry
  abstract: '  Abstract R is a powerful tool for data processing, visualization, and
    modeling. However, R is slower            than other languages used for similar
    purposes, such as Python. One reason for this is that R lacks            base
    support for collections, abstract data types that store, manipulate, and return
    data (e.g., sets,            maps, stacks). An exciting recent trend in the R
    extension ecosystem is the development of collection            packages, packages
    that provide classes that implement common collections. At least 12 collection            packages
    are available across the two major R extension repositories, the Comprehensive
    R Archive            Network (CRAN) and Bioconductor. In this article, we compare
    collection packages in terms of their            features, design philosophy,
    ease of use, and performance on benchmark tests. We demonstrate that,            when
    used well, the data structures provided by collection packages are in many cases
    significantly            faster than the data structures provided by base R. We
    also highlight current deficiencies among            R collection packages and
    propose avenues of possible improvement. This article provides useful            recommendations
    to R programmers seeking to speed up their programs and aims to inform the            development
    of future collection-oriented software for R.'
  acknowledged: '2017-11-05'
  online: '2018-06-13'
  CRANpkgs:
  - Rcpp
  - hashr
  - hashFunction
  - filehashSQLite
  - tictoc
  - DSL
  - bit64
  - bit
  - Oarray
  - sets
  - filehash
  - hash
  - hashmap
  - rstackdeque
  - rstack
  - liqueueR
  - dequer
  - flifo
  - listenv
  - stdvectors
  - microbenchmark
  - neuroim
  - FindMinIC
  BIOpkgs: S4Vectors
  CTV_rev:
  - HighPerformanceComputing
  - MedicalImaging
  - NumericalMathematics
  landing: '2018'
  pages:
  - 455
  - 471
- slug: RJ-2018-011
  title: Approximating the Sum of Independent Non-Identical Binomial Random Variables
  bibtitle: |-
    Approximating the Sum of Independent Non-Identical Binomial
              Random Variables
  author:
  - Boxiang Liu
  - Thomas Quertermous
  bibauthor: Boxiang Liu and Thomas Quertermous
  abstract: '  Abstract The distribution of the sum of independent non-identical binomial
    random variables is            frequently encountered in areas such as genomics,
    healthcare, and operations research. Analytical            solutions for the density
    and distribution are usually cumbersome to find and difficult to compute.            Several
    methods have been developed to approximate the distribution, among which is the
    saddlepoint            approximation. However, implementation of the saddlepoint
    approximation is non-trivial. In this            paper, we implement the saddlepoint
    approximation in the sinib package and provide two examples            to illustrate
    its usage. One example uses simulated data while the other uses real-world healthcare
    data.            The sinib package addresses the gap between the theory and the
    implementation of approximating            the sum of independent non-identical
    binomials.'
  acknowledged: '2017-12-05'
  online: '2018-05-16'
  CRANpkgs:
  - stats
  - EQL
  - sinib
  suppl: 1.9 Kb
  landing: '2018'
  pages:
  - 472
  - 483
- slug: RJ-2018-012
  title: 'cchs: An R Package for Stratified Case-Cohort Studies'
  bibtitle: 'cchs: An R Package for Stratified Case-Cohort Studies'
  author: Edmund Jones
  bibauthor: Edmund Jones
  abstract: '  Abstract The cchs package contains a function, also called cchs, for
    analyzing data from a stratified            case-cohort study, as used in epidemiology.
    For data from this type of study, cchs calculates Estimator            III of
    Borgan et al. (2000), which is a score-unbiased estimator for the regression coefficients
    in the            Cox proportional hazards model. From the user’s point of view,
    the function is similar to coxph            (in the survival package) and other
    widely used model-fitting functions. Convenient software has            not previously
    been available for Estimator III since it is complicated to calculate. SAS and
    S-Plus            code-fragments for the calculation have been published, but
    cchs is easier to use and more efficient            in terms of time and memory,
    and can cope with much larger datasets. It also avoids several minor            approximations
    and simplifications.'
  acknowledged: '2017-12-28'
  online: '2018-05-16'
  CRANpkgs:
  - cchs
  - survival
  - cchs
  - survival
  - survey
  - NestedCohort
  CTV_rev:
  - Survival
  - SocialSciences
  - ClinicalTrials
  - Econometrics
  - OfficialStatistics
  suppl: 1.3 Kb
  landing: '2018'
  pages:
  - 484
  - 494
- slug: RJ-2018-036
  title: Small Area Disease Risk Estimation and Visualization Using R
  bibtitle: Small Area Disease Risk Estimation and Visualization Using R
  author: Paula Moraga
  bibauthor: Paula Moraga
  abstract: '  Abstract Small area disease risk estimation is essential for disease
    prevention and control. In this            paper, we demonstrate how R can be
    used to obtain disease risk estimates and quantify risk factors            using
    areal data. We explain how to define disease risk models and how to perform Bayesian
    inference            using the INLA package. We also show how to make interactive
    maps of estimates using the leaflet            package to better understand the
    disease spatial patterns and communicate the results. We show an            example
    of lung cancer risk in Pennsylvania, United States, in year 2002, and demonstrate
    that R            represents an excellent tool for disease surveillance by enabling
    reproducible health data analysis.'
  acknowledged: '2018-02-03'
  online: '2018-06-07'
  CRANpkgs:
  - leaflet
  - SpatialEpi
  - spdep
  - ggplot2
  - flexdashboard
  - shiny
  - SpatialEpiApp
  - dygraphs
  - DT
  - rmarkdown
  CTV_rev:
  - ReproducibleResearch
  - Spatial
  - Econometrics
  - Graphics
  - Phylogenetics
  - TimeSeries
  - WebTechnologies
  suppl: 1.7 Kb
  landing: '2018'
  pages:
  - 495
  - 506
- slug: RJ-2018-031
  title: 'SetMethods: an Add-on R Package for Advanced QCA'
  bibtitle: 'SetMethods: an Add-on R Package for Advanced QCA'
  author:
  - Ioana-Elena Oana
  - Carsten Q. Schneider
  bibauthor: Ioana-Elena Oana and Carsten Q. Schneider
  abstract: '  Abstract This article presents the functionalities of the R package
    SetMethods, aimed at performing            advanced set-theoretic analyses. This
    includes functions for performing set-theoretic multi-method            research,
    set-theoretic theory evaluation, Enhanced Standard Analysis, diagnosing the impact
    of            temporal, spatial, or substantive clusterings of the data on the
    results obtained via Qualitative Com           parative Analysis (QCA), indirect
    calibration, and visualising QCA results via XY plots or radar charts.            Each
    functionality is presented in turn, the conceptual idea and the logic behind the
    procedure being            first summarized, and afterwards illustrated with data
    from Schneider et al. (2010).'
  acknowledged: '2018-02-02'
  online: '2018-05-21'
  CRANpkgs:
  - QCA
  - SetMethods
  suppl: 5.5 Kb
  landing: '2018'
  pages:
  - 507
  - 533
- slug: RJ-2018-032
  title: 'HRM: An R Package for Analysing High-dimensional Multi-factor Repeated Measures'
  bibtitle: |-
    HRM: An R Package for Analysing High-dimensional Multi-
              factor Repeated Measures
  author:
  - Martin Happ
  - Solomon W. Harrar
  - Arne C. Bathke
  bibauthor: Martin Happ and Solomon W. Harrar and Arne C. Bathke
  abstract: '  Abstract High-dimensional longitudinal data pose a serious challenge
    for statistical inference as many            test statistics cannot be computed
    for high-dimensional data, or they do not maintain the nominal            type-I
    error rate, or have very low power. Therefore, it is necessary to derive new inference
    methods            capable of dealing with high dimensionality, and to make them
    available to statistics practitioners.            One such method is implemented
    in the package HRM described in this article. This new method            uses
    a similar approach as the Welch-Satterthwaite t-test approximation and works very
    well for            high-dimensional data as long as the data distribution is
    not too skewed or heavy-tailed. The package            also provides a GUI to
    offer an easy way to apply the methods.'
  acknowledged: '2018-03-02'
  online: '2018-05-21'
  CRANpkgs:
  - HRM
  - ggplot2
  - data.table
  - RGtk2
  - RGtk2Extras
  - cairoDevice
  - xtable
  - longitudinal
  - MANOVA.RM
  CTV_rev:
  - Graphics
  - Finance
  - HighPerformanceComputing
  - Phylogenetics
  - ReproducibleResearch
  landing: '2018'
  pages:
  - 534
  - 548
- heading: News and Notes
- slug: erums
  author: Gergely Daróczi
  title: 'Conference Report: eRum 2018'
  bibtitle: 'Conference Report: eRum 2018'
  bibauthor: Gergely Daróczi
  pages:
  - 549
  - 550
- slug: rday
  author:
  - Fernando P. Mayer
  - Walmes M. Zeviani
  - Wagner H. Bonat
  - Elias T. Krainski
  - Paulo J. Ribeiro Jr           About
  title: R Day report
  bibtitle: R Day report
  bibauthor: |-
    Fernando P. Mayer and Walmes M. Zeviani and Wagner H. Bonat
              and Elias T. Krainski and Paulo J. Ribeiro Jr About
  pages:
  - 551
  - 554
- slug: foundation
  author: Torsten Hothorn
  title: R Foundation News
  bibtitle: R Foundation News
  bibauthor: Torsten Hothorn
  pages:
  - 555
  - 555
- slug: cran
  author:
  - Kurt Hornik
  - Uwe Ligges
  - Achim Zeileis
  title: Changes on CRAN
  bibtitle: Changes on CRAN
  bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
  pages:
  - 556
  - 559
- slug: bioc
  author: Bioconductor Core Team
  title: News from the Bioconductor Project
  bibtitle: News from the Bioconductor Project
  bibauthor: Bioconductor Core Team
  pages:
  - 560
  - 560
- slug: ch
  author: R Core Team
  title: Changes in R
  bibtitle: Changes in R
  bibauthor: R Core Team
  pages:
  - 561
  - 570
