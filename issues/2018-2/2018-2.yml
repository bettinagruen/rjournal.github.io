issue: 2018-2
year: 2018
volume: 10
num: 2
month: Dec.
bibmonth: dec
articles:
- slug: editorial
  cat: Editorial
  author: John Verzani
  title: Editorial
  bibtitle: Editorial
  bibauthor: John Verzani
  pages:
  - 4
  - 5
- heading: Contributed Research Articles
- slug: RJ-2018-053
  title: 'stplanr: A Package for Transport Planning'
  bibtitle: 'stplanr: A Package for Transport Planning'
  author:
  - Robin Lovelace
  - Richard Ellison
  bibauthor: Robin Lovelace and Richard Ellison
  abstract: '  Abstract Tools for transport planning should be flexible, scalable,
    and transparent. The stplanr            package demonstrates and provides a home
    for such tools, with an emphasis on spatial transport            data and non-motorized
    modes. The stplanr package facilitates common transport planning tasks            including:
    downloading and cleaning transport datasets; creating geographic “desire lines”
    from            origin-destination (OD) data; route assignment, locally and interfaces
    to routing services such as            CycleStreets.net; calculation of route
    segment attributes such as bearing and aggregate flow; and           ‘travel watershed’
    analysis. This paper demonstrates this functionality using reproducible examples            on
    real transport datasets. More broadly, the experience of developing and using
    R functions for            transport applications shows that open source software
    can form the basis of a reproducible transport            planning workflow. The
    stplanr package, alongside other packages and open source projects, could            provide
    a more transparent and democratically accountable alternative to the current approach,
    which            is heavily reliant on proprietary and relatively inaccessible
    software.'
  acknowledged: '2017-03-22'
  online: '2018-12-08'
  CRANpkgs:
  - sp
  - rgeos
  - rgdal
  - sf
  - SpatialEpi
  - diseasemapping
  - leaflet
  - tmap
  - mapview
  - mapmisc
  - XML
  - twitteR
  - ggplot2
  - muStat
  - mgcv
  - shiny
  - haven
  - rio
  - dplyr
  - osmdata
  - stats19
  - bikedata
  - stplanr
  - nycflights
  - nycflights13
  - cyclestreets
  - igraph
  - Rcpp
  - aspace
  - MCI
  CTV_rev:
  - Spatial
  - WebTechnologies
  - Graphics
  - OfficialStatistics
  - SpatioTemporal
  - Bayesian
  - Databases
  - Econometrics
  - Environmetrics
  - gR
  - HighPerformanceComputing
  - ModelDeployment
  - NumericalMathematics
  - Optimization
  - Phylogenetics
  - SocialSciences
  suppl: 2.6 Kb
  landing: '2018'
  pages:
  - 7
  - 23
- slug: RJ-2018-041
  title: 'The utiml Package: Multi-label Classification in R'
  bibtitle: 'The utiml Package: Multi-label Classification in R'
  author:
  - Adriano Rivolli
  - Andre C. P. L. F. de Carvalho
  bibauthor: Adriano Rivolli and Andre C. P. L. F. de Carvalho
  abstract: '  Abstract Learning classification tasks in which each instance is associated
    with one or more labels            are known as multi-label learning. The implementation
    of multi-label algorithms, performed by            different researchers, have
    several specificities, like input/output format, different internal functions,            distinct
    programming language, to mention just some of them. As a result, current machine
    learning            tools include only a small subset of multi-label decomposition
    strategies. The utiml package is a            framework for the application of
    classification algorithms to multi-label data. Like the well known            MULAN
    used with Weka, it provides a set of multi-label procedures such as sampling methods,            transformation
    strategies, threshold functions, pre-processing techniques and evaluation metrics.
    The            package was designed to allow users to easily perform complete
    multi-label classification experiments            in the R environment. This paper
    describes the utiml API and illustrates its use in different multi-label            classification
    scenarios.'
  acknowledged: '2017-04-07'
  online: '2018-08-17'
  CRANpkgs:
  - mldr
  - mlr
  - MLPUGS
  - utiml
  - randomForest
  - C50
  - e1071
  - parallel
  CTV_rev:
  - MachineLearning
  - Environmetrics
  - Cluster
  - Distributions
  - MissingData
  - Multivariate
  - Psychometrics
  suppl: 1.3 Kb
  landing: '2018'
  pages:
  - 24
  - 37
- slug: RJ-2018-054
  title: 'rcss: R package for optimal convex stochastic switching'
  bibtitle: 'rcss: R package for optimal convex stochastic switching'
  author:
  - Juri Hinz
  - Jeremy Yee
  bibauthor: Juri Hinz and Jeremy Yee
  abstract: '  Abstract The R package rcss provides users with a tool to approximate
    the value functions in the            Bellman recursion under certain assumptions
    that guarantee desirable convergence properties. This R            package represents
    the first software implementation of these methods using matrices and nearest            neighbors.
    This package also employs a pathwise dynamic method to gauge the quality of these
    value            function approximations. Statistical analysis can be performed
    on the results to obtain other useful            practical insights. This paper
    describes rcss version 1.6.'
  acknowledged: '2017-04-27'
  online: '2018-12-08'
  CRANpkgs:
  - rcss
  - Rcpp
  - OpenMp
  CTV_rev:
  - HighPerformanceComputing
  - NumericalMathematics
  suppl: 1.8 Kb
  landing: '2018'
  pages:
  - 38
  - 54
- slug: RJ-2018-043
  title: 'nsROC: An R package for Non-Standard ROC Curve Analysis'
  bibtitle: 'nsROC: An R package for Non-Standard ROC Curve Analysis'
  author:
  - Sonia Pérez-Fernández
  - Pablo Martínez-Camblor
  - Peter Filzmoser
  - Norberto Corral
  bibauthor: |-
    Sonia Pérez-Fernández and Pablo Martínez-Camblor and Peter
              Filzmoser and Norberto Corral
  abstract: ' Abstract The receiver operating characteristic (ROC) curve is a graphical
    method which           has become standard in the analysis of diagnostic markers,
    that is, in the study of the           classification ability of a numerical variable.
    Most of the commercial statistical software           provide routines for the
    standard ROC curve analysis. Of course, there are also many R           packages
    dealing with the ROC estimation as well as other related problems. In this work           we
    introduce the nsROC package which incorporates some new ROC curve procedures.           Particularly:
    ROC curve comparison based on general distances among functions for both           paired
    and unpaired designs; efficient confidence bands construction; a generalization
    of the           curve considering different classification subsets than the one
    involved in the classical defini          tion of the ROC curve; a procedure to
    deal with censored data in cumulative-dynamic ROC           curve estimation for
    time-to-event outcomes; and a non-parametric ROC curve method for           meta-analysis.
    This is the only R package which implements these particular procedures.'
  acknowledged: '2017-06-27'
  online: '2018-08-17'
  CRANpkgs:
  - pROC
  - ROCR
  - plotROC
  - fbroc
  - OptimalCutpoints
  - timeROC
  - survivalROC
  - HSROC
  - nsROC
  - sde
  - tdROC
  - survival
  CTV_rev:
  - Survival
  - ClinicalTrials
  - DifferentialEquations
  - Econometrics
  - Finance
  - MachineLearning
  - Multivariate
  - SocialSciences
  - TimeSeries
  suppl: 1.4 Kb
  landing: '2018'
  pages:
  - 55
  - 77
- slug: RJ-2018-055
  title: 'addhaz: Contribution of Chronic Diseases to the Disability Burden Using
    R'
  bibtitle: |-
    addhaz: Contribution of Chronic Diseases to the Disability
              Burden Using R
  author:
  - Renata Tiene de Carvalho Yokota
  - Caspar WN Looman
  - Wilma Johanna Nusselder
  - Herman Van            Oyen
  - Geert Molenberghs
  bibauthor: |-
    Renata Tiene de Carvalho Yokota and Caspar WN Looman and
              Wilma Johanna Nusselder and Herman Van Oyen and Geert
              Molenberghs
  abstract: '  Abstract The increase in life expectancy followed by the burden of
    chronic diseases contributes to            disability at older ages. The estimation
    of how much chronic conditions contribute to disability can be            useful
    to develop public health strategies to reduce the burden. This paper introduces
    the R package            addhaz, which is based on the attribution method (Nusselder
    and Looman, 2004) to partition disability            into the additive contributions
    of diseases using cross-sectional data. The R package includes tools to            fit
    the additive hazard model, the core of the attribution method, to binary and multinomial
    outcomes.            The models are fitted by maximizing the binomial and multinomial
    log-likelihood functions using            constrained optimization. Wald and bootstrap
    confidence intervals can be obtained for the parameter            estimates. Also,
    the contribution of diseases to the disability prevalence and their bootstrap
    confidence            intervals can be estimated. An additional feature is the
    possibility to use parallel computing to obtain            the bootstrap confidence
    intervals. In this manuscript, we illustrate the use of addhaz with several            examples
    for the binomial and multinomial models, using the data from the Brazilian National
    Health            Survey, 2013.'
  acknowledged: '2017-08-05'
  online: '2018-12-08'
  CRANpkgs:
  - addhaz
  - boot
  - stats
  - logbin
  - VGAM
  CTV_rev:
  - Econometrics
  - SocialSciences
  - Survival
  - Distributions
  - Environmetrics
  - ExtremeValue
  - Multivariate
  - Optimization
  - Psychometrics
  - TimeSeries
  suppl: 1.5 Kb
  landing: '2018'
  pages:
  - 75
  - 94
- slug: RJ-2018-056
  title: 'Snowboot: Bootstrap Methods for Network Inference'
  bibtitle: 'Snowboot: Bootstrap Methods for Network Inference'
  author:
  - Yuzhou Chen
  - Yulia R. Gel
  - Vyacheslav Lyubchich
  - Kusha Nezafati
  bibauthor: |-
    Yuzhou Chen and Yulia R. Gel and Vyacheslav Lyubchich and
              Kusha Nezafati
  abstract: '  Abstract Complex networks are used to describe a broad range of disparate
    social systems and natural            phenomena, from power grids to customer
    segmentation to human brain connectome. Challenges            of parametric model
    specification and validation inspire a search for more data-driven and flexible            nonparametric
    approaches for inference of complex networks. In this paper we discuss methodology            and
    R implementation of two bootstrap procedures on random networks, that is, patchwork
    bootstrap            of Thompson et al. (2016) and Gel et al. (2017) and vertex
    bootstrap of Snijders and Borgatti (1999). To            our knowledge, the new
    R package snowboot is the first implementation of the vertex and patchwork            bootstrap
    inference on networks in R. Our new package is accompanied with a detailed user’s
    manual,            and is compatible with the popular R package on network studies
    igraph. We evaluate the patchwork            bootstrap and vertex bootstrap with
    extensive simulation studies and illustrate their utility in an            application
    to analysis of real world networks.'
  acknowledged: '2017-08-11'
  online: '2018-12-08'
  CRANpkgs:
  - snowboot
  - bootnet
  - sna
  - graphics
  - igraph
  - parallel
  - Rcpp
  - Rdpack
  - stats
  - VGAM
  CTV_rev:
  - Optimization
  - SocialSciences
  - Bayesian
  - Distributions
  - Econometrics
  - Environmetrics
  - ExtremeValue
  - gR
  - Graphics
  - HighPerformanceComputing
  - Multivariate
  - NumericalMathematics
  - Psychometrics
  - Spatial
  - Survival
  suppl: 8.9 Kb
  landing: '2018'
  pages:
  - 95
  - 113
- slug: RJ-2018-044
  title: 'revengc: An R package to Reverse Engineer Summarized Data'
  bibtitle: 'revengc: An R package to Reverse Engineer Summarized Data'
  author:
  - Samantha Duchscherer
  - Robert Stewart
  - Marie Urban
  bibauthor: Samantha Duchscherer and Robert Stewart and Marie Urban
  abstract: '  Abstract Decoupled (e.g. separate averages) and censored (e.g. > 100
    species) variables are continually            reported by many well-established
    organizations, such as the World Health Organization (WHO),            Centers
    for Disease Control and Prevention (CDC), and World Bank. The challenge therefore
    is to infer            what the original data could have been given summarized
    information. We present an R package that            reverse engineers censored
    and/or decoupled data with two main functions. The cnbinom.pars()            function
    estimates the average and dispersion parameter of a censored univariate frequency
    table. The            rec() function reverse engineers summarized data into an
    uncensored bivariate table of probabilities.'
  acknowledged: '2017-08-24'
  online: '2018-12-07'
  CRANpkgs:
  - revengc
  - truncdist
  - mipfp
  CTV_rev: OfficialStatistics
  suppl: 2.1 Kb
  landing: '2018'
  pages:
  - 114
  - 123
- slug: RJ-2018-045
  title: Basis-Adaptive Selection Algorithm in dr-package
  bibtitle: Basis-Adaptive Selection Algorithm in dr-package
  author: Jae Keun Yoo
  bibauthor: Jae Keun Yoo
  abstract: '  Abstract Sufficient dimension reduction (SDR) turns out to be a useful
    dimension reduction tool in            high-dimensional regression analysis. Weisberg
    (2002) developed the dr-package to implement the            four most popular
    SDR methods. However, the package does not provide any clear guidelines as            to
    which method should be used given a data. Since the four methods may provide dramatically            different
    dimension reduction results, the selection in the dr-package is problematic for
    statistical            practitioners. In this paper, a basis-adaptive selection
    algorithm is developed in order to relieve this            issue. The basic idea
    is to select an SDR method that provides the highest correlation between the basis            estimates
    obtained by the four classical SDR methods. A real data example and numerical
    studies            confirm the practical usefulness of the developed algorithm.'
  acknowledged: '2017-08-24'
  online: '2018-12-07'
  CRANpkgs: dr
  CTV_rev:
  - Multivariate
  - SocialSciences
  suppl: 2.2 Kb
  landing: '2018'
  pages:
  - 124
  - 132
- slug: RJ-2018-070
  title: SARIMA Analysis and Automated Model Reports with BETS, an R Package
  bibtitle: |-
    SARIMA Analysis and Automated Model Reports with BETS, an R
              Package
  author:
  - Talitha F. Speranza
  - Pedro C. Ferreira
  - Jonatha A. da Costa
  bibauthor: |-
    Talitha F. Speranza and Pedro C. Ferreira and Jonatha A. da
              Costa
  abstract: '  Abstract This article aims to demonstrate how the powerful features
    of the R package BETS can be            applied to SARIMA time series analysis.
    BETS provides not only thousands of Brazilian economic            time series
    from different institutions, but also a range of analytical tools, and educational
    resources.            In particular, BETS is capable of generating automated model
    reports for any given time series. These            reports rely on a single function
    call and are able to build three types of models (SARIMA being one of            them).
    The functions need few inputs and output rich content. The output varies according
    to the            inputs and usually consists of a summary of the series properties,
    step-by-step explanations on how            the model was developed, predictions
    made by the model, and a file containing these predictions. This            work
    focuses on this feature and several other BETS functions that are designed to
    help in modeling            time series. We present them in a thorough case study:
    the SARIMA approach to model and forecast            the Brazilian production
    of intermediate goods index series.'
  acknowledged: '2017-09-13'
  online: '2018-12-11'
  CRANpkgs:
  - BETS
  - forecast
  - mFilter
  - urca
  - seasonal
  - httr
  - rvest
  - RMySQL
  - rmarkdown
  - stats
  - dygraphs
  CTV_rev:
  - TimeSeries
  - Econometrics
  - Finance
  - WebTechnologies
  - Databases
  - Environmetrics
  - MissingData
  - OfficialStatistics
  - ReproducibleResearch
  landing: '2018'
  pages:
  - 133
  - 147
- slug: RJ-2018-046
  title: 'fICA: FastICA Algorithms and Their Improved Variants'
  bibtitle: 'fICA: FastICA Algorithms and Their Improved Variants'
  author:
  - Jari Miettinen
  - Klaus Nordhausen
  - Sara Taskinen
  bibauthor: Jari Miettinen and Klaus Nordhausen and Sara Taskinen
  abstract: '  Abstract In independent component analysis (ICA) one searches for mutually
    independent non           gaussian latent variables when the components of the
    multivariate data are assumed to be linear            combinations of them. Arguably,
    the most popular method to perform ICA is FastICA. There are            two classical
    versions, the deflation-based FastICA where the components are found one by one,
    and            the symmetric FastICA where the components are found simultaneously.
    These methods have been            implemented previously in two R packages, fastICA
    and ica. We present the R package fICA and            compare it to the other
    packages. Additional features in fICA include optimization of the extraction            order
    in the deflation-based version, possibility to use any nonlinearity function,
    and improvement to            convergence of the deflation-based algorithm. The
    usage of the package is demonstrated by applying            it to the real ECG
    data of a pregnant woman.'
  acknowledged: '2017-09-21'
  online: '2018-12-07'
  CRANpkgs:
  - fastICA
  - ica
  - fICA
  - BSSasymp
  CTV_rev:
  - Psychometrics
  - ChemPhys
  - Multivariate
  suppl: 1.1 Kb
  landing: '2018'
  pages:
  - 148
  - 158
- slug: RJ-2018-040
  title: Profile Likelihood Estimation of the Correlation Coefficient in the Presence
    of Left, Right or Interval Censoring and Missing Data
  bibtitle: |-
    Profile Likelihood Estimation of the Correlation Coefficient
              in the Presence of Left, Right or Interval Censoring and
              Missing Data
  author:
  - Yanming Li
  - Brenda W. Gillespie
  - Kerby Shedden
  - John A. Gillespie
  bibauthor: |-
    Yanming Li and Brenda W. Gillespie and Kerby Shedden and
              John A. Gillespie
  abstract: '  Abstract We discuss implementation of a profile likelihood method for
    estimating a Pearson correla           tion coefficient from bivariate data with
    censoring and/or missing values. The method is implemented            in an R
    package clikcorr which calculates maximum likelihood estimates of the correlation
    coefficient            when the data are modeled with either a Gaussian or a Student
    t-distribution, in the presence of left,            right, or interval censored
    and/or missing data. The R package includes functions for conducting            inference
    and also provides graphical functions for visualizing the censored data scatter
    plot and            profile log likelihood function. The performance of clikcorr
    in a variety of circumstances is evaluated            through extensive simulation
    studies. We illustrate the package using two dioxin exposure datasets.'
  acknowledged: '2017-10-01'
  online: '2018-08-17'
  CRANpkgs:
  - clikcorr
  - survival
  - mvtnorm
  CTV_rev:
  - ClinicalTrials
  - Distributions
  - Econometrics
  - Finance
  - Multivariate
  - SocialSciences
  - Survival
  suppl: 3 Kb
  landing: '2018'
  pages:
  - 159
  - 179
- slug: RJ-2018-047
  title: Spatial Uncertainty Propagation Analysis with the spup R Package
  bibtitle: |-
    Spatial Uncertainty Propagation Analysis with the spup R
              Package
  author:
  - Kasia Sawicka
  - Gerard B.M. Heuvelink
  - Dennis J.J. Walvoort
  bibauthor: |-
    Kasia Sawicka and Gerard B.M. Heuvelink and Dennis J.J.
              Walvoort
  abstract: '  Abstract Many environmental and geographical models, such as those
    used in land degradation, agro           ecological and climate studies, make
    use of spatially distributed inputs that are known imperfectly.            The
    R package spup provides functions for examining the uncertainty propagation from
    input data            and model parameters onto model outputs via the environmental
    model. The functions include            uncertainty model specification, stochastic
    simulation and propagation of uncertainty using Monte            Carlo (MC) techniques.
    Uncertain variables are described by probability distributions. Both numerical            and
    categorical data types are handled. The package also accommodates spatial auto-correlation            within
    a variable and cross-correlation between variables. The MC realizations may be
    used as input            to the environmental models written in or called from
    R. This article provides theoretical background            and three worked examples
    that guide users through the application of spup.'
  acknowledged: '2017-10-03'
  online: '2018-12-07'
  CRANpkgs:
  - propagate
  - errors
  - metRology
  - spup
  - gstat
  - stats
  - mvtnorm
  - whisker
  - shiny
  CTV_rev:
  - ChemPhys
  - WebTechnologies
  - Distributions
  - Finance
  - Multivariate
  - Spatial
  - SpatioTemporal
  suppl: 3.3 Kb
  landing: '2018'
  pages:
  - 180
  - 199
- slug: RJ-2018-048
  title: 'clustMixType: User-Friendly Clustering of Mixed-Type Data in R'
  bibtitle: |-
    clustMixType: User-Friendly Clustering of Mixed-Type Data in
              R
  author: Gero Szepannek
  bibauthor: Gero Szepannek
  abstract: '  Abstract Clustering algorithms are designed to identify groups in data
    where the traditional emphasis            has been on numeric data. In consequence,
    many existing algorithms are devoted to this kind of            data even though
    a combination of numeric and categorical data is more common in most business            applications.
    Recently, new algorithms for clustering mixed-type data have been proposed based
    on            Huang’s k-prototypes algorithm. This paper describes the R package
    clustMixType which provides            an implementation of k-prototypes in R.'
  acknowledged: '2017-10-30'
  online: '2018-12-07'
  CRANpkgs:
  - gower
  - cluster
  - CluMix
  - flexclust
  - fpc
  - clustMD
  - kamila
  - clustMixType
  - klaR
  - wesanderson
  - clusteval
  CTV_rev:
  - Cluster
  - Multivariate
  - Environmetrics
  - Graphics
  - MachineLearning
  - Robust
  suppl: 1.1 Kb
  landing: '2018'
  pages:
  - 200
  - 208
- slug: RJ-2018-049
  title: 'Stilt: Easy Emulation of Time Series AR(1) Computer Model Output in Multidimensional
    Parameter Space'
  bibtitle: |-
    Stilt: Easy Emulation of Time Series AR(1) Computer Model
              Output in Multidimensional Parameter Space
  author:
  - Roman Olson
  - Kelsey L. Ruckert
  - Won Chang
  - Klaus Keller
  - Murali Haran
  - Soon-Il An
  bibauthor: |-
    Roman Olson and Kelsey L. Ruckert and Won Chang and Klaus
              Keller and Murali Haran and Soon-Il An
  abstract: '  Abstract Statistically approximating or “emulating” time series model
    output in parameter space is a            common problem in climate science and
    other fields. There are many packages for spatio-temporal            modeling.
    However, they often lack focus on time series, and exhibit statistical complexity.
    Here, we            present the R package stilt designed for simplified AR(1)
    time series Gaussian process emulation,            and provide examples relevant
    to climate modelling. Notably absent is Markov chain Monte Carlo            estimation
    – a challenging concept to many scientists. We keep the number of user choices
    to a            minimum. Hence, the package can be useful pedagogically, while
    still applicable to real life emulation            problems. We provide functions
    for emulator cross-validation, empirical coverage, prediction, as well            as
    response surface plotting. While the examples focus on climate model emulation,
    the emulator is            general and can be also used for kriging spatio-temporal
    data.'
  acknowledged: '2017-11-16'
  online: '2018-12-07'
  CRANpkgs:
  - gstat
  - mlegp
  - spBayes
  - ramps
  - spTimer
  - RandomFields
  - stilt
  - fields
  - maps
  - spam
  - dotCall64
  CTV_rev:
  - Spatial
  - SpatioTemporal
  - Bayesian
  - Multivariate
  - TimeSeries
  suppl: 1.4 Kb
  landing: '2018'
  pages:
  - 209
  - 225
- slug: RJ-2018-050
  title: 'SMM: An R Package for Estimation and Simulation of Discrete-time semi-Markov
    Models'
  bibtitle: |-
    SMM: An R Package for Estimation and Simulation of Discrete-
              time semi-Markov Models
  author:
  - Vlad Stefan Barbu
  - Caroline Bérard
  - Dominique Cellier
  - Mathilde Sautreuil
  - Nicolas Vergne
  bibauthor: |-
    Vlad Stefan Barbu and Caroline Bérard and Dominique Cellier
              and Mathilde Sautreuil and Nicolas Vergne
  abstract: '  Abstract Semi-Markov models, independently introduced by Lévy (1954),
    Smith (1955) and Takacs            (1954), are a generalization of the well-known
    Markov models. For semi-Markov models, sojourn            times can be arbitrarily
    distributed, while sojourn times of Markov models are constrained to be            exponentially
    distributed (in continuous time) or geometrically distributed (in discrete time).
    The aim            of this paper is to present the R package SMM, devoted to the
    simulation and estimation of discrete           time multi-state semi-Markov and
    Markov models. For the semi-Markov case we have considered:            parametric
    and non-parametric estimation; with and without censoring at the beginning and/or
    at the            end of sample paths; one or several independent sample paths.
    Several discrete-time distributions            are considered for the parametric
    estimation of sojourn time distributions of semi-Markov chains:            Uniform,
    Geometric, Poisson, Discrete Weibull and Binomial Negative.'
  acknowledged: '2017-11-28'
  online: '2018-12-07'
  CRANpkgs:
  - SMM
  - semiMarkov
  - hsmm
  - mhsmm
  landing: '2018'
  pages:
  - 226
  - 247
- slug: RJ-2018-051
  title: ggplot2 Compatible Quantile-Quantile Plots in R
  bibtitle: ggplot2 Compatible Quantile-Quantile Plots in R
  author:
  - Alexandre Almeida
  - Adam Loy
  - Heike Hofmann
  bibauthor: Alexandre Almeida and Adam Loy and Heike Hofmann
  abstract: ' Abstract Q-Q plots allow us to assess univariate distributional assumptions
    by comparing a set of           quantiles from the empirical and the theoretical
    distributions in the form of a scatterplot. To aid in           the interpretation
    of Q-Q plots, reference lines and confidence bands are often added. We can also           detrend
    the Q-Q plot so the vertical comparisons of interest come into focus. Various
    implementations           of Q-Q plots exist in R, but none implements all of
    these features. qqplotr extends ggplot2 to provide           a complete implementation
    of Q-Q plots. This paper introduces the plotting framework provided by           qqplotr
    and provides multiple examples of how it can be used.'
  acknowledged: '2017-12-20'
  online: '2018-12-07'
  CRANpkgs:
  - base
  - lattice
  - car
  - ggplot2
  - qqplotr
  - stats
  - robustbase
  - boot
  CTV_rev:
  - Multivariate
  - Econometrics
  - Graphics
  - Robust
  - SocialSciences
  - Finance
  - Optimization
  - Phylogenetics
  - Survival
  - TimeSeries
  suppl: 2.4 Kb
  landing: '2018'
  pages:
  - 248
  - 261
- slug: RJ-2018-052
  title: Forecast Combinations in R using the ForecastComb Package
  bibtitle: Forecast Combinations in R using the ForecastComb Package
  author:
  - Christoph E. Weiss
  - Eran Raviv
  - Gernot Roetzer
  bibauthor: Christoph E. Weiss and Eran Raviv and Gernot Roetzer
  abstract: '  Abstract This paper introduces the R package ForecastComb. The aim
    is to provide researchers and            practitioners with a comprehensive implementation
    of the most common ways in which forecasts can            be combined. The package
    in its current version covers 15 popular estimation methods for creating a            combined
    forecasts – including simple methods, regression-based methods, and eigenvector-based            methods.
    It also includes useful tools to deal with common challenges of forecast combination
    (e.g.,            missing values in component forecasts, or multicollinearity),
    and to rationalize and visualize the            combination results.'
  acknowledged: '2017-12-20'
  online: '2018-12-07'
  CRANpkgs:
  - BMA
  - opera
  - forecastHybrid
  - ForecastCombinations
  - GeomComb
  - quadprog
  - mtsdi
  - forecTheta
  CTV_rev:
  - TimeSeries
  - Bayesian
  - Econometrics
  - OfficialStatistics
  - Optimization
  - SocialSciences
  - Survival
  suppl: 1.2 Kb
  landing: '2018'
  pages:
  - 262
  - 281
- slug: RJ-2018-057
  title: 'testforDEP: An R Package for Modern Distribution-free Tests and Visualization
    Tools for Independence'
  bibtitle: |-
    testforDEP: An R Package for Modern Distribution-free Tests
              and Visualization Tools for Independence
  author:
  - Jeffrey C. Miecznikowski
  - En-shuo Hsu
  - Yanhua Chen
  - Albert Vexler
  bibauthor: |-
    Jeffrey C. Miecznikowski and En-shuo Hsu and Yanhua Chen and
              Albert Vexler
  abstract: '  Abstract This article introduces testforDEP, a portmanteau R package
    implementing for the first            time several modern tests and visualization
    tools for independence between two variables. While            classical tests
    for independence are in the base R packages, there have been several recently
    developed            tests for independence that are not available in R. This
    new package combines the classical tests            including Pearson’s product
    moment correlation coefficient method, Kendall’s τ rank correlation            coefficient
    method and Spearman’s ρ rank correlation coefficient method with modern tests
    consisting            of an empirical likelihood based test, a density-based empirical
    likelihood ratio test, Kallenberg data           driven test, maximal information
    coefficient test, Hoeffding’s independence test and the continuous            analysis
    of variance test. For two input vectors of observations, the function testforDEP
    provides a            common interface for each of the tests and returns test
    statistics, corresponding p values and bootstrap            confidence intervals
    as output. The function AUK provides an interface to visualize Kendall plots and            computes
    the area under the Kendall plot similar to computing the area under a receiver
    operating            characteristic (ROC) curve.'
  acknowledged: '2018-02-02'
  online: '2018-12-08'
  CRANpkgs:
  - testforDEP
  - Hmisc
  - minerva
  CTV_rev:
  - Bayesian
  - ClinicalTrials
  - Econometrics
  - MissingData
  - Multivariate
  - OfficialStatistics
  - ReproducibleResearch
  - SocialSciences
  suppl: 722 bytes
  landing: '2018'
  pages:
  - 282
  - 295
- slug: RJ-2018-059
  title: 'rFSA: An R Package for Finding Best Subsets and Interactions'
  bibtitle: 'rFSA: An R Package for Finding Best Subsets and Interactions'
  author:
  - Joshua Lambert
  - Liyu Gong
  - Corrine F. Elliott
  - Katherine Thompson
  - Arnold Stromberg
  bibauthor: |-
    Joshua Lambert and Liyu Gong and Corrine F. Elliott and
              Katherine Thompson and Arnold Stromberg
  abstract: '  Abstract Herein we present the R package rFSA, which implements an
    algorithm for improved            variable selection. The algorithm searches a
    data space for models of a user-specified form that are            statistically
    optimal under a measure of model quality. Many iterations afford a set of feasible
    solutions            (or candidate models) that the researcher can evaluate for
    relevance to his or her questions of interest.            The algorithm can be
    used to formulate new or to improve upon existing models in bioinformatics,            health
    care, and myriad other fields in which the volume of available data has outstripped
    researchers’            practical and computational ability to explore larger
    subsets or higher-order interaction terms. The            package accommodates
    linear and generalized linear models, as well as a variety of criterion functions            such
    as Allen’s PRESS and AIC. New modeling strategies and criterion functions can
    be adapted easily            to work with rFSA.'
  acknowledged: '2018-03-02'
  online: '2018-12-08'
  CRANpkgs:
  - rFSA
  - leaps
  - glmulti
  - glmnet
  - hierNet
  - hashmap
  - geepack
  - devtools
  CTV_rev:
  - SocialSciences
  - ChemPhys
  - Econometrics
  - MachineLearning
  - Survival
  suppl: 2.3 Kb
  landing: '2018'
  pages:
  - 295
  - 308
- slug: RJ-2018-042
  title: 'Dot-Pipe: an S3 Extensible Pipe for R'
  bibtitle: 'Dot-Pipe: an S3 Extensible Pipe for R'
  author:
  - John Mount
  - Nina Zumel
  bibauthor: John Mount and Nina Zumel
  abstract: '  Abstract Pipe notation is popular with a large league of R users, with
    magrittr being the dominant            realization. However, this should not be
    enough to consider piping in R as a settled topic that is not            subject
    to further discussion, experimentation, or possibility for improvement. To promote
    innovation            opportunities, we describe the wrapr R package and “dot-pipe”
    notation, a well behaved sequencing            operator with S3 extensibility.
    We include a number of examples of using this pipe to interact with            and
    extend other R packages.'
  acknowledged: '2018-03-02'
  online: '2018-08-17'
  CRANpkgs:
  - data.table
  - magrittr
  - dplyr
  - future
  - rmonad
  - pipeR
  - backpipe
  - drake
  - wrapr
  - ggplot2
  - rquery
  CTV_rev:
  - HighPerformanceComputing
  - Databases
  - Finance
  - Graphics
  - ModelDeployment
  - Phylogenetics
  - WebTechnologies
  landing: '2018'
  pages:
  - 309
  - 316
- slug: RJ-2018-081
  title: 'idmTPreg: Regression Model for Progressive Illness Death Data'
  bibtitle: |-
    idmTPreg: Regression Model for Progressive Illness Death
              Data
  author:
  - Leyla Azarang
  - Manuel Oviedo de la Fuente
  bibauthor: Leyla Azarang and Manuel Oviedo de la Fuente
  abstract: '  Abstract The progressive illness-death model is frequently used in
    medical applications. For example,            the model may be used to describe
    the disease process in cancer studies. We have developed a            new R package
    called idmTPreg to estimate regression coefficients in datasets that can be described            by
    the progressive illness-death model. The motivation for the development of the
    package is a            recent contribution that enables the estimation of possibly
    time-varying covariate effects on the            transition probabilities for
    a progressive illness-death data. The main feature of the package is that            it
    befits both non-Markov and Markov progressive illness-death data. The package
    implements the            introduced estimators obtained using a direct binomial
    regression approach. Also, variance estimates            and confidence bands
    are implemented in the package. This article presents guidelines for the use of            the
    package.'
  acknowledged: '2018-03-02'
  online: '2019-02-11'
  CRANpkgs:
  - idmTPreg
  - mstate
  - msm
  - p3state.msm
  - doParallel
  - foreach
  - survival
  CTVs: Survival
  CTV_rev:
  - Survival
  - ClinicalTrials
  - Distributions
  - Econometrics
  - HighPerformanceComputing
  - SocialSciences
  suppl: 422 bytes
  landing: '2018'
  pages:
  - 317
  - 325
- slug: RJ-2018-060
  title: 'lmridge: A Comprehensive R Package for Ridge Regression'
  bibtitle: 'lmridge: A Comprehensive R Package for Ridge Regression'
  author:
  - Muhammad Imdad Ullah
  - Muhammad Aslam
  - Saima Altaf
  bibauthor: Muhammad Imdad Ullah and Muhammad Aslam and Saima Altaf
  abstract: '  Abstract The ridge regression estimator, one of the commonly used alternatives
    to the conventional            ordinary least squares estimator, avoids the adverse
    effects in the situations when there exists some            considerable degree
    of multicollinearity among the regressors. There are many software packages            available
    for estimation of ridge regression coefficients. However, most of them display
    limited            methods to estimate the ridge biasing parameters without testing
    procedures. Our developed package,            lmridge can be used to estimate
    ridge coefficients considering a range of different existing biasing            parameters,
    to test these coefficients with more than 25 ridge related statistics, and to
    present different            graphical displays of these statistics.'
  acknowledged: '2018-03-02'
  online: '2018-12-08'
  CRANpkgs:
  - lmridge
  - ridge
  - MASS
  - lrmest
  - ltsbase
  - penalized
  - glmnet
  - RXshrink
  - rrBLUP
  - RidgeFusion
  - bigRR
  - lpridge
  - genridge
  - CoxRidge
  CTV_rev:
  - MachineLearning
  - Survival
  - Distributions
  - Econometrics
  - Environmetrics
  - Multivariate
  - NumericalMathematics
  - Psychometrics
  - Robust
  - SocialSciences
  suppl: 1.6 Kb
  landing: '2018'
  pages:
  - 326
  - 346
- slug: RJ-2018-061
  title: Geospatial Point Density
  bibtitle: Geospatial Point Density
  author:
  - Paul F. Evangelista
  - David Beskow
  bibauthor: Paul F. Evangelista and David Beskow
  abstract: '  Abstract This paper introduces a spatial point density algorithm designed
    to be explainable, meaning           ful, and efficient. Originally designed for
    military applications, this technique applies to any spatial            point
    process where there is a desire to clearly understand the measurement of density
    and maintain            fidelity of the point locations. Typical spatial density
    plotting algorithms, such as kernel density            estimation, implement some
    type of smoothing function that often results in a density value that is            difficult
    to interpret. The purpose of the visualization method in this paper is to understand
    spatial            point activity density with precision and meaning. The temporal
    tendency of the point process as an            extension of the point density
    methodology is also discussed and displayed. Applications include            visualization
    and measurement of any type of spatial point process. Visualization techniques
    integrate            ggmap with examples from San Diego crime data.'
  acknowledged: '2018-04-04'
  online: '2018-12-08'
  CRANpkgs:
  - pointdensityP
  - spatstat
  - kde2d
  - bkde2D
  - ggplot2
  - ggmap
  - data.table
  CTV_rev:
  - Spatial
  - Finance
  - Graphics
  - HighPerformanceComputing
  - Phylogenetics
  - SpatioTemporal
  - Survival
  - WebTechnologies
  suppl: 3.2 Kb
  landing: '2018'
  pages:
  - 347
  - 356
- slug: RJ-2018-080
  title: 'Consistency Cubes: a fast, efficient method for exact Boolean minimization.'
  bibtitle: |-
    Consistency Cubes: a fast, efficient method for exact
              Boolean minimization.
  author: Adrian Dusa
  bibauthor: Adrian Dusa
  abstract: '  Abstract A lot of effort has been spent over the past few decades in
    the QCA methodology field, to            develop efficient Boolean minimization
    algorithms to derive an exact, and more importantly complete            list of
    minimal prime implicants that explain the initial, observed positive configurations.                 As
    the complexity grows exponentially with every new condition, the required computer
    memory            goes past the current computer resources and the polynomial
    time required to solve this problem            quickly grows towards infinity.                 This
    paper introduces a new alternative to the existing non-polynomial attempts. It
    completely            solves the memory problem, and preliminary tests show it
    is exponentially hundreds of time faster            than eQMC, the current “best”
    algorithm for QCA in R, and probes into a territory where it competes            and
    even outperforms engineering algorithms such as Espresso, for exact minimizations.                 While
    speed is not much of an issue now (eQMC is fast enough for simple data), it might
    prove to be            essential when further developing towards all possible
    temporal orders, or searching for configurations            in panel data over
    time, combined with / or automatic detection of difficult counterfactuals etc.'
  acknowledged: '2018-05-01'
  online: '2018-12-08'
  CRANpkgs:
  - QCA
  - lpSolve
  - venn
  - LogicOpt
  CTV_rev: Optimization
  suppl: 1.8 Kb
  landing: '2018'
  pages:
  - 357
  - 370
- slug: RJ-2018-063
  title: 'sdpt3r: Semidefinite Quadratic Linear Programming in R'
  bibtitle: 'sdpt3r: Semidefinite Quadratic Linear Programming in R'
  author: Adam Rahman
  bibauthor: Adam Rahman
  abstract: '  Abstract We present the package sdpt3r, an R implementation of the
    Matlab package SDPT3 (Toh            et al., 1999). The purpose of the software
    is to solve semidefinite quadratic linear programming            (SQLP) problems,
    which encompasses problems such as D-optimal experimental design, the nearest            correlation
    matrix problem, and distance weighted discrimination, as well as problems in graph
    theory'
  acknowledged: '2018-05-01'
  online: '2018-12-08'
  CRANpkgs:
  - sdpt3r
  - Rdsdp
  - Rcsdp
  - cccp
  - scs
  - Rmosek
  - quantmod
  CTV_rev:
  - Optimization
  - Finance
  suppl: 882 bytes
  landing: '2018'
  pages:
  - 371
  - 394
- slug: RJ-2018-072
  title: 'Explanations of Model Predictions with live and breakDown Packages '
  bibtitle: |-
    Explanations of Model Predictions with live and breakDown
              Packages
  author:
  - Mateusz Staniak
  - Przemysław Biecek
  bibauthor: Mateusz Staniak and Przemysław Biecek
  abstract: '  Abstract Complex models are commonly used in predictive modeling. In
    this paper we present R            packages that can be used for explaining predictions
    from complex black box models and attributing            parts of these predictions
    to input features. We introduce two new approaches and corresponding            packages
    for such attribution, namely live and breakDown. We also compare their results
    with            existing implementations of state-of-the-art solutions, namely,
    lime (Pedersen and Benesty, 2018)            which implements Locally Interpretable
    Model-agnostic Explanations and iml (Molnar et al., 2018) which            implements
    Shapley values.'
  acknowledged: '2018-05-01'
  online: '2018-12-11'
  CRANpkgs:
  - pdp
  - lime
  - caret
  - mlr
  - DALEX
  - iml
  - live
  - breakDown
  - archivist
  - xgboost
  - party
  - data.table
  - e1071
  - glmnet
  - randomForest
  CTVs: MachineLearning
  CTV_rev:
  - MachineLearning
  - Environmetrics
  - HighPerformanceComputing
  - Multivariate
  - Survival
  - Cluster
  - Distributions
  - Finance
  - MissingData
  - ModelDeployment
  - Psychometrics
  - ReproducibleResearch
  suppl: 1.7 Kb
  landing: '2018'
  pages:
  - 395
  - 409
- slug: RJ-2018-064
  title: Downside Risk Evaluation with the R Package GAS
  bibtitle: Downside Risk Evaluation with the R Package GAS
  author:
  - David Ardia
  - Kris Boudt
  - Leopoldo Catania
  bibauthor: David Ardia and Kris Boudt and Leopoldo Catania
  abstract: '  Abstract Financial risk managers routinely use non–linear time series
    models to predict the downside            risk of the capital under management.
    They also need to evaluate the adequacy of their model            using so–called
    backtesting procedures. The latter involve hypothesis testing and evaluation of
    loss            functions. This paper shows how the R package GAS can be used
    for both the dynamic prediction and            the evaluation of downside risk.
    Emphasis is given to the two key financial downside risk measures:            Value-at-Risk
    (VaR) and Expected Shortfall (ES). High-level functions for: (i) prediction, (ii)
    backtesting,            and (iii) model comparison are discussed, and code examples
    are provided. An illustration using the            series of log–returns of the
    Dow Jones Industrial Average constituents is reported.'
  acknowledged: '2018-05-01'
  online: '2018-12-08'
  CRANpkgs:
  - GAS
  - cubature
  CTV_rev:
  - NumericalMathematics
  - TimeSeries
  suppl: 3.9 Kb
  landing: '2018'
  pages:
  - 410
  - 421
- slug: RJ-2018-065
  title: 'NetworkToolbox: Methods and Measures for Brain, Cognitive, and Psychometric
    Network Analysis in R'
  bibtitle: |-
    NetworkToolbox: Methods and Measures for Brain, Cognitive,
              and Psychometric Network Analysis in R
  author: Alexander P. Christensen
  bibauthor: Alexander P. Christensen
  abstract: '  Abstract This article introduces the NetworkToolbox package for R.
    Network analysis offers an            intuitive perspective on complex phenomena
    via models depicted by nodes (variables) and edges            (correlations).
    The ability of networks to model complexity has made them the standard approach            for
    modeling the intricate interactions in the brain. Similarly, networks have become
    an increasingly            attractive model for studying the complexity of psychological
    and psychopathological phenomena.            NetworkToolbox aims to provide researchers
    with state-of-the-art methods and measures for es           timating and analyzing
    brain, cognitive, and psychometric networks. In this article, I introduce            NetworkToolbox
    and provide a tutorial for applying some the package’s functions to personality            data.'
  acknowledged: '2018-06-07'
  online: '2018-12-08'
  CRANpkgs:
  - NetworkToolbox
  - statnet
  - igraph
  - sna
  - brainGraph
  - qgraph
  - IsingFit
  - bootnet
  - glasso
  - psych
  - MVN
  - EGA
  - lavaan
  CTV_rev:
  - Psychometrics
  - Optimization
  - SocialSciences
  - Bayesian
  - Econometrics
  - gR
  - Graphics
  - MissingData
  - OfficialStatistics
  - Spatial
  suppl: 2.2 Kb
  landing: '2018'
  pages:
  - 422
  - 439
- slug: RJ-2018-066
  title: 'jsr223: A Java Platform Integration for R with Programming Languages Groovy,
    JavaScript, JRuby, Jython, and Kotlin'
  bibtitle: |-
    jsr223: A Java Platform Integration for R with Programming
              Languages Groovy, JavaScript, JRuby, Jython, and Kotlin
  author:
  - Floid R. Gilbert
  - David B. Dahl
  bibauthor: Floid R. Gilbert and David B. Dahl
  abstract: '  Abstract The R package jsr223 is a high-level integration for five
    programming languages in the            Java platform: Groovy, JavaScript, JRuby,
    Jython, and Kotlin. Each of these languages can use Java            objects in
    their own syntax. Hence, jsr223 is also an integration for R and the Java platform.
    It enables            developers to leverage Java solutions from within R by embedding
    code snippets or evaluating script            files. This approach is generally
    easier than rJava’s low-level approach that employs the Java Native            Interface.
    jsr223’s multi-language support is dependent on the Java Scripting API: an implementation            of
    “JSR-223: Scripting for the Java Platform” that defines a framework to embed scripts
    in Java            applications. The jsr223 package also features extensive data
    exchange capabilities and a callback            interface that allows embedded
    scripts to access the current R session. In all, jsr223 makes solutions            developed
    in Java or any of the jsr223-supported languages easier to use in R.'
  acknowledged: '2018-05-29'
  online: '2018-12-08'
  CRANpkgs:
  - rJava
  - cranlogs
  - jsr223
  - rscala
  - jdx
  - V8
  - R6
  - Rserve
  - opencpu
  - rGroovy
  - jsonlite
  - reticulate
  - rJython
  - PythonInR
  - rjson
  CTV_rev:
  - WebTechnologies
  - ModelDeployment
  - NumericalMathematics
  - HighPerformanceComputing
  suppl: 3 Kb
  landing: '2018'
  pages:
  - 440
  - 454
- slug: RJ-2018-073
  title: 'bnclassify: Learning Bayesian Network Classifiers'
  bibtitle: 'bnclassify: Learning Bayesian Network Classifiers'
  author:
  - Bojan Mihaljević
  - Concha Bielza
  - Pedro Larrañaga
  bibauthor: Bojan Mihaljević and Concha Bielza and Pedro Larrañaga
  abstract: '  Abstract The bnclassify package provides state-of-the art algorithms
    for learning Bayesian network            classifiers from data. For structure
    learning it provides variants of the greedy hill-climbing search,            a
    well-known adaptation of the Chow-Liu algorithm and averaged one-dependence estimators.
    It            provides Bayesian and maximum likelihood parameter estimation, as
    well as three naive-Bayes           specific methods based on discriminative score
    optimization and Bayesian model averaging. The            implementation is efficient
    enough to allow for time-consuming discriminative scores on medium           sized
    data sets. The bnclassify package provides utilities for model evaluation, such
    as cross-validated            accuracy and penalized log-likelihood scores, and
    analysis of the underlying networks, including            network plotting via
    the Rgraphviz package. It is extensively tested, with over 200 automated tests            that
    give a code coverage of 94%. Here we present the main functionalities, illustrate
    them with a            number of data sets, and comment on related software.'
  acknowledged: '2018-05-29'
  online: '2018-12-11'
  CRANpkgs:
  - bnlearn
  - bnclassify
  - caret
  - mlr
  - gRain
  - deal
  BIOpkgs: Rgraphviz
  CTV_rev:
  - Bayesian
  - gR
  - HighPerformanceComputing
  - MachineLearning
  - Multivariate
  suppl: 833 bytes
  landing: '2018'
  pages:
  - 455
  - 468
- slug: RJ-2018-076
  title: Dynamic Simulation and Testing for Single-Equation Cointegrating and Stationary
    Autoregressive Distributed Lag Models
  bibtitle: |-
    Dynamic Simulation and Testing for Single-Equation
              Cointegrating and Stationary Autoregressive Distributed Lag
              Models
  author:
  - Soren Jordan
  - Andrew Q. Philips
  bibauthor: Soren Jordan and Andrew Q. Philips
  abstract: '  Abstract While autoregressive distributed lag models allow for extremely
    flexible dynamics, interpret           ing the substantive significance of complex
    lag structures remains difficult. In this paper we discuss            dynamac
    (dynamic autoregressive and cointegrating models), an R package designed to assist
    users in            estimating, dynamically simulating, and plotting the results
    of a variety of autoregressive distributed            lag models. It also contains
    a number of post-estimation diagnostics, including a test for cointegration            for
    when researchers are estimating the error-correction variant of the autoregressive
    distributed lag            model.'
  acknowledged: '2018-05-29'
  online: '2018-12-31'
  CRANpkgs:
  - dynsim
  - Zelig
  - urca
  - MASS
  CTV_rev:
  - Econometrics
  - Finance
  - SocialSciences
  - Distributions
  - Environmetrics
  - Multivariate
  - NumericalMathematics
  - Psychometrics
  - Robust
  - TimeSeries
  suppl: 1.3 Kb
  landing: '2018'
  pages:
  - 469
  - 488
- slug: RJ-2018-079
  title: 'The politeness Package: Detecting Politeness in Natural Language'
  bibtitle: |-
    The politeness Package: Detecting Politeness in Natural
              Language
  author:
  - Michael Yeomans
  - Alejandro Kantor
  - Dustin Tingley
  bibauthor: Michael Yeomans and Alejandro Kantor and Dustin Tingley
  abstract: '  Abstract This package provides tools to extract politeness markers
    in English natural language. It            also allows researchers to easily visualize
    and quantify politeness between groups of documents.            This package combines
    and extends prior research on the linguistic markers of politeness (Brown            and
    Levinson, 1987; Danescu-Niculescu-Mizil et al., 2013; Voigt et al., 2017). We
    demonstrate two            applications for detecting politeness in natural language
    during consequential social interactions—            distributive negotiations,
    and speed dating.'
  acknowledged: '2018-05-29'
  online: '2018-12-08'
  CRANpkgs:
  - tidytext
  - tm
  - quanteda
  - coreNLP
  - spacyR
  - SentimentAnalysis
  - syuzhet
  - topicmodeling
  - stm
  - glmnet
  - textir
  - hunspell
  - data.table
  - politeness
  CTV_rev:
  - NaturalLanguageProcessing
  - HighPerformanceComputing
  - Finance
  - MachineLearning
  - Survival
  suppl: 869.6 Kb
  landing: '2018'
  pages:
  - 489
  - 502
- slug: RJ-2018-074
  title: ShinyItemAnalysis for Teaching Psychometrics and to Enforce Routine Analysis
    of Educational Tests
  bibtitle: |-
    ShinyItemAnalysis for Teaching Psychometrics and to Enforce
              Routine Analysis of Educational Tests
  author:
  - Patrícia Martinková
  - Adéla Drabinová
  bibauthor: Patrícia Martinková and Adéla Drabinová
  abstract: '  Abstract This work introduces ShinyItemAnalysis, an R package and an
    online shiny application for            psychometric analysis of educational tests
    and items. ShinyItemAnalysis covers a broad range of psy           chometric methods
    and offers data examples, model equations, parameter estimates, interpretation
    of            results, together with a selected R code, and is therefore suitable
    for teaching psychometric concepts            with R. Furthermore, the application
    aspires to be an easy-to-use tool for analysis of educational            tests
    by allowing the users to upload and analyze their own data and to automatically
    generate            analysis reports in PDF or HTML. We argue that psychometric
    analysis should be a routine part of            test development in order to gather
    proofs of reliability and validity of the measurement, and we            demonstrate
    how ShinyItemAnalysis may help enforce this goal.'
  acknowledged: '2018-06-29'
  online: '2018-12-13'
  CRANpkgs:
  - psych
  - ltm
  - difR
  - lavaan
  - ShinyItemAnalysis
  - shiny
  - mirt
  - corrplot
  - cowplot
  - CTT
  - data.table
  - deltaPlotR
  - difNLR
  - DT
  - ggdendro
  - ggplot2
  - gridExtra
  - knitr
  - latticeExtra
  - moments
  - msm
  - nnet
  - plotly
  - psychometric
  - reshape2
  - rmarkdown
  - shinyBS
  - shinydashboard
  - shinyjs
  - stringr
  - xtable
  CTVs: Psychometrics
  CTV_rev:
  - Psychometrics
  - ReproducibleResearch
  - MissingData
  - Distributions
  - Econometrics
  - Graphics
  - WebTechnologies
  - Finance
  - HighPerformanceComputing
  - MachineLearning
  - MetaAnalysis
  - Multivariate
  - OfficialStatistics
  - Phylogenetics
  - SocialSciences
  - Survival
  suppl: 601.1 Kb
  landing: '2018'
  pages:
  - 503
  - 515
- slug: RJ-2018-068
  title: 'RcppMsgPack: MessagePack Headers and Interface Functions for R'
  bibtitle: |-
    RcppMsgPack: MessagePack Headers and Interface Functions for
              R
  author:
  - Travers Ching
  - Dirk Eddelbuettel
  bibauthor: Travers Ching and Dirk Eddelbuettel
  abstract: '  Abstract MessagePack, or MsgPack for short, or when referring to the
    implementation, is an efficient            binary serialization format for exchanging
    data between different programming languages. The            RcppMsgPack package
    provides R with both the MessagePack C++ header files, and the ability to            access,
    create and alter MessagePack objects directly from R. The main driver functions
    of the R            interface are two functions msgpack_pack and msgpack_unpack.
    The function msgpack_pack serializes            R objects to a raw MessagePack
    message. The function msgpack_unpack de-serializes MessagePack            messages
    back into R objects. Several helper functions are available to aid in processing
    and formatting            data including msgpack_simplify, msgpack_format and
    msgpack_map.'
  acknowledged: '2018-07-31'
  online: '2018-12-08'
  CRANpkgs:
  - mongolite
  - RProtoBuf
  - RcppRedis
  - RcppMsgPack
  - Rcpp
  - nanotime
  - httr
  - feather
  - data.table
  CTV_rev:
  - HighPerformanceComputing
  - Databases
  - NumericalMathematics
  - Finance
  - WebTechnologies
  suppl: 1 Mb
  landing: '2018'
  pages:
  - 516
  - 525
- slug: RJ-2018-069
  title: 'BNSP: an R Package for Fitting Bayesian Semiparametric Regression Models
    and Variable Selection'
  bibtitle: |-
    BNSP: an R Package for Fitting Bayesian Semiparametric
              Regression Models and Variable Selection
  author: Georgios Papageorgiou
  bibauthor: Georgios Papageorgiou
  abstract: '  Abstract The R package BNSP provides a unified framework for semiparametric
    location-scale            regression and stochastic search variable selection.
    The statistical methodology that the package is            built upon utilizes
    basis function expansions to represent semiparametric covariate effects in the
    mean            and variance functions, and spike-slab priors to perform selection
    and regularization of the estimated            effects. In addition to the main
    function that performs posterior sampling, the package includes            functions
    for assessing convergence of the sampler, summarizing model fits, visualizing
    covariate            effects and obtaining predictions for new responses or their
    means given feature/covariate vectors.'
  acknowledged: '2018-07-31'
  online: '2018-12-08'
  CRANpkgs:
  - BNSP
  - bamlss
  - spikeSlabGAM
  - brms
  - gamboostLSS
  - mgcv
  - coda
  - ggplot2
  - plot3D
  - threejs
  - colorspace
  - np
  - gamair
  - lattice
  CTV_rev:
  - Bayesian
  - Graphics
  - Econometrics
  - Environmetrics
  - Phylogenetics
  - SocialSciences
  - gR
  - MachineLearning
  - Multivariate
  suppl: 3.1 Kb
  landing: '2018'
  pages:
  - 526
  - 548
- slug: RJ-2018-075
  title: Measurement Errors in R
  bibtitle: Measurement Errors in R
  author:
  - Iñaki Ucar
  - Edzer Pebesma
  - Arturo Azcorra
  bibauthor: Iñaki Ucar and Edzer Pebesma and Arturo Azcorra
  abstract: '  Abstract This paper presents an R package to handle and represent measurements
    with errors in a            very simple way. We briefly introduce the main concepts
    of metrology and propagation of uncertainty,            and discuss related R
    packages. Building upon this, we introduce the errors package, which provides            a
    class for associating uncertainty metadata, automated propagation and reporting.
    Working with            errors enables transparent, lightweight, less error-prone
    handling and convenient representation            of measurements with errors.
    Finally, we discuss the advantages, limitations and future work of            computing
    with errors.'
  acknowledged: '2018-08-09'
  online: '2018-12-13'
  CRANpkgs:
  - units
  - errors
  - car
  - msm
  - metRology
  - propagate
  - spup
  - distr
  - distrEllipse
  - distrEx
  - distrMod
  - distrRmetrics
  - distrSim
  - distrTeach
  - magrittr
  - ggplot2
  - tibble
  CTV_rev:
  - Distributions
  - ChemPhys
  - Econometrics
  - Finance
  - Graphics
  - Multivariate
  - Phylogenetics
  - Robust
  - SocialSciences
  - Survival
  - WebTechnologies
  suppl: 1.4 Kb
  landing: '2018'
  pages:
  - 549
  - 557
- slug: RJ-2018-058
  title: Navigating the R Package Universe
  bibtitle: Navigating the R Package Universe
  author:
  - Julia Silge
  - John C. Nash
  - Spencer Graves
  bibauthor: Julia Silge and John C. Nash and Spencer Graves
  abstract: '  Abstract Today, the enormous number of contributed packages available
    to R users outstrips any given            user’s ability to understand how these
    packages work, their relative merits, or how they are related            to each
    other. We organized a plenary session at useR!2017 in Brussels for the R community
    to think            through these issues and ways forward. This session considered
    three key points of discussion. Users            can navigate the universe of
    R packages with (1) capabilities for directly searching for R packages, (2)            guidance
    for which packages to use, e.g., from CRAN Task Views and other sources, and (3)
    access to            common interfaces for alternative approaches to essentially
    the same problem.'
  acknowledged: '2018-09-07'
  online: '2018-12-08'
  CRANpkgs:
  - sos
  - CRANsearcher
  - utils
  - pkgdown
  - lfe
  - optimx
  CTV_rev:
  - Econometrics
  - Optimization
  suppl: 653 bytes
  landing: '2018'
  pages:
  - 558
  - 563
- heading: News and Notes
- slug: latinR
  author:
  - Laura Acion
  - Natalia da Silva
  - Riva Quiroga
  title: 'Conference Report: LatinR 2018'
  bibtitle: 'Conference Report: LatinR 2018'
  bibauthor: Laura Acion and Natalia da Silva and Riva Quiroga
  pages:
  - 564
  - 566
- slug: serIII
  author:
  - Ariel Levy
  - Luciane F. Alcoforado
  - Orlando Celso Longo
  title: 'Conference Report: SER III'
  bibtitle: 'Conference Report: SER III'
  bibauthor: Ariel Levy and Luciane F. Alcoforado and Orlando Celso Longo
  pages:
  - 567
  - 571
- slug: whyR
  author:
  - Michał Burdukiewicz
  - Marta Karas
  - Leon Eyrich Jessen
  - Marcin Kosiński
  - Bernd Bischl
  - '          Stefan Rödiger'
  title: 'Conference Report: Why R? 2018'
  bibtitle: 'Conference Report: Why R? 2018'
  bibauthor: |-
    Michał Burdukiewicz and Marta Karas and Leon Eyrich Jessen
              and Marcin Kosiński and Bernd Bischl and Stefan Rödiger
  pages:
  - 572
  - 578
- slug: R_Pharma
  author: Joseph Rickert
  title: 'Conference Report: R / Pharma 2018'
  bibtitle: 'Conference Report: R / Pharma 2018'
  bibauthor: Joseph Rickert
  pages:
  - 579
  - 580
- slug: R_Medicine
  author:
  - Joseph Rickert
  - Naras Balasubramanian
  - Michael Kane
  title: 'Conference Report: R / Medicine Report '
  bibtitle: 'Conference Report: R / Medicine Report'
  bibauthor: Joseph Rickert and Naras Balasubramanian and Michael Kane
  pages:
  - 581
  - 582
- slug: foundation
  author: Torsten Hothorn
  title: R Foundation News
  bibtitle: R Foundation News
  bibauthor: Torsten Hothorn
  pages:
  - 583
  - 583
- slug: cran
  author:
  - Kurt Hornik
  - Uwe Ligges
  - Achim Zeileis
  title: Changes on CRAN
  bibtitle: Changes on CRAN
  bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
  pages:
  - 584
  - 586
- slug: bioc
  author: Bioconductor Core Team
  title: News from the Bioconductor Project
  bibtitle: News from the Bioconductor Project
  bibauthor: Bioconductor Core Team
  pages:
  - 587
  - 587
- slug: ch
  author: R Core Team
  title: Changes in R
  bibtitle: Changes in R
  bibauthor: R Core Team
  pages:
  - 588
  - 590
