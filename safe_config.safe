markdown: kramdown
issues:
- issue: accepted
  articles:
  - slug: RJ-2018-040
    title: Profile Likelihood Estimation of the Correlation Coefficient in the Presence
      of Left, Right or Interval Censoring and Missing Data
    bibtitle: |-
      Profile Likelihood Estimation of the Correlation Coefficient
                in the Presence of Left, Right or Interval Censoring and
                Missing Data
    author:
    - Yanming Li
    - Brenda W. Gillespie
    - Kerby Shedden
    - John A. Gillespie
    bibauthor: |-
      Yanming Li and Brenda W. Gillespie and Kerby Shedden and
                John A. Gillespie
    abstract: '  Abstract We discuss implentation of a profile likelihood method for
      estimating a Pearson correlation            coefficient from bivariate data
      with censoring and/or missing values. The method is implemented in            an
      R package clikcorr which calculates maximum likelihood estimates of the correlation
      coefficient            when the data are modeled with either a Gaussian or a
      Student t-distribution, in the presence of left,            right, or interval
      censored and/or missing data. The R package includes functions for conducting            inference
      and also provides graphical functions for visualizing the censored data scatter
      plot and            profile log likelihood function. The performance of clikcorr
      in a variety of circumstances is evaluated            through extensive simulation
      studies. We illustrate the package using two dioxin exposure datasets.'
    acknowledged: '2017-10-01'
    online: '2018-08-17'
    CRANpkgs:
    - clikcorr
    - survival
    - mvtnorm
    CTV_rev:
    - ClinicalTrials
    - Distributions
    - Econometrics
    - Finance
    - Multivariate
    - SocialSciences
    - Survival
    suppl: 3 Kb
    landing: '2018'
  - slug: RJ-2018-041
    title: 'The utiml Package: Multi-label Classification in R'
    bibtitle: 'The utiml Package: Multi-label Classification in R'
    author:
    - Adriano Rivolli
    - Andre C. P. L. F. de Carvalho
    bibauthor: Adriano Rivolli and Andre C. P. L. F. de Carvalho
    abstract: '  Abstract Learning classification tasks in which each instance is
      associated with one or more labels            are known as multi-label learning.
      The implementation of multi-label algorithms, performed by            different
      researchers, have several specificities, like input/output format, different
      internal functions,            distinct programming language, to mention just
      some of them. As a result, current machine learning            tools include
      only a small subset of multi-label decomposition strategies. The utiml package
      is a            framework for the application of classification algorithms to
      multi-label data. Like the well known            MULAN used with Weka, it provides
      a set of multi-label procedures such as sampling methods,            transformation
      strategies, threshold functions, pre-processing techniques and evaluation metrics.
      The            package was designed to allow users to easily perform complete
      multi-label classification experiments            in the R environment. This
      paper describes the utiml API and illustrates its use in different multi-label            classification
      scenarios.'
    acknowledged: '2017-04-07'
    online: '2018-08-17'
    CRANpkgs:
    - mldr
    - mlr
    - MLPUGS
    - utiml
    - randomForest
    - C50
    - e1071
    - parallel
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - Cluster
    - Distributions
    - Multivariate
    - Psychometrics
    suppl: 1.3 Kb
    landing: '2018'
  - slug: RJ-2018-042
    title: 'Dot-Pipe: an S3 Extensible Pipe for R'
    bibtitle: 'Dot-Pipe: an S3 Extensible Pipe for R'
    author:
    - John Mount
    - Nina Zumel
    bibauthor: John Mount and Nina Zumel
    abstract: '    Abstract Pipe notation is popular with a large league of R users,
      with magrittr being the dominant              realization. However, this should
      not be enough to consider piping in R as a completely settled topic              that
      is not subject to further discussion, experiments, or the possibility of improvement.
      To promote              innovation opportunities we describe wrapr “dot-pipe”,
      a well behaved sequencing operator with S3              extensibility. In this
      article we include a number of examples of using this pipe to interact with
      and              extend other R packages.'
    acknowledged: '2018-03-02'
    online: '2018-08-17'
    CRANpkgs:
    - data.table
    - magrittr
    - dplyr
    - future
    - rmonad
    - pipeR
    - backpipe
    - drake
    - wrapr
    - ggplot2
    - rquery
    CTV_rev:
    - HighPerformanceComputing
    - Finance
    - Graphics
    - ModelDeployment
    - Phylogenetics
    - WebTechnologies
    landing: '2018'
  - slug: RJ-2018-043
    title: 'nsROC: An R package for non-standard ROC curve analysis'
    bibtitle: 'nsROC: An R package for non-standard ROC curve analysis'
    author:
    - Sonia Pérez-Fernández
    - Pablo Martínez-Camblor
    - Peter Filzmoser
    - Norberto Corral
    bibauthor: |-
      Sonia Pérez-Fernández and Pablo Martínez-Camblor and Peter
                Filzmoser and Norberto Corral
    abstract: ' Abstract The receiver operating characteristic (ROC) curve is a graphical
      method which           has become standard in the analysis of diagnostic markers,
      that is, in the study of the           classification ability of a numerical
      variable. Most of the commercial statistical software           provide routines
      for the standard ROC curve analysis. Of course, there are also many R           packages
      dealing with the ROC estimation as well as other related problems. In this work           we
      introduce the nsROC package which incorporates some new ROC curve procedures.           Particularly:
      ROC curve comparison based on general distances among functions for both           paired
      and unpaired designs; efficient confidence bands construction; a generalization
      of the           curve considering different classification subsets than the
      one involved in the classical defini          tion of the ROC curve; a procedure
      to deal with censored data in cumulative-dynamic ROC           curve estimation
      for time-to-event outcomes; and a non-parametric ROC curve method for           meta-analysis.
      This is the only R package which implements these particular procedures.'
    acknowledged: '2017-06-27'
    online: '2018-08-17'
    CRANpkgs:
    - pROC
    - ROCR
    - plotROC
    - fbroc
    - OptimalCutpoints
    - timeROC
    - survivalROC
    - HSROC
    - sde
    - tdROC
    - survival
    CTV_rev:
    - Survival
    - ClinicalTrials
    - DifferentialEquations
    - Econometrics
    - Finance
    - MachineLearning
    - Multivariate
    - SocialSciences
    - TimeSeries
    suppl: 1.4 Kb
    landing: '2018'
  - slug: RJ-2018-044
    title: 'revengc: An R package to Reverse Engineer Summarized Data'
    bibtitle: 'revengc: An R package to Reverse Engineer Summarized Data'
    author:
    - Samantha Duchscherer
    - Robert Stewart
    - Marie Urban
    bibauthor: Samantha Duchscherer and Robert Stewart and Marie Urban
    abstract: '  Abstract Decoupled (e.g. separate averages) and censored (e.g. >
      100 species) variables are continually            reported by many well-established
      organizations, such as the World Health Organization (WHO),            Centers
      for Disease Control and Prevention (CDC), and World Bank. The challenge therefore
      is to infer            what the original data could have been given summarized
      information. We present an R package that            reverse engineers censored
      and/or decoupled data with two main functions. The cnbinom.pars()            function
      estimates the average and dispersion parameter of a censored univariate frequency
      table. The            rec() function reverse engineers summarized data into
      an uncensored bivariate table of probabilities.'
    acknowledged: '2017-08-24'
    online: '2018-12-07'
    CRANpkgs:
    - revengc
    - truncdist
    - mipfp
    CTV_rev: OfficialStatistics
    suppl: 2.1 Kb
    landing: '2018'
  - slug: RJ-2018-045
    title: Basis-Adaptive Selection Algorithm in dr-package
    bibtitle: Basis-Adaptive Selection Algorithm in dr-package
    author: Jae Keun Yoo
    bibauthor: Jae Keun Yoo
    abstract: '  Abstract Sufficient dimension reduction (SDR) turns out to be a useful
      dimension reduction tool in            high-dimensional regression analysis.
      Weisberg (2002) developed the dr-package to implement the            four most
      popular SDR methods. However, the package does not provide any clear guidelines
      as            to which method should be used given a data. Since the four methods
      may provide dramatically            different dimension reduction results, the
      selection in the dr-package is problematic for statistical            practitioners.
      In this paper, a basis-adaptive selection algorithm is developed in order to
      relieve this            issue. The basic idea is to select an SDR method that
      provides the highest correlation between the basis            estimates obtained
      by the four classical SDR methods. A real data example and numerical studies            confirm
      the practical usefulness of the developed algorithm.'
    acknowledged: '2017-08-24'
    online: '2018-12-07'
    CRANpkgs: dr
    CTV_rev:
    - Multivariate
    - SocialSciences
    suppl: 2.2 Kb
    landing: '2018'
  - slug: RJ-2018-046
    title: 'fICA: FastICA Algorithms and Their Improved Variants'
    bibtitle: 'fICA: FastICA Algorithms and Their Improved Variants'
    author:
    - Jari Miettinen
    - Klaus Nordhausen
    - Sara Taskinen
    bibauthor: Jari Miettinen and Klaus Nordhausen and Sara Taskinen
    abstract: '  Abstract In independent component analysis (ICA) one searches for
      mutually independent non           gaussian latent variables when the components
      of the multivariate data are assumed to be linear            combinations of
      them. Arguably, the most popular method to perform ICA is FastICA. There are            two
      classical versions, the deflation-based FastICA where the components are found
      one by one,            and the symmetric FastICA where the components are found
      simultaneously. These methods have            been implemented previously in
      two R packages, fastICA and ica. We present the R package fICA            and
      compare it to the other packages. The additional features of the package include
      for example            optimization of the extraction order in the deflation-based
      version, possibility to use any nonlinearity            function, and improvement
      to convergence of the deflation-based algorithm. The usage of the package            is
      demonstrated by applying it to a real ECG data of a pregnant woman.'
    acknowledged: '2017-09-21'
    online: '2018-12-07'
    CRANpkgs:
    - fastICA
    - ica
    - fICA
    - BSSasymp
    CTV_rev:
    - Psychometrics
    - ChemPhys
    - Multivariate
    suppl: 1.1 Kb
    landing: '2018'
  - slug: RJ-2018-047
    title: Spatial Uncertainty Propagation Analysis with the spup R Package
    bibtitle: |-
      Spatial Uncertainty Propagation Analysis with the spup R
                Package
    author:
    - Kasia Sawicka
    - Gerard B.M. Heuvelink
    - Dennis J.J. Walvoort
    bibauthor: |-
      Kasia Sawicka and Gerard B.M. Heuvelink and Dennis J.J.
                Walvoort
    abstract: '  Abstract Many environmental and geographical models, such as those
      used in land degradation,            agro-ecological and climate studies, make
      use of spatially distributed inputs that are known im           perfectly. The
      R package spup provides functions for examining the uncertainty propagation
      from            input data and model parameters onto model outputs, via the
      environmental model. The functions            include uncertainty model specification,
      stochastic simulation and propagation of uncertainty using            Monte
      Carlo (MC) techniques. Uncertain variables are described by probability distributions.
      Both            numerical and categorical data types are handled. Spatial auto-correlation
      within a variable and            cross-correlation between variables is accommodated
      for. The MC realizations may be used as input            to the environmental
      models written in or called from R. This article provides theoretical background            and
      three worked examples that guide users through the application of spup.'
    acknowledged: '2017-10-03'
    online: '2018-12-07'
    CRANpkgs:
    - propagate
    - errors
    - metRology
    - spup
    - gstat
    - mvtnorm
    - graphics
    - magrittr
    - methods
    - purrr
    - raster
    - whisker
    - dplyr
    - GGally
    - gridExtra
    - knitr
    - readr
    - sp
    - roxygen2
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - ChemPhys
    - WebTechnologies
    - Databases
    - Distributions
    - Finance
    - ModelDeployment
    - Multivariate
    - ReproducibleResearch
    suppl: 3.3 Kb
    landing: '2018'
  - slug: RJ-2018-048
    title: 'clustMixType: User-Friendly Clustering of Mixed-Type Data in R'
    bibtitle: |-
      clustMixType: User-Friendly Clustering of Mixed-Type Data in
                R
    author: Gero Szepannek
    bibauthor: Gero Szepannek
    abstract: '  Abstract Clustering algorithms are designed to identify groups in
      data where traditionally the            emphasis in research has been on numeric
      data and in consequence most traditional algorithms are            devoted to
      this kind of data. A gap has uprised from industrial praxis by the fact that
      in most business            applications the variables are of both types: numeric
      and categorical. In recent past an increasing            number of algorithms
      for clustering of mixed-type data has been proposed. Many of these are based            on
      the idea of Huang’s k-prototypes algorithm. This paper describes the R package
      clustMixType            which provides an implementation of this algorithm in
      R.'
    acknowledged: '2017-10-30'
    online: '2018-12-07'
    CRANpkgs:
    - gower
    - cluster
    - CluMix
    - flexclust
    - fpc
    - clustMD
    - kamila
    - clustMixType
    - klaR
    - wesanderson
    - clusteval
    CTV_rev:
    - Cluster
    - Multivariate
    - Environmetrics
    - Graphics
    - MachineLearning
    - Robust
    suppl: 1.1 Kb
    landing: '2018'
  - slug: RJ-2018-049
    title: 'Stilt: Easy Emulation of Time Series AR(1) Computer Model Output in Multidimensional
      Parameter Space'
    bibtitle: |-
      Stilt: Easy Emulation of Time Series AR(1) Computer Model
                Output in Multidimensional Parameter Space
    author:
    - Roman Olson
    - Kelsey L. Ruckert
    - Won Chang
    - Klaus Keller
    - Murali Haran
    - Soon-Il An
    bibauthor: |-
      Roman Olson and Kelsey L. Ruckert and Won Chang and Klaus
                Keller and Murali Haran and Soon-Il An
    abstract: '  Abstract A common problem in climate science and other fields is
      one of statistically approximating            (“emulating”) time series model
      output in parameter space. There are many packages for spatio           temporal
      modeling. However, they often lack focus on time series, and exhibit statistical
      complexity.            Here, we present the R package stilt designed for simplified
      AR(1) timeseries Gaussian Process            emulation, and provide examples
      relevant to climate modelling. Notably absent is Markov chain            Monte
      Carlo estimation – a challenging concept to many scientists. We keep the number
      of user            choices to a minimum. Hence, the package can be useful pedagogically,
      while still applicable to real            life emulation problems. We provide
      functions for emulator cross-validation, empirical coverage,            prediction,
      as well as response surface plotting. While the examples focus on climate model
      emulation,            the emulator is general and can be also used for kriging
      spatio-temporal data.'
    acknowledged: '2017-11-16'
    online: '2018-12-07'
    CRANpkgs:
    - gstat
    - mlegp
    - spBayes
    - ramps
    - spTimer
    - RandomFields
    - stilt
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Bayesian
    - TimeSeries
    suppl: 1.4 Kb
    landing: '2018'
  - slug: RJ-2018-050
    title: 'SMM: An R Package for Estimation and Simulation of Discrete-time semi-Markov
      Models'
    bibtitle: |-
      SMM: An R Package for Estimation and Simulation of Discrete-
                time semi-Markov Models
    author:
    - Vlad Stefan Barbu
    - Caroline Bérard
    - Dominique Cellier
    - Mathilde Sautreuil
    - Nicolas Vergne
    bibauthor: |-
      Vlad Stefan Barbu and Caroline Bérard and Dominique Cellier
                and Mathilde Sautreuil and Nicolas Vergne
    abstract: '  Abstract Semi-Markov models, independently introduced by Lévy (1954),
      Smith (1955) and Takacs            (1954), are a generalization of the well-known
      Markov models. For semi-Markov models, sojourn            times can be arbitrarily
      distributed, while sojourn times of Markov models are constrained to be            exponentially
      distributed (in continuous time) or geometrically distributed (in discrete time).
      The aim            of this paper is to present the R package SMM, devoted to
      the simulation and estimation of discrete           time multi-state semi-Markov
      and Markov models. For the semi-Markov case we have considered:            parametric
      and non-parametric estimation; with and without censoring at the beginning and/or
      at the            end of sample paths; one or several independent sample paths.
      Several discrete-time distributions            are considered for the parametric
      estimation of sojourn time distributions of semi-Markov chains:            Uniform,
      Geometric, Poisson, Discrete Weibull and Binomial Negative.'
    acknowledged: '2017-11-28'
    online: '2018-12-07'
    CRANpkgs:
    - SMM
    - semiMarkov
    - hsmm
    - mhsmm
    landing: '2018'
  - slug: RJ-2018-051
    title: ggplot2 Compatible Quantile-Quantile Plots in R
    bibtitle: ggplot2 Compatible Quantile-Quantile Plots in R
    author:
    - Alexandre Almeida
    - Adam Loy
    - Heike Hofmann
    bibauthor: Alexandre Almeida and Adam Loy and Heike Hofmann
    abstract: ' Abstract Q-Q plots allow us to assess univariate distributional assumptions
      by comparing a set of           quantiles from the empirical and the theoretical
      distributions in the form of a scatterplot. To aid in           the interpretation
      of Q-Q plots, reference lines and confidence bands are often added. We can also           detrend
      the Q-Q plot so the vertical comparisons of interest come into focus. Various
      implementations           of Q-Q plots exist in R, but none implements all of
      these features. qqplotr extends ggplot2 to provide           a complete implementation
      of Q-Q plots. This paper introduces the plotting framework provided by           qqplotr
      and provides multiple examples of how it can be used.'
    acknowledged: '2017-12-20'
    online: '2018-12-07'
    CRANpkgs:
    - car
    - ggplot2
    - qqplotr
    - robustbase
    - boot
    CTV_rev:
    - Econometrics
    - Multivariate
    - SocialSciences
    - Finance
    - Graphics
    - Optimization
    - Phylogenetics
    - Robust
    - Survival
    - TimeSeries
    suppl: 2.4 Kb
    landing: '2018'
  - slug: RJ-2018-052
    title: Forecast Combinations in R using the ForecastComb Package
    bibtitle: Forecast Combinations in R using the ForecastComb Package
    author:
    - Christoph E. Weiss
    - Eran Raviv
    - Gernot Roetzer
    bibauthor: Christoph E. Weiss and Eran Raviv and Gernot Roetzer
    abstract: '  Abstract This paper introduces the R package ForecastComb. The aim
      is to provide researchers and            practitioners with a comprehensive
      implementation of the most common ways in which forecasts can            be
      combined. The package in its current version covers 15 popular estimation methods
      for creating a            combined forecasts – including simple methods, regression-based
      methods, and eigenvector-based            methods. It also includes useful tools
      to deal with common challenges of forecast combination (e.g.,            missing
      values in component forecasts, or multicollinearity), and to rationalize and
      visualize the            combination results.'
    acknowledged: '2017-12-20'
    online: '2018-12-07'
    CRANpkgs:
    - BMA
    - opera
    - forecastHybrid
    - ForecastCombinations
    - GeomComb
    - quadprog
    - mtsdi
    - forecTheta
    CTV_rev:
    - TimeSeries
    - Bayesian
    - Econometrics
    - OfficialStatistics
    - Optimization
    - SocialSciences
    - Survival
    suppl: 1.2 Kb
    landing: '2018'
  - slug: RJ-2018-053
    title: 'stplanr: A Package for Transport Planning'
    bibtitle: 'stplanr: A Package for Transport Planning'
    author:
    - Robin Lovelace
    - Richard Ellison
    bibauthor: Robin Lovelace and Richard Ellison
    abstract: '  Abstract Tools for transport planning should be flexible, scalable
      and transparent. The stplanr package            demonstrates and provides a
      home for such tools, with an emphasis on spatial transport data and            non-motorized
      modes. stplanr facilitates common transport planning tasks including: download           ing
      and cleaning transport datasets; creating geographic ‘desire lines’ from origin-destination
      (OD)            data; route assignment, via the SpatialLinesNetwork class and
      interfaces to routing services such            as CycleStreets.net; calculation
      of route segment attributes such as bearing and aggregate flow; and           ‘travel
      watershed’ analysis. This paper demonstrates this functionality using reproducible
      examples            on real transport datasets. More broadly, the experience
      shows open source software can form the            basis of a reproducible transport
      planning workflow. stplanr, alongside other packages and open            source
      projects, could provide a more transparent and democratically accountable alternative
      to the            current approach which is heavily reliant on proprietary and
      technically and financially inaccessible            software.'
    acknowledged: '2017-03-22'
    online: '2018-12-08'
    CRANpkgs:
    - sp
    - rgeos
    - rgdal
    - sf
    - SpatialEpi
    - diseasemapping
    - leaflet
    - tmap
    - mapview
    - mapmisc
    - XML
    - twitteR
    - ggplot2
    - muStat
    - mgcv
    - shiny
    - haven
    - rio
    - dplyr
    - osmdata
    - bikedata
    - stplanr
    - nycflights
    - nycflights13
    - cyclestreets
    - igraph
    - Rcpp
    - aspace
    - MCI
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Graphics
    - OfficialStatistics
    - SpatioTemporal
    - Bayesian
    - Databases
    - Econometrics
    - Environmetrics
    - gR
    - HighPerformanceComputing
    - ModelDeployment
    - NumericalMathematics
    - Optimization
    - Phylogenetics
    - SocialSciences
    suppl: 2.6 Kb
    landing: '2018'
  - slug: RJ-2018-054
    title: 'rcss: R package for optimal convex stochastic switching'
    bibtitle: 'rcss: R package for optimal convex stochastic switching'
    author:
    - Juri Hinz
    - Jeremy Yee
    bibauthor: Juri Hinz and Jeremy Yee
    abstract: '  Abstract The R package rcss provides users with a tool to approximate
      the value functions in the            Bellman recursion under certain assumptions
      that guarantee desirable convergence properties. This R            package represents
      the first software implementation of these methods using matrices and nearest            neighbours.
      This package also employs a pathwise dynamic method to gauge the quality of
      these            value function approximations. Statistical analysis can be
      performed on the results to obtain other            useful practical insights.
      This paper describes rcss version 1.6.'
    acknowledged: '2017-04-27'
    online: '2018-12-08'
    CRANpkgs:
    - rcss
    - Rcpp
    - OpenMp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    suppl: 1.8 Kb
    landing: '2018'
  - slug: RJ-2018-055
    title: 'addhaz: Contribution of Chronic Diseases to the Disability Burden Using
      R'
    bibtitle: |-
      addhaz: Contribution of Chronic Diseases to the Disability
                Burden Using R
    author:
    - Renata Tiene de Carvalho Yokota
    - Caspar WN Looman
    - Wilma Johanna Nusselder
    - Herman Van            Oyen
    - Geert Molenberghs
    bibauthor: |-
      Renata Tiene de Carvalho Yokota and Caspar WN Looman and
                Wilma Johanna Nusselder and Herman Van Oyen and Geert
                Molenberghs
    abstract: '  Abstract The increase in life expectancy followed by the burden of
      chronic diseases contributes to            disability at older ages. The estimation
      of how much chronic conditions contribute to disability can be            useful
      to develop public health strategies to reduce the burden. This paper introduces
      the R package            addhaz, which is based on the attribution method (Nusselder
      and Looman, 2004) to partition disability            into the additive contributions
      of diseases using cross-sectional data. The R package includes tools to            fit
      the additive hazard model, the core of the attribution method, to binary and
      multinomial outcomes.            The models are fitted by maximizing the binomial
      and multinomial log-likelihood functions using            constrained optimization.
      Wald and bootstrap confidence intervals can be obtained for the parameter            estimates.
      Also, the contribution of diseases to the disability prevalence and their bootstrap
      confidence            intervals can be estimated. An additional feature is the
      possibility to use parallel computing to obtain            the bootstrap confidence
      intervals. In this manuscript, we illustrate the use of addhaz with several            examples
      for the binomial and multinomial models, using the data from the Brazilian National
      Health            Survey, 2013.'
    acknowledged: '2017-08-05'
    online: '2018-12-08'
    CRANpkgs:
    - addhaz
    - boot
    - stats
    - logbin
    - VGAM
    CTV_rev:
    - Econometrics
    - SocialSciences
    - Survival
    - Distributions
    - Environmetrics
    - ExtremeValue
    - Multivariate
    - Optimization
    - Psychometrics
    - TimeSeries
    suppl: 1.5 Kb
    landing: '2018'
  - slug: RJ-2018-056
    title: 'Snowboot: Bootstrap Methods for Network Inference'
    bibtitle: 'Snowboot: Bootstrap Methods for Network Inference'
    author:
    - Yuzhou Chen
    - Yulia R. Gel
    - Vyacheslav Lyubchich
    - Kusha Nezafati
    bibauthor: |-
      Yuzhou Chen and Yulia R. Gel and Vyacheslav Lyubchich and
                Kusha Nezafati
    abstract: '  Abstract Complex networks are used to describe a broad range of disparate
      social systems and natural            phenomena, from power grids to customer
      segmentation to human brain connectome. Challenges            of parametric
      model specification and validation inspire a search for more data-driven and
      flexible            nonparametric approaches for inference of complex networks.
      In this paper we discuss methodology            and R implementation of two
      bootstrap procedures on random networks, that is, patchwork bootstrap            of
      Thompson et al. (2016) and Gel et al. (2017) and vertex bootstrap of Snijders
      and Borgatti (1999). To            our knowledge, the new R package snowboot
      is the first implementation of the vertex and patchwork            bootstrap
      inference on networks in R. Our new package is accompanied with a detailed user’s            manual,
      and is compatible with the popular R package on network studies igraph. We evaluate
      the            patchwork bootstrap and vertex bootstrap with extensive simulation
      studies and illustrate their utility            in application to analysis of
      real world networks.'
    acknowledged: '2017-08-11'
    online: '2018-12-08'
    CRANpkgs:
    - snowboot
    - bootnet
    - sna
    - sna
    - graphics
    - igraph
    - parallel
    - Rcpp
    - Rdpack
    - stats
    - VGAM
    CTV_rev:
    - Optimization
    - SocialSciences
    - Bayesian
    - Distributions
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - gR
    - Graphics
    - HighPerformanceComputing
    - Multivariate
    - NumericalMathematics
    - Psychometrics
    - Spatial
    - Survival
    suppl: 8.9 Kb
    landing: '2018'
  - slug: RJ-2018-057
    title: 'testforDEP: An R Package for Modern Distribution-free Tests and Visualization
      Tools for Independence'
    bibtitle: |-
      testforDEP: An R Package for Modern Distribution-free Tests
                and Visualization Tools for Independence
    author:
    - Jeffrey C. Miecznikowski
    - En-shuo Hsu
    - Yanhua Chen
    - Albert Vexler
    bibauthor: |-
      Jeffrey C. Miecznikowski and En-shuo Hsu and Yanhua Chen and
                Albert Vexler
    abstract: '  Abstract This article introduces testforDEP, a portmanteau R package
      implementing for the first            time several modern tests and visualization
      tools for independence between two variables. While            classical tests
      for independence are in the base R packages, there have been several recently
      developed            tests for independence that are not available in R. This
      new package combines the classical tests            including Pearson’s product
      moment correlation coefficient method, Kendall’s τ rank correlation            coefficient
      method and Spearman’s ρ rank correlation coefficient method with modern tests
      consisting            of an empirical likelihood based test, a density-based
      empirical likelihood ratio test, Kallenberg data           driven test, maximal
      information coefficient test, Hoeffding’s independence test and the continuous            analysis
      of variance test. For two input vectors of observations, the function testforDEP
      provides a            common interface for each of the tests and returns test
      statistics, corresponding p values and bootstrap            confidence intervals
      as output. The function AUK provides an interface to visualize Kendall plots
      and            computes the area under the Kendall plot similar to computing
      the area under a receiver operating            characteristic (ROC) curve.'
    acknowledged: '2018-02-02'
    online: '2018-12-08'
    CRANpkgs:
    - testforDEP
    - Hmisc
    - minerva
    CTV_rev:
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - MissingData
    - Multivariate
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
    suppl: 722 bytes
    landing: '2018'
  - slug: RJ-2018-058
    title: Navigating the R Package Universe
    bibtitle: Navigating the R Package Universe
    author:
    - Julia Silge
    - John C. Nash
    - Spencer Graves
    bibauthor: Julia Silge and John C. Nash and Spencer Graves
    abstract: '  Abstract Today, the enormous number of contributed packages available
      to R users outstrips any given            user’s ability to understand how these
      packages work, their relative merits, or how they are related            to
      each other. We organized a plenary session at useR!2017 in Brussels for the
      R community to think            through these issues and ways forward. This
      session considered three key points of discussion. Users            can navigate
      the universe of R packages with (1) capabilities for directly searching for
      R packages, (2)            guidance for which packages to use, e.g., from CRAN
      Task Views and other sources, and (3) access to            common interfaces
      for alternative approaches to essentially the same problem.'
    acknowledged: '2018-09-07'
    online: '2018-12-08'
    CRANpkgs:
    - sos
    - CRANsearcher
    - utils
    - pkgdown
    - lfe
    - optimx
    CTV_rev:
    - Econometrics
    - Optimization
    suppl: 653 bytes
    landing: '2018'
  - slug: RJ-2018-059
    title: 'rFSA: An R Package for Finding Best Subsets and Interactions'
    bibtitle: 'rFSA: An R Package for Finding Best Subsets and Interactions'
    author:
    - Joshua Lambert
    - Liyu Gong
    - Corrine F. Elliott
    - Katherine Thompson
    - Arnold Stromberg
    bibauthor: |-
      Joshua Lambert and Liyu Gong and Corrine F. Elliott and
                Katherine Thompson and Arnold Stromberg
    abstract: '  Abstract Herein we present the R package rFSA, which implements an
      algorithm for improved            variable selection. The algorithm searches
      a data space for models of a user-specified form that are            statistically
      optimal under a measure of model quality. Many iterations afford a set of feasible
      solutions            (or candidate models) that the researcher can evaluate
      for relevance to his or her questions of interest.            The algorithm
      can be used to formulate new or to improve upon existing models in bioinformatics,            health
      care, and myriad other fields in which the volume of available data has outstripped
      researchers’            practical and computational ability to explore larger
      subsets or higher-order interaction terms. The            package accommodates
      linear and generalized linear models, as well as a variety of criterion functions            such
      as Allen’s PRESS and AIC. New modeling strategies and criterion functions can
      be adapted easily            to work with rFSA.'
    acknowledged: '2018-03-02'
    online: '2018-12-08'
    CRANpkgs:
    - rFSA
    - leaps
    - glmulti
    - glmnet
    - hierNet
    - hashmap
    - geepack
    - devtools
    CTV_rev:
    - SocialSciences
    - ChemPhys
    - Econometrics
    - MachineLearning
    - Survival
    suppl: 2.3 Kb
    landing: '2018'
  - slug: RJ-2018-060
    title: 'lmridge: A Comprehensive R Package for the Ridge Regression'
    bibtitle: 'lmridge: A Comprehensive R Package for the Ridge Regression'
    author:
    - Muhammad Imdad Ullah
    - Muhammad Aslam
    - Saima Altaf
    bibauthor: Muhammad Imdad Ullah and Muhammad Aslam and Saima Altaf
    abstract: '  Abstract The ridge regression estimator is one of the commonly used
      alternative to the conventional            ordinary least squares estimator
      that avoids the adverse effects in the situations when there exists some            considerable
      degree of multicollinearity among the regressors. There are many software packages            available
      for estimation of the ridge regression coefficients. However, most of them display
      limited            methods to estimate the ridge biasing parameters without
      testing procedures. Our developed package,            lmridge can be used to
      estimate the ridge coefficients considering a range of different existing biasing            parameters,
      to test these coefficients with more than 25 ridge related statistics, and to
      present different            graphical displays of these statistics.'
    acknowledged: '2018-03-02'
    online: '2018-12-08'
    CRANpkgs:
    - lmridge
    - ridge
    - MASS
    - lrmest
    - ltsbase
    - penalized
    - glmnet
    - RXshrink
    - rrBLUP
    - RidgeFusion
    - bigRR
    - lpridge
    - genridge
    - CoxRidge
    CTV_rev:
    - MachineLearning
    - Survival
    - Distributions
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Psychometrics
    - Robust
    - SocialSciences
    suppl: 1.6 Kb
    landing: '2018'
  - slug: RJ-2018-061
    title: Geospatial Point Density
    bibtitle: Geospatial Point Density
    author:
    - Paul F. Evangelista
    - David Beskow
    bibauthor: Paul F. Evangelista and David Beskow
    abstract: '  Abstract This paper introduces a spatial point density algorithm
      designed to be explainable, meaning           ful, and efficient. Originally
      designed for military applications, this technique applies to any spatial            point
      process where there is a desire to clearly understand the measurement of density
      and maintain            fidelity of the point locations. Typical spatial density
      plotting algorithms, such as kernel density            estimation, implement
      some type of smoothing function that often results in a density value that is            difficult
      to interpret. The purpose of the visualization method in this paper is to understand
      spatial            point activity density with precision and meaning. The temporal
      tendency of the point process as an            extension of the point density
      methodology is also discussed and displayed. Applications include            visualization
      and measurement of any type of spatial point process. Visualization techniques
      integrate            ggmap with examples from San Diego crime data.'
    acknowledged: '2018-04-04'
    online: '2018-12-08'
    CRANpkgs:
    - ggmap
    - pointdensityP
    - kde2d
    - bkde2D
    - ggplot2
    - data.table
    CTV_rev:
    - Finance
    - Graphics
    - HighPerformanceComputing
    - Phylogenetics
    - Spatial
    - WebTechnologies
    suppl: 3 Kb
    landing: '2018'
  - slug: RJ-2018-062
    title: Consistency Cubes
    bibtitle: Consistency Cubes
    author: Adrian Dusa
    bibauthor: Adrian Dusa
    abstract: A lot of effort has been spent over the past few decades in the QCA
      methodology field, to develop efficient Boolean minimization algorithms to derive
      an exact, and more importantly complete list of minimal prime implicants that
      explain the initial, observed positive configurations.      As the complexity
      grows exponentially with every new condition, the required computer memory goes
      past the current computer resources and the polynomial time required to solve
      this problem quickly grows towards infinity.      This paper introduces a new
      alternative to the existing non-polynomial attempts. It completely solves the
      memory problem, and preliminary tests show it is exponentially hundreds of time
      faster than eQMC, the current “best” algorithm for QCA in R, and probes into
      a territory where it competes and even outperforms engineering algorithms such
      as Espresso, for exact minimizations.      While speed is not much of an issue
      now (eQMC is fast enough for simple data), it might prove to be essential when
      further developing towards all possible temporal orders, or searching for configurations
      in panel data over time, combined with / or automatic detection of difficult
      counterfactuals etc.
    acknowledged: '2018-05-01'
    online: '2018-12-08'
    CRANpkgs:
    - QCA
    - QCA
    - lpSolve
    - venn
    - LogicOpt
    - LogicOpt
    - QCA
    - LogicOpt
    - LogicOpt
    - QCA
    - QCA
    CTV_rev: Optimization
    suppl: 1.8 Kb
    landing: '2018'
  - slug: RJ-2018-063
    title: 'sdpt3r: Semidefinite Quadratic Linear Programming in R'
    bibtitle: 'sdpt3r: Semidefinite Quadratic Linear Programming in R'
    author: Adam Rahman
    bibauthor: Adam Rahman
    abstract: '  Abstract We present the package sdpt3r, an R implementation of the
      Matlab package SDPT3 (Toh            et al., 1999). The purpose of the software
      is to solve semidefinite quadratic linear programming            (SQLP) problems,
      which encompasses problems such as D-optimal experimental design, the nearest            correlation
      matrix problem, and distance weighted discrimination, as well as problems in
      graph theory'
    acknowledged: '2018-05-01'
    online: '2018-12-08'
    CRANpkgs:
    - sdpt3r
    - Rdsdp
    - Rcsdp
    - cccp
    - scs
    - Rmosek
    - quantmod
    CTV_rev:
    - Optimization
    - Finance
    suppl: 882 bytes
    landing: '2018'
  - slug: RJ-2018-064
    title: Downside Risk Evaluation with the R Package GAS
    bibtitle: Downside Risk Evaluation with the R Package GAS
    author:
    - David Ardia
    - Kris Boudt
    - Leopoldo Catania
    bibauthor: David Ardia and Kris Boudt and Leopoldo Catania
    abstract: '  Abstract Financial risk managers routinely use non–linear time series
      models to predict the downside            risk of the capital under management.
      They also need to evaluate the adequacy of their model            using so–called
      backtesting procedures. The latter involve hypothesis testing and evaluation
      of loss            functions. This paper shows how the R package GAS can be
      used for both the dynamic prediction            and the evaluation of downside
      risk. Emphasis is given to the two key financial downside risk            measures:
      Value–at–Risk (VaR) and Expected Shortfall (ES). High–level functions for: (i)
      prediction, (ii)            backtesting, and (iii) model comparison are discussed,
      and code examples are provided. An illustration            using the series
      of log–returns of the Dow Jones Industrial Average constituents is reported.'
    acknowledged: '2018-05-01'
    online: '2018-12-08'
    CRANpkgs:
    - GAS
    - cubature
    CTV_rev:
    - NumericalMathematics
    - TimeSeries
    suppl: 3.9 Kb
    landing: '2018'
  - slug: RJ-2018-065
    title: 'NetworkToolbox: Methods and Measures for Brain, Cognitive, and Psychometric
      Network Analysis in R'
    bibtitle: |-
      NetworkToolbox: Methods and Measures for Brain, Cognitive,
                and Psychometric Network Analysis in R
    author: Alexander P. Christensen
    bibauthor: Alexander P. Christensen
    abstract: '  Abstract This article introduces the NetworkToolbox package for R.
      Network analysis offers an            intuitive perspective on complex phenomena
      via models depicted by nodes (variables) and edges            (correlations).
      The ability of networks to model complexity has made them the standard approach            for
      modeling the intricate interactions in the brain. Similarly, networks have become
      an increasingly            attractive model for studying the complexity of psychological
      and psychopathological phenomena.            NetworkToolbox aims to provide
      researchers with state-of-the-art methods and measures for es           timating
      and analyzing brain, cognitive, and psychometric networks. In this article,
      I introduce            NetworkToolbox and provide a tutorial for applying some
      the package’s functions to personality            data.'
    acknowledged: '2018-06-07'
    online: '2018-12-08'
    CRANpkgs:
    - NetworkToolbox
    - statnet
    - igraph
    - sna
    - brainGraph
    - qgraph
    - IsingFit
    - bootnet
    - glasso
    - IsingFit
    - psych
    - MVN
    - EGA
    - lavaan
    CTV_rev:
    - Psychometrics
    - Optimization
    - SocialSciences
    - Bayesian
    - Econometrics
    - gR
    - Graphics
    - MissingData
    - OfficialStatistics
    - Spatial
    suppl: 2.2 Kb
    landing: '2018'
  - slug: RJ-2018-066
    title: 'jsr223: A Java Platform Integration for R with Programming Languages Groovy,
      JavaScript, JRuby, Jython, and Kotlin'
    bibtitle: |-
      jsr223: A Java Platform Integration for R with Programming
                Languages Groovy, JavaScript, JRuby, Jython, and Kotlin
    author:
    - Floid R. Gilbert
    - David B. Dahl
    bibauthor: Floid R. Gilbert and David B. Dahl
    abstract: '  Abstract The R package jsr223 is a high-level integration for five
      programming languages in the            Java platform: Groovy, JavaScript, JRuby,
      Jython, and Kotlin. Each of these languages can use Java            objects
      in their own syntax. Hence, jsr223 is also an integration for R and the Java
      platform. It enables            developers to leverage Java solutions from within
      R by embedding code snippets or evaluating script            files. This approach
      is generally easier than rJava’s low-level approach that employs the Java Native            Interface.
      jsr223’s multi-language support is dependent on the Java Scripting API: an implementation            of
      “JSR-223: Scripting for the Java Platform” that defines a framework to embed
      scripts in Java            applications. The jsr223 package also features extensive
      data exchange capabilities and a callback            interface that allows embedded
      scripts to access the current R session. In all, jsr223 makes solutions            developed
      in Java or any of the jsr223-supported languages easier to use in R.'
    acknowledged: '2018-05-29'
    online: '2018-12-08'
    CRANpkgs:
    - rJava
    - jsr223
    - rscala
    - jdx
    - V8
    - R6
    - Rserve
    - opencpu
    - rGroovy
    - jsonlite
    - reticulate
    - rJython
    - PythonInR
    - rjson
    CTV_rev:
    - WebTechnologies
    - ModelDeployment
    - NumericalMathematics
    - HighPerformanceComputing
    suppl: 3 Kb
    landing: '2018'
  - slug: RJ-2018-067
    title: 'The politeness Package: Detecting Politeness in Natural Language'
    bibtitle: |-
      The politeness Package: Detecting Politeness in Natural
                Language
    author:
    - Michael Yeomans
    - Alejandro Kantor
    - Dustin Tingley
    bibauthor: Michael Yeomans and Alejandro Kantor and Dustin Tingley
    abstract: '  Abstract This package provides tools to extract politeness markers
      in English natural language. It            also allows researchers to easily
      visualize and quantify politeness between groups of documents.            This
      package combines and extends prior research on the linguistic markers of politeness
      (Brown            and Levinson, 1987; Danescu-Niculescu-Mizil et al., 2013;
      Voigt et al., 2017). We demonstrate two            applications for detecting
      politeness in natural language during consequential social interactions            distributive
      negotiations, and speed dating.'
    acknowledged: '2018-05-29'
    online: '2018-12-08'
    CRANpkgs:
    - tidytext
    - tm
    - quanteda
    - coreNLP
    - spacyR
    - SentimentAnalysis
    - syuzhet
    - topicmodeling
    - stm
    - glmnet
    - textir
    - hunspell
    - data.table
    - politeness
    CTV_rev:
    - NaturalLanguageProcessing
    - HighPerformanceComputing
    - Finance
    - MachineLearning
    - Survival
    suppl: 1.8 Kb
    landing: '2018'
  - slug: RJ-2018-068
    title: 'RcppMsgPack: MessagePack Headers and Interface Functions for R'
    bibtitle: |-
      RcppMsgPack: MessagePack Headers and Interface Functions for
                R
    author:
    - Travers Ching
    - Dirk Eddelbuettel
    bibauthor: Travers Ching and Dirk Eddelbuettel
    abstract: '  Abstract MessagePack, or MsgPack for short, or when referring to
      the implementation, is an efficient            binary serialization format for
      exchanging data between different programming languages. The            RcppMsgPack
      package provides R with both the MessagePack C++ header files, and the ability
      to            access, create and alter MessagePack objects directly from R.
      The main driver functions of the R            interface are two functions msgpack_pack
      and msgpack_unpack. The function msgpack_pack serializes            R objects
      to a raw MessagePack message. The function msgpack_unpack de-serializes MessagePack            messages
      back into R objects. Several helper functions are available to aid in processing
      and formatting            data including msgpack_simplify, msgpack_format and
      msgpack_map.'
    acknowledged: '2018-07-31'
    online: '2018-12-08'
    CRANpkgs:
    - mongolite
    - RProtoBuf
    - RcppRedis
    - RcppMsgPack
    - Rcpp
    - nanotime
    - httr
    - feather
    - data.table
    CTV_rev:
    - HighPerformanceComputing
    - Databases
    - NumericalMathematics
    - Finance
    - WebTechnologies
    suppl: 1.6 Mb
    landing: '2018'
  - slug: RJ-2018-069
    title: 'BNSP: an R Package for Fitting Bayesian Semiparametric Regression Models
      and Variable Selection'
    bibtitle: |-
      BNSP: an R Package for Fitting Bayesian Semiparametric
                Regression Models and Variable Selection
    author: Georgios Papageorgiou
    bibauthor: Georgios Papageorgiou
    abstract: '  Abstract The R package BNSP provides a unified framework for semiparametric
      location-scale            regression and stochastic search variable selection.
      The statistical methodology that the package is            built upon utilizes
      basis function expansions to represent semiparametric covariate effects in the
      mean            and variance functions, and spike-slab priors to perform selection
      and regularization of the estimated            effects. In addition to the main
      function that performs posterior sampling, the package includes            functions
      for assessing convergence of the sampler, summarizing model fits, visualizing
      covariate            effects and obtaining predictions for new responses or
      their means given feature/covariate vectors.'
    acknowledged: '2018-07-31'
    online: '2018-12-08'
    CRANpkgs:
    - BNSP
    - bamlss
    - spikeSlabGAM
    - brms
    - gamboostLSS
    - mgcv
    - coda
    - ggplot2
    - plot3D
    - threejs
    - colorspace
    - np
    - gamair
    - lattice
    CTV_rev:
    - Bayesian
    - Graphics
    - Econometrics
    - Environmetrics
    - Phylogenetics
    - SocialSciences
    - gR
    - MachineLearning
    - Multivariate
    suppl: 3.1 Kb
    landing: '2018'
  - slug: RJ-2018-070
    title: SARIMA Analysis and Automated Model Reports with BETS, an R Package
    bibtitle: |-
      SARIMA Analysis and Automated Model Reports with BETS, an R
                Package
    author:
    - Talitha F. Speranza
    - Pedro C. Ferreira
    - Jonatha A. da Costa
    bibauthor: |-
      Talitha F. Speranza and Pedro C. Ferreira and Jonatha A. da
                Costa
    abstract: '  Abstract This article aims to demonstrate how the powerful features
      of the R package BETS can be            applied to SARIMA time series analysis.
      BETS provides not only thousands of Brazilian economic            time series
      from different institutions, but also a range of analytical tools and educational
      resources. In            particular, BETS is capable of generating automated
      model reports for any given time series. These            reports rely on a
      single function call and are able to build three types of models (SARIMA being
      one of            them), needing few inputs and outputting rich content. The
      output varies according to the inputs and            usually consists of a summary
      of the series properties, step by step explanations on how the model            was
      developed and predicitions made by the model, as well as a file containing these
      predictions. This            work focuses on this feature and several other
      BETS functions that are designed to help the time series            modeler.
      We present them in a thorough case study: the SARIMA approach to model and forecast
      the            Brazilian production of intermediate goods index series.'
    acknowledged: '2017-09-13'
    online: '2018-12-11'
    CRANpkgs:
    - BETS
    - forecast
    - mFilter
    - urca
    - seasonal
    - httr
    - rvest
    - RMySQL
    - rmarkdown
    - stats
    - dygraphs
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - WebTechnologies
    - Databases
    - Environmetrics
    - MissingData
    - OfficialStatistics
    - ReproducibleResearch
    landing: '2018'
  - slug: RJ-2018-072
    title: 'Explanations of model predictions with live and breakDown packages '
    bibtitle: |-
      Explanations of model predictions with live and breakDown
                packages
    author:
    - Mateusz Staniak
    - Przemysław Biecek
    bibauthor: Mateusz Staniak and Przemysław Biecek
    abstract: '  Abstract Complex models are commonly used in predictive modeling.
      In this paper we present R            packages that can be used for explaining
      predictions from complex black box models and attributing            parts of
      these predictions to input features. We introduce two new approaches and corresponding            packages
      for such attribution, namely live and breakDown. We also compare their results
      with            existing implementations of state-of-the-art solutions, namely,
      lime (Pedersen and Benesty, 2017)            which implements Locally Interpretable
      Model-agnostic Explanations and iml (Molnar et al., 2018) which            implements
      Shapley values.'
    acknowledged: '2018-05-01'
    online: '2018-12-11'
    CRANpkgs:
    - live
    - breakDown
    - lime
    - iml
    - pdp
    - caret
    - mlr
    - DALEX
    - archivist
    - xgboost
    - party
    - data.table
    - e1071
    - glmnet
    - randomForest
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - HighPerformanceComputing
    - Multivariate
    - Survival
    - Cluster
    - Distributions
    - Finance
    - MissingData
    - ModelDeployment
    - Psychometrics
    - ReproducibleResearch
    suppl: 1.7 Kb
    landing: '2018'
  - slug: RJ-2018-073
    title: 'bnclassify: Learning Bayesian Network Classifiers'
    bibtitle: 'bnclassify: Learning Bayesian Network Classifiers'
    author:
    - Bojan Mihaljević
    - Concha Bielza
    - Pedro Larrañaga
    bibauthor: Bojan Mihaljević and Concha Bielza and Pedro Larrañaga
    abstract: '  Abstract The bnclassify package provides state-of-the art algorithms
      for learning Bayesian network            classifiers from data. For structure
      learning it provides variants of the greedy hill-climbing search,            a
      well-known adaptation of the Chow-Liu algorithm and averaged one-dependence
      estimators. It            provides Bayesian and maximum likelihood parameter
      estimation, as well as three naive-Bayes           specific methods based on
      discriminative score optimization and Bayesian model averaging. The            implementation
      is efficient enough to allow for time-consuming discriminative scores on medium           sized
      data sets. The bnclassify package provides utilities for model evaluation, such
      as cross-validated            accuracy and penalized log-likelihood scores,
      and analysis of the underlying networks, including            network plotting
      via the Rgraphviz package. It is extensively tested, with over 200 automated
      tests            that give a code coverage of 94%. Here we present the main
      functionalities, illustrate them with a            number of data sets, and
      comment on related software.'
    acknowledged: '2018-05-29'
    online: '2018-12-11'
    CRANpkgs:
    - bnlearn
    - bnclassify
    - caret
    - mlr
    - gRain
    - deal
    BIOpkgs: Rgraphviz
    CTV_rev:
    - Bayesian
    - gR
    - HighPerformanceComputing
    - MachineLearning
    - Multivariate
    suppl: 833 bytes
    landing: '2018'
  - slug: RJ-2018-074
    title: ShinyItemAnalysis for Teaching Psychometrics and to Enforce Routine Analysis
      of Educational Tests
    bibtitle: |-
      ShinyItemAnalysis for Teaching Psychometrics and to Enforce
                Routine Analysis of Educational Tests
    author:
    - Patrícia Martinková
    - Adéla Drabinová
    bibauthor: Patrícia Martinková and Adéla Drabinová
    abstract: '  Abstract This work introduces ShinyItemAnalysis an R package and
      an online shiny application for            psychometric analysis of educational
      tests and items. ShinyItemAnalysis covers a broad range of psy           chometric
      methods and offers data examples, model equations, parameter estimates, interpretation
      of            results, together with a selected R code, and is therefore suitable
      for teaching psychometric concepts            with R. Furthermore, the application
      aspires to be an easy-to-use tool for analysis of educational            tests
      by allowing the users to upload and analyze their own data and to automatically
      generate            analysis reports in PDF or HTML. We argue that psychometric
      analysis should be a routine part of            test development in order to
      gather proofs of reliability and validity of the measurement, and we            demonstrate
      how ShinyItemAnalysis may help enforce this goal.'
    acknowledged: '2018-06-29'
    online: '2018-12-13'
    CRANpkgs:
    - psych
    - ltm
    - difR
    - lavaan
    - ShinyItemAnalysis
    - mirt
    - corrplot
    - cowplot
    - CTT
    - data.table
    - deltaPlotR
    - difNLR
    - DT
    - ggdendro
    - ggplot2
    - gridExtra
    - knitr
    - latticeExtra
    - moments
    - msm
    - nnet
    - plotly
    - psychometric
    - reshape2
    - rmarkdown
    - shiny
    - shinyBS
    - shinydashboard
    - shinyjs
    - stringr
    - xtable
    CTVs: Psychometrics
    CTV_rev:
    - Psychometrics
    - ReproducibleResearch
    - MissingData
    - Distributions
    - Econometrics
    - Graphics
    - WebTechnologies
    - Finance
    - HighPerformanceComputing
    - MachineLearning
    - MetaAnalysis
    - Multivariate
    - OfficialStatistics
    - Phylogenetics
    - SocialSciences
    - Survival
    suppl: 601.1 Kb
    landing: '2018'
  - slug: RJ-2018-075
    title: Measurement Errors in R
    bibtitle: Measurement Errors in R
    author:
    - Iñaki Ucar
    - Edzer Pebesma
    - Arturo Azcorra
    bibauthor: Iñaki Ucar and Edzer Pebesma and Arturo Azcorra
    abstract: '  Abstract This paper presents an R package to handle and represent
      measurements with errors in a            very simple way. We briefly introduce
      the main concepts of metrology and propagation of uncertainty,            and
      discuss related R packages. Building upon this, we introduce the errors package,
      which provides            a class for associating uncertainty metadata, automated
      propagation and reporting. Working with            errors enables transparent,
      lightweight, less error-prone handling and convenient representation            of
      measurements with errors. Finally, we discuss the advantages, limitations and
      future work of            computing with errors.'
    acknowledged: '2018-08-09'
    online: '2018-12-13'
    CRANpkgs:
    - units
    - errors
    - car
    - msm
    - metRology
    - propagate
    - spup
    - distr
    - distrEllipse
    - distrEx
    - distrMod
    - distrRmetrics
    - distrSim
    - distrTeach
    - magrittr
    - ggplot2
    - tibble
    CTV_rev:
    - Distributions
    - ChemPhys
    - Econometrics
    - Finance
    - Graphics
    - Multivariate
    - Phylogenetics
    - Robust
    - SocialSciences
    - Survival
    - WebTechnologies
    suppl: 1.4 Kb
    landing: '2018'
  - slug: RJ-2018-076
    title: Dynamic Simulation and Testing for Single-Equation Cointegrating and Stationary
      Autoregressive Distributed Lag Models
    bibtitle: |-
      Dynamic Simulation and Testing for Single-Equation
                Cointegrating and Stationary Autoregressive Distributed Lag
                Models
    author:
    - Soren Jordan
    - Andrew Q. Philips
    bibauthor: Soren Jordan and Andrew Q. Philips
    abstract: '  Abstract While autoregressive distributed lag models allow for extremely
      flexible dynamics, interpret           ing the substantive significance of complex
      lag structures remains difficult. In this paper we discuss            dynamac
      (dynamic autoregressive and cointegrating models), an R package designed to
      assist users in            estimating, dynamically simulating, and plotting
      the results of a variety of autoregressive distributed            lag models.
      It also contains a number of post-estimation diagnostics, including a test for
      cointegration            for when researchers are estimating the error-correction
      variant of the autoregressive distributed lag            model.'
    acknowledged: '2018-05-29'
    online: '2018-12-31'
    CRANpkgs:
    - dynsim
    - Zelig
    - urca
    - MASS
    CTV_rev:
    - Econometrics
    - Finance
    - SocialSciences
    - Distributions
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Psychometrics
    - Robust
    - TimeSeries
    suppl: 1.2 Kb
    landing: '2018'
  - slug: RJ-2018-079
    title: 'The politeness Package: Detecting Politeness in Natural Language'
    bibtitle: |-
      The politeness Package: Detecting Politeness in Natural
                Language
    author:
    - Michael Yeomans
    - Alejandro Kantor
    - Dustin Tingley
    bibauthor: Michael Yeomans and Alejandro Kantor and Dustin Tingley
    abstract: '  Abstract This package provides tools to extract politeness markers
      in English natural language. It            also allows researchers to easily
      visualize and quantify politeness between groups of documents.            This
      package combines and extends prior research on the linguistic markers of politeness
      (Brown            and Levinson, 1987; Danescu-Niculescu-Mizil et al., 2013;
      Voigt et al., 2017). We demonstrate two            applications for detecting
      politeness in natural language during consequential social interactions—            distributive
      negotiations, and speed dating.'
    acknowledged: '2018-05-29'
    online: '2018-12-08'
    CRANpkgs:
    - tidytext
    - tm
    - quanteda
    - coreNLP
    - spacyR
    - SentimentAnalysis
    - syuzhet
    - topicmodeling
    - stm
    - glmnet
    - textir
    - hunspell
    - data.table
    - politeness
    CTV_rev:
    - NaturalLanguageProcessing
    - HighPerformanceComputing
    - Finance
    - MachineLearning
    - Survival
    suppl: 869.6 Kb
    landing: '2018'
  - slug: RJ-2018-080
    title: 'Consistency Cubes: a fast, efficient method for exact Boolean minimization.'
    bibtitle: |-
      Consistency Cubes: a fast, efficient method for exact
                Boolean minimization.
    author: Adrian Dusa
    bibauthor: Adrian Dusa
    abstract: '  Abstract A lot of effort has been spent over the past few decades
      in the QCA methodology field, to            develop efficient Boolean minimization
      algorithms to derive an exact, and more importantly complete            list
      of minimal prime implicants that explain the initial, observed positive configurations.                 As
      the complexity grows exponentially with every new condition, the required computer
      memory            goes past the current computer resources and the polynomial
      time required to solve this problem            quickly grows towards infinity.                 This
      paper introduces a new alternative to the existing non-polynomial attempts.
      It completely            solves the memory problem, and preliminary tests show
      it is exponentially hundreds of time faster            than eQMC, the current
      “best” algorithm for QCA in R, and probes into a territory where it competes            and
      even outperforms engineering algorithms such as Espresso, for exact minimizations.                 While
      speed is not much of an issue now (eQMC is fast enough for simple data), it
      might prove to be            essential when further developing towards all possible
      temporal orders, or searching for configurations            in panel data over
      time, combined with / or automatic detection of difficult counterfactuals etc.'
    acknowledged: '2018-05-01'
    online: '2018-12-08'
    CRANpkgs:
    - QCA
    - lpSolve
    - venn
    - LogicOpt
    CTV_rev: Optimization
    suppl: 1.8 Kb
    landing: '2018'
  - slug: RJ-2018-081
    title: 'idmTPreg: Regression Model for Progressive Illness Death Data'
    bibtitle: |-
      idmTPreg: Regression Model for Progressive Illness Death
                Data
    author:
    - Leyla Azarang
    - Manuel Oviedo de la Fuente
    bibauthor: Leyla Azarang and Manuel Oviedo de la Fuente
    abstract: '  Abstract The progressive illness-death model is frequently used in
      medical applications. For example,            the model may be used to describe
      the disease process in cancer studies. We have developed a            new R
      package called idmTPreg to estimate regression coefficients in datasets that
      can be described            by the progressive illness-death model. The motivation
      for the development of the package is a            recent contribution that
      enables the estimation of possibly time-varying covariate effects on the            transition
      probabilities for a progressive illness-death data. The main feature of the
      package is that            it befits both non-Markov and Markov progressive
      illness-death data. The package implements the            introduced estimators
      obtained using a direct binomial regression approach. Also, variance estimates            and
      confidence bands are implemented in the package. This article presents guidelines
      for the use of            the package.'
    acknowledged: '2018-03-02'
    online: '2019-02-11'
    CRANpkgs:
    - idmTPreg
    - mstate
    - msm
    - p3state.msm
    - doParallel
    - foreach
    - survival
    CTVs: Survival
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Distributions
    - Econometrics
    - HighPerformanceComputing
    - SocialSciences
    suppl: 422 bytes
    landing: '2018'
- issue: 2009-1
  year: 2009
  volume: 1
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2009-008
    old_slug: Chambers
    title: Facets of R
    bibtitle: Facets of R
    author: John M. Chambers
    bibauthor: John M. Chambers
    landing: '2009'
    abstract: We are seeing today a widespread, and welcome, tendency for non-computer-specialists
      among statisticians and others to write collections of R functions that organize
      and communicate their work. Along with the flood of software sometimes comes
      an attitude that one need only learn, or teach, a sort of basic how-to-write-the-function
      level of R programming, beyond which most of the detail is unimportant or can
      be absorbed without much discussion. As delusions go, this one is not very objectionable
      if it encourages participation. Nevertheless, a delusion it is. In fact, functions
      are only one of a variety of important facets that R has acquired by intent
      or circumstance during the three-plus decades of the history of the software
      and of its predecessor S. To create valuable and trustworthy software using
      R often requires an understanding of some of these facets and their interrelations.
      This paper identifies six facets, discussing where they came from, how they
      support or conflict with each other, and what implications they have for the
      future of programming with R.
    pages:
    - 5
    - 8
  - slug: RJ-2009-007
    old_slug: Theussl+Zeileis
    title: Collaborative Software Development Using R-Forge
    bibtitle: Collaborative Software Development Using R-Forge
    author:
    - Stefan Theußl
    - Achim Zeileis
    bibauthor: Stefan Theußl and Achim Zeileis
    landing: '2009'
    abstract: 'Open source software (OSS) is typically created in a decentralized
      self-organizing process by a community of developers having the same or similar
      interests (see the famous essay by ?). A key factor for the success of OSS over
      the last two decades is the Internet: Developers who rarely meet face-to-face
      can employ new means of communication, both for rapidly writing and deploying
      software (in the spirit of Linus Torvald’s “release early, release often paradigm”).
      Therefore, many tools emerged that assist a collaborative software development
      process, including in particular tools for source code management (SCM) and
      version control.'
    pages:
    - 9
    - 14
  - slug: RJ-2009-006
    old_slug: Murrell
    title: Drawing Diagrams with R
    bibtitle: Drawing Diagrams with R
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2009'
    abstract: R provides a number of well-known high-level facilities for producing
      sophisticated statistical plots, including the “traditional” plots in the graphics
      package (R Development Core Team, 2008), the Trellis-style plots provided by
      lattice (Sarkar, 2008), and the grammar-of-graphics-inspired approach of ggplot2
      (Wickham, 2009).
    pages:
    - 15
    - 21
    CRANpkgs:
    - graphics
    - lattice
    - ggplot2
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
  - slug: RJ-2009-009
    old_slug: Pau+Huber
    title: 'The hwriter package: Composing HTML documents with R objects'
    bibtitle: 'The hwriter package: Composing HTML documents with R objects'
    author:
    - Gregoire Pau
    - Wolfgang Huber
    bibauthor: Gregoire Pau and Wolfgang Huber
    landing: '2009'
    abstract: HTML documents are structured documents made of diverse elements such
      as paragraphs, sections, columns, figures and tables organized in a hierarchical
      layout. Combination of HTML documents and hyperlinking is useful to report analysis
      results; for example, in the package arrayQualityMetrics, estimating the quality
      of microarray data sets and cellHTS2, performing the analysis of cell-based
      screens.
    pages:
    - 22
    - 24
  - slug: RJ-2009-003
    old_slug: Ardia+et+al
    title: AdMit
    bibtitle: AdMit
    author:
    - David Ardia
    - Lennart F. Hoogerheide
    - Herman K. van Dijk
    bibauthor: |-
      David Ardia and Lennart F. Hoogerheide and Herman K. van
                Dijk
    landing: '2009'
    abstract: A package for constructing and using an adaptive mixture of Student-t
      distributions as a flexible candidate distribution for efficient simulation.
    pages:
    - 25
    - 30
  - slug: RJ-2009-005
    old_slug: Goulet+et+al
    title: 'expert: Modeling Without Data Using Expert Opinion'
    bibtitle: 'expert: Modeling Without Data Using Expert Opinion'
    author:
    - Vincent Goulet
    - Michel Jacques
    - Mathieu Pigeon
    bibauthor: Vincent Goulet and Michel Jacques and Mathieu Pigeon
    landing: '2009'
    abstract: The expert package provides tools to create and manipulate empirical
      statistical models using expert opinion (or judgment). Here, the latter expression
      refers to a specific body of techniques to elicit the distribution of a random
      variable when data is scarce or unavailable. Opinions on the quantiles of the
      distribution are sought from experts in the field and aggregated into a final
      estimate. The package supports aggregation by means of the Cooke, Mendel–Sheridan
      and predefined weights models.
    pages:
    - 31
    - 36
  - slug: RJ-2009-001
    old_slug: Mi+et+al
    title: New Numerical Algorithm for Multivariate Normal Probabilities in Package
      mvtnorm
    bibtitle: |-
      New Numerical Algorithm for Multivariate Normal
                Probabilities in Package mvtnorm
    author:
    - Xuefei Mi
    - Tetsuhisa Miwa
    - Torsten Hothorn
    bibauthor: Xuefei Mi and Tetsuhisa Miwa and Torsten Hothorn
    landing: '2009'
    abstract: '? proposed a numerical algorithm for evaluating multivariate normal
      probabilities. Starting with version 0.9-0 of the mvtnorm package (??), this
      algorithm is available to the R community. We give a brief introduction to Miwa’s
      procedure and compare it to a quasi-randomized Monte-Carlo procedure proposed
      by ?, which has been available through mvtnorm for some years now, both with
      respect to computing time and accuracy.'
    pages:
    - 37
    - 39
  - slug: RJ-2009-002
    old_slug: Kim+Oh
    title: 'EMD: A Package for Empirical Mode Decomposition and Hilbert Spectrum'
    bibtitle: |-
      EMD: A Package for Empirical Mode Decomposition and Hilbert
                Spectrum
    author:
    - Donghoh Kim
    - Hee-Seok Oh
    bibauthor: Donghoh Kim and Hee-Seok Oh
    landing: '2009'
    abstract: The concept of empirical mode decomposition (EMD) and the Hilbert spectrum
      (HS) has been developed rapidly in many disciplines of science and engineering
      since Huang et al. (1998) invented EMD. The key feature of EMD is to decompose
      a signal into so-called intrinsic mode function (IMF). Furthermore, the Hilbert
      spectral analysis of intrinsic mode functions provides frequency information
      evolving with time and quantifies the amount of variation due to oscillation
      at different time scales and time locations. In this article, we introduce an
      R package called EMD (Kim and Oh, 2008) that performs oneand twodimensional
      EMD and HS.
    pages:
    - 40
    - 46
  - slug: RJ-2009-019
    old_slug: Orr+Liu
    title: Sample Size Estimation while Controlling False Discovery Rate for Microarray
      Experiments Using the ssize.fdr Package
    bibtitle: "Sample Size Estimation while Controlling False Discovery Rate \n    for
      Microarray Experiments Using the {ssize.fdr} Package"
    author:
    - Megan Orr
    - Peng Liu
    bibauthor: Megan Orr and Peng Liu
    landing: '2009'
    abstract: Microarray experiments are becoming more and more popular and critical
      in many biological disciplines. As in any statistical experiment, appropriate
      experimental design is essential for reliable statistical inference, and sample
      size has a crucial role in experimental design. Because microarray experiments
      are rather costly, it is important to have an adequate sample size that will
      achieve a desired power without wasting resources.
    pages:
    - 47
    - 53
  - slug: RJ-2009-004
    old_slug: Knaus+et+al
    title: Easier parallel computing in R with snowfall and sfCluster
    bibtitle: Easier parallel computing in R with snowfall and sfCluster
    author:
    - Jochen Knaus
    - Christine Porzelius
    - Harald Binder
    - Guido Schwarzer
    bibauthor: |-
      Jochen Knaus and Christine Porzelius and Harald Binder and
                Guido Schwarzer
    landing: '2009'
    abstract: Many statistical analysis task in areas such as bioinformatics are computationally
      very intensive, while lots of them rely on embarrasingly parallel computations
      (Ananth Grama, 2003). Multiple computers or even multiple processor cores on
      standard desktop computers, which are widespread available nowadays, can easily
      contribute to faster analyses.
    pages:
    - 54
    - 59
  - slug: RJ-2009-010
    old_slug: Guazzelli+et+al
    title: 'PMML: An Open Standard for Sharing Models'
    bibtitle: 'PMML: An Open Standard for Sharing Models'
    author:
    - Alex Guazzelli
    - Michael Zeller
    - Wen-Ching Lin
    - Graham Williams
    bibauthor: |-
      Alex Guazzelli and Michael Zeller and Wen-Ching Lin and
                Graham Williams
    landing: '2009'
    abstract: The PMML package exports a variety of predictive and descriptive models
      from R to the Predictive Model Markup Language (Data Mining Group, 2008). PMML
      is an XML-based language and has become the de-facto standard to represent not
      only predictive and descriptive models, but also data preand post-processing.
      In so doing, it allows for the interchange of models among different tools and
      environments, mostly avoiding proprietary issues and incompatibilities.
    pages:
    - 60
    - 65
  notes:
  - title: 'Forthcoming Events: Conference on Quantitative Social Science Research
      Using R'
    bibtitle: 'Forthcoming Events: Conference on Quantitative Social Science Research
      Using {R}'
    page: 66
  - title: 'Forthcoming Events: DSC 2009'
    bibtitle: 'Forthcoming Events: {DSC} 2009'
    page: 66
  - title: 'Forthcoming Events: useR! 2009'
    bibtitle: 'Forthcoming Events: {useR!} 2009'
    page: 67
  - title: 'Conference Review: The 1st Chinese R Conference'
    bibtitle: 'Conference Review: The 1st {C}hinese {R} Conference'
    page: 69
  - title: Changes in R 2.9.0
    bibtitle: Changes in {R} 2.9.0
    page: 71
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 77
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 91
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 92
- issue: 2009-2
  year: 2009
  volume: 1
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2009-014
    old_slug: Fox
    title: Aspects of the Social Organization and Trajectory of the R Project
    bibtitle: |-
      Aspects of the Social Organization and Trajectory of the R
                Project
    author: John Fox
    bibauthor: John Fox
    landing: '2009'
    abstract: Based partly on interviews with members of the R Core team, this paper
      considers the development of the R Project in the context of open-source software
      development and, more generally, voluntary activities. The paper describes aspects
      of the social organization of the R Project, including the organization of the
      R Core team; describes the trajectory of the R Project; seeks to identify factors
      crucial to the success of R; and speculates about the prospects for R.
    pages:
    - 5
    - 13
  - slug: RJ-2009-013
    old_slug: Strobl~et~al
    title: Party on!
    bibtitle: Party on!
    author:
    - Carolin Strobl
    - Torsten Hothorn
    - Achim Zeileis
    bibauthor: Carolin Strobl and Torsten Hothorn and Achim Zeileis
    landing: '2009'
    abstract: Recursive partitioning methods are amongst the most popular and widely
      used statistical learning tools for nonparametric regression and classification.
      Especially random forests, that can deal with large numbers of predictor variables
      even in the presence of complex interactions, are being applied successfully
      in many scientific fields (see, e.g., ??, and the references therein for applications
      in genetics and social sciences). Thus, it is not surprising that there is a
      variety of recursive partitioning tools available in R (see http://CRAN.R-project.org/view=MachineLearning
      for an overview).
    pages:
    - 14
    - 17
  - slug: RJ-2009-011
    old_slug: Lafaye~de~Micheaux+Liquet
    title: 'ConvergenceConcepts: An R Package to Investigate Various Modes of Convergence'
    bibtitle: |-
      ConvergenceConcepts: An R Package to Investigate Various
                Modes of Convergence
    author:
    - Pierre Lafaye de Micheaux
    - Benoit Liquet
    bibauthor: Pierre Lafaye de Micheaux and Benoit Liquet
    landing: '2009'
    abstract: 'ConvergenceConcepts is an R package, built upon the tkrplot, tcltk
      and lattice packages, designed to investigate the convergence of simulated sequences
      of random variables. Four classical modes of convergence may be studied, namely:
      almost sure convergence (a.s.), convergence in probability (P), convergence
      in law (L) and convergence in r-th mean (r). This investigation is performed
      through accurate graphical representations. This package may be used as a pedagogical
      tool. It may give students a better understanding of these notions and help
      them to visualize these difficult theoretical concepts. Moreover, some scholars
      could gain some insight into the behaviour of some random sequences they are
      interested in.'
    pages:
    - 18
    - 25
  - slug: RJ-2009-015
    old_slug: Coeurjolly~et~al
    title: 'asympTest: A Simple R Package for Classical Parametric Statistical Tests
      and Confidence Intervals in Large Samples'
    bibtitle: |-
      asympTest: A Simple R Package for Classical Parametric
                Statistical Tests and Confidence Intervals in Large Samples
    author:
    - J.-F. Coeurjolly
    - R. Drouilhet
    - P. Lafaye de Micheaux
    - J.-F. Robineau
    bibauthor: |-
      J.-F. Coeurjolly and R. Drouilhet and P. Lafaye de Micheaux
                and J.-F. Robineau
    landing: '2009'
    abstract: '  Abstract asympTest is an R package implementing large sample tests
      and confidence intervals. One            and two sample mean and variance tests
      (differences and ratios) are considered. The test statistics            are
      all expressed in the same form as the Student t-test, which facilitates their
      presentation in the            classroom. This contribution also fills the gap
      of a robust (to non-normality) alternative to the chi           square single
      variance test for large samples, since no such procedure is implemented in standard            statistical
      software.'
    pages:
    - 26
    - 30
    CRANpkgs:
    - asympTest
    - asympTest
    - asympTest
  - slug: RJ-2009-012
    old_slug: Carpenter~et~al
    title: 'copas: An R package for Fitting the Copas Selection Model'
    bibtitle: 'copas: An R package for Fitting the Copas Selection Model'
    author:
    - J. Carpenter
    - G. Rücker
    - G. Schwarzer
    bibauthor: J. Carpenter and G. Rücker and G. Schwarzer
    landing: '2009'
    abstract: This article describes the R package copas which is an add-on package
      to the R package meta. The R package copas can be used to fit the Copas selection
      model to adjust for bias in meta-analysis. A clinical example is used to illustrate
      fitting and interpreting the Copas selection model.
    pages:
    - 31
    - 36
    CRANpkgs:
    - copas
    - meta
    CTV_rev:
    - ClinicalTrials
    - MetaAnalysis
  - slug: RJ-2009-018
    old_slug: Damico
    title: 'Transitioning to R: Replicating SAS, Stata, and SUDAAN Analysis Techniques
      in Health Policy Data'
    bibtitle: |-
      Transitioning to R: Replicating SAS, Stata, and SUDAAN
                Analysis Techniques in Health Policy Data
    author: Anthony Damico
    bibauthor: Anthony Damico
    landing: '2009'
    abstract: Statistical, data manipulation, and presentation tools make R an ideal
      integrated package for research in the fields of health policy and healthcare
      management and evaluation. However, the technical documentation accompanying
      most data sets used by researchers in these fields does not include syntax examples
      for analysts to make the transition from another statistical package to R. This
      paper describes the steps required to import health policy data into R, to prepare
      that data for analysis using the two most common complex survey variance calculation
      techniques, and to produce the principal set of statistical estimates sought
      by health policy researchers. Using data from the Medical Expenditure Panel
      Survey Household Component (MEPS-HC), this paper outlines complex survey data
      analysis techniques in R, with side-by-side comparisons to the SAS, Stata, and
      SUDAAN statistical software packages.
    pages:
    - 37
    - 44
  - slug: RJ-2009-016
    old_slug: Williams
    title: 'Rattle: A Data Mining GUI for R'
    bibtitle: 'Rattle: A Data Mining GUI for R'
    author: Graham J Williams
    bibauthor: Graham J Williams
    landing: '2009'
    abstract: '  Abstract Data mining delivers insights, patterns, and descriptive
      and predictive models from the            large amounts of data available today
      in many organisations. The data miner draws heavily on            methodologies,
      techniques and algorithms from statistics, machine learning, and computer science.
      R            increasingly provides a powerful platform for data mining. However,
      scripting and programming            is sometimes a challenge for data analysts
      moving into data mining. The Rattle package provides a            graphical
      user interface specifically for data mining using R. It also provides a stepping
      stone toward            using R as a programming language for data analysis.'
    pages:
    - 45
    - 55
    CRANpkgs:
    - arules
    - RGtk2
    - RGtk2
    - rattle
    - rattle
    - rattle
    - rattle
    - Hmisc
    - fBasics
    - mice
    - rggobi
    - rggobi
    - latticist
    - playwith
    - lattice
    - reshape
    - randomForest
    - Amelia
    - rpart
    - party
    - rpart
    - randomForest
    - ROCR
    - pmml
    - rattle
    - pmml
    - RGtk2
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Graphics
    - Environmetrics
    - OfficialStatistics
    - SocialSciences
    - Survival
    - Bayesian
    - ClinicalTrials
    - Distributions
    - Econometrics
    - Finance
    - Pharmacokinetics
    - ReproducibleResearch
  - slug: RJ-2009-017
    old_slug: Graves~et~al
    title: 'sos: Searching Help Pages of R Packages'
    bibtitle: 'sos: Searching Help Pages of R Packages'
    author:
    - Spencer Graves
    - Sundar Dorai-Raj
    - Romain François
    bibauthor: Spencer Graves and Sundar Dorai-Raj and Romain François
    landing: '2009'
    abstract: The sos package provides a means to quickly and flexibly search the
      help pages of contributed packages, finding functions and datasets in seconds
      or minutes that could not be found in hours or days by any other means we know.
      Its findFn function accesses Jonathan Baron’s R Site Search database and returns
      the matches in a data frame of class "findFn", which can be further manipulated
      by other sos functions to produce, for example, an Excel file that starts with
      a summary sheet that makes it relatively easy to prioritize alternative packages
      for further study. As such, it provides a very powerful way to do a literature
      search for functions and packages relevant to a particular topic of interest
      and could become virtually mandatory for authors of new packages or papers in
      publications such as The R Journal and the Journal of Statistical Software.
    pages:
    - 56
    - 59
    CRANpkgs:
    - sos
    - sos
    - sos
    - sos
    - WriteXLS
    - RODBC
    - sos
    - fda
    - deSolve
    - PKfit
    - sos
    - sos
    - sos
    - sos
    CTV_rev:
    - DifferentialEquations
    - Pharmacokinetics
  - slug: Murdoch+Urbanek
    type: From the Core
    title: The New R Help System
    bibtitle: The New {R} Help System
    author:
    - Duncan Murdoch
    - Simon Urbanek
    pages:
    - 60
    - 65
  notes:
  - title: 'Conference Review: DSC 2009'
    bibtitle: 'Conference Review: {DSC} 2009'
    page: 66
  - title: 'Conference Review: WZUR(2.0) - The Second Meeting of Polish R Users'
    bibtitle: 'Conference Review: {WZUR(2.0)} -- The Second Meeting of {P}olish {R}
      Users'
    page: 67
  - title: 'R Changes: 2.9.1-2.10.0 Patched'
    bibtitle: 'R Changes: 2.9.1--2.10.0 Patched'
    page: 68
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 95
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 96
- issue: 2010-1
  volume: 2
  year: 2010
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2010-001
    old_slug: Pramana~et~al
    title: 'IsoGene: An R Package for Analyzing Dose-response Studies in Microarray
      Experiments'
    bibtitle: |-
      IsoGene: An R Package for Analyzing Dose-response Studies in
                Microarray Experiments
    author:
    - Setia Pramana
    - Dan Lin
    - Philippe Haldermans
    - Ziv Shkedy
    - Tobias Verbeke
    - Hinrich Göhlmann
    - An De Bondt
    - Willem Talloen
    - Luc Bijnens.
    bibauthor: |-
      Setia Pramana and Dan Lin and Philippe Haldermans and Ziv
                Shkedy and Tobias Verbeke and Hinrich Göhlmann and An De
                Bondt and Willem Talloen and Luc Bijnens.
    landing: '2010'
    abstract: IsoGene is an R package for the analysis of dose-response microarray
      experiments to identify gene or subsets of genes with a monotone relationship
      between the gene expression and the doses. Several testing procedures (i.e.,
      the likelihood ratio test, Williams, Marcus, the M, and Modified M), that take
      into account the order restriction of the means with respect to the increasing
      doses are implemented in the package. The inference is based on resampling methods,
      both permutations and the Significance Analysis of Microarrays (SAM).
    pages:
    - 5
    - 12
  - slug: RJ-2010-003
    old_slug: Brown+Zhou
    title: MCMC for Generalized Linear Mixed Models with glmmBUGS
    bibtitle: MCMC for Generalized Linear Mixed Models with glmmBUGS
    author:
    - Patrick Brown
    - Lutong Zhou
    bibauthor: Patrick Brown and Lutong Zhou
    landing: '2010'
    abstract: The glmmBUGS package is a bridging tool between Generalized Linear Mixed
      Models (GLMMs) in R and the BUGS language. It provides a simple way of performing
      Bayesian inference using Markov Chain Monte Carlo (MCMC) methods, taking a model
      formula and data frame in R and writing a BUGS model file, data file, and initial
      values files. Functions are provided to reformat and summarize the BUGS results.
      A key aim of the package is to provide files and objects that can be modified
      prior to calling BUGS, giving users a platform for customizing and extending
      the models to accommodate a wide variety of analyses.
    pages:
    - 13
    - 17
  - slug: RJ-2010-004
    old_slug: Weidmann+Skrede~Gleditsch
    title: Mapping and Measuring Country Shapes
    bibtitle: Mapping and Measuring Country Shapes
    author:
    - Nils B. Weidmann
    - Kristian Skrede Gleditsch
    bibauthor: Nils B. Weidmann and Kristian Skrede Gleditsch
    landing: '2010'
    abstract: The article introduces the cshapes R package, which includes our CShapes
      dataset of contemporary and historical country boundaries, as well as computational
      tools for computing geographical measures from these maps. We provide an overview
      of the need for considering spatial dependence in comparative research, how
      this requires appropriate historical maps, and detail how the cshapes associated
      R package cshapes can contribute to these ends. We illustrate the use of the
      package for drawing maps, computing spatial variables for countries, and generating
      weights matrices for spatial statistics.
    pages:
    - 18
    - 24
  - slug: RJ-2010-005
    old_slug: Wilhelm+Manjunath
    title: 'tmvtnorm: A Package for the Truncated Multivariate Normal Distribution'
    bibtitle: |-
      tmvtnorm: A Package for the Truncated Multivariate Normal
                Distribution
    author:
    - Stefan Wilhelm
    - B. G. Manjunath
    bibauthor: Stefan Wilhelm and B. G. Manjunath
    landing: '2010'
    abstract: '  Abstract In this article we present tmvtnorm, an R package implementation
      for the truncated mul           tivariate normal distribution. We consider random
      number generation with rejection and Gibbs            sampling, computation
      of marginal densities as well as computation of the mean and covariance of            the
      truncated variables. This contribution brings together latest research in this
      field and provides            useful methods for both scholars and practitioners
      when working with truncated normal variables.'
    pages:
    - 25
    - 29
  - slug: RJ-2010-006
    old_slug: Guenther+Fritsch
    title: 'neuralnet: Training of Neural Networks'
    bibtitle: 'neuralnet: Training of Neural Networks'
    author:
    - Frauke Günther
    - Stefan Fritsch
    bibauthor: Frauke Günther and Stefan Fritsch
    landing: '2010'
    abstract: Artificial neural networks are applied in many situations. neuralnet
      is built to train multilayer perceptrons in the context of regression analyses,
      i.e. to approximate functional relationships between covariates and response
      variables. Thus, neural networks are used as extensions of generalized linear
      models.       neuralnet is a very flexible package. The backpropagation algorithm
      and three versions of resilient backpropagation are implemented and it provides
      a custom-choice of activation and error function. An arbitrary number of covariates
      and response variables as well as of hidden layers can theoretically be included.       The
      paper gives a brief introduction to multi-layer perceptrons and resilient backpropagation
      and demonstrates the application of neuralnet using the data set infert, which
      is contained in the R distribution.
    pages:
    - 30
    - 38
  - slug: RJ-2010-007
    old_slug: Werft+Benner
    title: 'glmperm: A Permutation of Regressor Residuals Test for Inference in Generalized
      Linear Models'
    bibtitle: |-
      glmperm: A Permutation of Regressor Residuals Test for
                Inference in Generalized Linear Models
    author:
    - Wiebke Werft
    - Axel Benner
    bibauthor: Wiebke Werft and Axel Benner
    landing: '2010'
    abstract: '  Abstract We introduce a new R package called glmperm for inference
      in generalized linear models            especially for small and moderate-sized
      data sets. The inference is based on the permutation of            regressor
      residuals test introduced by Potter (2005). The implementation of glmperm outperforms            currently
      available permutation test software as glmperm can be applied in situations
      where more            than one covariate is involved.'
    pages:
    - 39
    - 43
  - slug: RJ-2010-002
    old_slug: Thioulouse~et~al
    title: 'Online Reproducible Research: An Application to Multivariate Analysis
      of Bacterial DNA Fingerprint Data'
    bibtitle: |-
      Online Reproducible Research: An Application to Multivariate
                Analysis of Bacterial DNA Fingerprint Data
    author:
    - Jean Thioulouse
    - Claire Valiente-Moro
    - Lionel Zenner
    bibauthor: Jean Thioulouse and Claire Valiente-Moro and Lionel Zenner
    landing: '2010'
    abstract: '  Abstract This paper presents an example of online reproducible multivariate
      data analysis. This            example is based on a web page providing an online
      computing facility on a server. HTML forms            contain editable R code
      snippets that can be executed in any web browser thanks to the Rweb software.            The
      example is based on the multivariate analysis of DNA fingerprints of the internal
      bacterial flora            of the poultry red mite Dermanyssus gallinae. Several
      multivariate data analysis methods from the            ade4 package are used
      to compare the fingerprints of mite pools coming from various poultry farms.            All
      the computations and graphical displays can be redone interactively and further
      explored online,            using only a web browser. Statistical methods are
      detailed in the duality diagram framework, and a            discussion about
      online reproducibility is initiated.'
    pages:
    - 44
    - 52
    CRANpkgs:
    - ade4
    - seqinr
    - ade4
    - vegan
    - CGIwithR
    - R2HTML
    CTV_rev:
    - Environmetrics
    - Multivariate
    - Psychometrics
    - Spatial
    - Graphics
    - Genetics
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2010-008
    old_slug: Fay
    title: Two-sided Exact Tests and Matching Confidence Intervals for Discrete Data
    bibtitle: |-
      Two-sided Exact Tests and Matching Confidence Intervals for
                Discrete Data
    author: Michael P. Fay
    bibauthor: Michael P. Fay
    landing: '2010'
    abstract: '  Abstract There is an inherent relationship between two-sided hypothesis
      tests and confidence intervals.            A series of two-sided hypothesis
      tests may be inverted to obtain the matching 100(1-α)% confidence            interval
      defined as the smallest interval that contains all point null parameter values
      that would not            be rejected at the α level. Unfortunately, for discrete
      data there are several different ways of defining            two-sided exact
      tests and the most commonly used two-sided exact tests are defined one way,
      while            the most commonly used exact confidence intervals are inversions
      of tests defined another way. This            can lead to inconsistencies where
      the exact test rejects but the exact confidence interval contains the            null
      parameter value. The packages exactci and exact2x2 provide several exact tests
      with the matching            confidence intervals avoiding these inconsistencies
      as much as possible. Examples are given for            binomial and Poisson
      parameters and both paired and unpaired 2 × 2 tables.                 Applied
      statisticians are increasingly being encouraged to report confidence intervals
      (CI) and            parameter estimates along with p-values from hypothesis
      tests. The htest class of the stats package            is ideally suited to
      these kinds of analyses, because all the related statistics may be presented
      when            the results are printed. For exact two-sided tests applied to
      discrete data, a test-CI inconsistency may            occur: the p-value may
      indicate a significant result at level α while the associated 100(1-α)% confidence            interval
      may cover the null value of the parameter. Ideally, we would like to present
      a unified report            (Hirji, 2006), whereby the p-value and the confidence
      interval match as much as possible.'
    pages:
    - 53
    - 58
    CRANpkgs:
    - exactci
    - exact2x2
    - exactci
    - exact2x2
    - exactci
    - exact2x2
    - PropCIs
    - rateratio.test
    - coin
    - perm
    CTV_rev:
    - ClinicalTrials
    - Survival
  notes:
  - title: A Beginner's Guide to R
    bibtitle: A Beginner's Guide to {R}
    page: 59
  - title: 'Conference Review: The 2nd Chinese R Conference'
    bibtitle: 'Conference Review: The 2nd {C}hinese {R} Conference'
    page: 60
  - title: 'Introducing NppToR: R Interaction for Notepad++'
    bibtitle: 'Introducing {NppToR}: {R} Interaction for {Notepad++}'
    page: 62
  - title: Changes in R 2.10.1-2.11.1
    bibtitle: Changes in {R} 2.10.1--2.11.1
    page: 64
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 72
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 85
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 86
- issue: 2010-2
  volume: 2
  year: 2010
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2010-013
    old_slug: Soetaert~et~al
    title: Solving Differential Equations in R
    bibtitle: Solving Differential Equations in R
    author:
    - Karline Soetaert
    - Thomas Petzoldt
    - R. Woodrow Setzer
    bibauthor: Karline Soetaert and Thomas Petzoldt and R. Woodrow Setzer
    landing: '2010'
    abstract: Although R is still predominantly applied for statistical analysis and
      graphical representation, it is rapidly becoming more suitable for mathematical
      computing. One of the fields where considerable progress has been made recently
      is the solution of differential equations. Here we give a brief overview of
      differential equations that can now be solved by R.
    pages:
    - 5
    - 15
    CRANpkgs:
    - limSolve
    - rootSolve
    - deSolve
    - bvpSolve
    - ReacTran
    - PBSddesolve
    - sde
    - pomp
    - bvpSolve
    - ReacTran
    - deSolve
    - deSolve
    - ReacTran
    - deSolve
    - odesolve
    - odesolve
    - nlmeODE
    - FME
    - ccems
    - ReacTran
    CTV_rev:
    - DifferentialEquations
    - Pharmacokinetics
    - TimeSeries
    - Bayesian
    - Finance
    - Optimization
  - slug: RJ-2010-010
    old_slug: Murdoch
    title: Source References
    bibtitle: Source References
    author: Duncan Murdoch
    bibauthor: Duncan Murdoch
    landing: '2010'
    abstract: Since version 2.10.0, R includes expanded support for source references
      in R code and ‘.Rd’ files. This paper describes the origin and purposes of source
      references, and current and future support for them.
    pages:
    - 16
    - 19
  - slug: RJ-2010-009
    old_slug: Roennegaard~et~al
    title: 'hglm: A Package for Fitting Hierarchical Generalized Linear Models'
    bibtitle: |-
      hglm: A Package for Fitting Hierarchical Generalized Linear
                Models
    author:
    - Lars Rönnegård
    - Xia Shen
    - Moudud Alam
    bibauthor: Lars Rönnegård and Xia Shen and Moudud Alam
    landing: '2010'
    abstract: '  Abstract We present the hglm package for fitting hierarchical generalized
      linear models. It can be            used for linear mixed models and generalized
      linear mixed models with random effects for a variety            of links and
      a variety of distributions for both the outcomes and the random effects. Fixed
      effects can            also be fitted in the dispersion part of the model.'
    pages:
    - 20
    - 28
    CRANpkgs:
    - hglm
    - lme4
    - MASS
    - dglm
    - HGLMMM
    - nlme
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Psychometrics
    - SocialSciences
    - OfficialStatistics
    - Pharmacokinetics
    - SpatioTemporal
    - Bayesian
    - ChemPhys
    - Distributions
    - Finance
    - Multivariate
    - NumericalMathematics
    - Robust
    - Spatial
  - slug: RJ-2010-011
    old_slug: Solymos
    title: 'dclone: Data Cloning in R'
    bibtitle: 'dclone: Data Cloning in R'
    author: Péter Sólymos
    bibauthor: Péter Sólymos
    landing: '2010'
    abstract: The dclone R package contains low level functions for implementing maximum
      likelihood estimating procedures for complex models using data cloning and Bayesian
      Markov Chain Monte Carlo methods with support for JAGS, WinBUGS and OpenBUGS.
    pages:
    - 29
    - 37
    CRANpkgs:
    - dclone
    - rjags
    - coda
    - R2WinBUGS
    - BRugs
    CTV_rev:
    - gR
    - Bayesian
    - Cluster
    - HighPerformanceComputing
    - Optimization
  - slug: RJ-2010-012
    old_slug: Wickham
    title: 'stringr: modern, consistent string processing'
    bibtitle: 'stringr: modern, consistent string processing'
    author: Hadley Wickham
    bibauthor: Hadley Wickham
    landing: '2010'
    abstract: '  Abstract String processing is not glamorous, but it is frequently
      used in data cleaning and preparation.            The existing string functions
      in R are powerful, but not friendly. To remedy this, the stringr package            provides
      string functions that are simpler and more consistent, and also fixes some functionality
      that            R is missing compared to other programming languages.'
    pages:
    - 38
    - 40
  - slug: RJ-2010-014
    old_slug: Ardia+Hoogerheide
    title: Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations
    bibtitle: |-
      Bayesian Estimation of the GARCH(1,1) Model with Student-t
                Innovations
    author:
    - David Ardia
    - Lennart F. Hoogerheide
    bibauthor: David Ardia and Lennart F. Hoogerheide
    landing: '2010'
    abstract: '  Abstract This note presents the R package bayesGARCH which provides
      functions for the Bayesian            estimation of the parsimonious and effective
      GARCH(1,1) model with Student-t innovations. The            estimation procedure
      is fully automatic and thus avoids the tedious task of tuning an MCMC sampling            algorithm.
      The usage of the package is shown in an empirical application to exchange rate
      log-returns.'
    pages:
    - 41
    - 47
    CRANpkgs:
    - fGarch
    - rgarch
    - tseries
    - bayesGARCH
    - coda
    - foreach
    CTV_rev:
    - Finance
    - Bayesian
    - TimeSeries
    - Econometrics
    - Environmetrics
    - gR
    - HighPerformanceComputing
  - slug: RJ-2010-015
    old_slug: Ferreira~da~Silva
    title: 'cudaBayesreg: Bayesian Computation in CUDA'
    bibtitle: 'cudaBayesreg: Bayesian Computation in CUDA'
    author: Adelino Ferreira da Silva
    bibauthor: Adelino Ferreira da Silva
    landing: '2010'
    abstract: '  Abstract Graphical processing units are rapidly gaining maturity
      as powerful general parallel comput           ing devices. The package cudaBayesreg
      uses GPU–oriented procedures to improve the performance            of Bayesian
      computations. The paper motivates the need for devising high-performance computing            strategies
      in the context of fMRI data analysis. Some features of the package for Bayesian
      analysis of            brain fMRI data are illustrated. Comparative computing
      performance figures between sequential and            parallel implementations
      are presented as well.'
    pages:
    - 48
    - 55
    CRANpkgs:
    - cudaBayesreg
    - bayesm
    - cudaBayesregData
    - oro.nifti
    CTV_rev:
    - MedicalImaging
    - Bayesian
    - HighPerformanceComputing
    - Cluster
    - Distributions
    - Econometrics
    - Multivariate
  - slug: RJ-2010-016
    old_slug: Bilder~et~al
    title: 'binGroup: A Package for Group Testing'
    bibtitle: 'binGroup: A Package for Group Testing'
    author:
    - Christopher R. Bilder
    - Boan Zhang
    - Frank Schaarschmidt
    - Joshua M. Tebbs
    bibauthor: |-
      Christopher R. Bilder and Boan Zhang and Frank Schaarschmidt
                and Joshua M. Tebbs
    landing: '2010'
    abstract: '  Abstract When the prevalence of a disease or of some other binary
      characteristic is small, group            testing (also known as pooled testing)
      is frequently used to estimate the prevalence and/or to identify            individuals
      as positive or negative. We have developed the binGroup package as the first
      package            designed to address the estimation problem in group testing.
      We present functions to estimate an            overall prevalence for a homogeneous
      population. Also, for this setting, we have functions to aid in            the
      very important choice of the group size. When individuals come from a heterogeneous
      population,            our group testing regression functions can be used to
      estimate an individual probability of disease            positivity by using
      the group observations only. We illustrate our functions with data from a multiple            vector
      transfer design experiment and a human infectious disease prevalence study.'
    pages:
    - 56
    - 60
    CRANpkgs:
    - binGroup
    - binom
  - slug: RJ-2010-017
    old_slug: Sariyar+Borg
    title: 'The RecordLinkage Package: Detecting Errors in Data'
    bibtitle: 'The RecordLinkage Package: Detecting Errors in Data'
    author:
    - Murat Sariyar
    - Andreas Borg
    bibauthor: Murat Sariyar and Andreas Borg
    landing: '2010'
    abstract: '  Abstract Record linkage deals with detecting homonyms and mainly
      synonyms in data. The package            RecordLinkage provides means to perform
      and evaluate different record linkage methods. A stochas           tic framework
      is implemented which calculates weights through an EM algorithm. The determination            of
      the necessary thresholds in this model can be achieved by tools of extreme value
      theory. Further           more, machine learning methods are utilized, including
      decision trees (rpart), bootstrap aggregating            (bagging), ada boost
      (ada), neural nets (nnet) and support vector machines (svm). The generation            of
      record pairs and comparison patterns from single data items are provided as
      well. Comparison            patterns can be chosen to be binary or based on
      some string metrics. In order to reduce computation            time and memory
      usage, blocking can be used. Future development will concentrate on additional            and
      refined methods, performance improvements and input/output facilities needed
      for real-world            application.'
    pages:
    - 61
    - 67
  - slug: RJ-2010-018
    old_slug: Ishwaran~et~al
    title: 'spikeslab: Prediction and Variable Selection Using Spike and Slab Regression'
    bibtitle: |-
      spikeslab: Prediction and Variable Selection Using Spike and
                Slab Regression
    author:
    - Hemant Ishwaran
    - Udaya B. Kogalur
    - J. Sunil Rao
    bibauthor: Hemant Ishwaran and Udaya B. Kogalur and J. Sunil Rao
    landing: '2010'
    abstract: '  Abstract Weighted generalized ridge regression offers unique advantages
      in correlated high-dimensional            problems. Such estimators can be efficiently
      computed using Bayesian spike and slab models and are            effective for
      prediction. For sparse variable selection, a generalization of the elastic net
      can be used in            tandem with these Bayesian estimates. In this article,
      we describe the R-software package spikeslab            for implementing this
      new spike and slab prediction and variable selection methodology.'
    pages:
    - 68
    - 73
    CRANpkgs:
    - lars
    - snow
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
  notes:
  - title: What's New?
    page: 74
  - title: useR! 2010
    bibtitle: '{useR!} 2010'
    page: 77
  - title: 'Forthcoming Events: useR! 2011'
    bibtitle: 'Forthcoming Events: {useR!} 2011'
    page: 79
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 81
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 90
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2011-1
  volume: 3
  year: 2011
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2011-002
    old_slug: Wickham
    title: 'testthat: Get Started with Testing'
    bibtitle: 'testthat: Get Started with Testing'
    author: Hadley Wickham
    bibauthor: Hadley Wickham
    landing: '2011'
    abstract: '  Abstract Software testing is important, but many of us don’t do it
      because it is frustrating and boring.            testthat is a new testing framework
      for R that is easy learn and use, and integrates with your existing            workflow.
      This paper shows how, with illustrations from existing packages.'
    pages:
    - 5
    - 10
    CRANpkgs:
    - testthat
    - RUnit
    - svUnit
    - stringr
    - lubridate
    CTV_rev:
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2011-003
    old_slug: Bohn~et~al
    title: Content-Based Social Network Analysis of Mailing Lists
    bibtitle: Content-Based Social Network Analysis of Mailing Lists
    author:
    - Angela Bohn
    - Ingo Feinerer
    - Kurt Hornik
    - Patrick Mair
    bibauthor: |-
      Angela Bohn and Ingo Feinerer and Kurt Hornik and Patrick
                Mair
    landing: '2011'
    abstract: Social Network Analysis (SNA) provides tools to examine relationships
      between people. Text Mining (TM) allows capturing the text they produce in Web
      2.0 applications, for example, however it neglects their social structure. This
      paper applies an approach to combine the two methods named “content-based SNA”.
      Using the R mailing lists, R-help and R-devel, we show how this combination
      can be used to describe people’s interests and to find out if authors who have
      similar interests actually communicate. We find that the expected positive relationship
      between sharing interests and communicating gets stronger as the centrality
      scores of authors in the communication networks increase.
    pages:
    - 11
    - 18
    CRANpkgs:
    - tm.plugin.mail
    - car
    - tm
    - sna
    - igraph
    CTV_rev:
    - NaturalLanguageProcessing
    - Optimization
    - SocialSciences
    - Bayesian
    - Econometrics
    - Finance
    - gR
    - Graphics
    - HighPerformanceComputing
    - Multivariate
    - Spatial
  - slug: RJ-2011-001
    old_slug: Chalabi~et~al
    title: Rmetrics - timeDate Package
    bibtitle: Rmetrics - timeDate Package
    author:
    - Yohan Chalabi
    - Martin Mächler
    - Diethelm Würtz
    bibauthor: Yohan Chalabi and Martin Mächler and Diethelm Würtz
    landing: '2011'
    abstract: '  Abstract The management of time and holidays can prove crucial in
      applications that rely on historical            data. A typical example is the
      aggregation of a data set recorded in different time zones and under dif           ferent
      daylight saving time rules. Besides the time zone conversion function, which
      is well supported            by default classes in R, one might need functions
      to handle special days or holidays. In this respect,            the package
      timeDate enhances default date-time classes in R and brings new functionalities
      to time            zone management and the creation of holiday calendars.'
    pages:
    - 19
    - 24
    CRANpkgs:
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    - timeDate
    CTV_rev:
    - Finance
    - TimeSeries
  - slug: RJ-2011-004
    old_slug: Poisot
    title: 'The digitize Package: Extracting Numerical Data from Scatterplots'
    bibtitle: |-
      The digitize Package: Extracting Numerical Data from
                Scatterplots
    author: Timothée Poisot
    bibauthor: Timothée Poisot
    landing: '2011'
    abstract: '  Abstract I present the small R package digitize, designed to extract
      data from scatterplots with a            simple method and suited to small datasets.
      I present an application of this method to the extraction            of data
      from a graph whose source is not available.'
    pages:
    - 25
    - 26
    CRANpkgs:
    - digitize
    - ReadImages
  - slug: RJ-2011-005
    old_slug: Ardia~et~al
    title: Differential Evolution with DEoptim
    bibtitle: Differential Evolution with DEoptim
    author:
    - David Ardia
    - Kris Boudt
    - Peter Carl
    - Katharine M. Mullen
    - Brian G. Peterson
    bibauthor: |-
      David Ardia and Kris Boudt and Peter Carl and Katharine M.
                Mullen and Brian G. Peterson
    landing: '2011'
    abstract: The R package DEoptim implements the Differential Evolution algorithm.
      This algorithm is an evolutionary technique similar to classic genetic algorithms
      that is useful for the solution of global optimization problems. In this note
      we provide an introduction to the package and demonstrate its utility for financial
      applications by solving a non-convex portfolio optimization problem.
    pages:
    - 27
    - 34
    CRANpkgs:
    - DEoptim
    - PortfolioAnalytics
    - quantmod
    - PerformanceAnalytics
    CTV_rev:
    - Finance
    - Optimization
  - slug: RJ-2011-006
    old_slug: South
    title: 'rworldmap : a new R package for mapping global data'
    bibtitle: 'rworldmap : a new R package for mapping global data'
    author: Andy South
    bibauthor: Andy South
    landing: '2011'
    abstract: '  Abstract rworldmap is a new package available on CRAN for mapping
      and visualisation of global            data. The vision is to make the display
      of global data easier, to facilitate understanding and com           munication.
      The initial concentration is on data referenced by country or grid due to the
      frequency            of use of such data in global assessments. Tools to link
      data referenced by country (either name or            code) to a map, and then
      to display the map are provided as are functions to map global gridded data.            Country
      and gridded functions accept the same arguments to specify the nature of categories
      and            colour and how legends are formatted. This package builds on
      the functionality of existing packages,            particularly sp, maptools
      and fields. Example code is provided to produce maps, to link with the            packages
      classInt, RColorBrewer and ncdf, and to plot examples of publicly available
      country and            gridded data.'
    pages:
    - 35
    - 43
  - slug: RJ-2011-007
    old_slug: Lafitte~et~al
    title: Cryptographic Boolean Functions with R
    bibtitle: Cryptographic Boolean Functions with R
    author:
    - Frédéric Lafitte
    - Dirk Van Heule
    - Julien Van hamme
    bibauthor: Frédéric Lafitte and Dirk Van Heule and Julien Van hamme
    landing: '2011'
    abstract: '  Abstract A new package called boolfun is available for R users. The
      package provides tools to handle            Boolean functions, in particular
      for cryptographic purposes. This document guides the user through            some
      (code) examples and gives a feel of what can be done with the package.'
    pages:
    - 44
    - 47
    CRANpkgs:
    - boolfun
    - R.oo
    - multipol
    CTV_rev: NumericalMathematics
  - slug: RJ-2011-008
    old_slug: Murrell
    title: Raster Images in R Graphics
    bibtitle: Raster Images in R Graphics
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2011'
    abstract: '  Abstract The R graphics engine has new support for rendering raster
      images via the functions            rasterImage() and grid.raster(). This leads
      to better scaling of raster images, faster rendering to            screen, and
      smaller graphics files. Several examples of possible applications of these new
      features are            described.'
    pages:
    - 48
    - 54
  - slug: RJ-2011-009
    old_slug: Fraley~et~al
    title: Probabilistic Weather Forecasting in R
    bibtitle: Probabilistic Weather Forecasting in R
    author:
    - Chris Fraley
    - Adrian Raftery
    - Tilmann Gneiting
    - McLean Sloughter
    - Veronica Berrocal
    bibauthor: |-
      Chris Fraley and Adrian Raftery and Tilmann Gneiting and
                McLean Sloughter and Veronica Berrocal
    landing: '2011'
    abstract: '  Abstract This article describes two R packages for probabilistic
      weather forecasting, ensembleBMA,            which offers ensemble postprocessing
      via Bayesian model averaging (BMA), and ProbForecastGOP,            which implements
      the geostatistical output perturbation (GOP) method. BMA forecasting models            use
      mixture distributions, in which each component corresponds to an ensemble member,
      and the            form of the component distribution depends on the weather
      parameter (temperature, quantitative            precipitation or wind speed).
      The model parameters are estimated from training data. The GOP            technique
      uses geostatistical methods to produce probabilistic forecasts of entire weather
      fields for            temperature or pressure, based on a single numerical forecast
      on a spatial grid. Both packages include            functions for evaluating
      predictive performance, in addition to model fitting and forecasting.'
    pages:
    - 55
    - 63
    CRANpkgs:
    - ensembleBMA
    - chron
    - fields
    - maps
    - ProbForecastGOP
    - RandomFields
    - fields
    CTV_rev:
    - Spatial
    - TimeSeries
    - Bayesian
    - SpatioTemporal
  - slug: RJ-2011-010
    old_slug: Kane~et~al
    title: Analyzing an Electronic Limit Order Book
    bibtitle: Analyzing an Electronic Limit Order Book
    author:
    - David Kane
    - Andrew Liu
    - Khanh Nguyen
    bibauthor: David Kane and Andrew Liu and Khanh Nguyen
    landing: '2011'
    abstract: '  Abstract The orderbook package provides facilities for exploring
      and visualizing the data associated            with an order book: the electronic
      collection of the outstanding limit orders for a financial instrument.            This
      article provides an overview of the orderbook package and examples of its use.'
    pages:
    - 64
    - 68
  - slug: Hyndman
    type: Help desk
    title: Giving a useR! Talk
    bibtitle: Giving a {useR!} Talk
    author: Rob J. Hyndman
    pages:
    - 69
    - 71
  - slug: Cook
    type: Help desk
    title: Tips for Presenting Your Work
    author: Dianne Cook
    pages:
    - 72
    - 74
  notes:
  - title: Forest Analytics with R (Use R)
    bibtitle: Forest Analytics with {R} ({Use R})
    page: 75
  - title: 'Conference Review: Third Meeting of Polish R Users, The Influenza Challenge'
    bibtitle: 'Conference Review: Third Meeting of {P}olish {R} Users, The Influenza
      Challenge'
    page: 76
  - title: 'Conference Review: Kickoff Workshop for Project MOSAIC'
    bibtitle: 'Conference Review: Kickoff Workshop for Project {MOSAIC}'
    page: 78
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 79
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 89
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2011-2
  volume: 3
  year: 2011
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2011-011
    old_slug: Baier~et~al
    title: Creating and Deploying an Application with (R)Excel and R
    bibtitle: Creating and Deploying an Application with (R)Excel and R
    author:
    - Thomas Baier
    - Erich Neuwirth
    - Michele De Meo
    bibauthor: Thomas Baier and Erich Neuwirth and Michele De Meo
    landing: '2011'
    abstract: '  Abstract We present some ways of using R in Excel and build an example
      application using the            package rpart. Starting with simple interactive
      use of rpart in Excel, we eventually package the code            into an Excel-based
      application, hiding all details (including R itself) from the end user. In the
      end, our            application implements a service-oriented architecture (SOA)
      with a clean separation of presentation            and computation layer.'
    pages:
    - 5
    - 11
    CRANpkgs: rpart
    CTV_rev:
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Survival
  - slug: RJ-2011-012
    old_slug: Marschner
    title: 'glm2: Fitting Generalized Linear Models with Convergence Problems'
    bibtitle: |-
      glm2: Fitting Generalized Linear Models with Convergence
                Problems
    author: Ian C. Marschner
    bibauthor: Ian C. Marschner
    landing: '2011'
    abstract: '  Abstract The R function glm uses step-halving to deal with certain
      types of convergence problems            when using iteratively reweighted least
      squares to fit a generalized linear model. This works well in            some
      circumstances but non-convergence remains a possibility, particularly with a
      non-standard link            function. In some cases this is because step-halving
      is never invoked, despite a lack of convergence. In            other cases step-halving
      is invoked but is unable to induce convergence. One remedy is to impose a            stricter
      form of step-halving than is currently available in glm, so that the deviance
      is forced to decrease            in every iteration. This has been implemented
      in the glm2 function available in the glm2 package.            Aside from a
      modified computational algorithm, glm2 operates in exactly the same way as glm
      and            provides improved convergence properties. These improvements
      are illustrated here with an identity            link Poisson model, but are
      also relevant in other contexts.'
    pages:
    - 12
    - 15
    CRANpkgs: glm2
  - slug: RJ-2011-013
    old_slug: Lundholm
    title: Implementing the Compendium Concept with Sweave and DOCSTRIP
    bibtitle: Implementing the Compendium Concept with Sweave and DOCSTRIP
    author: Michael Lundholm
    bibauthor: Michael Lundholm
    landing: '2011'
    abstract: This article suggests an implementation of the compendium concept by
      combining Sweave  and the LATEX literate programming environment DOCSTRIP.
    pages:
    - 16
    - 21
  - slug: RJ-2011-014
    old_slug: Hornik+Murdoch
    title: Watch Your Spelling!
    bibtitle: Watch Your Spelling!
    author:
    - Kurt Hornik
    - Duncan Murdoch
    bibauthor: Kurt Hornik and Duncan Murdoch
    landing: '2011'
    abstract: '  Abstract We discuss the facilities in base R for spell checking via
      Aspell, Hunspell or Ispell, which are            useful in particular for conveniently
      checking the spelling of natural language texts in package Rd            files
      and vignettes. Spell checking performance is illustrated using the Rd files
      in package stats. This            example clearly indicates the need for a domain-specific
      statistical dictionary. We analyze the results            of spell checking
      all Rd files in all CRAN packages and show how these can be employed for building            such
      a dictionary.'
    pages:
    - 22
    - 28
  - slug: RJ-2011-015
    old_slug: Wang+Song
    title: 'Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic
      Programming'
    bibtitle: |-
      Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension
                by Dynamic Programming
    author:
    - Haizhou Wang
    - Mingzhou Song
    bibauthor: Haizhou Wang and Mingzhou Song
    landing: '2011'
    abstract: '  Abstract            The heuristic k-means algorithm, widely used
      for cluster analysis, does not guarantee optimality. We            developed
      a dynamic programming algorithm for optimal one-dimensional clustering. The
      algorithm            is implemented as an R package called Ckmeans.1d.dp. We
      demonstrate its advantage in optimality            and runtime over the standard
      iterative k-means algorithm.'
    pages:
    - 29
    - 33
    CRANpkgs: Ckmeans.1d.dp
  - slug: RJ-2011-016
    old_slug: Arnold+Emerson
    title: Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions
    bibtitle: |-
      Nonparametric Goodness-of-Fit Tests for Discrete Null
                Distributions
    author:
    - Taylor B. Arnold
    - John W. Emerson
    bibauthor: Taylor B. Arnold and John W. Emerson
    landing: '2011'
    abstract: '  Abstract Methodology extending nonparametric goodness-of-fit tests
      to discrete null distributions has            existed for several decades. However,
      modern statistical software has generally failed to provide this            methodology
      to users. We offer a revision of R’s ks.test() function and a new cvm.test()
      function            that fill this need in the R language for two of the most
      popular nonparametric goodness-of-fit tests.            This paper describes
      these contributions and provides examples of their usage. Particular attention
      is            given to various numerical issues that arise in their implementation.'
    pages:
    - 34
    - 39
    CRANpkgs:
    - dgof
    - nortest
    - ADGofTest
    - CvM2SL1Test
    - CvM2SL2Test
    - cramer
    CTV_rev: Multivariate
  - slug: RJ-2011-017
    old_slug: Gesmann+de~Castillo
    title: Using the Google Visualisation API with R
    bibtitle: Using the Google Visualisation API with R
    author:
    - Markus Gesmann
    - Diego de Castillo
    bibauthor: Markus Gesmann and Diego de Castillo
    landing: '2011'
    abstract: '  Abstract The googleVis package provides an interface between R and
      the Google Visualisation API            to create interactive charts which can
      be embedded into web pages. The best known of these charts            is probably
      the Motion Chart, popularised by Hans Rosling in his TED talks. With the googleVis            package
      users can easily create web pages with interactive charts based on R data frames
      and display            them either via the local R HTTP help server or within
      their own sites.'
    pages:
    - 40
    - 44
    CRANpkgs:
    - rsp
    - googleVis
    - rjsonio
    - brew
    CTV_rev:
    - ReproducibleResearch
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2011-018
    old_slug: Herve
    title: 'GrapheR: a Multiplatform GUI for Drawing Customizable Graphs in R'
    bibtitle: |-
      GrapheR: a Multiplatform GUI for Drawing Customizable Graphs
                in R
    author: Maxime Hervé
    bibauthor: Maxime Hervé
    landing: '2011'
    abstract: '  Abstract This article presents GrapheR, a Graphical User Interface
      allowing the user to draw customiz           able and high-quality graphs without
      knowing any R commands. Six kinds of graph are available:            histograms,
      box-and-whisker plots, bar plots, pie charts, curves and scatter plots. The
      complete            process is described with the examples of a bar plot and
      a scatter plot illustrating the legendary puzzle            of African and European
      swallows’ migrations.'
    pages:
    - 45
    - 53
    CRANpkgs:
    - JGR
    - playwith
    - GrapheR
    CTV_rev: Graphics
  - slug: RJ-2011-019
    old_slug: Lin~Shang
    title: 'rainbow: An R Package for Visualizing Functional Time Series'
    bibtitle: 'rainbow: An R Package for Visualizing Functional Time Series'
    author: Han Lin Shang
    bibauthor: Han Lin Shang
    landing: '2011'
    abstract: Recent advances in computer technology have tremendously increased the
      use of functional data, whose graphical representation can be infinite-dimensional
      curves, images or shapes. This article describes four methods for visualizing
      functional time series using an R add-on package. These methods are demonstrated
      using age-specific Australian fertility data from 1921 to 2006 and monthly sea
      surface temperatures from January 1950 to December 2006.
    pages:
    - 54
    - 59
  - slug: RJ-2011-020
    old_slug: Plummer
    title: Portable C++ for R Packages
    bibtitle: Portable C++ for R Packages
    author: Martyn Plummer
    bibauthor: Martyn Plummer
    landing: '2011'
    abstract: '  Abstract Package checking errors are more common on Solaris than
      Linux. In many cases, these errors            are due to non-portable C++ code.
      This article reviews some commonly recurring problems in C++            code
      found in R packages and suggests solutions.'
    pages:
    - 60
    - 63
    CRANpkgs: Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
  notes:
  - title: R's Participation in the Google Summer of Code 2011
    bibtitle: '{R}''s Participation in the {Google Summer of Code 2011}'
    page: 64
  - title: 'Conference Report: useR! 2011'
    bibtitle: 'Conference Report: {useR!} 2011'
    page: 68
  - title: 'Forthcoming Events: useR! 2012'
    bibtitle: 'Forthcoming Events: {useR!} 2012'
    page: 70
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 72
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 84
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 86
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 87
- issue: 2012-1
  volume: 4
  year: 2012
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: RJ-2012-001
    old_slug: G~Barnett~et~al
    title: Analysing Seasonal Data
    bibtitle: Analysing Seasonal Data
    author:
    - Adrian G Barnett
    - Peter Baker
    - Annette J Dobson
    bibauthor: Adrian G Barnett and Peter Baker and Annette J Dobson
    landing: '2012'
    abstract: '  Abstract Many common diseases, such as the flu and cardiovascular
      disease, increase markedly in            winter and dip in summer. These seasonal
      patterns have been part of life for millennia and were            first noted
      in ancient Greece by both Hippocrates and Herodotus. Recent interest has focused
      on            climate change, and the concern that seasons will become more
      extreme with harsher winter and            summer weather. We describe a set
      of R functions designed to model seasonal patterns in disease.            We
      illustrate some simple descriptive and graphical methods, a more complex method
      that is able to            model non-stationary patterns, and the case-crossover
      to control for seasonal confounding.                 In this paper we illustrate
      some of the functions of the season package (Barnett et al., 2012), which            contains
      a range of functions for analysing seasonal health data. We were motivated by
      the great            interest in seasonality found in the health literature,
      and the relatively small number of seasonal tools            in R (or other
      software packages). The existing seasonal tools in R are:                • the
      baysea function of the timsac package and the decompose and stl functions of
      the stats                    package for decomposing a time series into a trend
      and season;                • the dynlm function of the dynlm package and the
      ssm function of the sspir package for fitting                    dynamic linear
      models with optional seasonal components;                • the arima function
      of the stats package and the Arima function of the forecast package for fitting                    seasonal
      components as part of an autoregressive integrated moving average (ARIMA) model;                    and                •
      the bfast package for detecting breaks in a seasonal pattern.            These
      tools are all useful, but most concern decomposing equally spaced time series
      data. Our package            includes models that can be applied to seasonal
      patterns in unequally spaced data. Such data are            common in observational
      studies when the timing of responses cannot be controlled (e.g. for a postal            survey).                 In
      the health literature much of the analysis of seasonal data uses simple methods
      such as com           paring rates of disease by month or using a cosinor regression
      model, which assumes a sinusoidal            seasonal pattern. We have created
      functions for these simple, but often very effective analyses, as we            describe
      below.                 More complex seasonal analyses examine non-stationary
      seasonal patterns that change over time.            Changing seasonal patterns
      in health are currently of great interest as global warming is predicted to            make
      seasonal changes in the weather more extreme. Hence there is a need for statistical
      tools that            can estimate whether a seasonal pattern has become more
      extreme over time or whether its phase has            changed.                 Ours
      is also the first R package that includes the case-crossover, a useful method
      for controlling for            seasonality.                 This paper illustrates
      just some of the functions of the season package. We show some descriptive            functions
      that give simple means or plots, and functions whose goal is inference based
      on generalised            linear models. The package was written as a companion
      to a book on seasonal analysis by Barnett and            Dobson (2010), which
      contains further details on the statistical methods and R code.'
    pages:
    - 5
    - 10
    CRANpkgs:
    - season
    - timsac
    - dynlm
    - sspir
    - forecast
    - bfast
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - Environmetrics
  - slug: RJ-2012-002
    old_slug: Holmes~et~al
    title: 'MARSS: Multivariate Autoregressive State-space Models for Analyzing Time-series
      Data'
    bibtitle: |-
      MARSS: Multivariate Autoregressive State-space Models for
                Analyzing Time-series Data
    author:
    - Elizabeth E. Holmes
    - Eric J. Ward
    - Kellie Wills
    bibauthor: Elizabeth E. Holmes and Eric J. Ward and Kellie Wills
    landing: '2012'
    abstract: '  Abstract MARSS is a package for fitting multivariate autoregressive
      state-space models to time-series            data. The MARSS package implements
      state-space models in a maximum likelihood framework. The            core functionality
      of MARSS is based on likelihood maximization using the Kalman filter/smoother,            combined
      with an EM algorithm. To make comparisons with other packages available, parameter            estimation
      is also permitted via direct search routines available in ’optim’. The MARSS
      package allows            data to contain missing values and allows a wide variety
      of model structures and constraints to be            specified (such as fixed
      or shared parameters). In addition to model-fitting, the package provides            bootstrap
      routines for simulating data and generating confidence intervals, and multiple
      options for            calculating model selection criteria (such as AIC).'
    pages:
    - 11
    - 19
    CRANpkgs:
    - MARSS
    - sspir
    - dlm
    - dse
    - KFAS
    - FKF
    CTV_rev:
    - TimeSeries
    - Finance
    - Bayesian
    - Environmetrics
  - slug: RJ-2012-003
    old_slug: Ropkins+Carslaw
    title: openair - Data Analysis Tools for the Air Quality Community
    bibtitle: openair - Data Analysis Tools for the Air Quality Community
    author:
    - Karl Ropkins
    - David C. Carslaw
    bibauthor: Karl Ropkins and David C. Carslaw
    landing: '2012'
    abstract: '  Abstract The openair package contains data analysis tools for the
      air quality community. This paper            provides an overview of data importers,
      main functions, and selected utilities and workhorse functions            within
      the package and the function output class, as of package version 0.4-14. It
      is intended as an            explanation of the rationale for the package and
      a technical description for those wishing to work            more interactively
      with the main functions or develop additional functions to support ‘higher level’            use
      of openair and R.                Large volumes of air quality data are routinely
      collected for regulatory purposes, but few of those            in local authorities
      and government bodies tasked with this responsibility have the time, expertise            or
      funds to comprehensively analyse this potential resource (Chow and Watson, 2008).
      Furthermore,            few of these institutions can routinely access the more
      powerful statistical methods typically required            to make the most
      effective use of such data without a suite of often expensive and niche-application            proprietary
      software products. This in turn places large cost and time burdens on both these
      institutions            and others (e.g. academic or commercial) wishing to
      contribute to this work. In addition, such            collaborative working
      practices can also become highly restricted and polarised if data analysis            undertaken
      by one partner cannot be validated or replicated by another because they lack
      access to            the same licensed products.                Being freely
      distributed under general licence, R has the obvious potential to act as a common            platform
      for those routinely collecting and archiving data and the wider air quality
      community.            This potential has already been proven in several other
      research areas, and commonly cited ex           amples include the Bioconductor
      project (Gentleman et al, 2004) and the Epitools collaboration            (http://www.medepi.com/epitools).
      However, what is perhaps most inspiring is the degree of trans           parency
      that has been demonstrated by the recent public analysis of climate change data
      in R and as           sociated open debate (http://chartsgraphs.wordpress.com/category/r-climate-data-analysis           tool/).
      Anyone affected by a policy decision, could potentially have unlimited access
      to scrutinise            both the tools and data used to shape that decision.'
    pages:
    - 20
    - 29
    CRANpkgs:
    - openair
    - openair
    - lattice
    - latticeExtra
    - hexbin
    - grDevices
    - mgcv
    - stats
    - grDevices
    - RColorBrewer
    CTV_rev:
    - Graphics
    - Environmetrics
    - SpatioTemporal
    - Bayesian
    - Econometrics
    - Multivariate
    - Pharmacokinetics
    - SocialSciences
    - Spatial
  - slug: RJ-2012-004
    old_slug: Adler
    title: Foreign Library Interface
    bibtitle: Foreign Library Interface
    author: Daniel Adler
    bibauthor: Daniel Adler
    landing: '2012'
    abstract: '  Abstract We present an improved Foreign Function Interface (FFI)
      for R to call arbitary native            functions without the need for C wrapper
      code. Further we discuss a dynamic linkage framework for            binding
      standard C libraries to R across platforms using a universal type information
      format. The            package rdyncall comprises the framework and an initial
      repository of cross-platform bindings for            standard libraries such
      as (legacy and modern) OpenGL, the family of SDL libraries and Expat. The            package
      enables system-level programming using the R language; sample applications are
      given in            the article. We outline the underlying automation tool-chain
      that extracts cross-platform bindings            from C headers, making the
      repository extendable and open for library developers.'
    pages:
    - 30
    - 40
    CRANpkgs:
    - rdyncall
    - Rffi
  - slug: RJ-2012-005
    old_slug: Lawson
    title: 'Vdgraph: A Package for Creating Variance Dispersion Graphs'
    bibtitle: 'Vdgraph: A Package for Creating Variance Dispersion Graphs'
    author: John Lawson
    bibauthor: John Lawson
    landing: '2012'
    abstract: '  Abstract This article introduces the package Vdgraph that is used
      for making variance dispersion            graphs of response surface designs.
      The package includes functions that make the variance dispersion            graph
      of one design or compare variance dispersion graphs of two designs, which are
      stored in data            frames or matrices. The package also contains several
      minimum run response surface designs (stored            as matrices) that are
      not available in other R packages.'
    pages:
    - 41
    - 44
    CRANpkgs:
    - Vdgraph
    - rsm
    CTV_rev: ExperimentalDesign
  - slug: RJ-2012-006
    old_slug: Anoke~et~al
    title: 'xgrid and R: Parallel Distributed Processing Using Heterogeneous Groups
      of Apple Computers'
    bibtitle: |-
      xgrid and R: Parallel Distributed Processing Using
                Heterogeneous Groups of Apple Computers
    author:
    - Sarah C. Anoke
    - Yuting Zhao
    - Rafael Jaeger
    - Nicholas J. Horton
    bibauthor: |-
      Sarah C. Anoke and Yuting Zhao and Rafael Jaeger and
                Nicholas J. Horton
    landing: '2012'
    abstract: '  Abstract The Apple Xgrid system provides access to groups (or grids)
      of computers that can be used            to facilitate parallel processing.
      We describe the xgrid package which facilitates access to this system            to
      undertake independent simulations or other long-running jobs that can be divided
      into replicate            runs within R. Detailed examples are provided to demonstrate
      the interface, along with results from a            simulation study of the
      performance gains using a variety of grids. Use of the grid for “embarassingly            parallel”
      independent jobs has the potential for major speedups in time to completion.
      Appendices            provide guidance on setting up the workflow, utilizing
      add-on packages, and constructing grids using            existing machines.'
    pages:
    - 45
    - 55
    CRANpkgs:
    - GridR
    - Rmpi
    - snow
    - multicore
    - xgrid
    - runjags
    - poLCA
    CTV_rev:
    - HighPerformanceComputing
    - Bayesian
    - Cluster
    - Multivariate
    - Psychometrics
  - slug: RJ-2012-007
    old_slug: Jurka
    title: 'maxent: An R Package for Low-memory Multinomial Logistic Regression with
      Support for Semi-automated Text Classification'
    bibtitle: |-
      maxent: An R Package for Low-memory Multinomial
                Logistic Regression with Support for Semi-automated Text
                Classification
    author: Timothy P. Jurka
    bibauthor: Timothy P. Jurka
    landing: '2012'
    abstract: '  Abstract maxent is a package with tools for data classification using
      multinomial logistic regression,            also known as maximum entropy. The
      focus of this maximum entropy classifier is to minimize memory            consumption
      on very large datasets, particularly sparse document-term matrices represented
      by the            tm text mining package.'
    pages:
    - 56
    - 59
    CRANpkgs:
    - nnet
    - mlogit
    - maxent
    - Rcpp
    - tm
    - Matrix
    - slam
    - SparseM
    CTV_rev:
    - Econometrics
    - NumericalMathematics
    - HighPerformanceComputing
    - Multivariate
    - NaturalLanguageProcessing
    - SocialSciences
    - MachineLearning
  - slug: RJ-2012-008
    old_slug: Bergsma+Smith
    title: 'Sumo: An Authenticating Web Application with an Embedded R Session'
    bibtitle: |-
      Sumo: An Authenticating Web Application with an Embedded R
                Session
    author:
    - Timothy T. Bergsma
    - Michael S. Smith
    bibauthor: Timothy T. Bergsma and Michael S. Smith
    landing: '2012'
    abstract: '  Abstract Sumo is a web application intended as a template for developers.
      It is distributed as a Java           ‘war’ file that deploys automatically
      when placed in a Servlet container’s ‘webapps’ directory. If a user            supplies
      proper credentials, Sumo creates a session-specific Secure Shell connection
      to the host and a            user-specific R session over that connection. Developers
      may write dynamic server pages that make            use of the persistent R
      session and user-specific file space. The supplied example plots a data set            conditional
      on preferences indicated by the user; it also displays some static text. A companion
      server            page allows the user to interact directly with the R session.
      Sumo’s novel feature set complements            previous efforts to supply R
      functionality over the internet.'
    pages:
    - 60
    - 63
    CRANpkgs:
    - Rpad
    - brew
    - R.rsp
    - Rook
    - Rserve
    - R2HTML
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
    - NumericalMathematics
  - slug: RJ-2012-009
    old_slug: Hornik~et~al
    title: Who Did What? The Roles of R Package Authors and How to Refer to Them
    bibtitle: |-
      Who Did What? The Roles of R Package Authors and How to
                Refer to Them
    author:
    - Kurt Hornik
    - Duncan Murdoch
    - Achim Zeileis
    bibauthor: Kurt Hornik and Duncan Murdoch and Achim Zeileis
    landing: '2012'
    abstract: '  Abstract Computational infrastructure for representing persons and
      citations has been available in R            for several years, but has been
      restructured through enhanced classes "person" and "bibentry" in            recent
      versions of R. The new features include support for the specification of the
      roles of package            authors (e.g. maintainer, author, contributor, translator,
      etc.) and more flexible formatting/printing            tools among various other
      improvements. Here, we introduce the new classes and their methods            and
      indicate how this functionality is employed in the management of R packages.
      Specifically, we            show how the authors of R packages can be specified
      along with their roles in package ‘DESCRIPTION’            and/or ‘CITATION’
      files and the citations produced from it.                 R packages are the
      result of scholarly activity and as such constitute scholarly resources which            must
      be clearly identifiable for the respective scientific communities and, more
      generally, today’s            information society. In particular, packages published
      by standard repositories can be regarded as            reliable sources which
      can and should be referenced (i.e. cited) by scientific works such as articles
      or            other packages. This requires conceptual frameworks and computational
      infrastructure for describing            bibliographic resources, general enough
      to encompass the needs of communities with an interest in R.            These
      needs include support for exporting bibliographic metadata in standardized formats
      such as            BIBTEX (Berry and Patashnik, 2010), but also facilitating
      bibliometric analyses and investigations of the            social fabric underlying
      the creation of scholarly knowledge.                 The latter requires a richer
      vocabulary than commonly employed by reference management            software
      such as BIBTEX, identifying persons and their roles in relation to bibliographic
      resources. For            example, a thesis typically has an author and advisors.
      Software can have an (original) author and a            translator to another
      language (such as from S to R). The maintainer of an R package is not necessarily            an
      author.                 In this paper, we introduce the base R infrastructure
      (as completely available in R since version            2.14.0) for representing
      and manipulating such scholarly data: objects of class "person" (hereafter,
      per           son objects) hold information about persons, possibly including
      their roles; objects of class "bibentry"            (hereafter, bibentry objects)
      hold bibliographic information in enhanced BIBTEX style, ideally using            person
      objects when referring to persons (such as authors or editors). Furthermore,
      we indicate how            this functionality is employed in the management
      of R packages, in particular in their ‘CITATION’ and           ‘DESCRIPTION’
      files.'
    pages:
    - 64
    - 69
    CRANpkgs:
    - boot
    - bibtex
    - XML
    CTV_rev:
    - Econometrics
    - Optimization
    - ReproducibleResearch
    - SocialSciences
    - Survival
    - TimeSeries
    - WebTechnologies
  notes:
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 70
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 96
- issue: 2012-2
  volume: 4
  year: 2012
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: RJ-2012-016
    old_slug: Murrell
    title: What's in a Name?
    bibtitle: What's in a Name?
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2012'
    abstract: '  Abstract Any shape that is drawn using the grid graphics package
      can have a name associated            with it. If a name is provided, it is
      possible to access, query, and modify the shape after it has been            drawn.
      These facilities allow for very detailed customisations of plots and also for
      very general            transformations of plots that are drawn by packages
      based on grid.'
    pages:
    - 5
    - 12
  - slug: RJ-2012-017
    old_slug: Murrell2
    title: It's Not What You Draw,It's What You Don't Draw
    bibtitle: It's Not What You Draw,It's What You Don't Draw
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2012'
    abstract: '  Abstract The R graphics engine has new support for drawing complex
      paths via the functions            polypath() and grid.path(). This article
      explains what is meant by a complex path and demonstrates            the usefulness
      of complex paths in drawing non-trivial shapes, logos, customised data symbols,
      and            maps.                 One of the design goals of the R graphics
      system is to allow fine control over the small details            of plots.
      One way that the R graphics system does this is by providing access to low-level
      generic            graphics facilities, such as the ability to draw basic shapes
      and the ability to control apparently esoteric,            but still useful,
      features of those shapes, such as the line end style used for drawing lines.                 In
      R version 2.12.0, another low-level graphics facility was added to R: the ability
      to draw complex            paths (not just polygons).                 This article
      describes this new facility and presents some examples that show how complex
      paths            might be useful.'
    pages:
    - 13
    - 18
    CRANpkgs:
    - grImport
    - maptools
    - maps
    CTV_rev: Spatial
  - slug: RJ-2012-013
    old_slug: Murrell+Ly
    title: Debugging grid Graphics
    bibtitle: Debugging grid Graphics
    author:
    - Paul Murrell
    - Velvet Ly
    bibauthor: Paul Murrell and Velvet Ly
    landing: '2012'
    abstract: '  Abstract A graphical scene that has been produced using the grid
      graphics package consists of grobs            (graphical objects) and viewports.
      This article describes functions that allow the exploration and            inspection
      of the grobs and viewports in a grid scene, including several functions that
      are available in            a new package called gridDebug. The ability to explore
      the grobs and viewports in a grid scene is            useful for adding more
      drawing to a scene that was produced using grid and for understanding and            debugging
      the grid code that produced a scene.'
    pages:
    - 19
    - 27
    CRANpkgs:
    - ggplot2
    - gridDebug
    - graph
    - Rgraphviz
    - gridGraphviz
    - gridSVG
    - playwith
    CTV_rev:
    - Graphics
    - Phylogenetics
  - slug: RJ-2012-010
    old_slug: Do~Ha~et~al
    title: 'frailtyHL: A Package for Fitting Frailty Models with H-likelihood'
    bibtitle: |-
      frailtyHL: A Package for Fitting Frailty Models with H-
                likelihood
    author:
    - Il Do Ha
    - Maengseok Noh
    - Youngjo Lee
    bibauthor: Il Do Ha and Maengseok Noh and Youngjo Lee
    landing: '2012'
    abstract: '   Abstract We present the frailtyHL package for fitting semi-parametric
      frailty models using h            likelihood. This package allows lognormal
      or gamma frailties for random-effect distribution, and it             fits shared
      or multilevel frailty models for correlated survival data. Functions are provided
      to format             and summarize the frailtyHL results. The estimates of
      fixed effects and frailty parameters and their             standard errors are
      calculated. We illustrate the use of our package with three well-known data
      sets             and compare our results with various alternative R-procedures.'
    pages:
    - 28
    - 37
    CRANpkgs:
    - frailtyHL
    - survival
    - coxme
    - phmm
    - frailtypack
    - hglm
    - HGLMMM
    - dhglm
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - SocialSciences
  - slug: RJ-2012-011
    old_slug: Nieuwenhuis~et~al
    title: 'influence.ME: Tools for Detecting Influential Data in Mixed Effects Models'
    bibtitle: |-
      influence.ME: Tools for Detecting Influential Data in Mixed
                Effects Models
    author:
    - Rense Nieuwenhuis
    - Manfred te Grotenhuis
    - Ben Pelzer
    bibauthor: Rense Nieuwenhuis and Manfred te Grotenhuis and Ben Pelzer
    landing: '2012'
    abstract: '  Abstract influence.ME provides tools for detecting influential data
      in mixed effects models. The            application of these models has become
      common practice, but the development of diagnostic tools            has lagged
      behind. influence.ME calculates standardized measures of influential data for
      the point            estimates of generalized mixed effects models, such as
      DFBETAS, Cook’s distance, as well as percentile            change and a test
      for changing levels of significance. influence.ME calculates these measures
      of            influence while accounting for the nesting structure of the data.
      The package and measures of            influential data are introduced, a practical
      example is given, and strategies for dealing with influential            data
      are suggested.                 The application of mixed effects regression models
      has become common practice in the field of            social sciences. As used
      in the social sciences, mixed effects regression models take into account            that
      observations on individual respondents are nested within higher-level groups
      such as schools,            classrooms, states, and countries (Snijders and
      Bosker, 1999), and are often referred to as multilevel            regression
      models. Despite these models’ increasing popularity, diagnostic tools to evaluate
      fitted            models lag behind.                 We introduce influence.ME
      (Nieuwenhuis, Pelzer, and te Grotenhuis, 2012), an R-package that            provides
      tools for detecting influential cases in mixed effects regression models estimated
      with lme4            (Bates and Maechler, 2010). It is commonly accepted that
      tests for influential data should be performed            on regression models,
      especially when estimates are based on a relatively small number of cases.            However,
      most existing procedures do not account for the nesting structure of the data.
      As a result,            these existing procedures fail to detect that higher-level
      cases may be influential on estimates of            variables measured at specifically
      that level.                 In this paper, we outline the basic rationale on
      detecting influential data, describe standardized            measures of influence,
      provide a practical example of the analysis of students in 23 schools, and            discuss
      strategies for dealing with influential cases. Testing for influential cases
      in mixed effects            regression models is important, because influential
      data negatively influence the statistical fit and            generalizability
      of the model. In social science applications of mixed models the testing for
      influential            data is especially important, since these models are
      frequently based on large numbers of observations            at the individual
      level while the number of higher level groups is relatively small. For instance,
      Van der            Meer, te Grotenhuis, and Pelzer (2010) were unable to find
      any country-level comparative studies            involving more than 54 countries.
      With such a relatively low number of countries, a single country can            easily
      be overly influential on the parameter estimates of one or more of the country-level
      variables.'
    pages:
    - 38
    - 47
  - slug: RJ-2012-012
    old_slug: Nie+S~Racine
    title: 'The crs Package: Nonparametric Regression Splines for Continuous and Categorical
      Predictors'
    bibtitle: |-
      The crs Package: Nonparametric Regression Splines for
                Continuous and Categorical Predictors
    author:
    - Zhenghua Nie
    - Jeffrey S. Racine
    bibauthor: Zhenghua Nie and Jeffrey S. Racine
    landing: '2012'
    abstract: '  Abstract A new package crs is introduced for computing nonparametric
      regression (and quantile)            splines in the presence of both continuous
      and categorical predictors. B-splines are employed in the            regression
      model for the continuous predictors and kernel weighting is employed for the
      categorical            predictors. We also develop a simple R interface to NOMAD,
      which is a mixed integer optimization            solver used to compute optimal
      regression spline solutions.'
    pages:
    - 48
    - 56
    CRANpkgs:
    - crs
    - SemiPar
    - mgcv
    - gss
    - gam
    - MASS
    - rgl
    CTV_rev:
    - SocialSciences
    - Econometrics
    - Environmetrics
    - Multivariate
    - Bayesian
    - Distributions
    - Graphics
    - NumericalMathematics
    - Optimization
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SpatioTemporal
    - Survival
  - slug: RJ-2012-014
    old_slug: Kloke+McKean
    title: 'Rfit: Rank-based Estimation for Linear Models'
    bibtitle: 'Rfit: Rank-based Estimation for Linear Models'
    author:
    - John D. Kloke
    - Joseph W. McKean
    bibauthor: John D. Kloke and Joseph W. McKean
    landing: '2012'
    abstract: '  Abstract In the nineteen seventies, Jurečková and Jaeckel proposed
      rank estimation for linear models.            Since that time, several authors
      have developed inference and diagnostic methods for these estimators.            These
      rank-based estimators and their associated inference are highly efficient and
      are robust to            outliers in response space. The methods include estimation
      of standard errors, tests of general linear            hypotheses, confidence
      intervals, diagnostic procedures including studentized residuals, and measures            of
      influential cases. We have developed an R package, Rfit, for computing of these
      robust procedures.            In this paper we highlight the main features of
      the package. The package uses standard linear model            syntax and includes
      many of the main inference and diagnostic functions.'
    pages:
    - 57
    - 64
    CRANpkgs:
    - Rfit
    - Rfit
    - MASS
    - quantreg
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Robust
    - SocialSciences
    - Distributions
    - Multivariate
    - NumericalMathematics
    - Optimization
    - Pharmacokinetics
    - Psychometrics
    - ReproducibleResearch
    - Survival
  - slug: RJ-2012-015
    old_slug: Sadeghi+Marchetti
    title: Graphical Markov Models with Mixed Graphs in R
    bibtitle: Graphical Markov Models with Mixed Graphs in R
    author:
    - Kayvan Sadeghi
    - Giovanni M. Marchetti
    bibauthor: Kayvan Sadeghi and Giovanni M. Marchetti
    landing: '2012'
    abstract: '  Abstract In this paper we provide a short tutorial illustrating the
      new functions in the package ggm            that deal with ancestral, summary
      and ribbonless graphs. These are mixed graphs (containing three            types
      of edges) that are important because they capture the modified independence
      structure after            marginalisation over, and conditioning on, nodes
      of directed acyclic graphs. We provide functions to            verify whether
      a mixed graph implies that A is independent of B given C for any disjoint sets
      of nodes            and to generate maximal graphs inducing the same independence
      structure of non-maximal graphs.            Finally, we provide functions to
      decide on the Markov equivalence of two graphs with the same node            set
      but different types of edges.'
    pages:
    - 65
    - 73
    CRANpkgs:
    - gRain
    - ggm
    - ggm
    - igraph
    - gRbase
    CTV_rev:
    - gR
    - Graphics
    - Optimization
    - Spatial
  - slug: RJ-2012-018
    old_slug: Baaaath
    title: The State of Naming Conventions in R
    bibtitle: The State of Naming Conventions in R
    author: Rasmus Bååth
    bibauthor: Rasmus Bååth
    landing: '2012'
    abstract: '  Abstract Most programming language communities have naming conventions
      that are generally            agreed upon, that is, a set of rules that governs
      how functions and variables are named. This is not the            case with
      R, and a review of unofficial style guides and naming convention usage on CRAN
      shows            that a number of different naming conventions are currently
      in use. Some naming conventions are,            however, more popular than others
      and as a newcomer to the R community or as a developer of a new            package
      this could be useful to consider when choosing what naming convention to adopt.'
    pages:
    - 74
    - 75
  notes:
  - title: Changes in R
    bibtitle: Changes in {R}
    page: 76
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    page: 80
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    page: 101
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    page: 102
- issue: 2013-1
  year: 2013
  num: 1
  volume: 5
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Hadley Wickham
    slug: editorial
    pages:
    - 4
    - 5
  - heading: Contributed Research Articles
  - slug: RJ-2013-001
    old_slug: collingwood-jurka-boydstun-etal
    title: 'RTextTools: A Supervised Learning Package for Text Classification'
    bibtitle: |-
      RTextTools: A Supervised Learning Package for Text
                Classification
    author:
    - Timothy P. Jurka
    - Loren Collingwood
    - Amber E. Boydstun
    - Emiliano Grossman
    - Wouter van            Atteveldt
    bibauthor: |-
      Timothy P. Jurka and Loren Collingwood and Amber E. Boydstun
                and Emiliano Grossman and Wouter van Atteveldt
    landing: '2013'
    abstract: '  Abstract Social scientists have long hand-labeled texts to create
      datasets useful for studying topics            from congressional policymaking
      to media reporting. Many social scientists have begun to incorporate            machine
      learning into their toolkits. RTextTools was designed to make machine learning
      accessible            by providing a start-to-finish product in less than 10
      steps. After installing RTextTools, the initial            step is to generate
      a document term matrix. Second, a container object is created, which holds all            the
      objects needed for further analysis. Third, users can use up to nine algorithms
      to train their data.            Fourth, the data are classified. Fifth, the
      classification is summarized. Sixth, functions are available for            performance
      evaluation. Seventh, ensemble agreement is conducted. Eighth, users can cross-validate            their
      data. Finally, users write their data to a spreadsheet, allowing for further
      manual coding if            required.'
    pages:
    - 6
    - 12
    acknowledged: '2011-08-19'
    online: '2013-06-03'
    CRANpkgs:
    - RTextTools
    - glmnet
    - maxent
    - e1071
    - tm
    - ipred
    - caTools
    - randomForest
    - nnet
    - tree
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - NaturalLanguageProcessing
    - Survival
    - Cluster
    - Distributions
    - Econometrics
    - HighPerformanceComputing
    - Multivariate
    - Psychometrics
    - SocialSciences
  - slug: RJ-2013-002
    old_slug: xiang-gubian-suomela-etal
    title: 'Generalized Simulated Annealing for Global Optimization: The GenSA Package'
    bibtitle: |-
      Generalized Simulated Annealing for Global Optimization: The
                GenSA Package
    author:
    - Yang Xiang
    - Sylvain Gubian
    - Brian Suomela
    - Julia Hoeng
    bibauthor: |-
      Yang Xiang and Sylvain Gubian and Brian Suomela and Julia
                Hoeng
    landing: '2013'
    abstract: '  Abstract Many problems in statistics, finance, biology, pharmacology,
      physics, mathematics, eco           nomics, and chemistry involve determination
      of the global minimum of multidimensional functions.            R packages for
      different stochastic methods such as genetic algorithms and differential evolution            have
      been developed and successfully used in the R community. Based on Tsallis statistics,
      the R            package GenSA was developed for generalized simulated annealing
      to process complicated non-linear            objective functions with a large
      number of local minima. In this paper we provide a brief introduction            to
      the R package and demonstrate its utility by solving a non-convex portfolio
      optimization problem            in finance and the Thomson problem in physics.
      GenSA is useful and can serve as a complementary            tool to, rather
      than a replacement for, other widely used R packages for optimization.'
    pages:
    - 13
    - 28
    acknowledged: '2011-11-29'
    online: '2013-06-03'
    CRANpkgs:
    - DEoptim
    - rgenoud
    - likelihood
    - dclone
    - subselect
    - GenSA
    CTV_rev:
    - Optimization
    - HighPerformanceComputing
    - Bayesian
    - ChemPhys
    - gR
    - MachineLearning
  - slug: RJ-2013-003
    old_slug: kostov-becuebertaut-husson
    title: Multiple Factor Analysis for Contingency Tables in the FactoMineR Package
    bibtitle: |-
      Multiple Factor Analysis for Contingency Tables in the
                FactoMineR Package
    author:
    - Belchin Kostov
    - Mónica Bécue-Bertaut
    - François Husson
    bibauthor: Belchin Kostov and Mónica Bécue-Bertaut and François Husson
    landing: '2013'
    abstract: '  Abstract We present multiple factor analysis for contingency tables
      (MFACT) and its implementation            in the FactoMineR package. This method,
      through an option of the MFA function, allows us to deal            with multiple
      contingency or frequency tables, in addition to the categorical and quantitative
      multiple            tables already considered in previous versions of the package.
      Thanks to this revised function, either            a multiple contingency table
      or a mixed multiple table integrating quantitative, categorical and            frequency
      data can be tackled.                The FactoMineR package (Lê et al., 2008;
      Husson et al., 2011) offers the most commonly used            principal component
      methods: principal component analysis (PCA), correspondence analysis (CA;            Benzécri,
      1973), multiple correspondence analysis (MCA; Lebart et al., 2006) and multiple
      factor            analysis (MFA; Escofier and Pagès, 2008). Detailed presentations
      of these methods enriched by            numerous examples can be consulted at
      the website http://factominer.free.fr/.                An extension of the MFA
      function that considers contingency or frequency tables as proposed by            Bécue-Bertaut
      and Pagès (2004, 2008) is detailed in this article.                First, an
      example is presented in order to motivate the approach. Next, the mortality
      data used            to illustrate the method are introduced. Then we briefly
      describe multiple factor analysis (MFA)            and present the principles
      of its extension to contingency tables. A real example on mortality data            illustrates
      the handling of the MFA function to analyse these multiple tables and, finally,
      conclusions            are presented.'
    pages:
    - 29
    - 38
    acknowledged: '2011-12-14'
    online: '2013-06-03'
    CRANpkgs: FactoMineR
    CTV_rev:
    - Multivariate
    - Psychometrics
  - slug: RJ-2013-004
    old_slug: fox-friendly-weisberg
    title: Hypothesis Tests for Multivariate Linear Models Using the car Package
    bibtitle: |-
      Hypothesis Tests for Multivariate Linear Models Using the
                car Package
    author:
    - John Fox
    - Michael Friendly
    - Sanford Weisberg
    bibauthor: John Fox and Michael Friendly and Sanford Weisberg
    landing: '2013'
    abstract: '  Abstract The multivariate linear model is                                                     Y    =   X       B    +     E                                                   (n×m)    (n×
      p)( p×m)       (n×m)            The multivariate linear model can be fit with
      the lm function in R, where the left-hand side of the            model comprises
      a matrix of response variables, and the right-hand side is specified exactly
      as for            a univariate linear model (i.e., with a single response variable).
      This paper explains how to use the            Anova and linearHypothesis functions
      in the car package to perform convenient hypothesis tests for            parameters
      in multivariate linear models, including models for repeated-measures data.'
    pages:
    - 39
    - 52
    acknowledged: '2012-01-13'
    online: '2013-06-03'
    CRANpkgs:
    - car
    - lme4
    - nlme
    - survival
    - nnet
    - MASS
    - survey
    - heplots
    CTV_rev:
    - SocialSciences
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Psychometrics
    - Finance
    - Multivariate
    - Pharmacokinetics
    - SpatioTemporal
    - Survival
    - Bayesian
    - ChemPhys
    - ClinicalTrials
    - Distributions
    - MachineLearning
    - NumericalMathematics
    - Robust
    - Spatial
  - slug: RJ-2013-005
    old_slug: eugster-schlesinger
    title: 'osmar: OpenStreetMap and R'
    bibtitle: 'osmar: OpenStreetMap and R'
    author:
    - Manuel J. A. Eugster
    - Thomas Schlesinger
    bibauthor: Manuel J. A. Eugster and Thomas Schlesinger
    landing: '2013'
    abstract: '  Abstract OpenStreetMap provides freely accessible and editable geographic
      data. The osmar package            smoothly integrates the OpenStreetMap project
      into the R ecosystem. The osmar package provides            infrastructure to
      access OpenStreetMap data from different sources, to enable working with the
      OSM            data in the familiar R idiom, and to convert the data into objects
      based on classes provided by existing            R packages. This paper explains
      the package’s concept and shows how to use it. As an application we            present
      a simple navigation device.'
    pages:
    - 53
    - 63
    acknowledged: '2012-02-03'
    online: '2013-06-03'
    CRANpkgs:
    - osmar
    - osmar
    - OpenStreetMap
    - RgoogleMaps
    - ggmap
    - sp
    - igraph
    - geosphere
    - Rcpp
    CTV_rev:
    - Spatial
    - WebTechnologies
    - gR
    - Graphics
    - HighPerformanceComputing
    - NumericalMathematics
    - Optimization
    - SpatioTemporal
  - slug: RJ-2013-006
    old_slug: shang
    title: 'ftsa: An R Package for Analyzing Functional Time Series'
    bibtitle: 'ftsa: An R Package for Analyzing Functional Time Series'
    author: Han Lin Shang
    bibauthor: Han Lin Shang
    landing: '2013'
    abstract: '  Abstract Recent advances in computer recording and storing technology
      have tremendously increased            the presence of functional data, whose
      graphical representation can be infinite-dimensional curve,            image,
      or shape. When the same functional object is observed over a period of time,
      such data            are known as functional time series. This article makes
      first attempt to describe several techniques            (centered around functional
      principal component analysis) for modeling and forecasting functional            time
      series from a computational aspect, using a readily-available R addon package.
      These methods            are demonstrated using age-specific Australian fertility
      rate data from 1921 to 2006, and monthly sea            surface temperature
      data from January 1950 to December 2011.'
    pages:
    - 64
    - 72
    acknowledged: '2012-02-03'
    online: '2013-06-03'
    CRANpkgs: ftsa
  - slug: RJ-2013-007
    old_slug: godfrey
    title: Statistical Software from a Blind Person's Perspective
    bibtitle: Statistical Software from a Blind Person's Perspective
    author: A. Jonathan R. Godfrey
    bibauthor: A. Jonathan R. Godfrey
    landing: '2013'
    abstract: '  Abstract Blind people have experienced access issues to many software
      applications since the advent            of the Windows operating system; statistical
      software has proven to follow the rule and not be an            exception. The
      ability to use R within minutes of download with next to no adaptation has opened            doors
      for accessible production of statistical analyses for this author (himself blind)
      and blind students            around the world. This article shows how little
      is required to make R the most accessible statistical            software available
      today. There is any number of ramifications that this opportunity creates for
      blind            students, especially in terms of their future research and
      employment prospects. There is potential            for making R even better
      for blind users. The extensibility of R makes this possible through added            functionality
      being made available in an add-on package called BrailleR. Functions in this
      package            are intended to make graphical information available in text
      form.'
    pages:
    - 73
    - 79
    acknowledged: '2012-03-26'
    online: '2013-06-03'
    CRANpkgs:
    - Rcmdr
    - TeachingDemos
    - BrailleR
    - R2HTML
    CTV_rev:
    - Finance
    - ReproducibleResearch
  - slug: RJ-2013-008
    old_slug: zagaglia
    title: 'PIN: Measuring Asymmetric Information in Financial Markets with R'
    bibtitle: |-
      PIN: Measuring Asymmetric Information in Financial Markets
                with R
    author: Paolo Zagaglia
    bibauthor: Paolo Zagaglia
    landing: '2013'
    abstract: The package PIN computes a measure of asymmetric information in financial
      markets, the so-called probability of informed trading. This is obtained from
      a sequential trade model and is used to study the determinants of an asset price.
      Since the probability of informed trading depends on the number of buyand sell-initiated
      trades during a trading day, this paper discusses the entire modelling cycle,
      from data handling to the computation of the probability of informed trading
      and the estimation of parameters for the underlying theoretical model.
    pages:
    - 80
    - 86
    acknowledged: '2012-04-05'
    online: '2013-06-04'
    CRANpkgs:
    - PIN
    - highfrequency
    - IBrokers
    - orderbook
    CTV_rev: Finance
  - slug: RJ-2013-009
    old_slug: thiem-dusa
    title: 'QCA: A Package for Qualitative Comparative Analysis'
    bibtitle: 'QCA: A Package for Qualitative Comparative Analysis'
    author:
    - Alrik Thiem
    - Adrian Duşa
    bibauthor: Alrik Thiem and Adrian Duşa
    landing: '2013'
    abstract: ' Abstract We present QCA, a package for performing Qualitative Comparative
      Analysis (QCA). QCA           is becoming increasingly popular with social scientists,
      but none of the existing software alternatives           covers the full range
      of core procedures. This gap is now filled by QCA. After a mapping of the           method’s
      diffusion, we introduce some of the package’s main capabilities, including the
      calibration           of crisp and fuzzy sets, the analysis of necessity relations,
      the construction of truth tables and the           derivation of complex, parsimonious
      and intermediate solutions.'
    pages:
    - 87
    - 97
    acknowledged: '2012-04-20'
    online: '2013-06-03'
    CRANpkgs:
    - QCA
    - QCA3
    - VennDiagram
  - slug: RJ-2013-010
    old_slug: colleter-guitton-gascuel
    title: 'An Introduction to the EcoTroph R Package: Analyzing Aquatic Ecosystem
      Trophic Networks'
    bibtitle: |-
      An Introduction to the EcoTroph R Package: Analyzing Aquatic
                Ecosystem Trophic Networks
    author:
    - Mathieu Colléter
    - Jérôme Guitton
    - Didier Gascuel
    bibauthor: Mathieu Colléter and Jérôme Guitton and Didier Gascuel
    landing: '2013'
    abstract: '  Abstract Recent advances in aquatic ecosystem modelling have particularly
      focused on trophic            network analysis through trophodynamic models.
      We present here a R package devoted to a recently            developed model,
      EcoTroph. This model enables the analysis of aquatic ecological networks and
      the            related impacts of fisheries. It was available through a plug-in
      in the well-known Ecopath with Ecosim            software or through implementations
      in Excel sheets. The R package we developed simplifies the            access
      to the EcoTroph model and offers a new interfacing between two widely used software,
      Ecopath            and R.'
    pages:
    - 98
    - 107
    acknowledged: '2012-05-18'
    online: '2013-06-03'
    CRANpkgs:
    - EcoTroph
    - XML
    CTV_rev: WebTechnologies
  - slug: RJ-2013-011
    old_slug: valle-dellomodarme
    title: 'stellaR: A Package to Manage Stellar Evolution Tracks and Isochrones'
    bibtitle: |-
      stellaR: A Package to Manage Stellar Evolution Tracks and
                Isochrones
    author:
    - Matteo Dell’Omodarme
    - Giada Valle
    bibauthor: Matteo Dell’Omodarme and Giada Valle
    landing: '2013'
    abstract: '  Abstract We present the R package stellaR, which is designed to access
      and manipulate publicly            available stellar evolutionary tracks and
      isochrones from the Pisa low-mass database. The procedures            for extracting
      important stages in the evolution of a star from the database, for constructing
      isochrones            from stellar tracks and for interpolating among tracks
      are discussed and demonstrated.                 Due to the advance in the instrumentation,
      nowadays astronomers can deal with a huge amount            of high-quality
      observational data. In the last decade impressive improvements of spectroscopic
      and            photometric observational capabilities made available data which
      stimulated the research in the glob           ular clusters field. The theoretical
      effort of recovering the evolutionary history of the clusters benefits            from
      the computation of extensive databases of stellar tracks and isochrones, such
      as Pietrinferni et al.            (2006); Dotter et al. (2008); Bertelli et
      al. (2008). We recently computed a large data set of stellar tracks            and
      isochrones, “The Pisa low-mass database” (Dell’Omodarme et al., 2012), with
      up to date physical            and chemical inputs, and made available all the
      calculations to the astrophysical community at the            Centre de Données
      astronomiques de Strasbourg (CDS)1 , a data center dedicated to the collection
      and            worldwide distribution of astronomical data.                 In
      most databases, the management of the information and the extraction of the
      relevant evolu           tionary properties from libraries of tracks and/or
      isochrones is the responsibility of the end users.            Due to its extensive
      capabilities of data manipulation and analysis, however, R is an ideal choice
      for            these tasks. Nevertheless R is not yet well known in astrophysics;
      up to December 2012 only seven            astronomical or astrophysical-oriented
      packages have been published on CRAN (see the CRAN Task            View Chemometrics
      and Computational Physics).                 The package stellaR (Dell’Omodarme
      and Valle, 2012) is an effort to make available to the astro           physical
      community a basic tool set with the following capabilities: retrieve the required
      calculations            from CDS; plot the information in a suitable form; construct
      by interpolation tracks or isochrones of            compositions different to
      the ones available in the database; construct isochrones for age not included            in
      the database; extract relevant evolutionary points from tracks or isochrones.'
    pages:
    - 108
    - 116
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs: stellaR
    CTV_rev: ChemPhys
  - slug: RJ-2013-012
    old_slug: hofmann-unwin-cook
    title: Let Graphics Tell the Story - Datasets in R
    bibtitle: Let Graphics Tell the Story - Datasets in R
    author:
    - Antony Unwin
    - Heike Hofmann
    - Dianne Cook
    bibauthor: Antony Unwin and Heike Hofmann and Dianne Cook
    landing: '2013'
    abstract: ' Abstract Graphics are good for showing the information in datasets
      and for complementing modelling.           Sometimes graphics show information
      models miss, sometimes graphics help to make model results           more understandable,
      and sometimes models show whether information from graphics has statistical           support
      or not. It is the interplay of the two approaches that is valuable. Graphics
      could be used a lot           more in R examples and we explore this idea with
      some datasets available in R packages.'
    pages:
    - 117
    - 129
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs:
    - MASS
    - granova
    - ggplot2
    - vcd
    - knitr
    - HH
    CTV_rev:
    - Graphics
    - Multivariate
    - SocialSciences
    - ClinicalTrials
    - Distributions
    - Econometrics
    - Environmetrics
    - ExperimentalDesign
    - NumericalMathematics
    - Pharmacokinetics
    - Phylogenetics
    - Psychometrics
    - ReproducibleResearch
    - Robust
  - slug: RJ-2013-013
    old_slug: wilhelm-matos
    title: Estimating Spatial Probit Models in R
    bibtitle: Estimating Spatial Probit Models in R
    author:
    - Stefan Wilhelm
    - Miguel Godinho de Matos
    bibauthor: Stefan Wilhelm and Miguel Godinho de Matos
    landing: '2013'
    abstract: '  Abstract In this article we present the Bayesian estimation of spatial
      probit models in R and provide an            implementation in the package spatialprobit.
      We show that large probit models can be estimated with            sparse matrix
      representations and Gibbs sampling of a truncated multivariate normal distribution
      with            the precision matrix. We present three examples and point to
      ways to achieve further performance            gains through parallelization
      of the Markov Chain Monte Carlo approach.'
    pages:
    - 130
    - 143
    acknowledged: '2012-05-30'
    online: '2013-06-03'
    CRANpkgs:
    - spBayes
    - spatial
    - geoR
    - sgeostat
    - spdep
    - sphet
    - sna
    - network
    - Matrix
    - sparseM
    - spatialprobit
    - McSpatial
    - LearnBayes
    - tmvtnorm
    - mvtnorm
    - igraph
    CTV_rev:
    - Spatial
    - Bayesian
    - Distributions
    - Econometrics
    - SocialSciences
    - gR
    - Multivariate
    - Optimization
    - SpatioTemporal
    - Finance
    - Graphics
    - NumericalMathematics
    - Survival
  - slug: RJ-2013-014
    old_slug: kahle-wickham
    title: 'ggmap: Spatial Visualization with ggplot2'
    bibtitle: 'ggmap: Spatial Visualization with ggplot2'
    author:
    - David Kahle
    - Hadley Wickham
    bibauthor: David Kahle and Hadley Wickham
    landing: '2013'
    abstract: ' Abstract In spatial statistics the ability to visualize data and models
      superimposed with their basic           social landmarks and geographic context
      is invaluable. ggmap is a new tool which enables such           visualization
      by combining the spatial information of static maps from Google Maps, OpenStreetMap,           Stamen
      Maps or CloudMade Maps with the layered grammar of graphics implementation of
      ggplot2.           In addition, several new utility functions are introduced
      which allow the user to access the Google           Geocoding, Distance Matrix,
      and Directions APIs. The result is an easy, consistent and modular           framework
      for spatial graphics with several convenient tools for spatial data analysis.'
    pages:
    - 144
    - 161
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs:
    - sp
    - RgoogleMaps
    - ggplot2
    - ggmap
    - maps
    - maptools
    - DeducerSpatial
    - plyr
    - rjson
    - osmar
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Graphics
    - Phylogenetics
    - SpatioTemporal
  - slug: RJ-2013-015
    old_slug: kahle
    title: 'mpoly: Multivariate Polynomials in R'
    bibtitle: 'mpoly: Multivariate Polynomials in R'
    author: David Kahle
    bibauthor: David Kahle
    landing: '2013'
    abstract: '  Abstract The mpoly package is a general purpose collection of tools
      for symbolic computing with            multivariate polynomials in R. In addition
      to basic arithmetic, mpoly can take derivatives of polyno           mials, compute
      Gröbner bases of collections of polynomials, and convert polynomials into a
      functional            form to be evaluated. Among other things, it is hoped
      that mpoly will provide an R-based foundation            for the computational
      needs of algebraic statisticians.'
    pages:
    - 162
    - 170
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs:
    - mpoly
    - multipol
    - polynom
    - PolynomF
    - rSymPy
    CTV_rev: NumericalMathematics
  - slug: RJ-2013-016
    old_slug: forcheh-verbeke-kasim-etal
    title: 'beadarrayFilter: An R Package to Filter Beads'
    bibtitle: 'beadarrayFilter: An R Package to Filter Beads'
    author:
    - Anyiawung Chiara Forcheh
    - Geert Verbeke
    - Adetayo Kasim
    - Dan Lin
    - Ziv Shkedy
    - Willem Talloen
    - '           Hinrich W.H. Göhlmann'
    - Lieven Clement
    bibauthor: |-
      Anyiawung Chiara Forcheh and Geert Verbeke and Adetayo Kasim
                and Dan Lin and Ziv Shkedy and Willem Talloen and Hinrich
                W.H. Göhlmann and Lieven Clement
    landing: '2013'
    abstract: '  Abstract Microarrays enable the expression levels of thousands of
      genes to be measured simultane           ously. However, only a small fraction
      of these genes are expected to be expressed under different            experimental
      conditions. Nowadays, filtering has been introduced as a step in the microarray
      pre           processing pipeline. Gene filtering aims at reducing the dimensionality
      of data by filtering redundant            features prior to the actual statistical
      analysis. Previous filtering methods focus on the Affymetrix            platform
      and can not be easily ported to the Illumina platform. As such, we developed
      a filtering            method for Illumina bead arrays. We developed an R package,
      beadarrayFilter, to implement the            latter method. In this paper, the
      main functions in the package are highlighted and using many            examples,
      we illustrate how beadarrayFilter can be used to filter bead arrays.'
    pages:
    - 171
    - 180
    acknowledged: '2012-07-06'
    online: '2013-06-03'
    CRANpkgs: beadarrayFilter
  - slug: RJ-2013-017
    old_slug: mcdaniel-henderson-rathouz
    title: 'Fast Pure R Implementation of GEE: Application of the Matrix Package'
    bibtitle: |-
      Fast Pure R Implementation of GEE: Application of the Matrix
                Package
    author:
    - Lee S. McDaniel
    - Nicholas C. Henderson
    - Paul J. Rathouz
    bibauthor: |-
      Lee S. McDaniel and Nicholas C. Henderson and Paul J.
                Rathouz
    landing: '2013'
    abstract: '  Abstract Generalized estimating equation solvers in R only allow
      for a few pre-determined options            for the link and variance functions.
      We provide a package, geeM, which is implemented entirely in R            and
      allows for user specified link and variance functions. The sparse matrix representations
      provided            in the Matrix package enable a fast implementation. To gain
      speed, we make use of analytic inverses            of the working correlation
      when possible and a trick to find quick numeric inverses when an analytic            inverse
      is not available. Through three examples, we demonstrate the speed of geeM,
      which is not            much worse than C implementations like geepack and gee
      on small data sets and faster on large data            sets.'
    pages:
    - 181
    - 187
    acknowledged: '2012-10-17'
    online: '2013-06-03'
    CRANpkgs:
    - geepack
    - gee
    - geeM
    - Matrix
    CTV_rev:
    - Econometrics
    - SocialSciences
    - Multivariate
    - NumericalMathematics
  - slug: RJ-2013-018
    old_slug: bouchetvalat-bastin
    title: RcmdrPlugin.temis, a Graphical Integrated Text Mining Solution in R
    bibtitle: |-
      RcmdrPlugin.temis, a Graphical Integrated Text Mining
                Solution in R
    author:
    - Milan Bouchet-Valat
    - Gilles Bastin
    bibauthor: Milan Bouchet-Valat and Gilles Bastin
    landing: '2013'
    abstract: '  Abstract We present the package RcmdrPlugin.temis, a graphical user
      interface for user-friendly            text mining in R. Built as a plug-in
      to the R Commander provided by the Rcmdr package, it brings            together
      several existing packages and provides new features streamlining the process
      of importing,            managing and analyzing a corpus, in addition to saving
      results and plots to a report file. Beyond            common file formats, automated
      import of corpora from the Dow Jones Factiva content provider and            Twitter
      is supported. Featured analyses include vocabulary and dissimilarity tables,
      terms frequencies,            terms specific of levels of a variable, term co-occurrences,
      time series, correspondence analysis and            hierarchical clustering.'
    pages:
    - 188
    - 196
    acknowledged: '2012-10-29'
    online: '2013-06-03'
    CRANpkgs:
    - tm
    - RcmdrPlugin.temis
    - Rcmdr
    - RODBC
    - tm.plugin.factiva
    - twitteR
    - SnowballC
    - zoo
    - lattice
    - ca
    - R2HTML
    CTV_rev:
    - NaturalLanguageProcessing
    - Finance
    - Multivariate
    - Econometrics
    - Environmetrics
    - Graphics
    - HighPerformanceComputing
    - Pharmacokinetics
    - Psychometrics
    - ReproducibleResearch
    - TimeSeries
    - WebTechnologies
  - slug: RJ-2013-019
    old_slug: ooms
    title: Possible Directions for Improving Dependency Versioning in R
    bibtitle: Possible Directions for Improving Dependency Versioning in R
    author: Jeroen Ooms
    bibauthor: Jeroen Ooms
    landing: '2013'
    abstract: '  Abstract One of the most powerful features of R is its infrastructure
      for contributed code. The            built-in package manager and complementary
      repositories provide a great system for development            and exchange
      of code, and have played an important role in the growth of the platform towards
      the            de-facto standard in statistical computing that it is today.
      However, the number of packages on CRAN            and other repositories has
      increased beyond what might have been foreseen, and is revealing some            limitations
      of the current design. One such problem is the general lack of dependency versioning
      in            the infrastructure. This paper explores this problem in greater
      detail, and suggests approaches taken            by other open source communities
      that might work for R as well. Three use cases are defined that            exemplify
      the issue, and illustrate how improving this aspect of package management could
      increase            reliability while supporting further growth of the R community.'
    pages:
    - 197
    - 206
    acknowledged: '2013-01-17'
    online: '2013-06-03'
    CRANpkgs: CRAN
  - slug: RJ-2013-020
    old_slug: lebauer-dietze-bolker
    title: 'Translating Probability Density Functions: From R to BUGS and Back Again'
    bibtitle: |-
      Translating Probability Density Functions: From R to BUGS
                and Back Again
    author:
    - David S. LeBauer
    - Michael C. Dietze
    - Benjamin M. Bolker
    bibauthor: |-
      David S. LeBauer and Michael C. Dietze and Benjamin M.
                Bolker
    landing: '2013'
    abstract: '  Abstract The ability to implement statistical models in the BUGS
      language facilitates Bayesian in           ference by automating MCMC algorithms.
      Software packages that interpret the BUGS language            include OpenBUGS,
      WinBUGS, and JAGS. R packages that link BUGS software to the R environment,            including
      rjags and R2WinBUGS, are widely used in Bayesian analysis. Indeed, many packages
      in            the Bayesian task view on CRAN (http://cran.r-project.org/web/views/Bayesian.html)
      depend            on this integration. However, the R and BUGS languages use
      different representations of common            probability density functions,
      creating a potential for errors to occur in the implementation or interpre           tation
      of analyses that use both languages. Here we review different parameterizations
      used by the R            and BUGS languages, describe how to translate between
      the languages, and provide an R function,            r2bugs.distributions, that
      transforms parameterizations from R to BUGS and back again.'
    pages:
    - 207
    - 209
    acknowledged:
    - '2013-02-08'
    - '2013-02-15'
    online: '2013-06-17'
    CRANpkgs:
    - rjags
    - R2WinBUGS
    CTV_rev:
    - Bayesian
    - gR
    - Cluster
  - heading: News and Notes
  - title: 'Conference Review: The 6th Chinese R Conference'
    bibtitle: 'Conference Review: The 6th {C}hinese {R} Conference'
    author:
    - Jing Leng
    - Jingjing Guan
    slug: chinese-r-conf
    pages:
    - 210
    - 211
  - title: 'Conference Report: R/Finance 2013'
    bibtitle: 'Conference Report: {R/F}inance 2013'
    author: Joshua Ulrich
    slug: r-finance
    pages:
    - 212
    - 214
  - title: The R User Conference 2013
    bibtitle: The {R} {U}ser {C}onference 2013
    author: UseR 2013 Organising Committee
    bibauthor: '{UseR 2013 Organising Committee}'
    slug: user2013
    pages:
    - 215
    - 217
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 218
    - 219
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 220
    - 220
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 221
    - 238
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 239
    - 264
- issue: 2013-2
  year: 2013
  volume: 5
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Hadley Wickham
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2013-021
    old_slug: armstrong
    title: 'factorplot: Improving Presentation of Simple Contrasts in Generalized
      Linear Models'
    bibtitle: |-
      factorplot: Improving Presentation of Simple Contrasts in
                Generalized Linear Models
    author: David A. Armstrong II
    bibauthor: David A. Armstrong II
    landing: '2013'
    abstract: '  Abstract Recent statistical literature has paid attention to the
      presentation of pairwise comparisons            either from the point of view
      of the reference category problem in generalized linear models (GLMs)            or
      in terms of multiple comparisons. Both schools of thought are interested in
      the parsimonious            presentation of sufficient information to enable
      readers to evaluate the significance of contrasts            resulting from
      the inclusion of qualitative variables in GLMs. These comparisons also arise
      when            trying to interpret multinomial models where one category of
      the dependent variable is omitted as            a reference. While considerable
      advances have been made, opportunities remain to improve the            presentation
      of this information, especially in graphical form. The factorplot package provides
      new            functions for graphically and numerically presenting results
      of hypothesis tests related to pairwise            comparisons resulting from
      qualitative covariates in GLMs or coefficients in multinomial logistic            regression
      models.'
    pages:
    - 4
    - 15
    acknowledged: '2012-03-13'
    online: '2013-11-22'
    CRANpkgs:
    - multcomp
    - qvcalc
    - Epi
    - car
    - multcompView
    - factorplot
    CTV_rev:
    - SocialSciences
    - Survival
    - ClinicalTrials
    - Econometrics
    - Finance
    - Multivariate
  - slug: RJ-2013-022
    old_slug: sartore
    title: 'spMC: Modelling Spatial Random Fields with Continuous Lag Markov Chains'
    bibtitle: |-
      spMC: Modelling Spatial Random Fields with Continuous Lag
                Markov Chains
    author: Luca Sartore
    bibauthor: Luca Sartore
    landing: '2013'
    abstract: '  Abstract Currently, a part of the R statistical software is developed
      in order to deal with spatial models.            More specifically, some available
      packages allow the user to analyse categorical spatial random            patterns.
      However, only the spMC package considers a viewpoint based on transition probabilities            between
      locations. Through the use of this package it is possible to analyse the spatial
      variability of            data, make inference, predict and simulate the categorical
      classes in unobserved sites. An example is            presented by analysing
      the well-known Swiss Jura data set.'
    pages:
    - 16
    - 28
    acknowledged: '2012-08-27'
    online: '2013-09-27'
    CRANpkgs:
    - spMC
    - gstat
    - geoRglm
    - RandomFields
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Bayesian
  - slug: RJ-2013-023
    old_slug: michna-woods
    title: RNetCDF - A Package for Reading and Writing NetCDF Datasets
    bibtitle: RNetCDF - A Package for Reading and Writing NetCDF Datasets
    author:
    - Pavel Michna
    - Milton Woods
    bibauthor: Pavel Michna and Milton Woods
    landing: '2013'
    abstract: '  Abstract This paper describes the RNetCDF package (version 1.6),
      an interface for reading and            writing files in Unidata NetCDF format,
      and gives an introduction to the NetCDF file format. NetCDF            is a
      machine independent binary file format which allows storage of different types
      of array based            data, along with short metadata descriptions. The
      package presented here allows access to the most            important functions
      of the NetCDF C-interface for reading, writing, and modifying NetCDF datasets.            In
      this paper, we present a short overview on the NetCDF file format and show usage
      examples of the            package.'
    pages:
    - 29
    - 36
    acknowledged: '2012-08-27'
    online: '2013-10-14'
    CRANpkgs:
    - RNetCDF
    - ncdf
    - ncdf4
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2013-024
    old_slug: roediger-bohm-schimke
    title: Surface Melting Curve Analysis with R
    bibtitle: Surface Melting Curve Analysis with R
    author:
    - Stefan Rödiger
    - Alexander Böhm
    - Ingolf Schimke
    bibauthor: Stefan Rödiger and Alexander Böhm and Ingolf Schimke
    landing: '2013'
    abstract: ' Abstract Nucleic acid Melting Curve Analysis is a powerful method
      to investigate the interaction           of double stranded nucleic acids. Many
      researchers rely on closed source software which is not           ubiquitously
      available, and gives only little control over the computation and data presentation.           R
      in contrast, is open source, highly adaptable and provides numerous utilities
      for data import,           sophisticated statistical analysis and presentation
      in publication quality. This article covers methods,           implemented in
      the MBmca package, for DNA Melting Curve Analysis on microbead surfaces.           Particularly,
      the use of the second derivative melting peaks is suggested as an additional
      parameter to           characterize the melting behavior of DNA duplexes. Examples
      of microbead surface Melting Curve           Analysis on fragments of human
      genes are presented.'
    pages:
    - 37
    - 52
    acknowledged: '2012-09-04'
    online: '2013-08-26'
    CRANpkgs:
    - qpcR
    - MBmca
    - robustbase
    - stats
    - signal
    - zoo
    - delftfews
    - Hmisc
    - base
    - fda
    CTV_rev:
    - Econometrics
    - Multivariate
    - Bayesian
    - ClinicalTrials
    - Environmetrics
    - Finance
    - NumericalMathematics
    - OfficialStatistics
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - TimeSeries
  - slug: RJ-2013-025
    old_slug: lu-kane
    title: Performance Attribution for Equity Portfolios
    bibtitle: Performance Attribution for Equity Portfolios
    author:
    - Yang Lu
    - David Kane
    bibauthor: Yang Lu and David Kane
    landing: '2013'
    abstract: '  Abstract The pa package provides tools for conducting performance
      attribution for long-only, single            currency equity portfolios. The
      package uses two methods: the Brinson-Hood-Beebower model            (hereafter
      referred to as the Brinson model) and a regression-based analysis. The Brinson
      model takes            an ANOVA-type approach and decomposes the active return
      of any portfolio into asset allocation,            stock selection, and interaction
      effect. The regression-based analysis utilizes estimated coefficients,            based
      on a regression model, to attribute active return to different factors.'
    pages:
    - 53
    - 62
    acknowledged: '2012-10-11'
    online: '2013-09-23'
    CRANpkgs:
    - pa
    - portfolio
    - PerformanceAnalytics
    - portfolio
    CTV_rev: Finance
  - slug: RJ-2013-026
    old_slug: wang-shan
    title: 'ExactCIdiff: An R Package for Computing Exact Confidence Intervals for
      the Difference of Two Proportions'
    bibtitle: |-
      ExactCIdiff: An R Package for Computing Exact Confidence
                Intervals for the Difference of Two Proportions
    author:
    - Guogen Shan
    - Weizhen Wang
    bibauthor: Guogen Shan and Weizhen Wang
    landing: '2013'
    abstract: '  Abstract Comparing two proportions through the difference is a basic
      problem in statistics and has            applications in many fields. More than
      twenty confidence intervals (Newcombe, 1998a,b) have been            proposed.
      Most of them are approximate intervals with an asymptotic infimum coverage probability            much
      less than the nominal level. In addition, large sample may be costly in practice.
      So exact            optimal confidence intervals become critical for drawing
      valid statistical inference with accuracy and            precision. Recently,
      Wang (2010, 2012) derived the exact smallest (optimal) one-sided 1 − α confidence            intervals
      for the difference of two paired or independent proportions. His intervals,
      however, are            computer-intensive by nature. In this article, we provide
      an R package ExactCIdiff to implement the            intervals when the sample
      size is not large. This would be the first available package in R to calculate            the
      exact confidence intervals for the difference of proportions. Exact two-sided
      1 − α interval can be            easily obtained by taking the intersection
      of the lower and upper one-sided 1 − α/2 intervals. Readers            may jump
      to Examples 1 and 2 to obtain these intervals.'
    pages:
    - 62
    - 70
    acknowledged:
    - '2012-12-21'
    - '2013-02-15'
    online: '2013-08-16'
    CRANpkgs:
    - ExactCIdiff
    - Epi
    - PropCIs
    - exactci
    CTV_rev: Survival
  - slug: RJ-2013-027
    old_slug: bilgic-susmann
    title: 'rlme: An R Package for Rank-Based Estimation and Prediction in Random
      Effects Nested Models'
    bibtitle: |-
      rlme: An R Package for Rank-Based Estimation and Prediction
                in Random Effects Nested Models
    author:
    - Yusuf K. Bilgic
    - Herbert Susmann
    bibauthor: Yusuf K. Bilgic and Herbert Susmann
    landing: '2013'
    abstract: '  Abstract There is a lack of robust statistical analyses for random
      effects linear models. In practice,            statistical analyses, including
      estimation, prediction and inference, are not reliable when data are            unbalanced,
      of small size, contain outliers, or not normally distributed. It is fortunate
      that rank-based            regression analysis is a robust nonparametric alternative
      to likelihood and least squares analysis. We            propose an R package
      that calculates rank-based statistical analyses for twoand three-level random            effects
      nested designs. In this package, a new algorithm which recursively obtains robust
      predictions            for both scale and random effects is used, along with
      three rank-based fitting methods.'
    pages:
    - 71
    - 79
    acknowledged: '2013-02-04'
    online: '2013-10-25'
    CRANpkgs:
    - aa
    - Rfit
    - rlme
    - lme4
    CTV_rev:
    - Bayesian
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - SpatioTemporal
  - slug: RJ-2013-028
    old_slug: sax-steiner
    title: Temporal Disaggregation of Time Series
    bibtitle: Temporal Disaggregation of Time Series
    author:
    - Christoph Sax
    - Peter Steiner
    bibauthor: Christoph Sax and Peter Steiner
    landing: '2013'
    abstract: '  Abstract Temporal disaggregation methods are used to disaggregate
      low frequency time series to            higher frequency series, where either
      the sum, the average, the first or the last value of the resulting            high
      frequency series is consistent with the low frequency series. Temporal disaggregation
      can be            performed with or without one or more high frequency indicator
      series. The package tempdisagg is a            collection of several methods
      for temporal disaggregation.'
    pages:
    - 80
    - 87
    acknowledged: '2013-03-01'
    online: '2013-08-26'
    CRANpkgs: tempdisagg
    CTV_rev: TimeSeries
  - slug: RJ-2013-029
    old_slug: boehringer
    title: Dynamic Parallelization of R Functions
    bibtitle: Dynamic Parallelization of R Functions
    author: Stefan Böhringer
    bibauthor: Stefan Böhringer
    landing: '2013'
    abstract: '  Abstract R offers several extension packages that allow it to perform
      parallel computations. These            operate on fixed points in the program
      flow and make it difficult to deal with nested parallelism and            to
      organize parallelism in complex computations in general. In this article we
      discuss, first, of how to            detect parallelism in functions, and second,
      how to minimize user intervention in that process. We            present a solution
      that requires minimal code changes and enables to flexibly and dynamically choose            the
      degree of parallelization in the resulting computation. An implementation is
      provided by the R            package parallelize.dynamic and practical issues
      are discussed with the help of examples.'
    pages:
    - 88
    - 96
    acknowledged: '2013-03-29'
    online: '2013-12-27'
    CRANpkgs:
    - Rsge
    - foreach
    - boot
    - snow
    - parallelize.dynamic
    CTV_rev:
    - HighPerformanceComputing
    - Econometrics
    - Optimization
    - SocialSciences
    - Survival
    - TimeSeries
  - slug: RJ-2013-030
    old_slug: nadarajah-bakar
    title: 'CompLognormal: An R Package for Composite Lognormal Distributions'
    bibtitle: |-
      CompLognormal: An R Package for Composite Lognormal
                Distributions
    author:
    - S. Nadarajah
    - S. A. A. Bakar
    bibauthor: S. Nadarajah and S. A. A. Bakar
    landing: '2013'
    abstract: '  Abstract In recent years, composite models based on the lognormal
      distribution have become popular            in actuarial sciences and related
      areas. In this short note, we present a new R package for computing the            probability
      density function, cumulative density function, and quantile function, and for
      generating            random numbers of any composite model based on the lognormal
      distribution. The use of the package            is illustrated using a real
      data set.'
    pages:
    - 97
    - 103
    acknowledged: '2013-04-12'
    online: '2013-11-18'
    CRANpkgs:
    - CompLognormal
    - CRAN
    - poweRlaw
    - SMPracticals
    - MASS
    - fitdistrplus
    - distrMod
    CTV_rev:
    - Distributions
    - Survival
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2013-031
    old_slug: gaure
    title: 'lfe: Linear Group Fixed Effects'
    bibtitle: 'lfe: Linear Group Fixed Effects'
    author: Simen Gaure
    bibauthor: Simen Gaure
    landing: '2013'
    abstract: '  Abstract Linear models with fixed effects and many dummy variables
      are common in some fields.            Such models are straightforward to estimate
      unless the factors have too many levels. The R package            lfe solves
      this problem by implementing a generalization of the within transformation to
      multiple            factors, tailored for large problems.'
    pages:
    - 104
    - 116
    acknowledged:
    - '2013-04-12'
    - '2013-07-18'
    online: '2013-11-18'
    CRANpkgs:
    - Matrix
    - plm
    - lfe
    - igraph
    - multicore
    CTV_rev:
    - Econometrics
    - gR
    - Graphics
    - Multivariate
    - NumericalMathematics
    - Optimization
    - Spatial
    - SpatioTemporal
  - slug: RJ-2013-032
    old_slug: dietrich-zug-kaiser
    title: The R in Robotics
    bibtitle: The R in Robotics
    author:
    - André Dietrich
    - Sebastian Zug
    - Jörg Kaiser
    bibauthor: André Dietrich and Sebastian Zug and Jörg Kaiser
    landing: '2013'
    abstract: '  Abstract The aim of this contribution is to connect two previously
      separated worlds: robotic application            development with the Robot
      Operating System (ROS) and statistical programming with R. This            fruitful
      combination becomes apparent especially in the analysis and visualization of
      sensory data. We            therefore introduce a new language extension for
      ROS that allows to implement nodes in pure R. All            relevant aspects
      are described in a step-by-step development of a common sensor data transformation            node.
      This includes the reception of raw sensory data via the ROS network, message
      interpretation,            bag-file analysis, transformation and visualization,
      as well as the transmission of newly generated            messages back into
      the ROS network.'
    pages:
    - 117
    - 128
    acknowledged: '2013-04-12'
    online: '2013-12-13'
    CRANpkgs: Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
  - slug: RJ-2013-033
    old_slug: hofert
    title: On Sampling from the Multivariate t Distribution
    bibtitle: On Sampling from the Multivariate t Distribution
    author: Marius Hofert
    bibauthor: Marius Hofert
    landing: '2013'
    abstract: '  Abstract The multivariate normal and the multivariate t distributions
      belong to the most widely used            multivariate distributions in statistics,
      quantitative risk management, and insurance. In contrast to            the multivariate
      normal distribution, the parameterization of the multivariate t distribution
      does            not correspond to its moments. This, paired with a non-standard
      implementation in the R package            mvtnorm, provides traps for working
      with the multivariate t distribution. In this paper, common            traps
      are clarified and corresponding recent changes to mvtnorm are presented.'
    pages:
    - 129
    - 136
    acknowledged: '2013-04-29'
    online: '2013-11-04'
    CRANpkgs:
    - mvtnorm
    - MASS
    - evir
    - mnormt
    - QRM
    CTV_rev:
    - Distributions
    - Multivariate
    - Environmetrics
    - ExtremeValue
    - Econometrics
    - Finance
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2013-034
    old_slug: sucarrat
    title: 'betategarch: Simulation, Estimation and Forecasting of Beta-Skew-t-EGARCH
      Models'
    bibtitle: |-
      betategarch: Simulation, Estimation and Forecasting of Beta-
                Skew-t-EGARCH Models
    author: Genaro Sucarrat
    bibauthor: Genaro Sucarrat
    landing: '2013'
    abstract: '  Abstract This paper illustrates the usage of the betategarch package,
      a package for the simulation,            estimation and forecasting of Beta-Skew-t-EGARCH
      models. The Beta-Skew-t-EGARCH model is            a dynamic model of the scale
      or volatility of financial returns. The model is characterised by its            robustness
      to jumps or outliers, and by its exponential specification of volatility. The
      latter enables            richer dynamics, since parameters need not be restricted
      to be positive to ensure positivity of volatility.            In addition, the
      model also allows for heavy tails and skewness in the conditional return (i.e.
      scaled            return), and for leverage and a time-varying long-term component
      in the volatility specification. More            generally, the model can be
      viewed as a model of the scale of the error in a dynamic regression.'
    pages:
    - 137
    - 147
    acknowledged: '2013-06-04'
    online: '2013-12-23'
    CRANpkgs:
    - tseries
    - fGarch
    - rugarch
    - AutoSEARCH
    - zoo
    CTV_rev:
    - Finance
    - TimeSeries
    - Econometrics
    - Environmetrics
  - slug: RJ-2013-035
    old_slug: murrell
    title: Changes to grid for R 3.0.0
    bibtitle: Changes to grid for R 3.0.0
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2013'
    abstract: '  Abstract From R 3.0.0, there is a new recommended way to develop
      new grob classes in grid.            In a nutshell, two new “hook” functions,
      makeContext() and makeContent() have been added to            grid to provide
      an alternative to the existing hook functions preDrawDetails(), drawDetails(),
      and            postDrawDetails(). There is also a new function called grid.force().
      This article discusses why            these changes have been made, provides
      a simple demonstration of the use of the new functions, and            discusses
      some of the implications for packages that build on grid.'
    pages:
    - 148
    - 160
    acknowledged: '2013-06-04'
    online: '2013-09-27'
    CRANpkgs:
    - lattice
    - ggplot2
    - gtable
    - gridSVG
    - grImport
    - gridGraphviz
    - gridExtra
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
  - heading: News and Notes
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 161
    - 161
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 162
    - 163
  - title: 'Conference Report: Deuxièmes Rencontres R'
    bibtitle: 'Conference Report: Deuxi{\` e}mes Rencontres {R}'
    author:
    - Aurelie Siberchicot
    - Stephane Dray
    slug: siberchicot-dray
    pages:
    - 164
    - 165
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 166
    - 191
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 192
    - 198
- issue: 2014-1
  year: 2014
  volume: 6
  num: 1
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Deepayan Sarkar
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2014-001
    old_slug: sievert
    title: Taming PITCHf/x Data with XML2R and pitchRx
    bibtitle: Taming PITCHf/x Data with XML2R and pitchRx
    author: Carson Sievert
    bibauthor: Carson Sievert
    landing: '2014'
    abstract: '  Abstract XML2R is a framework that reduces the effort required to
      transform XML content into tables            in a way that preserves parent
      to child relationships. pitchRx applies XML2R’s grammar for XML            manipulation
      to Major League Baseball Advanced Media (MLBAM)’s Gameday data. With pitchRx,            one
      can easily obtain and store Gameday data in a remote database. The Gameday website
      hosts a            wealth of XML data, but perhaps most interesting is PITCHf/x.
      Among other things, PITCHf/x data            can be used to recreate a baseball’s
      flight path from a pitcher’s hand to home plate. With pitchRx, one            can
      easily create animations and interactive 3D scatterplots of the baseball’s flight
      path. PITCHf/x data            is also commonly used to generate a static plot
      of baseball locations at the moment they cross home            plate. These
      plots, sometimes called strike-zone plots, can also refer to a plot of event
      probabilities            over the same region. pitchRx provides an easy and
      robust way to generate strike-zone plots using            the ggplot2 package.'
    pages:
    - 5
    - 19
    acknowledged: '2013-01-17'
    online: '2014-03-03'
    CRANpkgs:
    - pitchRx
    - XML2R
    - ggplot2
    - rgl
    - dplyr
    - mgcv
    - knitr
    CTV_rev:
    - Graphics
    - Bayesian
    - Econometrics
    - Environmetrics
    - Multivariate
    - Phylogenetics
    - ReproducibleResearch
    - SocialSciences
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2014-002
    old_slug: nunes-taylor-eckley
    title: A Multiscale Test of Spatial Stationarity for Textured Images in R
    bibtitle: |-
      A Multiscale Test of Spatial Stationarity for Textured
                Images in R
    author:
    - Matthew A. Nunes
    - Sarah L. Taylor
    - Idris A. Eckley
    bibauthor: Matthew A. Nunes and Sarah L. Taylor and Idris A. Eckley
    landing: '2014'
    abstract: '  Abstract The ability to automatically identify areas of homogeneous
      texture present within a greyscale            image is an important feature
      of image processing algorithms. This article describes the R package            LS2Wstat
      which employs a recent wavelet-based test of stationarity for locally stationary
      random fields            to assess such spatial homogeneity. By embedding this
      test within a quadtree image segmentation            procedure we are also able
      to identify texture regions within an image.'
    pages:
    - 20
    - 30
    acknowledged: '2013-07-18'
    online: '2014-06-16'
    CRANpkgs:
    - LS2Wstat
    - LS2W
    - urca
    - CADFtest
    - locits
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
  - slug: RJ-2014-003
    old_slug: gu-shapiro-hughes-etal
    title: Stratified Weibull Regression Model for Interval-Censored Data
    bibtitle: |-
      Stratified Weibull Regression Model for Interval-Censored
                Data
    author:
    - Xiangdong Gu
    - David Shapiro
    - Michael D. Hughes
    - Raji Balasubramanian
    bibauthor: |-
      Xiangdong Gu and David Shapiro and Michael D. Hughes and
                Raji Balasubramanian
    landing: '2014'
    abstract: '  Abstract Interval censored outcomes arise when a silent event of
      interest is known to have occurred            within a specific time period
      determined by the times of the last negative and first positive diagnostic            tests.
      There is a rich literature on parametric and non-parametric approaches for the
      analysis of            interval-censored outcomes. A commonly used strategy
      is to use a proportional hazards (PH) model            with the baseline hazard
      function parameterized. The proportional hazards assumption can be relaxed            in
      stratified models by allowing the baseline hazard function to vary across strata
      defined by a subset of            explanatory variables. In this paper, we describe
      and implement a new R package straweib, for fitting            a stratified
      Weibull model appropriate for interval censored outcomes. We illustrate the
      R package            straweib by analyzing data from a longitudinal oral health
      study on the timing of the emergence of            permanent teeth in 4430 children.'
    pages:
    - 31
    - 40
    acknowledged: '2013-07-19'
    online: '2014-03-03'
    CRANpkgs:
    - survival
    - straweib
    CTV_rev:
    - ClinicalTrials
    - Econometrics
    - SocialSciences
    - Survival
  - slug: RJ-2014-004
    old_slug: muschelli-sweeney-crainiceanu
    title: 'brainR: Interactive 3 and 4D Images of High Resolution Neuroimage Data'
    bibtitle: |-
      brainR: Interactive 3 and 4D Images of High Resolution
                Neuroimage Data
    author:
    - John Muschelli
    - Elizabeth Sweeney
    - Ciprian Crainiceanu
    bibauthor: John Muschelli and Elizabeth Sweeney and Ciprian Crainiceanu
    landing: '2014'
    abstract: '  Abstract We provide software tools for displaying and publishing
      interactive 3-dimensional (3D) and            4-dimensional (4D) figures to
      html webpages, with examples of high-resolution brain imaging. Our            framework
      is based in the R statistical software using the rgl package, a 3D graphics
      library. We build            on this package to allow manipulation of figures
      including rotation and translation, zooming, coloring            of brain substructures,
      adjusting transparency levels, and addition/or removal of brain structures.            The
      need for better visualization tools of ultra high dimensional data is ever present;
      we are providing            a clean, simple, web-based option. We also provide
      a package (brainR) for users to readily implement            these tools.'
    pages:
    - 41
    - 48
    acknowledged: '2013-08-16'
    online: '2014-06-03'
    CRANpkgs:
    - rgl
    - knitr
    - Sweave
    - slidify
    - misc3d
    - brainR
    CTV_rev:
    - Graphics
    - Multivariate
    - MedicalImaging
    - ReproducibleResearch
    - SpatioTemporal
  - slug: RJ-2014-005
    old_slug: vandekerckhove-wabersich
    title: 'The RWiener Package: an R Package Providing Distribution Functions for
      the Wiener Diffusion Model'
    bibtitle: |-
      The RWiener Package: an R Package Providing Distribution
                Functions for the Wiener Diffusion Model
    author:
    - Dominik Wabersich
    - Joachim Vandekerckhove
    bibauthor: Dominik Wabersich and Joachim Vandekerckhove
    landing: '2014'
    abstract: '  Abstract We present the RWiener package that provides R functions
      for the Wiener diffusion model.            The core of the package are the four
      distribution functions dwiener, pwiener, qwiener and rwiener,            which
      use up-to-date methods, implemented in C, and provide fast and accurate computation
      of the            density, distribution, and quantile function, as well as a
      random number generator for the Wiener            diffusion model. We used the
      typical Wiener diffusion model with four parameters: boundary            separation,
      non-decision time, initial bias and drift rate parameter. Beyond the distribution
      functions,            we provide extended likelihood-based functions that can
      be used for parameter estimation and model            selection. The package
      can be obtained via CRAN.'
    pages:
    - 49
    - 56
    acknowledged: '2013-08-23'
    online: '2014-04-19'
    CRANpkgs: RWiener
  - slug: RJ-2014-006
    old_slug: qian
    title: 'PivotalR: A Package for Machine Learning on Big Data'
    bibtitle: 'PivotalR: A Package for Machine Learning on Big Data'
    author: Hai Qian
    bibauthor: Hai Qian
    landing: '2014'
    abstract: '  Abstract PivotalR is an R package that provides a front-end to PostgreSQL
      and all PostgreSQL-like            databases such as Pivotal Inc.’s Greenplum
      Database (GPDB) (Pivotal Inc., 2013a), HAWQ (Pivotal            Inc., 2013b).
      When running on the products of Pivotal Inc., PivotalR utilizes the full power
      of parallel            computation and distributive storage, and thus gives
      the normal R user access to big data. PivotalR            also provides the
      R wrapper for MADlib. MADlib is an open-source library for scalable in-database            analytics.
      It provides data-parallel implementations of mathematical, statistical and machine-learning            algorithms
      for structured and unstructured data. Thus PivotalR also enables the user to
      apply machine            learning algorithms onto big data.'
    pages:
    - 57
    - 67
    acknowledged: '2013-09-21'
    online: '2014-05-27'
    CRANpkgs:
    - PivotalR
    - RPostgreSQL
    - shiny
    CTV_rev: WebTechnologies
  - slug: RJ-2014-007
    old_slug: stanfill-hofmann-genschel
    title: 'rotations: An R Package for SO(3) Data'
    bibtitle: 'rotations: An R Package for SO(3) Data'
    author:
    - Bryan Stanfill
    - Heike Hofmann
    - Ulrike Genschel
    bibauthor: Bryan Stanfill and Heike Hofmann and Ulrike Genschel
    landing: '2014'
    abstract: '  Abstract In this article we introduce the rotations package which
      provides users with the ability to            simulate, analyze and visualize
      three-dimensional rotation data. More specifically it includes four            commonly
      used distributions from which to simulate data, four estimators of the central
      orientation,            six confidence region estimation procedures and two
      approaches to visualizing rotation data. All of            these features are
      available for two different parameterizations of rotations: three-by-three matrices            and
      quaternions. In addition, two datasets are included that illustrate the use
      of rotation data in            practice.'
    pages:
    - 68
    - 78
    acknowledged: '2013-09-21'
    online: '2014-04-19'
    CRANpkgs:
    - orientlib
    - onion
    - circular
    - SpherWave
    - rotations
    - ggplot2
    - sphereplot
    - Rcpp
    - RcppArmadillo
    CTV_rev:
    - NumericalMathematics
    - Graphics
    - Environmetrics
    - HighPerformanceComputing
    - Phylogenetics
  - slug: RJ-2014-008
    old_slug: menardi-lunardon-torelli
    title: 'ROSE: a Package for Binary Imbalanced Learning'
    bibtitle: 'ROSE: a Package for Binary Imbalanced Learning'
    author:
    - Nicola Lunardon
    - Giovanna Menardi
    - Nicola Torelli
    bibauthor: Nicola Lunardon and Giovanna Menardi and Nicola Torelli
    landing: '2014'
    abstract: '  Abstract The ROSE package provides functions to deal with binary
      classification problems in the            presence of imbalanced classes. Artificial
      balanced samples are generated according to a smoothed            bootstrap
      approach and allow for aiding both the phases of estimation and accuracy evaluation
      of a            binary classifier in the presence of a rare class. Functions
      that implement more traditional remedies for            the class imbalance
      and different metrics to evaluate accuracy are also provided. These are estimated            by
      holdout, bootstrap or cross-validation methods.'
    pages:
    - 79
    - 89
    acknowledged: '2013-09-21'
    online: '2014-06-16'
    CRANpkgs:
    - DMwR
    - caret
    - ROSE
    - ROSE
    - ROSE
    - class
    CTV_rev:
    - Multivariate
    - HighPerformanceComputing
    - MachineLearning
    - SocialSciences
  - slug: RJ-2014-009
    old_slug: greenwell-kabban
    title: 'investr: An R Package for Inverse Estimation'
    bibtitle: 'investr: An R Package for Inverse Estimation'
    author:
    - Brandon M. Greenwell
    - Christine M. Schubert Kabban
    bibauthor: Brandon M. Greenwell and Christine M. Schubert Kabban
    landing: '2014'
    abstract: '  Abstract Inverse estimation is a classical and well-known problem
      in regression. In simple terms, it            involves the use of an observed
      value of the response to make inference on the corresponding unknown            value
      of the explanatory variable. To our knowledge, however, statistical software
      is somewhat lacking            the capabilities for analyzing these types of
      problems. In this paper1 , we introduce investr (which            stands for
      inverse estimation in R), a package for solving inverse estimation problems
      in both linear            and nonlinear regression models.'
    pages:
    - 90
    - 100
    acknowledged: '2013-09-27'
    online: '2014-05-27'
    CRANpkgs:
    - investr
    - MASS
    - drc
    - car
    - boot
    CTV_rev:
    - Econometrics
    - SocialSciences
    - ChemPhys
    - Multivariate
    - Pharmacokinetics
    - Distributions
    - Environmetrics
    - Finance
    - NumericalMathematics
    - Optimization
    - Psychometrics
    - Robust
    - Survival
    - TimeSeries
  - slug: RJ-2014-010
    old_slug: jacques-grimonprez-biernacki
    title: 'Rankcluster: An R Package for Clustering Multivariate Partial Rankings'
    bibtitle: |-
      Rankcluster: An R Package for Clustering Multivariate
                Partial Rankings
    author:
    - Julien Jacques
    - Quentin Grimonprez
    - Christophe Biernacki
    bibauthor: |-
      Julien Jacques and Quentin Grimonprez and Christophe
                Biernacki
    landing: '2014'
    abstract: '  Abstract The Rankcluster package is the first R package proposing
      both modeling and clustering            tools for ranking data, potentially
      multivariate and partial. Ranking data are modeled by the Insertion            Sorting
      Rank (ISR) model, which is a meaningful model parametrized by a central ranking
      and a            dispersion parameter. A conditional independence assumption
      allows multivariate rankings to be            taken into account, and clustering
      is performed by means of mixtures of multivariate ISR models.            The
      parameters of the cluster (central rankings and dispersion parameters) help
      the practitioners            to interpret the clustering. Moreover, the Rankcluster
      package provides an estimate of the missing            ranking positions when
      rankings are partial. After an overview of the mixture of multivariate ISR            models,
      the Rankcluster package is described and its use is illustrated through the
      analysis of two            real datasets.'
    pages:
    - 101
    - 110
    acknowledged: '2013-10-04'
    online: '2014-03-03'
    CRANpkgs:
    - Rankcluster
    - pmr
    - RMallow
  - slug: RJ-2014-011
    old_slug: loo
    title: The stringdist Package for Approximate String Matching
    bibtitle: The stringdist Package for Approximate String Matching
    author: Mark P.J. van der Loo
    bibauthor: Mark P.J. van der Loo
    landing: '2014'
    abstract: '  Abstract Comparing text strings in terms of distance functions is
      a common and fundamental task in            many statistical text-processing
      applications. Thus far, string distance functionality has been somewhat            scattered
      around R and its extension packages, leaving users with inconistent interfaces
      and encoding            handling. The stringdist package was designed to offer
      a low-level interface to several popular string            distance algorithms
      which have been re-implemented in C for this purpose. The package offers            distances
      based on counting q-grams, edit-based distances, and some lesser known heuristic
      distance            functions. Based on this functionality, the package also
      offers inexact matching equivalents of R’s            native exact matching
      functions match and %in%.'
    pages:
    - 111
    - 122
    acknowledged: '2013-11-04'
    online: '2014-04-27'
    CRANpkgs:
    - kernlab
    - RecordLinkage
    - MiscPsycho
    - cba
    - Mkmisc
    - deducorrect
    - vwr
    - stringdist
    - textcat
    - TraMineR
    CTV_rev:
    - OfficialStatistics
    - Cluster
    - NaturalLanguageProcessing
    - Graphics
    - MachineLearning
    - Multivariate
    - Optimization
    - Survival
  - slug: RJ-2014-012
    old_slug: kaptein
    title: 'RStorm: Developing and Testing Streaming Algorithms in R'
    bibtitle: 'RStorm: Developing and Testing Streaming Algorithms in R'
    author: Maurits Kaptein
    bibauthor: Maurits Kaptein
    landing: '2014'
    abstract: '  Abstract Streaming data, consisting of indefinitely evolving sequences,
      are becoming ubiquitous in            many branches of science and in various
      applications. Computer scientists have developed streaming            applications
      such as Storm and the S4 distributed stream computing platform1 to deal with
      data            streams. However, in current production packages testing and
      evaluating streaming algorithms is            cumbersome. This paper presents
      RStorm for the development and evaluation of streaming algorithms            analogous
      to these production packages, but implemented fully in R. RStorm allows developers
      of            streaming algorithms to quickly test, iterate, and evaluate various
      implementations of streaming            algorithms. The paper provides both
      a canonical computer science example, the streaming word count,            and
      examples of several statistical applications of RStorm.'
    pages:
    - 123
    - 132
    acknowledged: '2013-11-18'
    online: '2014-03-18'
    CRANpkgs:
    - RStorm
    - stream
  - slug: RJ-2014-013
    old_slug: murrell-potter
    title: The gridSVG Package
    bibtitle: The gridSVG Package
    author:
    - Paul Murrell
    - Simon Potter
    bibauthor: Paul Murrell and Simon Potter
    landing: '2014'
    abstract: '  Abstract The gridSVG package can be used to generate a grid-based
      R plot in an SVG format, with            the ability to add special effects
      to the plot. The special effects include animation, interactivity, and            advanced
      graphical features, such as masks and filters. This article provides a basic
      introduction            to important functions in the gridSVG package and discusses
      the advantages and disadvantages of            gridSVG compared to similar R
      packages.'
    pages:
    - 133
    - 143
    acknowledged: '2013-11-18'
    online: '2014-06-02'
    CRANpkgs:
    - gridSVG
    - lattice
    - ggplot2
    - animation
    - RSVGTipsDevice
    - googleVis
    - shiny
    CTV_rev:
    - Graphics
    - WebTechnologies
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
    - ReproducibleResearch
    - SpatioTemporal
  - slug: RJ-2014-014
    old_slug: koziol-bilder
    title: 'MRCV: A Package for Analyzing Categorical Variables with Multiple Response
      Options'
    bibtitle: |-
      MRCV: A Package for Analyzing Categorical Variables with
                Multiple Response Options
    author:
    - Natalie A. Koziol
    - Christopher R. Bilder
    bibauthor: Natalie A. Koziol and Christopher R. Bilder
    landing: '2014'
    abstract: '  Abstract Multiple response categorical variables (MRCVs), also known
      as “pick any” or “choose            all that apply” variables, summarize survey
      questions for which respondents are allowed to select            more than one
      category response option. Traditional methods for analyzing the association
      between            categorical variables are not appropriate with MRCVs due
      to the within-subject dependence among            responses. We have developed
      the MRCV package as the first R package available to correctly analyze            MRCV
      data. Statistical methods offered by our package include counterparts to traditional
      Pearson            chi-square tests for independence and loglinear models, where
      bootstrap methods and Rao-Scott            adjustments are relied on to obtain
      valid inferences. We demonstrate the primary functions within the            package
      by analyzing data from a survey assessing the swine waste management practices
      of Kansas            farmers.'
    pages:
    - 144
    - 150
    acknowledged: '2013-11-22'
    online: '2014-04-19'
    CRANpkgs:
    - MRCV
    - geepack
    CTV_rev:
    - Econometrics
    - SocialSciences
  - slug: RJ-2014-015
    old_slug: leeper
    title: Archiving Reproducible Research with R and Dataverse
    bibtitle: Archiving Reproducible Research with R and Dataverse
    author: Thomas J. Leeper
    bibauthor: Thomas J. Leeper
    landing: '2014'
    abstract: '  Abstract Reproducible research and data archiving are increasingly
      important issues in research            involving statistical analyses of quantitative
      data. This article introduces the dvn package, which            allows R users
      to publicly archive datasets, analysis files, codebooks, and associated metadata
      in            Dataverse Network online repositories, an open-source data archiving
      project sponsored by Harvard            University. In this article I review
      the importance of data archiving in the context of reproducible            research,
      introduces the Dataverse Network, explain the implementation of the dvn package,
      and            provide example code for archiving and releasing data using the
      package.'
    pages:
    - 151
    - 158
    acknowledged: '2013-12-06'
    online: '2014-03-03'
    CRANpkgs:
    - dvn
    - knitr
    - rfigshare
    - RCurl
    - XML
    - rfigshare
    - rdryad
    - OAIHarvester
    CTV_rev:
    - WebTechnologies
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2014-018
    old_slug: bottomly-wilmot-mcweeney
    title: 'oligoMask: A Framework for Assessing and Removing the Effect of Genetic
      Variants on Microarray Probes'
    bibtitle: |-
      oligoMask: A Framework for Assessing and Removing the Effect
                of Genetic Variants on Microarray Probes
    author:
    - Daniel Bottomly
    - Beth Wilmot
    - Shannon K. McWeeney
    bibauthor: Daniel Bottomly and Beth Wilmot and Shannon K. McWeeney
    landing: '2014'
    abstract: '  Abstract As expression microarrays are typically designed relative
      to a reference genome, any            individual genetic variant that overlaps
      a probe’s genomic position can possibly cause a reduction            in hybridization
      due to the probe no longer being a perfect match to a given sample’s mRNA at            that
      locus. If the samples or groups used in a microarray study differ in terms of
      genetic variants,            the results of the microarray experiment can be
      negatively impacted. The oligoMask package is an            R/SQLite framework
      which can utilize publicly available genetic variants and works in conjunction            with
      the oligo package to read in the expression data and remove microarray probes
      which are likely            to impact a given microarray experiment prior to
      analysis. Tools are provided for creating an SQLite            database containing
      the probe and variant annotations and for performing the commonly used RMA            preprocessing
      procedure for Affymetrix microarrays. The oligoMask package is freely available
      at            https://github.com/dbottomly/oligoMask.'
    pages:
    - 159
    - 163
    acknowledged: '2014-03-06'
    online: '2014-05-27'
    BIOpkgs:
    - oligo
    - xps
    - maskBAD
    - VariantAnnotation
    - BSgenome
    - Biostrings
  - slug: RJ-2014-019
    old_slug: lombardi-pastore
    title: 'sgr: A Package for Simulating Conditional Fake Ordinal Data'
    bibtitle: 'sgr: A Package for Simulating Conditional Fake Ordinal Data'
    author:
    - Luigi Lombardi
    - Massimiliano Pastore
    bibauthor: Luigi Lombardi and Massimiliano Pastore
    landing: '2014'
    abstract: '  Abstract Many self-report measures of attitudes, beliefs, personality,
      and pathology include items that            can be easily manipulated by respondents.
      For example, an individual may deliberately attempt to            manipulate
      or distort responses to simulate grossly exaggerated physical or psychological
      symptoms            in order to reach specific goals such as, for example, obtaining
      financial compensation, avoiding being            charged with a crime, avoiding
      military duty, or obtaining drugs. This article introduces the package            sgr
      that can be used to perform fake data analysis according to the sample generation
      by replacement            approach. The package includes functions for making
      simple inferences about discrete/ordinal fake            data. The package allows
      to quantify uncertainty in inferences based on possible fake data as well as            to
      study the implications of fake data for empirical results.'
    pages:
    - 164
    - 177
    acknowledged: '2014-02-03'
    online: '2014-04-19'
    CRANpkgs:
    - sgr
    - polycor
    - MASS
    CTV_rev:
    - Multivariate
    - Psychometrics
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Pharmacokinetics
    - Robust
    - SocialSciences
  - heading: News and Notes
  - slug: RJ-2014-016
    old_slug: mair-chamberlain
    title: Web Technologies Task View
    bibtitle: Web Technologies Task View
    author:
    - Patrick Mair
    - Scott Chamberlain
    bibauthor: Patrick Mair and Scott Chamberlain
    landing: '2014'
    abstract: '  Abstract This article presents the CRAN Task View on Web Technologies.
      We describe the most            important aspects of Web Technologies and Web
      Scraping and list some of the packages that are            currently available
      on CRAN. Finally, we plot the network of Web Technology related package            dependencies.'
    pages:
    - 178
    - 181
    acknowledged: '2014-01-03'
    online: '2014-06-10'
    CRANpkgs:
    - XML
    - RCurl
    - rjson
    - RJSONIO
    - jsonlite
    - httr
    - ROAuth
    - shiny
    - rgbif
    - rfishbase
    - rfisheries
    - rsnps
    - rentrez
    - crn
    - RNCEP
    - WDI
    - TFX
    - anametrix
    - rpubchem
    - cimis
    - nhlscrapr
    - tm
    - translate
    - scholar
    - RgoogleMap
    - Rfacebook
    - twitteR
    - streamR
    - AWS.tools
    - MTurkR
    - GuardianR
    - igraph
    CTV_rev:
    - WebTechnologies
    - Spatial
    - ChemPhys
    - Finance
    - gR
    - Graphics
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - Optimization
  - slug: RJ-2014-017
    old_slug: godfrey-erhardt
    title: Addendum to ``Statistical Software from a Blind Person's Perspective''
    bibtitle: |-
      Addendum to ``Statistical Software from a Blind Person's
                Perspective''
    author:
    - A. Jonathan R. Godfrey
    - Robert Erhardt
    bibauthor: A. Jonathan R. Godfrey and Robert Erhardt
    landing: '2014'
    abstract: '  Abstract This short note explains a solution to a problem for blind
      users when using the R terminal            under Windows Vista or Windows 7,
      as identified in Godfrey (2013). We note the way the solution            was
      discovered and subsequent confirmatory experiments.                 As part
      of his preparations for teaching a blind student in a statistics course, the
      second author'
    pages:
    - 182
    - 182
    acknowledged: []
    online: '2014-03-03'
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    slug: r-foundation
    pages:
    - 183
    - 183
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: Bioconductor Team
    bibauthor: '{Bioconductor Team}'
    slug: bioconductor
    pages:
    - 184
    - 185
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 186
    - 220
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    bibauthor: '{The R Core Team}'
    pages:
    - 221
    - 235
- issue: 2014-2
  year: 2014
  volume: 6
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Deepayan Sarkar
    slug: editorial
    pages:
    - 3
    - 3
  - heading: Contributed Research Articles
  - slug: RJ-2014-020
    old_slug: stocco
    title: 'Coordinate-Based Meta-Analysis of fMRI Studies with R '
    bibtitle: Coordinate-Based Meta-Analysis of fMRI Studies with R
    author: Andrea Stocco
    bibauthor: Andrea Stocco
    landing: '2014'
    abstract: '  Abstract This paper outlines how to conduct a simple meta-analysis
      of neuroimaging foci of activation            in R. In particular, the first
      part of this paper reviews the nature of fMRI data, and briefly overviews            the
      existing packages that can be used to analyze fMRI data in R. The second part
      illustrates how            to handle fMRI data by showing how to visualize the
      results of different neuroimaging studies in a            so-called orthographic
      view, where the spatial distribution of the foci of activation from different
      fMRI            studies can be inspected visually.                 Functional
      MRI (fMRI) is one of the most important and powerful tools of neuroscientific
      research.            Although not as commonly used for fMRI analysis as some
      specific applications such as SPM (Friston            et al., 2006), AFNI (Cox
      and Hyde, 1997), or FSL (Smith et al., 2004), R does provide several packages            that
      can be employed in neuroimaging research. These packages deal with a variety
      of topics, ranging            from reading and manipulating fMRI datasets, to
      implementing sophisticated statistical models.                 The goal of this
      paper is to provide a brief introduction to fMRI analysis, and the various R            packages
      that can be used to carry it out. As an example, it will show how to use simple
      R commands            to read fMRI images and plot results from previous studies,
      which can then be visually compared. This            is a special form of meta-analysis,
      and a common way to compare results from the existing literature.'
    pages:
    - 5
    - 15
    acknowledged: '2013-03-01'
    online: '2014-11-13'
    CRANpkgs:
    - fmri
    - RNiftyReg
    - AnalyzeFMRI
    - RfmriVC
    - arf3DS4
    - BHMSMAfMRI
    - neuRosim
    - oro.nifti
    - spatstat
    CTV_rev:
    - MedicalImaging
    - ChemPhys
    - Spatial
    - SpatioTemporal
    - Survival
  - slug: RJ-2014-021
    old_slug: oh
    title: Automatic Conversion of Tables to LongForm Dataframes
    bibtitle: Automatic Conversion of Tables to LongForm Dataframes
    author: Jimmy Oh
    bibauthor: Jimmy Oh
    landing: '2014'
    abstract: '  Abstract TableToLongForm automatically converts hierarchical Tables
      intended for a human reader            into a simple LongForm dataframe that
      is machine readable, making it easier to access and use the data            for
      analysis. It does this by recognising positional cues present in the hierarchical
      Table (which would            normally be interpreted visually by the human
      brain) to decompose, then reconstruct the data into a            LongForm dataframe.
      The article motivates the benefit of such a conversion with an example Table,            followed
      by a short user manual, which includes a comparison between the simple one argument
      call            to TableToLongForm, with code for an equivalent manual conversion.
      The article then explores the            types of Tables the package can convert
      by providing a gallery of all recognised patterns. It finishes            with
      a discussion of available diagnostic methods and future work.'
    pages:
    - 16
    - 26
    acknowledged: '2013-11-04'
    online: '2014-09-26'
    CRANpkgs:
    - TableToLongForm
    - reshape2
    - plyr
  - slug: RJ-2014-022
    old_slug: zhang-etal
    title: Prinsimp
    bibtitle: Prinsimp
    author:
    - Jonathan Zhang
    - Nancy Heckman
    - Davor Cubranic
    - Joel G. Kingsolver
    - Travis Gaydos
    - J.S.            Marron
    bibauthor: |-
      Jonathan Zhang and Nancy Heckman and Davor Cubranic and Joel
                G. Kingsolver and Travis Gaydos and J.S. Marron
    landing: '2014'
    abstract: '  Abstract Principal Components Analysis (PCA) is a common way to study
      the sources of variation in            a high-dimensional data set. Typically,
      the leading principal components are used to understand the            variation
      in the data or to reduce the dimension of the data for subsequent analysis.
      The remaining            principal components are ignored since they explain
      little of the variation in the data. However, the            space spanned by
      the low variation principal components may contain interesting structure, structure            that
      PCA cannot find. Prinsimp is an R package that looks for interesting structure
      of low variability.           “Interesting” is defined in terms of a simplicity
      measure. Looking for interpretable structure in a low            variability
      space has particular importance in evolutionary biology, where such structure
      can signify            the existence of a genetic constraint.'
    pages:
    - 27
    - 42
    acknowledged: '2013-11-04'
    online: '2014-09-28'
    CRANpkgs: prinsimp
  - slug: RJ-2014-023
    old_slug: grayling
    title: 'phaseR: An R Package for Phase Plane Analysis of Autonomous ODE Systems'
    bibtitle: |-
      phaseR: An R Package for Phase Plane Analysis of Autonomous
                ODE Systems
    author: Michael J. Grayling
    bibauthor: Michael J. Grayling
    landing: '2014'
    abstract: '  Abstract When modelling physical systems, analysts will frequently
      be confronted by differential            equations which cannot be solved analytically.
      In this instance, numerical integration will usually be            the only
      way forward. However, for autonomous systems of ordinary differential equations
      (ODEs)            in one or two dimensions, it is possible to employ an instructive
      qualitative analysis foregoing this            requirement, using so-called
      phase plane methods. Moreover, this qualitative analysis can even prove            to
      be highly useful for systems that can be solved analytically, or will be solved
      numerically anyway.            The package phaseR allows the user to perform
      such phase plane analyses: determining the stability            of any equilibrium
      points easily, and producing informative plots.'
    pages:
    - 43
    - 51
    acknowledged: '2014-01-03'
    online: '2014-09-30'
    CRANpkgs:
    - deSolve
    - ReacTran
    - rootSolve
    - bvpSolve
    - sde
    - phaseR
    CTV_rev:
    - DifferentialEquations
    - Finance
    - Pharmacokinetics
    - TimeSeries
  - slug: RJ-2014-024
    old_slug: domelen-pittard
    title: Flexible R Functions for Processing Accelerometer Data, with Emphasis on
      NHANES 2003-2006
    bibtitle: |-
      Flexible R Functions for Processing Accelerometer Data, with
                Emphasis on NHANES 2003-2006
    author:
    - Dane R. Van Domelen
    - W. Stephen Pittard
    bibauthor: Dane R. Van Domelen and W. Stephen Pittard
    landing: '2014'
    abstract: '  Abstract Accelerometers are a valuable tool for measuring physical
      activity (PA) in epidemiological            studies. However, considerable processing
      is needed to convert time-series accelerometer data into            meaningful
      variables for statistical analysis. This article describes two recently developed
      R packages            for processing accelerometer data. The package accelerometry
      contains functions for performing            various data processing procedures,
      such as identifying periods of non-wear time and bouts of activity.            The
      functions are flexible, computationally efficient, and compatible with uniaxial
      or triaxial data.            The package nhanesaccel is specifically for processing
      data from the National Health and Nutrition            Examination Survey (NHANES),
      years 2003–2006. Its primary function generates measures of PA            volume,
      intensity, frequency, and patterns according to user-specified data processing
      methods. This            function can process the NHANES 2003-2006 dataset in
      under one minute, which is a drastic improve           ment over existing software.
      This article highlights important features of packages accelerometry and            nhanesaccel
      and demonstrates typical usage for PA researchers.'
    pages:
    - 52
    - 62
    acknowledged: '2014-03-15'
    online: '2015-01-04'
    CRANpkgs:
    - accelerometry
    - Rcpp
    - pawacc
    - PhysicalActivity
    - survey
    - GGIR
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    - OfficialStatistics
    - SocialSciences
    - Survival
  - slug: RJ-2014-025
    old_slug: alden-read-andrews-etal
    title: Applying spartan to Understand Parameter Uncertainty in Simulations
    bibtitle: |-
      Applying spartan to Understand Parameter Uncertainty in
                Simulations
    author:
    - Kieran Alden
    - Mark Read
    - Paul S Andrews
    - Jon Timmis
    - Mark Coles
    bibauthor: |-
      Kieran Alden and Mark Read and Paul S Andrews and Jon Timmis
                and Mark Coles
    landing: '2014'
    abstract: '  Abstract In attempts to further understand the dynamics of complex
      systems, the application of            computer simulation is becoming increasingly
      prevalent. Whereas a great deal of focus has been            placed in the development
      of software tools that aid researchers develop simulations, similar focus has            not
      been applied in the creation of tools that perform a rigorous statistical analysis
      of results generated            through simulation: vital in understanding how
      these results offer an insight into the captured            system. This encouraged
      us to develop spartan, a package of statistical techniques designed to assist            researchers
      in understanding the relationship between their simulation and the real system.
      Previously            we have described each technique within spartan in detail,
      with an accompanying immunology case            study examining the development
      of lymphoid tissue. Here we provide a practical introduction to            the
      package, demonstrating how each technique is run in R, to assist researchers
      in integrating this            package alongside their chosen simulation platform.'
    pages:
    - 63
    - 80
    acknowledged: '2014-04-08'
    online: '2014-09-30'
    CRANpkgs:
    - spartan
    - lhs
    - gplots
    - XML
    CTV_rev:
    - Distributions
    - ExperimentalDesign
    - Graphics
    - WebTechnologies
  - slug: RJ-2014-026
    old_slug: hughes
    title: 'ngspatial: A Package for Fitting the Centered Autologistic and Sparse
      Spatial Generalized Linear Mixed Models for Areal Data'
    bibtitle: |-
      ngspatial: A Package for Fitting the Centered Autologistic
                and Sparse Spatial Generalized Linear Mixed Models for Areal
                Data
    author: John Hughes
    bibauthor: John Hughes
    landing: '2014'
    abstract: '  Abstract Two important recent advances in areal modeling are the
      centered autologistic model and            the sparse spatial generalized linear
      mixed model (SGLMM), both of which are reparameterizations            of traditional
      models. The reparameterizations improve regression inference by alleviating
      spatial            confounding, and the sparse SGLMM also greatly speeds computing
      by reducing the dimension of the            spatial random effects. Package
      ngspatial (’ng’ = non-Gaussian) provides routines for fitting these            new
      models. The package supports composite likelihood and Bayesian inference for
      the centered            autologistic model, and Bayesian inference for the sparse
      SGLMM.'
    pages:
    - 81
    - 95
    acknowledged: '2014-04-18'
    online: '2015-01-04'
    CRANpkgs:
    - ngspatial
    - CARBayes
    - spdep
    - Rcpp
    - RcppArmadillo
    - batchmeans
    CTV_rev:
    - Spatial
    - NumericalMathematics
    - Econometrics
    - HighPerformanceComputing
  - slug: RJ-2014-027
    old_slug: conde-alvarez
    title: 'sgof: An R Package for Multiple Testing Problems'
    bibtitle: 'sgof: An R Package for Multiple Testing Problems'
    author:
    - Irene Castro-Conde
    - Jacobo de Uña-Álvarez
    bibauthor: Irene Castro-Conde and Jacobo de Uña-Álvarez
    landing: '2014'
    abstract: '  Abstract In this paper we present a new R package called sgof for
      multiple hypothesis testing. The            principal aim of this package is
      to implement SGoF-type multiple testing methods, known to be            more
      powerful than the classical false discovery rate (FDR) and family-wise error
      rate (FWER) based            methods in certain situations, particularly when
      the number of tests is large. This package includes Bi           nomial and
      Conservative SGoF and the Bayesian and Beta-Binomial SGoF multiple testing procedures,            which
      are adaptations of the original SGoF method to the Bayesian setting and to possibly
      correlated            tests, respectively. The sgof package also implements
      the Benjamini-Hochberg and Benjamini-Yekutieli            FDR controlling procedures.
      For each method the package provides (among other things) the number            of
      rejected null hypotheses, estimation of the corresponding FDR, and the set of
      adjusted p values.            Some automatic plots of interest are implemented
      too. Two real data examples are used to illustrate            how sgof works.'
    pages:
    - 96
    - 113
    acknowledged: '2014-04-18'
    online: '2014-11-24'
    CRANpkgs:
    - sgof
    - mutoss
    - multcomp
    BIOpkgs:
    - qvalue
    - HybridMTest
    - multtest
    CTV_rev:
    - ClinicalTrials
    - SocialSciences
    - Survival
  - slug: RJ-2014-028
    old_slug: rebora-salim-reilly
    title: 'bshazard: A Flexible Tool for Nonparametric Smoothing of the Hazard Function'
    bibtitle: |-
      bshazard: A Flexible Tool for Nonparametric Smoothing of the
                Hazard Function
    author:
    - Paola Rebora
    - Agus Salim
    - Marie Reilly
    bibauthor: Paola Rebora and Agus Salim and Marie Reilly
    landing: '2014'
    abstract: '  Abstract The hazard function is a key component in the inferential
      process in survival analysis and            relevant for describing the pattern
      of failures. However, it is rarely shown in research papers due            to
      the difficulties in nonparametric estimation. We developed the bshazard package
      to facilitate the            computation of a nonparametric estimate of the
      hazard function, with data-driven smoothing. The            method accounts
      for left truncation, right censoring and possible covariates. B-splines are
      used to            estimate the shape of the hazard within the generalized linear
      mixed models framework. Smoothness is            controlled by imposing an autoregressive
      structure on the baseline hazard coefficients. This perspective            allows
      an ’automatic’ smoothing by avoiding the need to choose the smoothing parameter,
      which is            estimated from the data as a dispersion parameter. A simulation
      study demonstrates the capability            of our software and an application
      to estimate the hazard of Non-Hodgkin’s lymphoma in Swedish            population
      data shows its potential.'
    pages:
    - 114
    - 122
    acknowledged: '2014-05-25'
    online: '2015-01-09'
    CRANpkgs:
    - muhaz
    - flexsurv
    - bshazard
    - Epi
    - survival
    - splines
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Distributions
    - Econometrics
    - SocialSciences
  - slug: RJ-2014-029
    old_slug: ferreira-batista
    title: 'SMR: An R package for computing the externally studentized normal midrange
      distribution'
    bibtitle: |-
      SMR: An R package for computing the externally studentized
                normal midrange distribution
    author:
    - Ben Dêivide Oliveira Batista
    - Daniel Furtado Ferreira
    bibauthor: Ben Dêivide Oliveira Batista and Daniel Furtado Ferreira
    landing: '2014'
    abstract: '  Abstract The main purpose of this paper is to present the main algorithms
      underlining the con           struction and implementation of the SMR package,
      whose aim to compute studentized normal            midrange distribution. Details
      on the externally studentized normal midrange and standardized            normal
      midrange distributions are also given. The package follows the same structure
      as the prob           ability functions implemented in R. That is: the probability
      density function (dSMR), the cumulative            distribution function (pSMR),
      the quantile function (qSMR) and the random number generating function            (rSMR).
      The pseudocodes and illustrative examples of how to use the package are presented.'
    pages:
    - 123
    - 136
    acknowledged: '2014-05-25'
    online: '2015-01-04'
    CRANpkgs: SMR
    CTV_rev: Distributions
  - slug: RJ-2014-030
    old_slug: hoff-gran-farewell
    title: 'Farewell''s Linear Increments Model for Missing Data: The FLIM package'
    bibtitle: |-
      Farewell's Linear Increments Model for Missing Data: The
                FLIM package
    author:
    - Rune Hoff
    - Jon Michael Gran
    - Daniel Farewell
    bibauthor: Rune Hoff and Jon Michael Gran and Daniel Farewell
    landing: '2014'
    abstract: '  Abstract Missing data is common in longitudinal studies. We present
      a package for Farewell’s Linear            Increments Model for Missing Data
      (the FLIM package), which can be used to fit linear models for            observed
      increments of longitudinal processes and impute missing data. The method is
      valid for            data with regular observation patterns. The end result
      is a list of fitted models and a hypothetical            complete dataset corresponding
      to the data we might have observed had individuals not been missing.            The
      FLIM package may also be applied to longitudinal studies for causal analysis,
      by considering            counterfactual data as missing data for instance to
      compare the effect of different treatments when            only data from observational
      studies are available. The aim of this article is to give an introduction to            the
      FLIM package and to demonstrate how the package can be applied.'
    pages:
    - 137
    - 150
    acknowledged: '2014-05-25'
    online: '2015-01-09'
    CRANpkgs: zoo
    CTV_rev:
    - Econometrics
    - Environmetrics
    - Finance
    - TimeSeries
  - slug: RJ-2014-031
    old_slug: korkmaz-goksuluk-zararsiz
    title: 'MVN: An R Package for Assessing Multivariate Normality'
    bibtitle: 'MVN: An R Package for Assessing Multivariate Normality'
    author:
    - Selcuk Korkmaz
    - Dincer Goksuluk
    - Gokmen Zararsiz
    bibauthor: Selcuk Korkmaz and Dincer Goksuluk and Gokmen Zararsiz
    landing: '2014'
    abstract: '  Abstract Assessing the assumption of multivariate normality is required
      by many parametric mul           tivariate statistical methods, such as MANOVA,
      linear discriminant analysis, principal component            analysis, canonical
      correlation, etc. It is important to assess multivariate normality in order
      to proceed            with such statistical methods. There are many analytical
      methods proposed for checking multivariate            normality. However, deciding
      which method to use is a challenging process, since each method may            give
      different results under certain conditions. Hence, we may say that there is
      no best method, which            is valid under any condition, for normality
      checking. In addition to numerical results, it is very useful            to
      use graphical methods to decide on multivariate normality. Combining the numerical
      results from            several methods with graphical approaches can be useful
      and provide more reliable decisions. Here,            we present an R package,
      MVN, to assess multivariate normality. It contains the three most widely            used
      multivariate normality tests, including Mardia’s, Henze-Zirkler’s and Royston’s,
      and graphical            approaches, including chi-square Q-Q, perspective and
      contour plots. It also includes two multivariate            outlier detection
      methods, which are based on robust Mahalanobis distances. Moreover, this package            offers
      functions to check the univariate normality of marginal distributions through
      both tests and            plots. Furthermore, especially for non-R users, we
      provide a user-friendly web application of the            package. This application
      is available at http://www.biosoft.hacettepe.edu.tr/MVN/.'
    pages:
    - 151
    - 162
    acknowledged: '2014-06-10'
    online: '2015-01-04'
    CRANpkgs:
    - MASS
    - FactoMineR
    - psych
    - CCA
    - MVN
    - shiny
    CTV_rev:
    - Psychometrics
    - Multivariate
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Pharmacokinetics
    - Robust
    - SocialSciences
    - WebTechnologies
  - slug: RJ-2014-032
    old_slug: zabala
    title: 'qmethod: A Package to Explore Human Perspectives Using Q Methodology'
    bibtitle: |-
      qmethod: A Package to Explore Human Perspectives Using Q
                Methodology
    author: Aiora Zabala
    bibauthor: Aiora Zabala
    landing: '2014'
    abstract: '  Abstract Q is a methodology to explore the distinct subjective perspectives
      that exist within a group. It            is used increasingly across disciplines.
      The methodology is semi-qualitative and the data are analysed            using
      data reduction methods to discern the existing patterns of thought. This package
      is the first to            perform Q analysis in R, and it provides many advantages
      to the existing software: namely, it is fully            cross-platform, the
      algorithms can be transparently examined, it provides results in a clearly structured            and
      tabulated form ready for further exploration and modelling, it produces a graphical
      summary            of the results, and it generates a more concise report of
      the distinguishing and consensus statements.            This paper introduces
      the methodology and explains how to use the package, its advantages as well            as
      its limitations. I illustrate the main functions with a dataset on value patterns
      about democracy.'
    pages:
    - 163
    - 173
    acknowledged: '2014-07-28'
    online: '2015-01-04'
    CRANpkgs:
    - qmethod
    - psych
    - GPArotation
    - FactoMineR
    CTV_rev:
    - Psychometrics
    - Multivariate
  - slug: RJ-2014-033
    old_slug: liu
    title: 'gset: An R Package for Exact Sequential Test of Equivalence Hypothesis
      Based on Bivariate Non-Central t-Statistics'
    bibtitle: |-
      gset: An R Package for Exact Sequential Test of Equivalence
                Hypothesis Based on Bivariate Non-Central t-Statistics
    author: Fang Liu
    bibauthor: Fang Liu
    landing: '2014'
    abstract: '  Abstract The R package gset calculates equivalence and futility boundaries
      based on the exact            bivariate non-central t test statistics. It is
      the first R package that targets specifically at the group            sequential
      test of equivalence hypotheses. The exact test approach adopted by gset neither
      assumes            the large-sample normality of the test statistics nor ignores
      the contribution to the overall Type I error            rate from rejecting
      one out of the two one-sided hypotheses under a null value. The features of
      gset            include: error spending functions, computation of equivalence
      boundaries and futility boundaries,            either binding or nonbinding,
      depiction of stagewise boundary plots, and operating characteristics            of
      a given group sequential design including empirical Type I error rate, empirical
      power, expected            sample size, and probability of stopping at an interim
      look due to equivalence or futility.'
    pages:
    - 174
    - 184
    acknowledged: '2014-08-16'
    online: '2015-01-04'
    CRANpkgs:
    - gsDesign
    - GroupSeq
    - Hmisc
    - PwrGSD
    - AGSDest
    - clinfun
    CTV_rev:
    - ClinicalTrials
    - ExperimentalDesign
    - Bayesian
    - Econometrics
    - Multivariate
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
    - Survival
  - heading: News and Notes
  - title: 'Conference Report: R in Insurance 2014'
    bibtitle: 'Conference Report: {R} in Insurance 2014'
    slug: gesmann-tsanakas
    author:
    - Markus Gesmann
    - Andreas Tsanakas
    pages:
    - 185
    - 186
  - title: Conference Report Polish Academic R User Meeting
    bibtitle: 'Conference Report: {P}olish Academic {R} User Meeting'
    slug: beresewicz-szabelska-zyprychwalczak-etal
    author:
    - Maciej Beręsewicz
    - Alicja Szabelska
    - Joanna Zyprych-Walczak
    - Łukasz Wawrowski
    bibauthor:
    - Maciej Ber{\k e}sewicz
    - Alicja Szabelska
    - Joanna Zyprych-Walczak
    - \L{}ukasz Wawrowski
    pages:
    - 187
    - 189
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author:
    - Martin Mächler
    - Kurt Hornik
    slug: r-foundation
    bibauthor:
    - Martin M{\" a}chler
    - Kurt Hornik
    pages:
    - 190
    - 191
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 192
    - 223
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    bibauthor: '{The R Core Team}'
    pages:
    - 224
    - 226
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    bibauthor: '{The Bioconductor Team}'
    slug: bioconductor
    pages:
    - 227
    - 228
- issue: 2015-1
  year: 2015
  volume: 7
  num: 1
  month: June
  bibmonth: jun
  articles:
  - title: Editorial
    author: Bettina Grün
    bibauthor: Bettina Gr{\" u}n
    slug: editorial
    pages: 3
  - heading: Contributed Research Articles
  - slug: RJ-2015-001
    old_slug: osorio-rondonvillarreal-torres
    title: 'Peptides: A Package for Data Mining of Antimicrobial Peptides'
    bibtitle: |-
      Peptides: A Package for Data Mining of Antimicrobial
                Peptides
    author:
    - Daniel Osorio
    - Paola Rondón-Villarreal
    - Rodrigo Torres
    bibauthor: Daniel Osorio and Paola Rondón-Villarreal and Rodrigo Torres
    landing: '2015'
    abstract: '  Abstract Antimicrobial peptides (AMP) are a promising source of antibiotics
      with a broad spectrum            activity against bacteria and low incidence
      of developing resistance. The mechanism by which an            AMP executes
      its function depends on a set of computable physicochemical properties from
      the amino            acid sequence. The Peptides package was designed to allow
      the quick and easy computation of ten            structural characteristics
      own of the antimicrobial peptides, with the aim of generating data to increase            the
      accuracy in classification and design of new amino acid sequences. Moreover,
      the options to read            and plot XVG output files from GROMACS molecular
      dynamics package are included.'
    pages:
    - 4
    - 14
    acknowledged: '2014-04-18'
    online: '2015-02-04'
    CRANpkgs:
    - Peptides
    - caret
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
    - Multivariate
  - slug: RJ-2015-002
    old_slug: abel
    title: 'fanplot: An R Package for Visualising Sequential Distributions'
    bibtitle: |-
      fanplot: An R Package for Visualising Sequential
                Distributions
    author: Guy J. Abel
    bibauthor: Guy J. Abel
    landing: '2015'
    abstract: '  Abstract Fan charts, first developed by the Bank of England in 1996,
      have become a standard method            for visualising forecasts with uncertainty.
      Using shading fan charts focus the attention towards the            whole distribution
      away from a single central measure. This article describes the basics of plotting            fan
      charts using an R add-on package alongside some additional methods for displaying
      sequential            distributions. Examples are based on distributions of
      both estimated parameters from a time series            model and future values
      with uncertainty.'
    pages:
    - 15
    - 23
    acknowledged: '2014-05-25'
    online: '2015-04-07'
    CRANpkgs:
    - vars
    - forecast
    - fanplot
    - R2OpenBUGS
    - zoo
    - tsbugs
    - RColorBrewer
    - shiny
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - Environmetrics
    - gR
    - Graphics
    - Spatial
    - WebTechnologies
  - slug: RJ-2015-003
    old_slug: templ-kowarik-meindl
    title: 'sparkTable: Generating Graphical Tables for Websites and Documents with
      R'
    bibtitle: |-
      sparkTable: Generating Graphical Tables for Websites and
                Documents with R
    author:
    - Alexander Kowarik
    - Bernhard Meindl
    - Matthias Templ
    bibauthor: Alexander Kowarik and Bernhard Meindl and Matthias Templ
    landing: '2015'
    abstract: '  Abstract                  Visual analysis of data is important to
      understand the main characteristics, main trends and            relationships
      in data sets and it can be used to assess the data quality. Using the R package
      sparkTable,            statistical tables holding quantitative information can
      be enhanced by including spark-type graphs            such as sparklines                and
      sparkbars              .                  These kind of graphics are well-known
      in literature and are considered as simple, intense and            illustrative
      graphs that are small enough to fit in a single line. Thus, they can easily
      enrich tables and            texts with additional information in a comprehensive
      visual way.                  The R package sparkTable uses a clean S4 class
      design and provides methods to create different            types of sparkgraphs
      that can be used in websites, presentations and documents. We also implemented            an
      easy way for non-experts to create highly complex tables. In this case, graphical
      parameters can be            interactively changed, variables can be sorted,
      graphs can be added and removed in an interactive            manner. Thereby
      it is possible to produce custom-tailored graphical tables – standard tables
      that are            enriched with graphs – that can be displayed in a browser
      and exported to various formats.'
    pages:
    - 24
    - 37
    acknowledged: '2014-06-23'
    online: '2015-05-29'
    CRANpkgs:
    - sparkTable
    - knitr
    - brew
    - xtable
    - shiny
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
  - slug: RJ-2015-004
    old_slug: cattaneo-calonico-titiunik
    title: 'rdrobust: An R Package for Robust Nonparametric Inference in Regression-Discontinuity
      Designs'
    bibtitle: |-
      rdrobust: An R Package for Robust Nonparametric Inference in
                Regression-Discontinuity Designs
    author:
    - Sebastian Calonico
    - Matias D. Cattaneo
    - Rocío Titiunik
    bibauthor: Sebastian Calonico and Matias D. Cattaneo and Rocío Titiunik
    landing: '2015'
    abstract: '  Abstract This article describes the R package rdrobust, which provides
      data-driven graphical and in           ference procedures for RD designs. The
      package includes three main functions: rdrobust, rdbwselect            and rdplot.
      The first function (rdrobust) implements conventional local-polynomial RD treatment            effect
      point estimators and confidence intervals, as well as robust bias-corrected
      confidence intervals,            for average treatment effects at the cutoff.
      This function covers sharp RD, sharp kink RD, fuzzy RD            and fuzzy
      kink RD designs, among other possibilities. The second function (rdbwselect)
      implements            several bandwidth selectors proposed in the RD literature.
      The third function (rdplot) provides            data-driven optimal choices
      of evenly-spaced and quantile-spaced partition sizes, which are used to            implement
      several data-driven RD plots.'
    pages:
    - 38
    - 51
    acknowledged:
    - '2014-07-28'
    - '2014-11-26'
    online: '2015-04-23'
    CRANpkgs: rdrobust
    CTV_rev: Econometrics
  - slug: RJ-2015-005
    old_slug: arcos-molina-ranalli-etal
    title: 'Frames2: A Package for Estimation in Dual Frame Surveys'
    bibtitle: 'Frames2: A Package for Estimation in Dual Frame Surveys'
    author:
    - Antonio Arcos
    - David Molina
    - Maria Giovanna Ranalli
    - María del Mar Rueda
    bibauthor: |-
      Antonio Arcos and David Molina and Maria Giovanna Ranalli
                and María del Mar Rueda
    landing: '2015'
    abstract: '  Abstract Data from complex survey designs require special consideration
      with regard to estimation            of finite population parameters and corresponding
      variance estimation procedures, as a consequence            of significant departures
      from the simple random sampling assumption. In the past decade a number            of
      statistical software packages have been developed to facilitate the analysis
      of complex survey            data. All these statistical software packages are
      able to treat samples selected from one sampling            frame containing
      all population units. Dual frame surveys are very useful when it is not possible
      to            guarantee a complete coverage of the target population and may
      result in considerable cost savings            over a single frame design with
      comparable precision. There are several estimators available in the            statistical
      literature but no existing software covers dual frame estimation procedures.
      This gap is now            filled by package Frames2. In this paper we highlight
      the main features of the package. The package            includes the main estimators
      in dual frame surveys and also provides interval confidence estimation.'
    pages:
    - 52
    - 72
    acknowledged: '2014-09-05'
    online: '2015-04-23'
    CRANpkgs:
    - survey
    - sampling
    - laeken
    - TeachingSampling
    - Frames2
    CTV_rev:
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
    - Survival
  - slug: RJ-2015-006
    old_slug: hankin
    title: The Complex Multivariate Gaussian Distribution
    bibtitle: The Complex Multivariate Gaussian Distribution
    author: Robin K. S. Hankin
    bibauthor: Robin K. S. Hankin
    landing: '2015'
    abstract: '  Abstract Here I introduce package cmvnorm, a complex generalization
      of the mvtnorm package. A            complex generalization of the Gaussian
      process is suggested and numerical results presented using the            package.
      An application in the context of approximating the Weierstrass σ-function using
      a complex            Gaussian process is given.'
    pages:
    - 73
    - 80
    acknowledged: '2014-09-18'
    online: '2015-04-23'
    CRANpkgs:
    - cmvnorm
    - mvtnorm
    - emulator
    CTV_rev:
    - Distributions
    - Finance
    - Multivariate
  - slug: RJ-2015-007
    old_slug: molina-marhuenda
    title: 'sae: An R Package for Small Area Estimation'
    bibtitle: 'sae: An R Package for Small Area Estimation'
    author:
    - Isabel Molina
    - Yolanda Marhuenda
    bibauthor: Isabel Molina and Yolanda Marhuenda
    landing: '2015'
    abstract: '  Abstract We describe the R package sae for small area estimation.
      This package can be used to            obtain model-based estimates for small
      areas based on a variety of models at the area and unit levels,            along
      with basic direct and indirect estimates. Mean squared errors are estimated
      by analytical            approximations in simple models and applying bootstrap
      procedures in more complex models. We            describe the package functions
      and show how to use them through examples.'
    pages:
    - 81
    - 98
    acknowledged: '2014-09-20'
    online: '2015-06-02'
    CRANpkgs:
    - sae
    - nlme
    - MASS
    - survey
    - sampling
    - rsae
    - JoSae
    - hbsae
    - mme
    - saery
    - sae2
    CTV_rev:
    - OfficialStatistics
    - SocialSciences
    - Econometrics
    - Environmetrics
    - Pharmacokinetics
    - Psychometrics
    - Bayesian
    - ChemPhys
    - Distributions
    - Finance
    - Multivariate
    - NumericalMathematics
    - Robust
    - Spatial
    - SpatioTemporal
    - Survival
    - TimeSeries
  - slug: RJ-2015-008
    old_slug: qiu
    title: 'showtext: Using System Fonts in R Graphics'
    bibtitle: 'showtext: Using System Fonts in R Graphics'
    author: Yixuan Qiu
    bibauthor: Yixuan Qiu
    landing: '2015'
    abstract: '  Abstract This article introduces the showtext package that makes
      it easy to use system fonts in R            graphics. Unlike other methods to
      embed fonts into graphics, showtext converts text into raster images            or
      polygons, and then adds them to the plot canvas. This method produces platform-independent            image
      files that do not rely on the fonts that create them. It supports a large number
      of font formats            and R graphics devices, and meanwhile provides convenient
      features such as using web fonts and            integrating with knitr. This
      article provides an elaborate introduction to the showtext package,            including
      its design, usage, and examples.'
    pages:
    - 99
    - 108
    acknowledged: '2014-10-26'
    online: '2015-05-29'
    CRANpkgs:
    - extrafont
    - showtext
    - knitr
    - Cairo
    - Rttf2pt1
    - sysfonts
    - RCurl
    - jsonlite
    - ggplot2
    - xkcd
    - RSvgDevice
    CTV_rev:
    - Graphics
    - WebTechnologies
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2015-010
    old_slug: kostov-becuebertaut-husson
    title: Correspondence Analysis on Generalised Aggregated Lexical Tables (CA-GALT)
      in the FactoMineR Package
    bibtitle: |-
      Correspondence Analysis on Generalised Aggregated Lexical
                Tables (CA-GALT) in the FactoMineR Package
    author:
    - Belchin Kostov
    - Mónica Bécue-Bertaut
    - François Husson
    bibauthor: Belchin Kostov and Mónica Bécue-Bertaut and François Husson
    landing: '2015'
    abstract: '  Abstract Correspondence analysis on generalised aggregated lexical
      tables (CA-GALT) is a method            that generalizes classical CA-ALT to
      the case of several quantitative, categorical and mixed variables.            It
      aims to establish a typology of the external variables and a typology of the
      events from their mutual            relationships. In order to do so, the influence
      of external variables on the lexical choices is untangled            cancelling
      the associations among them, and to avoid the instability issued from multicollinearity,
      they            are substituted by their principal components. The CaGalt function,
      implemented in the FactoMineR            package, provides numerous numerical
      and graphical outputs. Confidence ellipses are also provided            to validate
      and improve the representation of words and variables. Although this methodology
      was            developed mainly to give an answer to the problem of analyzing
      open-ended questions, it can be            applied to any kind of frequency/contingency
      table with external variables.'
    pages:
    - 109
    - 117
    acknowledged: '2014-11-04'
    online: '2015-06-02'
    CRANpkgs: FactoMineR
    CTV_rev:
    - Multivariate
    - Psychometrics
  - slug: RJ-2015-009
    old_slug: oneil
    title: Implementing Persistent O(1) Stacks and Queues in R
    bibtitle: Implementing Persistent O(1) Stacks and Queues in R
    author: Shawn T. O’Neil
    bibauthor: Shawn T. O’Neil
    landing: '2015'
    abstract: '  Abstract True to their functional roots, most R functions are side-effect-free,
      and users expect datatypes            to be persistent. However, these semantics
      complicate the creation of efficient and dynamic data            structures.
      Here, we describe the implementation of stack and queue data structures satisfying
      these            conditions in R, available in the CRAN package rstackdeque.
      Guided by important work in purely            functional languages, we look
      at both partiallyand fully-persistent versions of queues, comparing            their
      performance characteristics. Finally, we illustrate the usefulness of such dynamic
      structures with            examples of generating and solving mazes.'
    pages:
    - 118
    - 126
    acknowledged: '2014-12-16'
    online: '2015-06-24'
    CRANpkgs:
    - rstackdeque
    - dplyr
    - microbenchmark
    - ggplot2
    - hash
    - Rcpp
    CTV_rev:
    - Graphics
    - HighPerformanceComputing
    - NumericalMathematics
    - Phylogenetics
  - slug: RJ-2015-011
    old_slug: rodiger-burdukiewicz-blagodatskikh-etal
    title: R as an Environment for Reproducible Analysis of DNA Amplification Experiments
    bibtitle: |-
      R as an Environment for Reproducible Analysis of DNA
                Amplification Experiments
    author:
    - Stefan Rödiger
    - Michał Burdukiewicz
    - Konstantin Blagodatskikh
    - Michael Jahn
    - Peter Schierack
    bibauthor: |-
      Stefan Rödiger and Michał Burdukiewicz and Konstantin
                Blagodatskikh and Michael Jahn and Peter Schierack
    landing: '2015'
    abstract: '  Abstract There is an ever-increasing number of applications, which
      use quantitative PCR (qPCR) or            digital PCR (dPCR) to elicit fundamentals
      of biological processes. Moreover, quantitative isother           mal amplification
      (qIA) methods have become more prominent in life sciences and point-of-care           diagnostics.
      Additionally, the analysis of melting data is essential during many experiments.
      Several            software packages have been developed for the analysis of
      such datasets. In most cases, the software            is either distributed
      as closed source software or as monolithic block with little freedom to perform            highly
      customized analysis procedures. We argue, among others, that R is an excellent
      foundation            for reproducible and transparent data analysis in a highly
      customizable cross-platform environment.            However, for novices it
      is often challenging to master R or learn capabilities of the vast number            of
      packages available. In the paper, we describe exemplary workflows for the analysis
      of qPCR,            qIA or dPCR experiments including the analysis of melting
      curve data. Our analysis relies entirely            on R packages available
      from public repositories. Additionally, we provide information related to            standardized
      and reproducible research.'
    pages:
    - 127
    - 150
    acknowledged: '2014-11-30'
    online: '2015-06-25'
    CRANpkgs:
    - dpcR
    - kulife
    - MCMC.qpcr
    - qPCR.CT
    - DivMelt
    - qpcR
    - chipPCR
    - MBmca
    - RDML
    - RNetCDF
    - archivist
    - settings
    - shiny
    - rateratio.test
    BIOpkgs:
    - nondetects
    - qpcrNorm
    - HTqPCR
    - SLqPCR
    - ddCt
    - EasyqpcR
    - unifiedWMWqPCR
    - ReadqPCR
    - NormqPCR
    CTV_rev:
    - ReproducibleResearch
    - Spatial
    - SpatioTemporal
    - WebTechnologies
  - slug: RJ-2015-012
    old_slug: murrell
    title: The gridGraphics Package
    bibtitle: The gridGraphics Package
    author: Paul Murrell
    bibauthor: Paul Murrell
    landing: '2015'
    abstract: '  Abstract The gridGraphics package provides a function, grid.echo(),
      that can be used to convert a            plot drawn with the graphics package
      to a visually identical plot drawn using grid. This conversion            provides
      access to a variety of grid tools for making customisations and additions to
      the plot that are            not possible with the graphics package.'
    pages:
    - 151
    - 162
    acknowledged: '2014-11-30'
    online: '2015-04-23'
    CRANpkgs:
    - gridGraphics
    - lattice
    - ggplot2
    - plotrix
    - maps
    - gridBase
    - gridSVG
    CTV_rev:
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - Phylogenetics
    - Spatial
  - slug: RJ-2015-013
    old_slug: muschelli-sweeney-lindquist-etal
    title: 'fslr: Connecting the FSL Software with R'
    bibtitle: 'fslr: Connecting the FSL Software with R'
    author:
    - John Muschelli
    - Elizabeth Sweeney
    - Martin Lindquist
    - Ciprian Crainiceanu
    bibauthor: |-
      John Muschelli and Elizabeth Sweeney and Martin Lindquist
                and Ciprian Crainiceanu
    landing: '2015'
    abstract: '  Abstract We present the package fslr, a set of R functions that interface
      with FSL (FMRIB Software            Library), a commonly-used open-source software
      package for processing and analyzing neuroimaging            data. The fslr
      package performs operations on ‘nifti’ image objects in R using command-line            functions
      from FSL, and returns R objects back to the user. fslr allows users to develop
      image            processing and analysis pipelines based on FSL functionality
      while interfacing with the functionality            provided by R. We present
      an example of the analysis of structural magnetic resonance images,            which
      demonstrates how R users can leverage the functionality of FSL without switching
      to shell            commands.                                                          Glossary
      of acronyms                   MRI     Magnetic Resonance Imaging/Image          FSL     FMRIB
      Software Library                    PD     Proton Density                           FAST     FMRIB’s
      Automated Segmentation Tool                  FLAIR    Fluid-Attenuated Inversion
      Recovery      FLIRT    FMRIB’s Linear Image Registration Tool                   MS      Multiple
      Sclerosis                        BET     Brain Extraction Tool                  FMRIB    Functional
      MRI of the Brain Group       FNIRT     FMRIB’s Nonlinear Image Registration
      Tool                   MNI     Montreal Neurological Institute'
    pages:
    - 163
    - 175
    acknowledged: '2014-11-30'
    online: '2015-06-02'
    CRANpkgs:
    - AnalyzeFMRI
    - RNiftyReg
    - fmri
    - fslr
    - oro.nifti
    - ggplot2
    - ggplot2
    - mgcv
    BIOpkgs: EBImage
    CTV_rev:
    - MedicalImaging
    - ChemPhys
    - Graphics
    - Phylogenetics
    - Bayesian
    - Econometrics
    - Environmetrics
    - SocialSciences
  - slug: RJ-2015-014
    old_slug: baumgartner-thiem
    title: Identifying Complex Causal Dependencies in Configurational Data with Coincidence
      Analysis
    bibtitle: |-
      Identifying Complex Causal Dependencies in Configurational
                Data with Coincidence Analysis
    author:
    - Michael Baumgartner
    - Alrik Thiem
    bibauthor: Michael Baumgartner and Alrik Thiem
    landing: '2015'
    abstract: '  Abstract We present cna, a package for performing Coincidence Analysis
      (CNA). CNA is a config           urational comparative method for the identification
      of complex causal dependencies—in particular,            causal chains and common
      cause structures—in configurational data. After a brief introduction to the            method’s
      theoretical background and main algorithmic ideas, we demonstrate the use of
      the package            by means of an artificial and a real-life data set. Moreover,
      we outline planned enhancements of the            package that will further
      increase its applicability.'
    pages:
    - 176
    - 184
    acknowledged: '2014-12-17'
    online: '2015-03-30'
    CRANpkgs:
    - QCA
    - SetMethods
    - cna
  - slug: RJ-2015-015
    old_slug: hare-buja-hofmann
    title: Manipulation of Discrete Random Variables with discreteRV
    bibtitle: Manipulation of Discrete Random Variables with discreteRV
    author:
    - Eric Hare
    - Andreas Buja
    - Heike Hofmann
    bibauthor: Eric Hare and Andreas Buja and Heike Hofmann
    landing: '2015'
    abstract: '  Abstract A prominent issue in statistics education is the sometimes
      large disparity between the            theoretical and the computational coursework.
      discreteRV is an R package for manipulation of            discrete random variables
      which uses clean and familiar syntax similar to the mathematical notation in            introductory
      probability courses. The package offers functions that are simple enough for
      users with            little experience with statistical programming, but has
      more advanced features which are suitable for            a large number of more
      complex applications. In this paper, we introduce and motivate discreteRV,            describe
      its functionality, and provide reproducible examples illustrating its use.'
    pages:
    - 185
    - 194
    acknowledged: '2015-02-07'
    online: '2015-05-06'
    CRANpkgs:
    - discreteRV
    - devtools
  - slug: RJ-2015-016
    old_slug: lenth
    title: Estimability Tools for Package Developers
    bibtitle: Estimability Tools for Package Developers
    author: Russell V. Lenth
    bibauthor: Russell V. Lenth
    landing: '2015'
    abstract: '  Abstract When a linear model is rank-deficient, then predictions
      based on that model become            questionable because not all predictions
      are uniquely estimable. However, some of them are, and the            estimability
      package provides tools that package developers can use to tell which is which.
      With the            use of these tools, a model object’s predict method could
      return estimable predictions as-is while            flagging non-estimable ones
      in some way, so that the user can know which predictions to believe. The            estimability
      package also provides, as a demonstration, an estimability-enhanced epredict
      method            to use in place of predict for models fitted using the stats
      package.'
    pages:
    - 195
    - 199
    acknowledged: '2015-02-11'
    online: '2015-05-11'
    CRANpkgs: estimability
  - heading: News and Notes
  - title: R Foundation News
    bibtitle: '{R} {F}oundation News'
    author: Kurt Hornik
    bibauthor: Kurt Hornik
    slug: r-foundation
    pages: 200
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 201
    - 226
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    bibauthor: '{The R Core Team}'
    slug: r-changes
    pages:
    - 227
    - 238
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    bibauthor: '{The Bioconductor Team}'
    slug: bioconductor
    pages:
    - 239
    - 240
- issue: 2015-2
  year: 2015
  volume: 7
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Bettina Grün
    bibauthor: Bettina Gr{\" u}n
    slug: editorial
    pages: 4
  - heading: Contributed Research Articles
  - slug: RJ-2015-017
    old_slug: alam-ronnegard-shen
    title: Fitting Conditional and Simultaneous Autoregressive Spatial Models in hglm
    bibtitle: |-
      Fitting Conditional and Simultaneous Autoregressive Spatial
                Models in hglm
    author:
    - Moudud Alam
    - Lars Rönnegård
    - Xia Shen
    bibauthor: Moudud Alam and Lars Rönnegård and Xia Shen
    landing: '2015'
    abstract: '  Abstract We present a new version (> 2.0) of the hglm package for
      fitting hierarchical generalized            linear models (HGLMs) with spatially
      correlated random effects. CAR() and SAR() families for con           ditional
      and simultaneous autoregressive random effects were implemented. Eigen decomposition            of
      the matrix describing the spatial structure (e.g., the neighborhood matrix)
      was used to transform            the CAR/SAR random effects into an independent,
      but heteroscedastic, Gaussian random effect. A            linear predictor is
      fitted for the random effect variance to estimate the parameters in the CAR
      and SAR            models. This gives a computationally efficient algorithm
      for moderately sized problems.'
    pages:
    - 5
    - 18
    acknowledged: '2014-01-21'
    online: '2015-09-09'
    CRANpkgs:
    - hglm
    - spaMM
    - HGLMMM
    CTV_rev: Spatial
  - slug: RJ-2015-018
    old_slug: genuer-poggi-tuleaumalot
    title: 'VSURF: An R Package for Variable Selection Using Random Forests'
    bibtitle: |-
      VSURF: An R Package for Variable Selection Using Random
                Forests
    author:
    - Robin Genuer
    - Jean-Michel Poggi
    - Christine Tuleau-Malot
    bibauthor: |-
      Robin Genuer and Jean-Michel Poggi and Christine Tuleau-
                Malot
    landing: '2015'
    abstract: '  Abstract This paper describes the R package VSURF. Based on random
      forests, and for both regression            and classification problems, it
      returns two subsets of variables. The first is a subset of important            variables
      including some redundancy which can be relevant for interpretation, and the
      second one            is a smaller subset corresponding to a model trying to
      avoid redundancy focusing more closely on            the prediction objective.
      The two-stage strategy is based on a preliminary ranking of the explanatory            variables
      using the random forests permutation-based score of importance and proceeds
      using a            stepwise forward strategy for variable introduction. The
      two proposals can be obtained automatically            using data-driven default
      values, good enough to provide interesting results, but strategy can also            be
      tuned by the user. The algorithm is illustrated on a simulated example and its
      applications to real            datasets are presented.'
    pages:
    - 19
    - 33
    acknowledged: '2014-07-28'
    online: '2015-11-08'
    CRANpkgs:
    - VSURF
    - rpart
    - randomForest
    - party
    - ipred
    - Boruta
    - varSelRF
    - spikeSlabGAM
    - BioMark
    - mlbench
    - mixOmics
    CTV_rev:
    - MachineLearning
    - Environmetrics
    - Survival
    - ChemPhys
    - Multivariate
    - Bayesian
    - HighPerformanceComputing
  - slug: RJ-2015-019
    old_slug: liu-kong
    title: 'zoib: An R Package for Bayesian Inference for Beta Regression and Zero/One
      Inflated Beta Regression'
    bibtitle: |-
      zoib: An R Package for Bayesian Inference for Beta
                Regression and Zero/One Inflated Beta Regression
    author:
    - Fang Liu
    - Yunchuan Kong
    bibauthor: Fang Liu and Yunchuan Kong
    landing: '2015'
    abstract: ' Abstract The beta distribution is a versatile function that accommodates
      a broad range of probability           distribution shapes. Beta regression
      based on the beta distribution can be used to model a response           variable
      y that takes values in open unit interval (0, 1). Zero/one inflated beta (ZOIB)
      regression           models can be applied when y takes values from closed unit
      interval [0, 1]. The ZOIB model is based a           piecewise distribution
      that accounts for the probability mass at 0 and 1, in addition to the probability           density
      within (0, 1). This paper introduces an R package – zoib that provides Bayesian
      inferences for           a class of ZOIB models. The statistical methodology
      underlying the zoib package is discussed, the           functions covered by
      the package are outlined, and the usage of the package is illustrated with three           examples
      of different data and model types. The package is comprehensive and versatile
      in that it           can model data with or without inflation at 0 or 1, accommodate
      clustered and correlated data via           latent variables, perform penalized
      regression as needed, and allow for model comparison via the           computation
      of the DIC criterion.'
    pages:
    - 34
    - 51
    acknowledged: '2014-08-16'
    online: '2015-07-18'
    CRANpkgs:
    - betareg
    - Bayesianbetareg
    - zoib
    - coda
    - rjags
    CTV_rev:
    - Bayesian
    - gR
    - Cluster
    - Econometrics
    - Psychometrics
    - SocialSciences
  - slug: RJ-2015-020
    old_slug: nielsen
    title: 'apc: An R Package for Age-Period-Cohort Analysis'
    bibtitle: 'apc: An R Package for Age-Period-Cohort Analysis'
    author: Bent Nielsen
    bibauthor: Bent Nielsen
    landing: '2015'
    abstract: '  Abstract The apc package includes functions for age-period-cohort
      analysis based on the canonical            parametrisation of Kuang et al. (2008a).
      The package includes functions for organizing the data,            descriptive
      plots, a deviance table, estimation of (sub-models of) the age-period-cohort
      model, a plot            for specification testing, plots of estimated parameters,
      and sub-sample analysis.'
    pages:
    - 52
    - 64
    acknowledged: '2014-09-16'
    online: '2015-08-05'
    CRANpkgs:
    - apc
    - Epi
    CTV_rev: Survival
  - slug: RJ-2015-021
    old_slug: charlier-paindaveine-saracco
    title: 'QuantifQuantile: An R Package for Performing Quantile Regression Through
      Optimal Quantization'
    bibtitle: |-
      QuantifQuantile: An R Package for Performing Quantile
                Regression Through Optimal Quantization
    author:
    - Isabelle Charlier
    - Davy Paindaveine
    - Jérôme Saracco
    bibauthor: Isabelle Charlier and Davy Paindaveine and Jérôme Saracco
    landing: '2015'
    abstract: '  Abstract In quantile regression, various quantiles of a response
      variable Y are modelled as func           tions of covariates (rather than its
      mean). An important application is the construction of reference            curves/surfaces
      and conditional prediction intervals for Y. Recently, a nonparametric quantile
      regres           sion method based on the concept of optimal quantization was
      proposed. This method competes very            well with k-nearest neighbor,
      kernel, and spline methods. In this paper, we describe an R package,            called
      QuantifQuantile, that allows to perform quantization-based quantile regression.
      We describe            the various functions of the package and provide examples.'
    pages:
    - 65
    - 80
    acknowledged: '2014-09-28'
    online: '2015-10-30'
    CRANpkgs:
    - quantreg
    - quantregGrowth
    - QuantifQuantile
    - rgl
    - quantregGrowth
    CTV_rev:
    - Environmetrics
    - Econometrics
    - Graphics
    - Multivariate
    - Optimization
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - SpatioTemporal
    - Survival
  - slug: RJ-2015-022
    old_slug: hankin
    title: Numerical Evaluation of the Gauss Hypergeometric Function with the hypergeo
      Package
    bibtitle: |-
      Numerical Evaluation of the Gauss Hypergeometric Function
                with the hypergeo Package
    author: Robin K. S. Hankin
    bibauthor: Robin K. S. Hankin
    landing: '2015'
    abstract: '  Abstract This paper introduces the hypergeo package of R routines
      for numerical calculation of            hypergeometric functions. The package
      is focussed on efficient and accurate evaluation of the Gauss            hypergeometric
      function over the whole of the complex plane within the constraints of fixed-precision            arithmetic.
      The hypergeometric series is convergent only within the unit circle, so analytic
      continuation            must be used to define the function outside the unit
      circle. This short document outlines the numerical            and conceptual
      methods used in the package; and justifies the package philosophy, which is
      to            maintain transparent and verifiable links between the software
      and Abramowitz and Stegun (1965).            Most of the package functionality
      is accessed via the single function hypergeo(), which dispatches to            one
      of several methods depending on the value of its arguments. The package is demonstrated
      in the            context of game theory.'
    pages:
    - 81
    - 88
    acknowledged: '2014-12-16'
    online: '2015-11-18'
    CRANpkgs:
    - gsl
    - appell
    - hypergeo
    CTV_rev:
    - NumericalMathematics
    - Optimization
  - slug: RJ-2015-023
    old_slug: villacorta-saez
    title: 'SRCS: Statistical Ranking Color Scheme for Visualizing Parameterized Multiple
      Pairwise Comparisons with R'
    bibtitle: |-
      SRCS: Statistical Ranking Color Scheme for Visualizing
                Parameterized Multiple Pairwise Comparisons with R
    author:
    - Pablo J. Villacorta
    - José A. Sáez
    bibauthor: Pablo J. Villacorta and José A. Sáez
    landing: '2015'
    abstract: '  Abstract The problem of comparing a new solution method against existing
      ones to find statistically            significant differences arises very often
      in sciences and engineering. When the problem instance being            solved
      is defined by several parameters, assessing a number of methods with respect
      to many problem            configurations simultaneously becomes a hard task.
      Some visualization technique is required for            presenting a large number
      of statistical significance results in an easily interpretable way. Here we            review
      an existing color-based approach called Statistical Ranking Color Scheme (SRCS)
      for displaying            the results of multiple pairwise statistical comparisons
      between several methods assessed separately on            a number of problem
      configurations. We introduce an R package implementing SRCS, which performs            all
      the pairwise statistical tests from user data and generates customizable plots.
      We demonstrate            its applicability on two examples from the areas of
      dynamic optimization and machine learning, in            which several algorithms
      are compared on many problem instances, each defined by a combination of            parameters.'
    pages:
    - 89
    - 104
    acknowledged: '2015-01-02'
    online: '2015-07-29'
    CRANpkgs:
    - factorplot
    - SRCS
    - e1071
    - RWeka
    BIOpkgs: paircompviz
    CTV_rev:
    - MachineLearning
    - Cluster
    - Distributions
    - Environmetrics
    - Multivariate
    - NaturalLanguageProcessing
    - Psychometrics
  - slug: RJ-2015-024
    old_slug: vegabayo
    title: 'An R Package for the Panel Approach Method for Program Evaluation: pampe'
    bibtitle: |-
      An R Package for the Panel Approach Method for Program
                Evaluation: pampe
    author: Ainhoa Vega-Bayo
    bibauthor: Ainhoa Vega-Bayo
    landing: '2015'
    abstract: '  Abstract The pampe package for R implements the panel data approach
      method for program evalua           tion designed to estimate the causal effects
      of political interventions or treatments. This procedure            exploits
      the dependence among cross-sectional units to construct a counterfactual of
      the treated unit(s),            and it is an appropriate method for research
      events that occur at an aggregate level like countries or            regions
      and that affect only one or a small number of units. The implementation of the
      pampe package            is illustrated using data from Hong Kong and 24 other
      units, by examining the economic impact of the            political and economic
      integration of Hong Kong with mainland China in 1997 and 2004 respectively.'
    pages:
    - 105
    - 121
    acknowledged: '2015-02-04'
    online: '2015-11-10'
    CRANpkgs:
    - pampe
    - leaps
    - xtable
    CTV_rev:
    - ChemPhys
    - Econometrics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2015-025
    old_slug: lee-chen
    title: 'BSGS: Bayesian Sparse Group Selection'
    bibtitle: 'BSGS: Bayesian Sparse Group Selection'
    author:
    - Kuo-Jung Lee
    - Ray-Bing Chen
    bibauthor: Kuo-Jung Lee and Ray-Bing Chen
    landing: '2015'
    abstract: '  Abstract An R package BSGS is provided for the integration of Bayesian
      variable and sparse group            selection separately proposed by Chen et
      al. (2011) and Chen et al. (in press) for variable selection            problems,
      even in the cases of large p and small n. This package is designed for variable
      selection            problems including the identification of the important
      groups of variables and the active variables            within the important
      groups. This article introduces the functions in the BSGS package that can be            used
      to perform sparse group selection as well as variable selection through simulation
      studies and            real data.'
    pages:
    - 122
    - 133
    acknowledged: '2015-02-16'
    online: '2015-08-05'
    CRANpkgs: BSGS
  - slug: RJ-2015-026
    old_slug: vigneau-chen-qannari
    title: 'ClustVarLV: An R Package for the Clustering of Variables Around Latent
      Variables'
    bibtitle: |-
      ClustVarLV: An R Package for the Clustering of Variables
                Around Latent Variables
    author:
    - Evelyne Vigneau
    - Mingkun Chen
    - El Mostafa Qannari
    bibauthor: Evelyne Vigneau and Mingkun Chen and El Mostafa Qannari
    landing: '2015'
    abstract: '  Abstract The clustering of variables is a strategy for deciphering
      the underlying structure of a data            set. Adopting an exploratory data
      analysis point of view, the Clustering of Variables around Latent            Variables
      (CLV) approach has been proposed by Vigneau and Qannari (2003). Based on a family
      of            optimization criteria, the CLV approach is adaptable to many situations.
      In particular, constraints may            be introduced in order to take account
      of additional information about the observations and/or the            variables.
      In this paper, the CLV method is depicted and the R package ClustVarLV including
      a set of            functions developed so far within this framework is introduced.
      Considering successively different            types of situations, the underlying
      CLV criteria are detailed and the various functions of the package            are
      illustrated using real case studies.'
    pages:
    - 134
    - 148
    acknowledged: '2015-03-04'
    online: '2015-10-23'
    CRANpkgs:
    - cluster
    - ClustVarLV
    - ClustOfVar
    - clere
    - biclust
    - pvclust
    - Hmisc
    - FactoMineR
    - plsgenomics
    - Rcpp
    - ClustVarLV
    CTV_rev:
    - Multivariate
    - Cluster
    - Psychometrics
    - Environmetrics
    - HighPerformanceComputing
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - Graphics
    - NumericalMathematics
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2015-027
    old_slug: charte-charte
    title: 'Working with Multilabel Datasets in R: The mldr Package'
    bibtitle: 'Working with Multilabel Datasets in R: The mldr Package'
    author:
    - Francisco Charte
    - David Charte
    bibauthor: Francisco Charte and David Charte
    landing: '2015'
    abstract: '  Abstract Most classification algorithms deal with datasets which
      have a set of input features, the            variables to be used as predictors,
      and only one output class, the variable to be predicted. However,            in
      late years many scenarios in which the classifier has to work with several outputs
      have come to            life. Automatic labeling of text documents, image annotation
      or protein classification are among            them. Multilabel datasets are
      the product of these new needs, and they have many specific traits.            The
      mldr package allows the user to load datasets of this kind, obtain their characteristics,
      produce            specialized plots, and manipulate them. The goal is to provide
      the exploratory tools needed to analyze            multilabel datasets, as well
      as the transformation and manipulation functions that will make possible            to
      apply binary and multiclass classification models to this data or the development
      of new multilabel            classifiers. Thanks to its integrated user interface,
      the exploratory functions will be available even to            non-specialized
      R users.'
    pages:
    - 149
    - 162
    acknowledged: '2015-03-09'
    online: '2015-09-16'
    CRANpkgs:
    - RWeka
    - mldr
    - shiny
    - Rcmdr
    - rattle
    - XML
    - circlize
    - devtools
    - pROC
    - shiny
    CTV_rev:
    - WebTechnologies
    - MachineLearning
    - Finance
    - NaturalLanguageProcessing
  - slug: RJ-2015-028
    old_slug: valliant-dever-kreuter
    title: 'PracTools: Computations for Design of Finite Population Samples'
    bibtitle: |-
      PracTools: Computations for Design of Finite Population
                Samples
    author:
    - Richard Valliant
    - Jill A. Dever
    - Frauke Kreuter
    bibauthor: Richard Valliant and Jill A. Dever and Frauke Kreuter
    landing: '2015'
    abstract: '  Abstract PracTools is an R package with functions that compute sample
      sizes for various types of            finite population sampling designs when
      totals or means are estimated. One-, two-, and three-stage            designs
      are covered as well as allocations for stratified sampling and probability proportional
      to size            sampling. Sample allocations can be computed that minimize
      the variance of an estimator subject to a            budget constraint or that
      minimize cost subject to a precision constraint. The package also contains            some
      specialized functions for estimating variance components and design effects.
      Several finite            populations are included that are useful for classroom
      instruction.'
    pages:
    - 163
    - 176
    acknowledged: '2015-03-18'
    online: '2015-06-30'
    CRANpkgs:
    - pps
    - sampling
    - samplingbook
    - simFrame
    - survey
    - PracTools
    - stratification
    - alabama
    - Rsolnp
    - SamplingStrata
    CTV_rev:
    - OfficialStatistics
    - Optimization
    - SocialSciences
    - Survival
  - slug: RJ-2015-029
    old_slug: seo-pan
    title: 'ALTopt: An R Package for Optimal Experimental Design of Accelerated Life
      Testing'
    bibtitle: |-
      ALTopt: An R Package for Optimal Experimental Design of
                Accelerated Life Testing
    author:
    - Kangwon Seo
    - Rong Pan
    bibauthor: Kangwon Seo and Rong Pan
    landing: '2015'
    abstract: '  Abstract The R package ALTopt has been developed with the aim of
      creating and evaluating optimal            experimental designs of censored
      accelerated life tests (ALTs). This package takes the generalized            linear
      model approach to ALT planning, because this approach can easily handle censoring
      plans and            derive information matrices for evaluating designs. Three
      types of optimality criteria are considered:            D-optimality for model
      parameter estimation, U-optimality for reliability prediction at a single use            condition,
      and I-optimality for reliability prediction over a region of use conditions.
      The Weibull            distribution is assumed for failure time data and more
      than one stress factor can be specified in the            package. Several graphical
      evaluation tools are also provided for the comparison of different ALT test            plans.'
    pages:
    - 177
    - 188
    acknowledged: '2015-03-18'
    online: '2015-09-29'
    CRANpkgs: ALTopt
    CTV_rev: ExperimentalDesign
  - slug: RJ-2015-030
    old_slug: nunes-prangle
    title: 'abctools: An R Package for Tuning Approximate Bayesian Computation Analyses'
    bibtitle: |-
      abctools: An R Package for Tuning Approximate Bayesian
                Computation Analyses
    author:
    - Matthew A. Nunes
    - Dennis Prangle
    bibauthor: Matthew A. Nunes and Dennis Prangle
    landing: '2015'
    abstract: '  Abstract Approximate Bayesian computation (ABC) is a popular family
      of algorithms which perform            approximate parameter inference when
      numerical evaluation of the likelihood function is not possible            but
      data can be simulated from the model. They return a sample of parameter values
      which produce            simulations close to the observed dataset. A standard
      approach is to reduce the simulated and            observed datasets to vectors
      of summary statistics and accept when the difference between these is            below
      a specified threshold. ABC can also be adapted to perform model choice.                 In
      this article, we present a new software package for R, abctools which provides
      methods for            tuning ABC algorithms. This includes recent dimension
      reduction algorithms to tune the choice            of summary statistics, and
      coverage methods to tune the choice of threshold. We provide several            illustrations
      of these routines on applications taken from the ABC literature.'
    pages:
    - 189
    - 205
    acknowledged: '2015-03-25'
    online: '2015-07-29'
    CRANpkgs:
    - abctools
    - abc
    - easyABC
    - MASS
    CTV_rev:
    - Bayesian
    - Distributions
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Pharmacokinetics
    - Psychometrics
    - Robust
    - SocialSciences
  - slug: RJ-2015-031
    old_slug: wang-faivre-richard-etal
    title: 'mtk: A General-Purpose and Extensible R Environment for Uncertainty and
      Sensitivity Analyses of Numerical Experiments'
    bibtitle: |-
      mtk: A General-Purpose and Extensible R Environment
                for Uncertainty and Sensitivity Analyses of Numerical
                Experiments
    author:
    - Juhui Wang
    - Robert Faivre
    - Hervé Richard
    - Hervé Monod
    bibauthor: |-
      Juhui Wang and Robert Faivre and Hervé Richard and Hervé
                Monod
    landing: '2015'
    abstract: '  Abstract Along with increased complexity of the models used for scientific
      activities and engineering            come diverse and greater uncertainties.
      Today, effectively quantifying the uncertainties contained            in a model
      appears to be more important than ever. Scientific fellows know how serious
      it is to            calibrate their model in a robust way, and decision-makers
      describe how critical it is to keep the best            effort to reduce the
      uncertainties about the model. Effectively accessing the uncertainties about
      the            model requires mastering all the tasks involved in the numerical
      experiments, from optimizing the            experimental design to managing
      the very time consuming aspect of model simulation and choosing            the
      adequate indicators and analysis methods.                 In this paper, we
      present an open framework for organizing the complexity associated with            numerical
      model simulation and analyses. Named mtk (Mexico Toolkit), the developed system
      aims            at providing practitioners from different disciplines with a
      systematic and easy way to compare and            to find the best method to
      effectively uncover and quantify the uncertainties contained in the model            and
      further to evaluate their impact on the performance of the model. Such requirements
      imply that            the system must be generic, universal, homogeneous, and
      extensible. This paper discusses such an            implementation using the
      R scientific computing platform and demonstrates its functionalities with            examples
      from agricultural modeling.                 The package mtk is of general purpose
      and easy to extend. Numerous methods are already            available in the
      actual release version, including Fast, Sobol, Morris, Basic Monte-Carlo, Regression,            LHS
      (Latin Hypercube Sampling), PLMM (Polynomial Linear metamodel). Most of them
      are compiled            from available R packages with extension tools delivered
      by package mtk.'
    pages:
    - 206
    - 226
    acknowledged: '2015-03-30'
    online: '2015-10-01'
    CRANpkgs:
    - sensitivity
    - spartan
    - diceDesign
    - planor
    - mtk
    - ff
    CTV_rev:
    - Environmetrics
    - ExperimentalDesign
    - HighPerformanceComputing
  - slug: RJ-2015-032
    old_slug: buttrey-whitaker
    title: 'treeClust: An R Package for Tree-Based Clustering Dissimilarities'
    bibtitle: |-
      treeClust: An R Package for Tree-Based Clustering
                Dissimilarities
    author:
    - Samuel E. Buttrey
    - Lyn R. Whitaker
    bibauthor: Samuel E. Buttrey and Lyn R. Whitaker
    landing: '2015'
    abstract: '  Abstract This paper describes treeClust, an R package that produces
      dissimilarities useful for cluster           ing. These dissimilarities arise
      from a set of classification or regression trees, one with each variable in            the
      data acting in turn as a the response, and all others as predictors. This use
      of trees produces dissim           ilarities that are insensitive to scaling,
      benefit from automatic variable selection, and appear to perform            well.
      The software allows a number of options to be set, affecting the set of objects
      returned in the call;            the user can also specify a clustering algorithm
      and, optionally, return only the clustering vector. The            package can
      also generate a numeric data set whose inter-point distances relate to the treeClust
      ones;            such a numeric data set can be much smaller than the vector
      of inter-point dissimilarities, a useful            feature in big data sets.'
    pages:
    - 227
    - 236
    acknowledged: '2015-04-07'
    online: '2015-09-16'
    CRANpkgs:
    - treeClust
    - cluster
    - rpart
    - tree
    CTV_rev:
    - Cluster
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Survival
  - slug: RJ-2015-033
    old_slug: hino-takano-murata
    title: 'mmpp: A Package for Calculating Similarity and Distance Metrics for Simple
      and Marked Temporal Point Processes'
    bibtitle: |-
      mmpp: A Package for Calculating Similarity and Distance
                Metrics for Simple and Marked Temporal Point Processes
    author:
    - Hideitsu Hino
    - Ken Takano
    - Noboru Murata
    bibauthor: Hideitsu Hino and Ken Takano and Noboru Murata
    landing: '2015'
    abstract: '  Abstract A simple temporal point process (SPP) is an important class
      of time series, where the sample            realization of the process is solely
      composed of the times at which events occur. Particular examples            of
      point process data are neuronal spike patterns or spike trains, and a large
      number of distance and            similarity metrics for those data have been
      proposed. A marked point process (MPP) is an extension            of a simple
      temporal point process, in which a certain vector valued mark is associated
      with each of            the temporal points in the SPP. Analyses of MPPs are
      of practical importance because instances of            MPPs include recordings
      of natural disasters such as earthquakes and tornadoes. In this paper, we            introduce
      the R package mmpp, which implements a number of distance and similarity metrics
      for            SPPs, and also extends those metrics for dealing with MPPs.'
    pages:
    - 237
    - 248
    acknowledged: '2015-04-17'
    online: '2015-09-29'
    CRANpkgs:
    - splancs
    - spatstat
    - PtProcess
    - stpp
    - mmpp
    - SAPP
    - etasFLP
    CTV_rev:
    - SpatioTemporal
    - Spatial
    - Survival
  - slug: RJ-2015-034
    old_slug: koohafkan-younis
    title: Open-Channel Computation with R
    bibtitle: Open-Channel Computation with R
    author:
    - Michael C. Koohafkan
    - Bassam A. Younis
    bibauthor: Michael C. Koohafkan and Bassam A. Younis
    landing: '2015'
    abstract: '  Abstract The rivr package provides a computational toolset for simulating
      steady and unsteady one           dimensional flows in open channels. It is
      designed primarily for use by instructors of undergraduate           and graduate-level
      open-channel hydrodynamics courses in such diverse fields as river engineering,            physical
      geography and geophysics. The governing equations used to describe open-channel
      flows            are briefly presented, followed by example applications. These
      include the computation of gradually           varied flows and two examples
      of unsteady flows in channels—namely, the tracking of the evolution            of
      a flood wave in a channel and the prediction of extreme variation in the water-surface
      profile            that results when a sluice gate is abruptly closed. Model
      results for the unsteady flow examples            are validated against standard
      benchmarks. The article concludes with a discussion of potential            modifications
      and extensions to the package.'
    pages:
    - 249
    - 262
    acknowledged: '2015-04-19'
    online: '2015-11-28'
    CRANpkgs:
    - rivr
    - knitr
    - shiny
    - Rcpp
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    - ReproducibleResearch
    - WebTechnologies
  - slug: RJ-2015-035
    old_slug: morina-higueras-puig-etal
    title: Generalized Hermite Distribution Modelling with the R Package hermite
    bibtitle: |-
      Generalized Hermite Distribution Modelling with the R
                Package hermite
    author:
    - David Moriña
    - Manuel Higueras
    - Pedro Puig
    - María Oliveira
    bibauthor: |-
      David Moriña and Manuel Higueras and Pedro Puig and María
                Oliveira
    landing: '2015'
    abstract: '  Abstract The Generalized Hermite distribution (and the Hermite distribution
      as a particular case) is            often used for fitting count data in the
      presence of overdispersion or multimodality. Despite this, to            our
      knowledge, no standard software packages have implemented specific functions
      to compute basic            probabilities and make simple statistical inference
      based on these distributions. We present here a set            of computational
      tools that allows the user to face these difficulties by modelling with the
      Generalized            Hermite distribution using the R package hermite. The
      package can also be used to generate random            deviates from a Generalized
      Hermite distribution and to use basic functions to compute probabilities            (density,
      cumulative density and quantile functions are available), to estimate parameters
      using the            maximum likelihood method and to perform the likelihood
      ratio test for Poisson assumption against a            Generalized Hermite alternative.
      In order to improve the density and quantile functions performance            when
      the parameters are large, Edgeworth and Cornish-Fisher expansions have been
      used. Hermite            regression is also a useful tool for modeling inflated
      count data, so its inclusion to a commonly used            software like R will
      make this tool available to a wide range of potential users. Some examples of            usage
      in several fields of application are also given.'
    pages:
    - 263
    - 274
    acknowledged: '2015-04-27'
    online: '2015-12-10'
    CRANpkgs:
    - maxLik
    - radir
    CTV_rev: Optimization
  - slug: RJ-2015-036
    old_slug: rubio-villar
    title: 'Code Profiling in R: A Review of Existing Methods and an Introduction
      to Package GUIProfiler'
    bibtitle: |-
      Code Profiling in R: A Review of Existing Methods and an
                Introduction to Package GUIProfiler
    author:
    - Angel Rubio
    - Fernando de Villar
    bibauthor: Angel Rubio and Fernando de Villar
    landing: '2015'
    abstract: '  Abstract Code analysis tools are crucial to understand program behavior.
      Profile tools use the results            of time measurements in the execution
      of a program to gain this understanding and thus help in the            optimization
      of the code. In this paper, we review the different available packages to profile
      R code            and show the advantages and disadvantages of each of them.
      In additon, we present GUIProfiler, a            package that fulfills some
      unmet needs.                 Package GUIProfiler generates an HTML report with
      the timing for each code line and the            relationships between different
      functions. This package mimics the behavior of the MATLAB profiler.            The
      HTML report includes information on the time spent on each of the lines of the
      profiled code            (the slowest code is highlighted). If the package is
      used within the RStudio environment, the user            can navigate across
      the bottlenecks in the code and open the editor to modify the lines of code
      where            more time is spent. It is also possible to edit the code using
      Notepad++ (a free editor for Windows) by            simply clicking on the corresponding
      line. The graphical user interface makes it easy to identify the            specific
      lines which slow down the code.                 The integration in RStudio and
      the generation of an HTML report makes GUIProfiler a very            convenient
      tool to perform code optimization.'
    pages:
    - 275
    - 287
    acknowledged: '2015-05-04'
    online: '2015-11-18'
    CRANpkgs:
    - aprof
    - proftools
    - profr
    - microbenchmark
    - Nozzle.R1
    - knitr
    - GUIProfiler
    - stringr
    - plyr
    - devtools
    - shiny
    BIOpkgs:
    - Rgraphviz
    - graph
    CTV_rev:
    - HighPerformanceComputing
    - ReproducibleResearch
    - WebTechnologies
  - heading: News and Notes
  - title: The R Consortium and the R Foundation
    bibtitle: The {R} Consortium and the {R} Foundation
    slug: plummer
    author: Martyn Plummer
    pages: 288
  - title: 'Conference Report: useR! 2015'
    bibtitle: 'Conference Report: {useR!} 2015'
    slug: tvedebrink
    author: Torben Tvedebrink
    pages:
    - 289
    - 290
  - title: News from the Bioconductor Project
    bibtitle: News from the {B}ioconductor Project
    author: The Bioconductor Team
    slug: bioconductor
    pages:
    - 291
    - 292
  - title: Changes in R
    bibtitle: Changes in {R}
    author: The R Core Team
    slug: r-changes
    pages:
    - 293
    - 297
  - title: Changes on CRAN
    bibtitle: Changes on {CRAN}
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    pages:
    - 298
    - 339
- issue: 2016-1
  year: 2016
  volume: 8
  num: 1
  month: Aug.
  bibmonth: aug
  articles:
  - title: Editorial
    author: Michael Lawrence
    slug: editorial
    pages:
    - 4
    - 4
  - heading: Contributed Research Articles
  - slug: RJ-2016-001
    old_slug: beath
    title: 'metaplus: An R Package for the Analysis of Robust Meta-Analysis and Meta-Regression'
    bibtitle: |-
      metaplus: An R Package for the Analysis of Robust Meta-
                Analysis and Meta-Regression
    author: Ken J. Beath
    bibauthor: Ken J. Beath
    landing: '2016'
    abstract: '  Abstract The metaplus package is described with examples of its use
      for fitting meta-analysis and            meta-regression. For either meta-analysis
      or meta-regression it is possible to fit one of three models:            standard
      normal random effect, t-distribution random effect or mixture of normal random
      effects. The            latter two models allow for robustness by allowing for
      a random effect distribution with heavier tails            than the normal distribution,
      and for both robust models the presence of outliers may be tested using            the
      parametric bootstrap. For the mixture of normal random effects model the outlier
      studies may be            identified through their posterior probability of
      membership in the outlier component of the mixture.            Plots allow the
      results of the different models to be compared. The package is demonstrated
      on three            examples: a meta-analysis with no outliers, a meta-analysis
      with an outlier and a meta-regression with            an outlier.'
    pages:
    - 5
    - 16
    acknowledged: '2015-02-17'
    online: '2016-06-13'
    CRANpkgs:
    - metaplus
    - metafor
    - bbmle
    - forestplot
    - extrafont
    CTV_rev:
    - MetaAnalysis
    - ClinicalTrials
    - Phylogenetics
  - slug: RJ-2016-002
    old_slug: wais
    title: Gender Prediction Methods Based on First Names with genderizeR
    bibtitle: |-
      Gender Prediction Methods Based on First Names with
                genderizeR
    author: Kamil Wais
    bibauthor: Kamil Wais
    landing: '2016'
    abstract: '  Abstract In recent years, there has been increased interest in methods
      for gender prediction based on            first names that employ various open
      data sources. These methods have applications from bibliometric            studies
      to customizing commercial offers for web users. Analysis of gender disparities
      in science based            on such methods are published in the most prestigious
      journals, although they could be improved            by choosing the most suited
      prediction method with optimal parameters and performing validation            studies
      using the best data source for a given purpose. There is also a need to monitor
      and report how            well a given prediction method works in comparison
      to others. In this paper, the author recommends            a set of tools (including
      one dedicated to gender prediction, the R package called genderizeR), data            sources
      (including the genderize.io API), and metrics that could be fully reproduced
      and tested in            order to choose the optimal approach suitable for different
      gender analyses.'
    pages:
    - 17
    - 37
    acknowledged: '2015-12-17'
    online: '2016-07-23'
    CRANpkgs:
    - genderizeR
    - qdap
    - gender
    - babynames
    - sortinghat
    - stringr
    - tm
    - ROCR
    - verification
    - data.table
    - dplyr
    CTV_rev:
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - Finance
    - MachineLearning
    - Multivariate
    - WebTechnologies
  - slug: RJ-2016-003
    old_slug: sophie-brouste-istas
    title: Conditional Fractional Gaussian Fields with the Package FieldSim
    bibtitle: |-
      Conditional Fractional Gaussian Fields with the Package
                FieldSim
    author:
    - Alexandre Brouste
    - Jacques Istas
    - Sophie Lambert-Lacroix
    bibauthor: |-
      Alexandre Brouste and Jacques Istas and Sophie Lambert-
                Lacroix
    landing: '2016'
    abstract: '  Abstract We propose an effective and fast method to simulate multidimensional
      conditional fractional            Gaussian fields with the package FieldSim.
      Our method is valid not only for conditional simulations            associated
      to fractional Brownian fields, but to any Gaussian field and on any (non regular)
      grid of            points.'
    pages:
    - 38
    - 47
    acknowledged: '2015-03-06'
    online: '2016-04-03'
    CRANpkgs:
    - FieldSim
    - RandomFields
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2016-004
    old_slug: demirhan
    title: 'rTableICC: An R Package for Random Generation of 22K and RC Contingency
      Tables'
    bibtitle: |-
      rTableICC: An R Package for Random Generation of 22K and RC
                Contingency Tables
    author: Haydar Demirhan
    bibauthor: Haydar Demirhan
    landing: '2016'
    abstract: '  Abstract In this paper, we describe the R package rTableICC that
      provides an interface for random            generation of 2×2×K and R×C contingency
      tables constructed over either intraclass-correlated or            uncorrelated
      individuals. Intraclass correlations arise in studies where sampling units include
      more            than one individual and these individuals are correlated. The
      package implements random generation            of contingency tables over individuals
      with or without intraclass correlations under various sampling            plans.
      The package include two functions for the generation of K 2×2 tables over product-multinomial            sampling
      schemes and that of 2×2×K tables under Poisson or multinomial sampling plans.
      It also            contains two functions that generate R×C tables under product-multinomial,
      multinomial or Poisson            sampling plans with or without intraclass
      correlations. The package also includes a function for            random number
      generation from a given probability distribution. In addition to the contingency
      table            format, the package also provides raw data required for further
      estimation purposes.'
    pages:
    - 48
    - 63
    acknowledged: '2015-03-24'
    online: '2016-04-02'
    CRANpkgs:
    - rTableICC
    - partitions
    CTV_rev: NumericalMathematics
  - slug: RJ-2016-005
    old_slug: brown
    title: Maps, Coordinate Reference Systems and Visualising Geographic Data with
      mapmisc
    bibtitle: |-
      Maps, Coordinate Reference Systems and Visualising
                Geographic Data with mapmisc
    author: Patrick E. Brown
    bibauthor: Patrick E. Brown
    landing: '2016'
    abstract: '  Abstract The mapmisc package provides functions for visualising geospatial
      data, including fetching            background map layers, producing colour
      scales and legends, and adding scale bars and orientation            arrows
      to plots. Background maps are returned in the coordinate reference system of
      the dataset            supplied, and inset maps and direction arrows reflect
      the map projection being plotted. This is a “light            weight” package
      having an emphasis on simplicity and ease of use.'
    pages:
    - 64
    - 91
    acknowledged: '2015-03-25'
    online: '2016-07-28'
    CRANpkgs:
    - sp
    - raster
    - mapmisc
    - rgdal
    - RColorBrewer
    - classInt
    - rgeos
    - geosphere
    - dismo
    - maptools
    - R.utils
    - geostatsp
    - knitr
    - ggplot2
    - leaflet
    CTV_rev:
    - Spatial
    - Graphics
    - SpatioTemporal
    - Phylogenetics
    - ReproducibleResearch
  - slug: RJ-2016-006
    old_slug: jacques-yengo-biernacki-etal
    title: 'Variable Clustering in High-Dimensional Linear Regression: The R Package
      clere'
    bibtitle: |-
      Variable Clustering in High-Dimensional Linear Regression:
                The R Package clere
    author:
    - Loïc Yengo
    - Julien Jacques
    - Christophe Biernacki
    - Mickael Canouil
    bibauthor: |-
      Loïc Yengo and Julien Jacques and Christophe Biernacki and
                Mickael Canouil
    landing: '2016'
    abstract: '  Abstract Dimension reduction is one of the biggest challenges in
      high-dimensional regression models.            We recently introduced a new
      methodology based on variable clustering as a means to reduce dimen           sionality.
      We present here the R package clere that implements some refinements of this
      methodology.            An overview of the package functionalities as well as
      examples to run an analysis are described.            Numerical experiments
      on real data were performed to illustrate the good predictive performance of            our
      parsimonious method compared to standard dimension reduction approaches.'
    pages:
    - 92
    - 106
    acknowledged: '2015-03-26'
    online: '2016-04-03'
    CRANpkgs:
    - glmnet
    - spikeslab
    - clere
    - Rcpp
    - RcppEigen
    - lasso2
    - flare
    CTV_rev:
    - MachineLearning
    - NumericalMathematics
    - Bayesian
    - HighPerformanceComputing
    - Survival
  - slug: RJ-2016-007
    old_slug: eder-rybicki-kestemont
    title: 'Stylometry with R: A Package for Computational Text Analysis'
    bibtitle: 'Stylometry with R: A Package for Computational Text Analysis'
    author:
    - Maciej Eder
    - Jan Rybicki
    - Mike Kestemont
    bibauthor: Maciej Eder and Jan Rybicki and Mike Kestemont
    landing: '2016'
    abstract: '  Abstract This software paper describes ‘Stylometry with R’ (stylo),
      a flexible R package for the high           level analysis of writing style
      in stylometry. Stylometry (computational stylistics) is concerned with the            quantitative
      study of writing style, e.g. authorship verification, an application which has
      considerable            potential in forensic contexts, as well as historical
      research. In this paper we introduce the possibilities            of stylo for
      computational text analysis, via a number of dummy case studies from English
      and French            literature. We demonstrate how the package is particularly
      useful in the exploratory statistical analysis            of texts, e.g. with
      respect to authorial writing style. Because stylo provides an attractive graphical
      user            interface for high-level exploratory analyses, it is especially
      suited for an audience of novices, without            programming skills (e.g.
      from the Digital Humanities). More experienced users can benefit from our            implementation
      of a series of standard pipelines for text processing, as well as a number of
      similarity            metrics.'
    pages:
    - 107
    - 121
    acknowledged: '2015-04-07'
    online: '2015-12-22'
    CRANpkgs: stylo
  - slug: RJ-2016-008
    old_slug: linares-na
    title: 'quickpsy: An R Package to Fit Psychometric Functions for Multiple Groups'
    bibtitle: |-
      quickpsy: An R Package to Fit Psychometric Functions for
                Multiple Groups
    author:
    - Daniel Linares
    - Joan López-Moliner
    bibauthor: Daniel Linares and Joan López-Moliner
    landing: '2016'
    abstract: '  Abstract quickpsy is a package to parametrically fit psychometric
      functions. In comparison with            previous R packages, quickpsy was built
      to easily fit and plot data for multiple groups. Here,            we describe
      the standard parametric model used to fit psychometric functions and the standard            estimation
      of its parameters using maximum likelihood. We also provide examples of usage
      of            quickpsy, including how allowing the lapse rate to vary can sometimes
      eliminate the bias in parameter            estimation, but not in general. Finally,
      we describe some implementation details, such as how to avoid            the
      problems associated to round-off errors in the maximisation of the likelihood
      or the use of closures            and non-standard evaluation functions.'
    pages:
    - 122
    - 131
    acknowledged: '2015-05-12'
    online: '2015-11-08'
    CRANpkgs:
    - quickpsy
    - psyphy
    - modelfree
    - MPDiR
    - gridExtra
    - dplyr
    - ggplot2
    CTV_rev:
    - Psychometrics
    - Graphics
    - Phylogenetics
  - slug: RJ-2016-009
    old_slug: sestelo-villanueva-meiramachado-etal
    title: 'FWDselect: An R Package for Variable Selection in Regression Models'
    bibtitle: |-
      FWDselect: An R Package for Variable Selection in Regression
                Models
    author:
    - Marta Sestelo
    - Nora M. Villanueva
    - Luis Meira-Machado
    - Javier Roca-Pardiñas
    bibauthor: |-
      Marta Sestelo and Nora M. Villanueva and Luis Meira-Machado
                and Javier Roca-Pardiñas
    landing: '2016'
    abstract: '  Abstract In multiple regression models, when there are a large number
      (p) of explanatory variables            which may or may not be relevant for
      predicting the response, it is useful to be able to reduce the model.            To
      this end, it is necessary to determine the best subset of q (q ≤ p) predictors
      which will establish            the model with the best prediction capacity.
      FWDselect package introduces a new forward stepwise           based selection
      procedure to select the best model in different regression frameworks (parametric            or
      nonparametric). The developed methodology, which can be equally applied to linear
      models,            generalized linear models or generalized additive models,
      aims to introduce solutions to the following            two topics: i) selection
      of the best combination of q variables by using a step-by-step method; and,            perhaps,
      most importantly, ii) search for the number of covariates to be included in
      the model based            on bootstrap resampling techniques. The software
      is illustrated using real and simulated data.'
    pages:
    - 132
    - 148
    acknowledged: '2015-05-18'
    online: '2016-04-20'
    CRANpkgs:
    - meifly
    - leaps
    - subselect
    - leaps
    - subselect
    - lars
    - glmnet
    - glmulti
    - bestglm
    - mgcv
    - FWDselect
    CTV_rev:
    - ChemPhys
    - SocialSciences
    - MachineLearning
    - Bayesian
    - Econometrics
    - Environmetrics
    - Survival
  - slug: RJ-2016-010
    old_slug: joblin-mauerer
    title: An Interactive Survey Application for Validating Social Network Analysis
      Techniques
    bibtitle: |-
      An Interactive Survey Application for Validating Social
                Network Analysis Techniques
    author:
    - Mitchell Joblin
    - Wolfgang Mauerer
    bibauthor: Mitchell Joblin and Wolfgang Mauerer
    landing: '2016'
    abstract: '  Abstract Social network analysis is extremely well supported by the
      R community and is routinely            used for studying the relationships
      between people engaged in collaborative activities. While there            has
      been rapid development of new approaches and metrics in this field, the challenging
      question            of validity (how well insights derived from social networks
      agree with reality) is often difficult to            address. We propose the
      use of several R packages to generate interactive surveys that are specifically            well
      suited for validating social network analyses. Using our web-based survey application,
      we were            able to validate the results of applying community-detection
      algorithms to infer the organizational            structure of software developers
      contributing to open-source projects.'
    pages:
    - 149
    - 158
    acknowledged: '2015-05-18'
    online: '2015-11-04'
    CRANpkgs:
    - igraph
    - sna
    - twitteR
    - Rfacebook
    - shiny
    BIOpkgs: graph
    CTV_rev:
    - WebTechnologies
    - Optimization
    - Bayesian
    - gR
    - Graphics
    - SocialSciences
    - Spatial
  - slug: RJ-2016-011
    old_slug: franck-osborne
    title: Exploring Interaction Effects in Two-Factor Studies using the hiddenf Package
      in R.
    bibtitle: |-
      Exploring Interaction Effects in Two-Factor Studies using
                the hiddenf Package in R.
    author:
    - Christopher T. Franck
    - Jason A. Osborne
    bibauthor: Christopher T. Franck and Jason A. Osborne
    landing: '2016'
    abstract: '  Abstract In crossed, two-factor studies with one observation per
      factor-level combination, interaction            effects between factors can
      be hard to detect and can make the choice of a suitable statistical model            difficult.
      This article describes hiddenf, an R package that enables users to quantify
      and characterize a            certain form of interaction in two-factor layouts.
      When effects of one factor (a) fall into two groups            depending on
      the level of another factor, and (b) are constant within these groups, the interaction            pattern
      is deemed "hidden additivity" because within groups, the effects of the two
      factors are additive,            while between groups the factors are allowed
      to interact. The hiddenf software can be used to estimate,            test,
      and report an appropriate factorial effects model corresponding to hidden additivity,
      which is            intermediate between the unavailable full factorial model
      and the overly-simplistic additive model.            Further, the software also
      conducts five statistical tests for interaction proposed between 1949 and            2014.
      A collection of 17 datasets is used for illustration.'
    pages:
    - 159
    - 172
    acknowledged: '2015-05-27'
    online: '2016-04-03'
    CRANpkgs:
    - hiddenf
    - additivityTests
  - slug: RJ-2016-012
    old_slug: messner-mayr-zeileis
    title: Heteroscedastic Censored and Truncated Regression with crch
    bibtitle: Heteroscedastic Censored and Truncated Regression with crch
    author:
    - Jakob W. Messner
    - Georg J. Mayr
    - Achim Zeileis
    bibauthor: Jakob W. Messner and Georg J. Mayr and Achim Zeileis
    landing: '2016'
    abstract: '  Abstract The crch package provides functions for maximum likelihood
      estimation of censored            or truncated regression models with conditional
      heteroscedasticity along with suitable standard            methods to summarize
      the fitted models and compute predictions, residuals, etc. The supported            distributions
      include leftor right-censored or truncated Gaussian, logistic, or student-t
      distributions            with potentially different sets of regressors for modeling
      the conditional location and scale. The models            and their R implementation
      are introduced and illustrated by numerical weather prediction tasks            using
      precipitation data for Innsbruck (Austria).'
    pages:
    - 173
    - 181
    acknowledged: '2015-06-28'
    online: '2015-10-14'
    CRANpkgs:
    - dglm
    - glmx
    - gamlss
    - betareg
    - crch
    - Formula
    - gamlss.cens
    - gamlss.tr
    - sampleSelection
    - mhurdle
    CTV_rev:
    - Econometrics
    - Psychometrics
    - SocialSciences
    - Survival
  - slug: RJ-2016-013
    old_slug: pritikin-schmidt
    title: Model Builder for Item Factor Analysis with OpenMx
    bibtitle: Model Builder for Item Factor Analysis with OpenMx
    author:
    - Joshua N. Pritikin
    - Karen M. Schmidt
    bibauthor: Joshua N. Pritikin and Karen M. Schmidt
    landing: '2016'
    abstract: '  Abstract We introduce a shiny web application to facilitate the construction
      of Item Factor Analysis            (a.k.a. Item Response Theory) models using
      the OpenMx package. The web application assists with            importing data,
      outcome recoding, and model specification. However, the app does not conduct
      any            analysis but, rather, generates an analysis script. Generated
      Rmarkdown output serves dual purposes:            to analyze a data set and
      demonstrate good programming practices. The app can be used as a teaching            tool
      or as a starting point for custom analysis scripts.'
    pages:
    - 182
    - 203
    acknowledged: '2015-07-21'
    online: '2016-04-03'
    CRANpkgs:
    - OpenMx
    - shiny
    - Rmarkdown
    - ifaTools
    - rpf
    CTV_rev:
    - Psychometrics
    - WebTechnologies
  - slug: RJ-2016-014
    old_slug: na-pebesma-heuvelink
    title: Spatio-Temporal Interpolation using gstat
    bibtitle: Spatio-Temporal Interpolation using gstat
    author:
    - Benedikt Gräler
    - Edzer Pebesma
    - Gerard Heuvelink
    bibauthor: Benedikt Gräler and Edzer Pebesma and Gerard Heuvelink
    landing: '2016'
    abstract: '  Abstract We present new spatio-temporal geostatistical modelling
      and interpolation capabilities of            the R package gstat. Various spatio-temporal
      covariance models have been implemented, such as the            separable, product-sum,
      metric and sum-metric models. In a real-world application we compare spatio           temporal
      interpolations using these models with a purely spatial kriging approach. The
      target variable            of the application is the daily mean PM10 concentration
      measured at rural air quality monitoring            stations across Germany
      in 2005. R code for variogram fitting and interpolation is presented in            this
      paper to illustrate the workflow of spatio-temporal interpolation using gstat.
      We conclude            that the system works properly and that the extension
      of gstat facilitates and eases spatio-temporal            geostatistical modelling
      and prediction for R users.'
    pages:
    - 204
    - 218
    acknowledged: '2015-07-24'
    online: '2016-06-13'
    CRANpkgs:
    - spacetime
    - gstat
    - RandomFields
    - spTimer
    - spBayes
    - spate
    - FNN
    CTV_rev:
    - SpatioTemporal
    - Spatial
    - Bayesian
    - TimeSeries
  - slug: RJ-2016-015
    old_slug: beck
    title: 'SWMPr: An R Package for Retrieving, Organizing, and Analyzing Environmental
      Data for Estuaries'
    bibtitle: |-
      SWMPr: An R Package for Retrieving, Organizing, and
                Analyzing Environmental Data for Estuaries
    author: Marcus W Beck
    bibauthor: Marcus W Beck
    landing: '2016'
    abstract: '  Abstract The System-Wide Monitoring Program (SWMP) was implemented
      in 1995 by the US National            Estuarine Research Reserve System. This
      program has provided two decades of continuous monitoring            data at
      over 140 fixed stations in 28 estuaries. However, the increasing quantity of
      data provided by the            monitoring network has complicated broad-scale
      comparisons between systems and, in some cases,            prevented simple
      trend analysis of water quality parameters at individual sites. This article
      describes            the SWMPr package that provides several functions that
      facilitate data retrieval, organization, and            analysis of time series
      data in the reserve estuaries. Previously unavailable functions for estuaries
      are            also provided to estimate rates of ecosystem metabolism using
      the open-water method. The SWMPr            package has facilitated a cross-reserve
      comparison of water quality trends and links quantitative            information
      with analysis tools that have use for more generic applications to environmental
      time            series.'
    pages:
    - 219
    - 232
    acknowledged: '2015-09-04'
    online: '2016-04-03'
    CRANpkgs:
    - SWMPr
    - shiny
    - cents
    - wq
    - ggmap
    - StreamMetabolism
    CTV_rev:
    - WebTechnologies
    - Environmetrics
    - Spatial
    - TimeSeries
  - slug: RJ-2016-016
    old_slug: demirhan-bitirim
    title: 'CryptRndTest: An R Package for Testing the Cryptographic Randomness'
    bibtitle: |-
      CryptRndTest: An R Package for Testing the Cryptographic
                Randomness
    author:
    - Haydar Demirhan
    - Nihan Bitirim
    bibauthor: Haydar Demirhan and Nihan Bitirim
    landing: '2016'
    abstract: '  Abstract In this article, we introduce the R package CryptRndTest
      that performs eight statistical            randomness tests on cryptographic
      random number sequences. The purpose of the package is to            provide
      software implementing recently proposed cryptographic randomness tests utilizing
      goodness           of-fit tests superior to the usual chi-square test in terms
      of statistical performance. Most of the tests            included in package
      CryptRndTest are not available in other software packages such as the R package            RDieHarder
      or the C library TestU01. Chi-square, Anderson-Darling, Kolmogorov-Smirnov,
      and            Jarque-Bera goodness-of-fit procedures are provided along with
      cryptographic randomness tests.            CryptRndTest utilizes multiple precision
      floating numbers for sequences longer than 64-bit based            on the package
      Rmpfr. By this way, included tests are applied precisely for higher bit-lengths.
      In            addition CryptRndTest provides a user friendly interface to these
      cryptographic randomness tests.            As an illustrative application, CryptRndTest
      is used to test available random number generators in R.'
    pages:
    - 233
    - 247
    acknowledged: '2015-09-10'
    online: '2016-04-03'
    CRANpkgs:
    - RDieHarder
    - randtests
    - DescTools
    - CryptRndTest
    - Rmpfr
    - kSamples
    - tseries
    - copula
    - gmp
    CTV_rev:
    - Distributions
    - Finance
    - NumericalMathematics
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - Multivariate
    - TimeSeries
  - slug: RJ-2016-017
    old_slug: calvo-na
    title: 'scmamp: Statistical Comparison of Multiple Algorithms in Multiple Problems'
    bibtitle: |-
      scmamp: Statistical Comparison of Multiple Algorithms in
                Multiple Problems
    author:
    - Borja Calvo
    - Guzmán Santafé
    bibauthor: Borja Calvo and Guzmán Santafé
    landing: '2016'
    abstract: '  Abstract Comparing the results obtained by two or more algorithms
      in a set of problems is a central            task in areas such as machine learning
      or optimization. Drawing conclusions from these comparisons            may require
      the use of statistical tools such as hypothesis testing. There are some interesting
      papers            that cover this topic. In this manuscript we present scmamp,
      an R package aimed at being a tool            that simplifies the whole process
      of analyzing the results obtained when comparing algorithms, from            loading
      the data to the production of plots and tables.                 Comparing the
      performance of different algorithms is an essential step in many research and            practical
      computational works. When new algorithms are proposed, they have to be compared
      with            the state of the art. Similarly, when an algorithm is used for
      a particular problem, its performance with            different sets of parameters
      has to be compared, in order to tune them for the best results.                 When
      the differences are very clear (e.g., when an algorithm is the best in all the
      problems used in            the comparison), the direct comparison of the results
      may be enough. However, this is an unusual            situation and, thus, in
      most situations a direct comparison may be misleading and not enough to draw            sound
      conclusions; in those cases, the statistical assessment of the results is advisable.                 The
      statistical comparison of algorithms in the context of machine learning has
      been covered in            several papers. In particular, the tools implemented
      in this package are those presented in Demšar            (2006); García and
      Herrera (2008); García et al. (2010). Another good review that covers, among
      other            aspects, the statistical assessment of the results in the context
      of supervised classification can be found            in Santafé et al. (2015).'
    pages:
    - 248
    - 256
    acknowledged: '2015-09-28'
    online: '2015-11-26'
    CRANpkgs: scmamp
  - slug: RJ-2016-018
    old_slug: an-liu
    title: 'keyplayer: An R Package for Locating Key Players in Social Networks'
    bibtitle: |-
      keyplayer: An R Package for Locating Key Players in Social
                Networks
    author:
    - Weihua An
    - Yu-Hsin Liu
    bibauthor: Weihua An and Yu-Hsin Liu
    landing: '2016'
    abstract: '  Abstract Interest in social network analysis has exploded in the
      past few years, partly thanks to            the advancements in statistical
      methods and computing for network analysis. A wide range of the            methods
      for network analysis is already covered by existent R packages. However, no
      comprehensive            packages are available to calculate group centrality
      scores and to identify key players (i.e., those players            who constitute
      the most central group) in a network. These functionalities are important because,            for
      example, many social and health interventions rely on key players to facilitate
      the intervention.            Identifying key players is challenging because
      players who are individually the most central are not            necessarily
      the most central as a group due to redundancy in their connections. In this
      paper we            develop methods and tools for computing group centrality
      scores and for identifying key players in            social networks. We illustrate
      the methods using both simulated and empirical examples. The package            keyplayer
      providing the presented methods is available from Comprehensive R Archive Network            (CRAN).'
    pages:
    - 257
    - 268
    acknowledged:
    - '2015-10-16'
    - '2015-10-17'
    online: '2016-05-01'
    CRANpkgs:
    - network
    - sna
    - igraph
    - statnet
    - RSiena
    - keyplayer
    - influenceR
    CTV_rev:
    - SocialSciences
    - gR
    - Optimization
    - Bayesian
    - Graphics
    - Spatial
  - slug: RJ-2016-019
    old_slug: north
    title: 'SchemaOnRead: A Package for Schema-on-Read in R'
    bibtitle: 'SchemaOnRead: A Package for Schema-on-Read in R'
    author: Michael J. North
    bibauthor: Michael J. North
    landing: '2016'
    abstract: '  Abstract SchemaOnRead is a CRAN package that provides an extensible
      mechanism for importing a            wide range of file types into R as well
      as support for the emerging schema-on-read paradigm in R. The            schema-on-read
      tools within the package include a single function call that recursively reads
      folders            with text, comma separated value, raster image, R data, HDF5,
      NetCDF, spreadsheet, Weka, Epi Info,            Pajek network, R network, HTML,
      SPSS, Systat, and Stata files. It also recursively reads folders (e.g.,            schemaOnRead("folder")),
      returning a nested list of the contained elements. The provided tools can            be
      used as-is or easily customized to implement tool chains in R. This paper’s
      contribution is that it            introduces and describes the SchemaOnRead
      package and compares it to related R packages.'
    pages:
    - 269
    - 275
    acknowledged: '2015-10-27'
    online: '2016-04-03'
    CRANpkgs:
    - SchemaOnRead
    - rio
    - readbitmap
    - foreign
    - testthat
    CTV_rev:
    - OfficialStatistics
    - WebTechnologies
  - slug: RJ-2016-020
    old_slug: leeper
    title: Crowdsourced Data Preprocessing with R and Amazon Mechanical Turk
    bibtitle: |-
      Crowdsourced Data Preprocessing with R and Amazon Mechanical
                Turk
    author: Thomas J. Leeper
    bibauthor: Thomas J. Leeper
    landing: '2016'
    abstract: '  Abstract This article introduces the use of the Amazon Mechanical
      Turk (MTurk) crowdsourcing            platform as a resource for R users to
      leverage crowdsourced human intelligence for preprocessing           “messy”
      data into a form easily analyzed within R. The article first describes MTurk
      and the MTurkR            package, then outlines how to use MTurkR to gather
      and manage crowdsourced data with MTurk            using some of the package’s
      core functionality. Potential applications of MTurkR include construction            of
      manually coded training sets, human transcription and translation, manual data
      scraping from            scanned documents, content analysis, image classification,
      and the completion of online survey            questionnaires, among others.
      As an example of massive data preprocessing, the article describes an            image
      rating task involving 225 crowdsourced workers and more than 5500 images using
      just three            MTurkR function calls.'
    pages:
    - 276
    - 288
    acknowledged: '2015-10-30'
    online: '2016-06-13'
    CRANpkgs:
    - MTurkR
    - MTurkRGUI
    - tcltk
    - curl
    - XML
    CTV_rev: WebTechnologies
  - slug: RJ-2016-021
    old_slug: scrucca-fop-murphy-etal
    title: 'mclust 5: Clustering, Classification and Density Estimation Using Gaussian
      Finite Mixture Models'
    bibtitle: |-
      mclust 5: Clustering, Classification and Density Estimation
                Using Gaussian Finite Mixture Models
    author:
    - Luca Scrucca
    - Michael Fop
    - T. Brendan Murphy
    - Adrian E. Raftery
    bibauthor: |-
      Luca Scrucca and Michael Fop and T. Brendan Murphy and
                Adrian E. Raftery
    landing: '2016'
    abstract: '  Abstract Finite mixture models are being used increasingly to model
      a wide variety of random            phenomena for clustering, classification
      and density estimation. mclust is a powerful and popular            package
      which allows modelling of data as a Gaussian finite mixture with different covariance            structures
      and different numbers of mixture components, for a variety of purposes of analysis.
      Recently,            version 5 of the package has been made available on CRAN.
      This updated version adds new covariance            structures, dimension reduction
      capabilities for visualisation, model selection criteria, initialisation            strategies
      for the EM algorithm, and bootstrap-based inference, making it a full-featured
      R package            for data analysis via finite mixture modelling.'
    pages:
    - 289
    - 317
    acknowledged: '2015-11-11'
    online: '2016-06-13'
    CRANpkgs:
    - mclust
    - cranlogs
    - Rmixmod
    - mixture
    - EMCluster
    - mixtools
    - bgmm
    - flexmix
    - igraph
    - gclus
    - rrcov
    - tourr
    - fpc
    CTV_rev:
    - Cluster
    - Multivariate
    - Distributions
    - Environmetrics
    - Graphics
    - gR
    - Optimization
    - Psychometrics
    - Robust
    - Spatial
  - slug: RJ-2016-022
    old_slug: szkaliczki
    title: 'clustering.sc.dp: Optimal Clustering with Sequential Constraint by Using
      Dynamic Programming'
    bibtitle: |-
      clustering.sc.dp: Optimal Clustering with Sequential
                Constraint by Using Dynamic Programming
    author: Tibor Szkaliczki
    bibauthor: Tibor Szkaliczki
    landing: '2016'
    abstract: '  Abstract The general clustering algorithms do not guarantee optimality
      because of the hardness of the            problem. Polynomial-time methods can
      find the clustering corresponding to the exact optimum only            in special
      cases. For example, the dynamic programming algorithm can solve the one-dimensional            clustering
      problem, i.e., when the items to be clustered can be characterised by only one
      scalar            number. Optimal one-dimensional clustering is provided by
      package Ckmeans.1d.dp in R. The paper            shows a possible generalisation
      of the method implemented in this package to multidimensional            data:
      the dynamic programming method can be applied to find the optimum clustering
      of vectors            when only subsequent items may form a cluster. Sequential
      data are common in various fields            including telecommunication, bioinformatics,
      marketing, transportation etc. The proposed algorithm            can determine
      the optima for a range of cluster numbers in order to support the case when
      the number            of clusters is not known in advance.'
    pages:
    - 318
    - 327
    acknowledged: '2015-12-09'
    online: '2016-05-01'
    CRANpkgs:
    - Ckmeans.1d.dp
    - clustering.sc.dp
  - slug: RJ-2016-023
    old_slug: hu-qutub
    title: 'progenyClust: an R package for Progeny Clustering'
    bibtitle: 'progenyClust: an R package for Progeny Clustering'
    author:
    - Chenyue W. Hu
    - Amina A. Qutub
    bibauthor: Chenyue W. Hu and Amina A. Qutub
    landing: '2016'
    abstract: '  Abstract Identifying the optimal number of clusters is a common problem
      faced by data scientists            in various research fields and industry
      applications. Though many clustering evaluation techniques            have been
      developed to solve this problem, the recently developed algorithm Progeny Clustering            is
      a much faster alternative and one that is relevant to biomedical applications.
      In this paper, we            introduce an R package progenyClust that implements
      and extends the original Progeny Clustering            algorithm for evaluating
      clustering stability and identifying the optimal cluster number. We illustrate            its
      applicability using two examples: a simulated test dataset for proof-of-concept,
      and a cell imaging            dataset for demonstrating its application potential
      in biomedical research. The progenyClust package            is versatile in
      that it offers great flexibility for picking methods and tuning parameters.
      In addition,            the default parameter setting as well as the plot and
      summary methods offered in the package make            the application of Progeny
      Clustering straightforward and coherent.'
    pages:
    - 328
    - 338
    acknowledged: '2016-01-01'
    online: '2016-05-01'
    CRANpkgs:
    - cclust
    - clusterSim
    - cluster
    - Nbclust
    - fpc
    - progenyClust
    - stat
    - Hmisc
    CTV_rev:
    - Cluster
    - Multivariate
    - Bayesian
    - ClinicalTrials
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - ReproducibleResearch
    - SocialSciences
  - slug: RJ-2016-024
    old_slug: giner-smyth
    title: 'statmod: Probability Calculations for the Inverse Gaussian Distribution'
    bibtitle: |-
      statmod: Probability Calculations for the Inverse Gaussian
                Distribution
    author:
    - Göknur Giner
    - Gordon K. Smyth
    bibauthor: Göknur Giner and Gordon K. Smyth
    landing: '2016'
    abstract: '  Abstract The inverse Gaussian distribution (IGD) is a well known
      and often used probability dis           tribution for which fully reliable
      numerical algorithms have not been available. We develop fast,            reliable
      basic probability functions (dinvgauss, pinvgauss, qinvgauss and rinvgauss)
      for the IGD            that work for all possible parameter values and which
      achieve close to full machine accuracy. The            most challenging task
      is to compute quantiles for given cumulative probabilities and we develop            a
      simple but elegant mathematical solution to this problem. We show that Newton’s
      method for            finding the quantiles of a IGD always converges monotonically
      when started from the mode of the            distribution. Simple Taylor series
      expansions are used to improve accuracy on the log-scale. The            IGD
      probability functions provide the same options and obey the same conventions
      as do probability            functions provided in the stats package.'
    pages:
    - 339
    - 351
    acknowledged: '2016-01-05'
    online: '2016-07-27'
    CRANpkgs:
    - SuppDists
    - STAR
    - statmod
    CTV_rev:
    - Distributions
    - HighPerformanceComputing
    - NumericalMathematics
  - slug: RJ-2016-025
    old_slug: wright
    title: Using DECIPHER v2.0 to Analyze Big Biological Sequence Data in R
    bibtitle: |-
      Using DECIPHER v2.0 to Analyze Big Biological Sequence Data
                in R
    author: Erik S. Wright
    bibauthor: Erik S. Wright
    landing: '2016'
    abstract: '  Abstract In recent years, the cost of DNA sequencing has decreased
      at a rate that has outpaced            improvements in memory capacity. It is
      now common to collect or have access to many gigabytes            of biological
      sequences. This has created an urgent need for approaches that analyze sequences
      in            subsets without requiring all of the sequences to be loaded into
      memory at one time. It has also opened            opportunities to improve the
      organization and accessibility of information acquired in sequencing            projects.
      The DECIPHER package offers solutions to these problems by assisting in the
      curation of            large sets of biological sequences stored in compressed
      format inside a database. This approach has            many practical advantages
      over standard bioinformatics workflows, and enables large analyses that            would
      otherwise be prohibitively time consuming.'
    pages:
    - 352
    - 359
    acknowledged: '2016-01-29'
    online: '2016-05-01'
    CRANpkgs: RSQLite
    BIOpkgs:
    - Biostrings
    - DECIPHER
  - slug: RJ-2016-026
    old_slug: keyes-rudis-jacobs
    title: R Packages to Aid in Handling Web Access Logs
    bibtitle: R Packages to Aid in Handling Web Access Logs
    author:
    - Oliver Keyes
    - Bob Rudis
    - Jay Jacobs
    bibauthor: Oliver Keyes and Bob Rudis and Jay Jacobs
    landing: '2016'
    abstract: '  Abstract Web access logs contain information on HTTP(S) requests
      and form a key part of both            industry and academic explorations of
      human behaviour on the internet. But the preparation (reading,            parsing
      and manipulation) of that data is just unique enough to make generalized tools
      unfit for the            task, both in programming time and processing time
      which are compounded when dealing with large            data sets common with
      web access logs. In this paper we explain and demonstrate a series of packages            designed
      to efficiently read in, parse and munge access log data, allowing researchers
      to handle URLs            and IP addresses easily. These packages are substantially
      faster than existing R methods from a            3-500% speedup for file reading
      to a 57,000% speedup in URL parsing.'
    pages:
    - 360
    - 366
    acknowledged: '2016-01-29'
    online: '2016-06-13'
    CRANpkgs:
    - httr
    - ApacheLogProcessor
    - webreadr
    - readr
    - microbenchmark
    - urltools
    - httr
    - XML
    - lubridate
    - iptools
    - rgeolocate
    - Rcpp
    CTV_rev:
    - WebTechnologies
    - HighPerformanceComputing
    - NumericalMathematics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-027
    old_slug: feys
    title: Nonparametric Tests for the Interaction in Two-way Factorial Designs Using
      R
    bibtitle: |-
      Nonparametric Tests for the Interaction in Two-way Factorial
                Designs Using R
    author: Jos Feys
    bibauthor: Jos Feys
    landing: '2016'
    abstract: '  Abstract An increasing number of R packages include nonparametric
      tests for the interaction in            two-way factorial designs. This paper
      briefly describes the different methods of testing and reports            the
      resulting p-values of such tests on datasets for four types of designs: between,
      within, mixed, and            pretest-posttest designs. Potential users are
      advised only to apply tests they are quite familiar with            and not
      be guided by p-values for selecting packages and tests.'
    pages:
    - 367
    - 378
    acknowledged: '2016-02-28'
    online: '2016-07-27'
    CRANpkgs:
    - WRS2
    - nparLD
    - coin
    - lmPerm
    - perm
    - ez
    - boot
    - ART
    - ARTool
    - npIntFactRep
    - Rfit
    - StatMethRank
    - outliers
    - npsm
    - cocor
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - ExperimentalDesign
    - Optimization
    - Psychometrics
    - Robust
    - SocialSciences
    - TimeSeries
  - slug: RJ-2016-028
    old_slug: yozgatligil-dag
    title: 'GMDH: An R Package for Short Term Forecasting via GMDH-Type Neural Network
      Algorithms'
    bibtitle: |-
      GMDH: An R Package for Short Term Forecasting via GMDH-Type
                Neural Network Algorithms
    author:
    - Osman Dag
    - Ceylan Yozgatligil
    bibauthor: Osman Dag and Ceylan Yozgatligil
    landing: '2016'
    abstract: '  Abstract Group Method of Data Handling (GMDH)-type neural network
      algorithms are the heuristic            self organization method for the modelling
      of complex systems. GMDH algorithms are utilized            for a variety of
      purposes, examples include identification of physical laws, the extrapolation
      of            physical fields, pattern recognition, clustering, the approximation
      of multidimensional processes,            forecasting without models, etc. In
      this study, the R package GMDH is presented to make short term            forecasting
      through GMDH-type neural network algorithms. The GMDH package has options to
      use            different transfer functions (sigmoid, radial basis, polynomial,
      and tangent functions) simultaneously            or separately. Data on cancer
      death rate of Pennsylvania from 1930 to 2000 are used to illustrate the            features
      of the GMDH package. The results based on ARIMA models and exponential smoothing            methods
      are included for comparison.'
    pages:
    - 379
    - 386
    acknowledged: '2016-03-10'
    online: '2016-06-13'
    CRANpkgs:
    - glarma
    - ftsa
    - MARSS
    - ensembleBMA
    - ProbForecastGOP
    - forecast
    CTV_rev:
    - TimeSeries
    - Bayesian
    - Econometrics
    - Environmetrics
    - Finance
  - slug: RJ-2016-029
    old_slug: winslow-chamberlain-appling-etal
    title: 'sbtools: A Package Connecting R to Cloud-based Data for Collaborative
      Online Research'
    bibtitle: |-
      sbtools: A Package Connecting R to Cloud-based Data for
                Collaborative Online Research
    author:
    - Luke A Winslow
    - Scott Chamberlain
    - Alison P Appling
    - Jordan S Read
    bibauthor: |-
      Luke A Winslow and Scott Chamberlain and Alison P Appling
                and Jordan S Read
    landing: '2016'
    abstract: '  Abstract The adoption of high-quality tools for collaboration and
      reproducibile research such as R            and Github is becoming more common
      in many research fields. While Github and other version            management
      systems are excellent resources, they were originally designed to handle code
      and scale            poorly to large text-based or binary datasets. A number
      of scientific data repositories are coming            online and are often focused
      on dataset archival and publication. To handle collaborative workflows            using
      large scientific datasets, there is increasing need to connect cloud-based online
      data storage to            R. In this article, we describe how the new R package
      sbtools enables direct access to the advanced            online data functionality
      provided by ScienceBase, the U.S. Geological Survey’s online scientific data            storage
      platform.'
    pages:
    - 387
    - 398
    acknowledged: '2016-04-30'
    online: '2016-07-23'
  - heading: News and Notes
  - title: 'Conference Report: useR! 2016'
    author: Joe Rickert
    slug: user2016
    bibtitle: 'Conference Report: {useR}! 2016'
    pages:
    - 399
    - 401
  - title: Changes on CRAN
    author:
    - Kurt Hornik
    - Achim Zeileis
    slug: cran
    bibtitle: Changes on {CRAN}
    pages:
    - 402
    - 403
  - title: News from the Bioconductor Project
    author: The Bioconductor Team
    slug: bioconductor
    pages:
    - 404
    - 405
  - title: Changes in R
    author: The R Core Team
    slug: r-changes
    bibtitle: Changes in {R}
    pages:
    - 406
    - 415
- issue: 2016-2
  year: 2016
  volume: 8
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - title: Editorial
    author: Michael Lawrence
    slug: editorial
    pages:
    - 4
    - 4
  - heading: Contributed Research Articles
  - slug: RJ-2016-030
    old_slug: stoer-samuelsen
    title: 'multipleNCC: Inverse Probability Weighting of Nested Case-Control Data'
    bibtitle: |-
      multipleNCC: Inverse Probability Weighting of Nested Case-
                Control Data
    author:
    - Nathalie C. Støer
    - Sven Ove Samuelsen
    bibauthor: Nathalie C. Støer and Sven Ove Samuelsen
    landing: '2016'
    abstract: '  Abstract Reuse of controls from nested case-control designs can increase
      efficiency in many situations,            for instance with competing risks
      or in other multiple endpoints situations. The matching between            cases
      and controls must be broken when controls are to be used for other endpoints.
      A weighted            analysis can then be performed to take care of the biased
      sampling from the cohort. We present the            R package multipleNCC for
      reuse of controls in nested case-control studies by inverse probability            weighting
      of the partial likelihood. The package handles right-censored, left-truncated
      and additionally            matched data, and varying numbers of sampled controls
      and the whole analysis is carried out using            one simple command. Four
      weight estimators are presented and variance estimation is explained.            The
      package is illustrated by analyzing health survey data from three counties in
      Norway for two            causes of death: cardiovascular disease and death
      from alcohol abuse, liver disease, and accidents and            violence. The
      data set is included in the package.'
    pages:
    - 5
    - 18
    acknowledged: '2015-08-23'
    online: '2016-08-11'
    CRANpkgs:
    - multipleNCC
    - survival
    - mgcv
    - ipw
    - MatchIt
    - NestedCohort
    - survey
    - Epi
    - gam
    CTV_rev:
    - SocialSciences
    - Survival
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Bayesian
    - ClinicalTrials
  - slug: RJ-2016-031
    old_slug: moore-stieha-nolting-etal
    title: 'QPot: An R Package for Stochastic Differential Equation Quasi-Potential
      Analysis'
    bibtitle: |-
      QPot: An R Package for Stochastic Differential Equation
                Quasi-Potential Analysis
    author:
    - Christopher M. Moore
    - Christopher R. Stieha
    - Ben C. Nolting
    - Maria K. Cameron
    - Karen C.            Abbott
    bibauthor: |-
      Christopher M. Moore and Christopher R. Stieha and Ben C.
                Nolting and Maria K. Cameron and Karen C. Abbott
    landing: '2016'
    abstract: '  Abstract QPot (pronounced kyoo + p ät) is an R package for analyzing
      two-dimensional systems of            stochastic differential equations. It
      provides users with a wide range of tools to simulate, analyze,            and
      visualize the dynamics of these systems. One of QPot’s key features is the computation
      of the            quasi-potential, an important tool for studying stochastic
      systems. Quasi-potentials are particularly            useful for comparing the
      relative stabilities of equilibria in systems with alternative stable states.
      This            paper describes QPot’s primary functions, and explains how quasi-potentials
      can yield insights about            the dynamics of stochastic systems. Three
      worked examples guide users through the application of            QPot’s functions.'
    pages:
    - 19
    - 38
    acknowledged: '2015-10-22'
    online: '2016-09-09'
    CRANpkgs:
    - QPot
    - rootSolve
    - deSolve
    - phaseR
    - Sim.DiffProc
    - yuima
    - viridis
    - plot3D
    - rgl
    CTV_rev:
    - DifferentialEquations
    - TimeSeries
    - Finance
    - Graphics
    - Multivariate
    - Pharmacokinetics
    - SpatioTemporal
  - slug: RJ-2016-032
    old_slug: ramazzotti-antoniotti-caravagna-etal
    title: Design of the TRONCO BioConductor Package for TRanslational ONCOlogy
    bibtitle: |-
      Design of the TRONCO BioConductor Package for TRanslational
                ONCOlogy
    author:
    - Marco Antoniotti
    - Giulio Caravagna
    - Luca De Sano
    - Alex Graudenzi
    - Giancarlo Mauri
    - Bud            Mishra
    - Daniele Ramazzotti
    bibauthor: |-
      Marco Antoniotti and Giulio Caravagna and Luca De Sano
                and Alex Graudenzi and Giancarlo Mauri and Bud Mishra and
                Daniele Ramazzotti
    landing: '2016'
    abstract: '  Abstract Models of cancer progression provide insights on the order
      of accumulation of genetic            alterations during cancer development.
      Algorithms to infer such models from the currently available            mutational
      profiles collected from different cancer patients (cross-sectional data) have
      been defined in            the literature since late the 90s. These algorithms
      differ in the way they extract a graphical model of the            events modelling
      the progression, e.g., somatic mutations or copy-number alterations.                  TRONCO
      is an R package for TRanslational ONcology which provides a series of functions            to
      assist the user in the analysis of cross-sectional genomic data and, in particular,
      it implements            algorithms that aim to model cancer progression by
      means of the notion of selective advantage. These            algorithms are
      proved to outperform the current state-of-the-art in the inference of cancer
      progression            models. TRONCO also provides functionalities to load
      input cross-sectional data, set up the execution            of the algorithms,
      assess the statistical confidence in the results, and visualize the models.            Availability.
      Freely available at http://www.bioconductor.org/ under GPL license; project
      hosted            at http://bimib.disco.unimib.it/ and https://github.com/BIMIB-DISCo/TRONCO.            Contact.
      tronco@disco.unimib.it'
    pages:
    - 39
    - 59
    acknowledged: '2015-10-22'
    online: '2016-10-21'
    BIOpkgs: TRONCO
  - slug: RJ-2016-033
    old_slug: guevara-hartmann-mendoza
    title: 'diverse: an R Package to Analyze Diversity in Complex Systems'
    bibtitle: |-
      diverse: an R Package to Analyze Diversity in Complex
                Systems
    author:
    - Miguel R. Guevara
    - Dominik Hartmann
    - Marcelo Mendoza
    bibauthor: Miguel R. Guevara and Dominik Hartmann and Marcelo Mendoza
    landing: '2016'
    abstract: '  Abstract The package diverse provides an easy-to-use interface to
      calculate and visualize different            aspects of diversity in complex
      systems. In recent years, an increasing number of research projects in            social
      and interdisciplinary sciences, including fields like innovation studies, scientometrics,
      economics,            and network science have emphasized the role of diversification
      and sophistication of socioeconomic            systems. However, so far no dedicated
      package exists that covers the needs of these emerging fields            and
      interdisciplinary teams. Most packages about diversity tend to be created according
      to the            demands and terminology of particular areas of natural and
      biological sciences. The package diverse            uses interdisciplinary concepts
      of diversity—like variety, disparity and balance— as well as ubiquity            and
      revealed comparative advantages, that are relevant to many fields of science,
      but are in particular            useful for interdisciplinary research on diversity
      in socioeconomic systems. The package diverse            provides a toolkit
      for social scientists, interdisciplinary researcher, and beginners in ecology
      to (i)            import data, (ii) calculate different data transformations
      and normalization like revealed comparative            advantages, (iii) calculate
      different diversity measures, and (iv) connect diverse to other specialized
      R            packages on similarity measures, data visualization techniques,
      and statistical significance tests. The            comprehensiveness of the
      package, from matrix import and transformations options, over similarity            and
      diversity measures, to data visualization methods, makes it a useful package
      to explore different            dimensions of diversity in complex systems.'
    pages:
    - 60
    - 78
    acknowledged: '2015-11-10'
    online: '2016-12-12'
    CRANpkgs:
    - entropart
    - vegan
    - biodiversityR
    - Blaunet
    - diveRsity
    - divo
    - FD
    - hierDiversity
    - simboot
    - treescape
    - SYNCSA
    - diverse
    - proxy
    - pheatmap
    - treemap
    - igraph
    - foreign
    - spadeR
    CTV_rev:
    - Environmetrics
    - Multivariate
    - OfficialStatistics
    - Phylogenetics
    - Spatial
    - gR
    - Graphics
    - Optimization
    - Psychometrics
  - slug: RJ-2016-034
    old_slug: touloumis
    title: 'Simulating Correlated Binary and Multinomial Responses under Marginal
      Model Specification: The SimCorMultRes Package'
    bibtitle: |-
      Simulating Correlated Binary and Multinomial Responses under
                Marginal Model Specification: The SimCorMultRes Package
    author: Anestis Touloumis
    bibauthor: Anestis Touloumis
    landing: '2016'
    abstract: '  Abstract We developed the R package SimCorMultRes to facilitate simulation
      of correlated categori           cal (binary and multinomial) responses under
      a desired marginal model specification. The simulated            correlated
      categorical responses are obtained by applying threshold approaches to correlated
      contin           uous responses of underlying regression models and the dependence
      structure is parametrized in            terms of the correlation matrix of the
      latent continuous responses. This article provides an elaborate            introduction
      to the SimCorMultRes package demonstrating its design and usage via three examples.            The
      package can be obtained via CRAN.'
    pages:
    - 79
    - 91
    acknowledged: '2015-12-14'
    online: '2016-09-09'
    CRANpkgs:
    - SimCorMultRes
    - GenOrd
    - MultiOrd
    - mvtBinaryEP
    - multgee
    CTV_rev:
    - Distributions
    - SocialSciences
  - slug: RJ-2016-035
    old_slug: collingwood-oskooii-garciarios-etal
    title: 'eiCompare: Comparing Ecological Inference Estimates across EI and EI:RC'
    bibtitle: |-
      eiCompare: Comparing Ecological Inference Estimates across
                EI and EI:RC
    author:
    - Loren Collingwood
    - Kassra Oskooii
    - Sergio Garcia-Rios
    - Matt Barreto
    bibauthor: |-
      Loren Collingwood and Kassra Oskooii and Sergio Garcia-Rios
                and Matt Barreto
    landing: '2016'
    abstract: '  Abstract Social scientists and statisticians often use aggregate
      data to predict individual-level behavior            because the latter are
      not always available. Various statistical techniques have been developed to            make
      inferences from one level (e.g., precinct) to another level (e.g., individual
      voter) that minimize            errors associated with ecological inference.
      While ecological inference has been shown to be highly            problematic
      in a wide array of scientific fields, many political scientists and analysis
      employ the            techniques when studying voting patterns. Indeed, federal
      voting rights lawsuits now require such            an analysis, yet expert reports
      are not consistent in which type of ecological inference is used. This            is
      especially the case in the analysis of racially polarized voting when there
      are multiple candidates            and multiple racial groups. The eiCompare
      package was developed to easily assess two of the more            common ecological
      inference methods: EI and EI:R×C. The package facilitates a seamless comparison            between
      these methods so that scholars and legal practitioners can easily assess the
      two methods and            whether they produce similar or disparate findings.'
    pages:
    - 92
    - 101
    acknowledged: '2016-01-06'
    online: '2016-09-09'
    CRANpkgs:
    - ei
    - eiPack
    - eiCompare
  - slug: RJ-2016-036
    old_slug: vitolo-fry-buytaert
    title: 'rnrfa: An R package to Retrieve, Filter and Visualize Data from the UK
      National River Flow Archive'
    bibtitle: |-
      rnrfa: An R package to Retrieve, Filter and Visualize Data
                from the UK National River Flow Archive
    author:
    - Claudia Vitolo
    - Matthew Fry
    - Wouter Buytaert
    bibauthor: Claudia Vitolo and Matthew Fry and Wouter Buytaert
    landing: '2016'
    abstract: '  Abstract The UK National River Flow Archive (NRFA) stores several
      types of hydrological data and            metadata: daily river flow and catchment
      rainfall time series, gauging station and catchment informa           tion.
      Data are served through the NRFA web services via experimental RESTful APIs.
      Obtaining NRFA            data can be unwieldy due to complexities in handling
      HTTP GET requests and parsing responses in            JSON and XML formats.
      The rnrfa package provides a set of functions to programmatically access,            filter,
      and visualize NRFA data using simple R syntax. This paper describes the structure
      of the rnrfa            package, including examples using the main functions
      gdf() and cmr() for flow and rainfall data,            respectively. Visualization
      examples are also provided with a shiny web application and functions            provided
      in the package. Although this package is regional specific, the general framework
      and            structure could be applied to similar databases.'
    pages:
    - 102
    - 116
    acknowledged: '2016-01-29'
    online: '2017-01-03'
    CRANpkgs:
    - rnrfa
    - rnoaa
    - waterData
    - RNCEP
    - shiny
    - leaflet
    - rmarkdown
    - DT
    - dplyr
    - cowplot
    - plyr
    - httr
    - xml2
    - stringr
    - xts
    - rjson
    - ggmap
    - ggplot2
    - rgdal
    - sp
    - ggrepel
    - devtools
    - microbenchmark
    - cranlogs
    - evd
    - outliers
    - spacetime
    - sos4R
    CTV_rev:
    - WebTechnologies
    - Spatial
    - SpatioTemporal
    - ReproducibleResearch
    - Distributions
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - Finance
    - Graphics
    - Phylogenetics
    - TimeSeries
  - slug: RJ-2016-037
    old_slug: geraci
    title: 'Qtools: A Collection of Models and Tools for Quantile Inference'
    bibtitle: |-
      Qtools: A Collection of Models and Tools for Quantile
                Inference
    author: Marco Geraci
    bibauthor: Marco Geraci
    landing: '2016'
    abstract: '  Abstract Quantiles play a fundamental role in statistics. The quantile
      function defines the distribution            of a random variable and, thus,
      provides a way to describe the data that is specular but equivalent            to
      that given by the corresponding cumulative distribution function. There are
      many advantages in            working with quantiles, starting from their properties.
      The renewed interest in their usage seen in the            last years is due
      to the theoretical, methodological, and software contributions that have broadened            their
      applicability. This paper presents the R package Qtools, a collection of utilities
      for unconditional            and conditional quantiles.'
    pages:
    - 117
    - 138
    acknowledged: '2016-09-15'
    online: '2016-12-12'
    CRANpkgs:
    - quantreg
    - bayesQR
    - BSquare
    - lqmm
    - Qtools
    - boot
    - Rearrangement
    - mice
    CTV_rev:
    - SocialSciences
    - Bayesian
    - Econometrics
    - Optimization
    - Robust
    - Survival
    - Environmetrics
    - Multivariate
    - OfficialStatistics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-038
    old_slug: bacci-bartolucci
    title: Two-Tier Latent Class IRT Models in R
    bibtitle: Two-Tier Latent Class IRT Models in R
    author:
    - Silvia Bacci
    - Francesco Bartolucci
    bibauthor: Silvia Bacci and Francesco Bartolucci
    landing: '2016'
    abstract: '  Abstract In analyzing data deriving from the administration of a
      questionnaire to a group of individu           als, Item Response Theory (IRT)
      models provide a flexible framework to account for several aspects            involved
      in the response process, such as the existence of multiple latent traits. In
      this paper, we focus            on a class of semi-parametric multidimensional
      IRT models, in which these traits are represented            through one or
      more discrete latent variables; these models allow us to cluster individuals
      into homo           geneous latent classes and, at the same time, to properly
      study item characteristics. In particular, we            follow a within-item
      multidimensional formulation similar to that adopted in the two-tier models,            with
      each item measuring one or two latent traits. The proposed class of models may
      be estimated            through the package MLCIRTwithin, whose functioning
      is illustrated in this paper with examples            based on data about quality-of-life
      measurement and about the propensity to commit a crime.'
    pages:
    - 139
    - 166
    acknowledged: '2016-02-28'
    online: '2016-09-09'
    CRANpkgs:
    - MLCIRTwithin
    - MultiLCIRT
    - CDM
    - mirt
    - flirt
    - covLCA
    - lavaan
    - OpenMx
    - LMest
    CTV_rev:
    - Psychometrics
    - Econometrics
    - OfficialStatistics
  - slug: RJ-2016-039
    old_slug: lombardo-beh
    title: Variants of Simple Correspondence Analysis
    bibtitle: Variants of Simple Correspondence Analysis
    author:
    - Rosaria Lombardo
    - Eric J. Beh
    bibauthor: Rosaria Lombardo and Eric J. Beh
    landing: '2016'
    abstract: '  Abstract This paper presents the R package CAvariants (Lombardo and
      Beh, 2017). The package            performs six variants of correspondence analysis
      on a two-way contingency table. The main function            that shares the
      same name as the package – CAvariants – allows the user to choose (via a series
      of            input parameters) from six different correspondence analysis procedures.
      These include the classical            approach to (symmetrical) correspondence
      analysis, singly ordered correspondence analysis, doubly            ordered
      correspondence analysis, non symmetrical correspondence analysis, singly ordered
      non            symmetrical correspondence analysis and doubly ordered non symmetrical
      correspondence analysis.            The code provides the flexibility for constructing
      either a classical correspondence plot or a biplot            graphical display.
      It also allows the user to consider other important features that allow to assess
      the            reliability of the graphical representations, such as the inclusion
      of algebraically derived elliptical            confidence regions. This paper
      provides R functions that elaborates more fully on the code presented            in
      Beh and Lombardo (2014).'
    pages:
    - 167
    - 184
    acknowledged: '2016-02-28'
    online: '2016-10-21'
    CRANpkgs:
    - MASS
    - ca
    - anacor
    - FactoMineR
    - cabootcrs
    - CAinterprTools
    - homals
    - dualScale
    - ExPosition
    - vegan
    - ade4
    - cncaGUI
    - PTAk
    - CAvariants
    CTV_rev:
    - Psychometrics
    - Multivariate
    - Environmetrics
    - ChemPhys
    - Spatial
    - Distributions
    - Econometrics
    - Graphics
    - MedicalImaging
    - NumericalMathematics
    - Pharmacokinetics
    - Phylogenetics
    - Robust
    - SocialSciences
  - slug: RJ-2016-040
    old_slug: spindler-chernozhukov-hansen
    title: 'hdm: High-Dimensional Metrics'
    bibtitle: 'hdm: High-Dimensional Metrics'
    author:
    - Victor Chernozhukov
    - Chris Hansen
    - Martin Spindler
    bibauthor: Victor Chernozhukov and Chris Hansen and Martin Spindler
    landing: '2016'
    abstract: '  Abstract In this article the package High-dimensional Metrics hdm
      is introduced. It is a collection of            statistical methods for estimation
      and quantification of uncertainty in high-dimensional approximately            sparse
      models. It focuses on providing confidence intervals and significance testing
      for (possibly many)            low-dimensional subcomponents of the high-dimensional
      parameter vector. Efficient estimators and            uniformly valid confidence
      intervals for regression coefficients on target variables (e.g., treatment or            policy
      variable) in a high-dimensional approximately sparse regression model, for average
      treatment            effect (ATE) and average treatment effect for the treated
      (ATET), as well for extensions of these param           eters to the endogenous
      setting are provided. Theory grounded, data-driven methods for selecting            the
      penalization parameter in Lasso regressions under heteroscedastic and non-Gaussian
      errors are            implemented. Moreover, joint/ simultaneous confidence
      intervals for regression coefficients of a            high-dimensional sparse
      regression are implemented. Data sets which have been used in the literature            and
      might be useful for classroom demonstration and for testing new estimators are
      included.'
    pages:
    - 185
    - 199
    acknowledged: '2016-02-28'
    online: '2016-09-09'
    CRANpkgs:
    - glmnet
    - lars
    - hdm
    CTV_rev:
    - MachineLearning
    - Survival
  - slug: RJ-2016-041
    old_slug: young
    title: Normal Tolerance Interval Procedures in the tolerance Package
    bibtitle: |-
      Normal Tolerance Interval Procedures in the tolerance
                Package
    author: Derek S. Young
    bibauthor: Derek S. Young
    landing: '2016'
    abstract: '  Abstract Statistical tolerance intervals are used for a broad range
      of applications, such as quality            control, engineering design tests,
      environmental monitoring, and bioequivalence testing. tolerance            is
      the only R package devoted to procedures for tolerance intervals and regions.
      Perhaps the most            commonly-employed functions of the package involve
      normal tolerance intervals. A number of new            procedures for this setting
      have been included in recent versions of tolerance. In this paper, we discuss            and
      illustrate the functions that implement these normal tolerance interval procedures,
      one of which            is a new, novel type of operating characteristic curve.'
    pages:
    - 200
    - 212
    acknowledged: '2016-02-28'
    online: '2017-01-03'
    CRANpkgs:
    - tolerance
    - cranlogs
    - rgl
    CTV_rev:
    - Distributions
    - Graphics
    - Multivariate
    - SpatioTemporal
  - slug: RJ-2016-042
    old_slug: goksuluk-korkmaz-zararsiz-etal
    title: 'easyROC: An Interactive Web-tool for ROC Curve Analysis Using R Language
      Environment'
    bibtitle: |-
      easyROC: An Interactive Web-tool for ROC Curve Analysis
                Using R Language Environment
    author:
    - Dincer Goksuluk
    - Selcuk Korkmaz
    - Gokmen Zararsiz
    - A. Ergun Karaagaoglu
    bibauthor: |-
      Dincer Goksuluk and Selcuk Korkmaz and Gokmen Zararsiz and
                A. Ergun Karaagaoglu
    landing: '2016'
    abstract: '  Abstract ROC curve analysis is a fundamental tool for evaluating
      the performance of a marker in a            number of research areas, e.g.,
      biomedicine, bioinformatics, engineering etc., and is frequently used            for
      discriminating cases from controls. There are a number of analysis tools which
      are used to guide            researchers through their analysis. Some of these
      tools are commercial and provide basic methods            for ROC curve analysis
      while others offer advanced analysis techniques and a command-based user            interface,
      such as the R environment. The R environmentg includes comprehensive tools for
      ROC curve            analysis; however, using a command-based interface might
      be challenging and time consuming when a            quick evaluation is desired;
      especially for non-R users, physicians etc. Hence, a quick, comprehensive,            free
      and easy-to-use analysis tool is required. For this purpose, we developed a
      user-friendly web           tool based on the R language. This tool provides
      ROC statistics, graphical tools, optimal cutpoint            calculation, comparison
      of several markers, and sample size estimation to support researchers in their            decisions
      without writing R codes. easyROC can be used via any device with an internet
      connection            independently of the operating system. The web interface
      of easyROC is constructed with the R            package shiny. This tool is
      freely available through www.biosoft.hacettepe.edu.tr/easyROC.'
    pages:
    - 213
    - 230
    acknowledged: '2016-02-28'
    online: '2016-12-23'
    CRANpkgs:
    - ROCR
    - pROC
    - OptimalCutpoints
    - shiny
    - plotROC
    - plyr
    BIOpkgs: ROC
    CTV_rev:
    - MachineLearning
    - Multivariate
    - WebTechnologies
  - slug: RJ-2016-043
    old_slug: walker
    title: 'tigris: An R Package to Access and Work with Geographic Data from the
      US Census Bureau'
    bibtitle: |-
      tigris: An R Package to Access and Work with Geographic Data
                from the US Census Bureau
    author: Kyle Walker
    bibauthor: Kyle Walker
    landing: '2016'
    abstract: '  Abstract TIGER/Line shapefiles from the United States Census Bureau
      are commonly used for the            mapping and analysis of US demographic
      trends. The tigris package provides a uniform interface            for R users
      to download and work with these shapefiles. Functions in tigris allow R users
      to request            Census geographic datasets using familiar geographic identifiers
      and return those datasets as objects            of class "Spatial*DataFrame".
      In turn, tigris ensures consistent and high-quality spatial data for R            users’
      cartographic and spatial analysis projects that involve US Census data. This
      article provides            an overview of the functionality of the tigris package,
      and concludes with an applied example of a            geospatial workflow using
      data retrieved with tigris.'
    pages:
    - 231
    - 242
    acknowledged: '2016-02-28'
    online: '2016-08-11'
    CRANpkgs:
    - tigris
    - rgdal
    - sp
    - UScensus2010
    - USABoundaries
    - choroplethr
    - ggplot2
    - sp
    - rappdirs
    - dplyr
    - tmap
    - shiny
    - leaflet
    - devtools
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Graphics
    - OfficialStatistics
    - Phylogenetics
    - WebTechnologies
  - slug: RJ-2016-044
    old_slug: schloerke-wickham-cook-etal
    title: Escape from Boxland
    bibtitle: Escape from Boxland
    author:
    - Barret Schloerke
    - Hadley Wickham
    - Dianne Cook
    - Heike Hofmann
    bibauthor: |-
      Barret Schloerke and Hadley Wickham and Dianne Cook and
                Heike Hofmann
    landing: '2016'
    abstract: '  Abstract A library of common geometric shapes can be used to train
      our brains for understanding data            structure in high-dimensional Euclidean
      space. This article describes the methods for producing cubes,            spheres,
      simplexes, and tori in multiple dimensions. It also describes new ways to define
      and generate            high-dimensional tori. The algorithms are described,
      critical code chunks are given, and a large            collection of generated
      data are provided. These are available in the R package geozoo, and selected            movies
      and images, are available on the GeoZoo web site (http://schloerke.github.io/geozoo/).'
    pages:
    - 243
    - 257
    acknowledged: '2016-03-10'
    online: '2016-11-21'
    CRANpkgs:
    - geozoo
    - tourr
    - bitops
    - geozoo
    - geozoo
    CTV_rev: Multivariate
  - slug: RJ-2016-045
    old_slug: some-wansouwe-kokonendji
    title: 'Ake: An R Package for Discrete and Continuous Associated Kernel Estimations'
    bibtitle: |-
      Ake: An R Package for Discrete and Continuous Associated
                Kernel Estimations
    author:
    - Wanbitching E. Wansouwé
    - Sobom M. Somé
    - Célestin C. Kokonendji
    bibauthor: |-
      Wanbitching E. Wansouwé and Sobom M. Somé and Célestin C.
                Kokonendji
    landing: '2016'
    abstract: '  Abstract Kernel estimation is an important technique in exploratory
      data analysis. Its utility relies            on its ease of interpretation,
      especially based on graphical means. The Ake package is introduced            for
      univariate density or probability mass function estimation and also for continuous
      and discrete            regression functions using associated kernel estimators.
      These associated kernels have been proposed            due to their specific
      features of variables of interest. The package focuses on associated kernel
      methods            appropriate for continuous (bounded, positive) or discrete
      (count, categorical) data often found in            applied settings. Furthermore,
      optimal bandwidths are selected by cross-validation for any associated            kernel
      and by Bayesian methods for the binomial kernel. Other Bayesian methods for
      selecting            bandwidths with other associated kernels will complete
      this package in its future versions; particularly,            a Bayesian adaptive
      method for gamma kernel estimation of density functions is developed. Some            practical
      and theoretical aspects of the normalizing constant in both density and probability
      mass            functions estimations are given.'
    pages:
    - 258
    - 276
    acknowledged: '2016-03-10'
    online: '2016-12-12'
    CRANpkgs: Ake
  - slug: RJ-2016-046
    old_slug: sachs-gabriel
    title: An Introduction to Principal Surrogate Evaluation with the pseval Package
    bibtitle: |-
      An Introduction to Principal Surrogate Evaluation with the
                pseval Package
    author:
    - Michael C. Sachs
    - Erin E. Gabriel
    bibauthor: Michael C. Sachs and Erin E. Gabriel
    landing: '2016'
    abstract: '  Abstract We describe a new package called pseval that implements
      the core methods for the evaluation            of principal surrogates in a
      single clinical trial. It provides a flexible interface for defining models
      for            the risk given treatment and the surrogate, the models for integration
      over the missing counterfactual            surrogate responses, and the estimation
      methods. Estimated maximum likelihood and pseudo-score            can be used
      for estimation, and the bootstrap for inference. A variety of post-estimation
      methods are            provided, including print, summary, plot, and testing.
      We summarize the main statistical methods            that are implemented in
      the package and illustrate its use from the perspective of a novice R user.'
    pages:
    - 277
    - 292
    acknowledged: '2016-03-19'
    online: '2016-11-21'
    CRANpkgs:
    - pseval
    - survival
    - survey
    - ggplot2
    - lattice
    - Surrogate
    CTV_rev:
    - Graphics
    - SocialSciences
    - Survival
    - ClinicalTrials
    - Econometrics
    - Multivariate
    - OfficialStatistics
    - Pharmacokinetics
    - Phylogenetics
  - slug: RJ-2016-047
    old_slug: deveau-barillot-boeva-etal
    title: Calculating Biological Module Enrichment or Depletion and Visualizing Data
      on Large-scale Molecular Maps with ACSNMineR and RNaviCell Packages
    bibtitle: |-
      Calculating Biological Module Enrichment or Depletion
                and Visualizing Data on Large-scale Molecular Maps with
                ACSNMineR and RNaviCell Packages
    author:
    - Paul Deveau
    - Emmanuel Barillot
    - Valentina Boeva
    - Andrei Zinovyev
    - Eric Bonnet
    bibauthor: |-
      Paul Deveau and Emmanuel Barillot and Valentina Boeva and
                Andrei Zinovyev and Eric Bonnet
    landing: '2016'
    abstract: '  Abstract Biological pathways or modules represent sets of interactions
      or functional relationships            occurring at the molecular level in living
      cells. A large body of knowledge on pathways is organized in            public
      databases such as the KEGG, Reactome, or in more specialized repositories, the
      Atlas of Cancer            Signaling Network (ACSN) being an example. All these
      open biological databases facilitate analyses,            improving our understanding
      of cellular systems. We hereby describe ACSNMineR for calculation of            enrichment
      or depletion of lists of genes of interest in biological pathways. ACSNMineR
      integrates            ACSN molecular pathways gene sets, but can use any gene
      set encoded as a GMT file, for instance            sets of genes available in
      the Molecular Signatures Database (MSigDB). We also present RNaviCell,            that
      can be used in conjunction with ACSNMineR to visualize different data types
      on web-based,            interactive ACSN maps. We illustrate the functionalities
      of the two packages with biological data            taken from large-scale cancer
      datasets.'
    pages:
    - 293
    - 306
    acknowledged: '2016-04-02'
    online: '2016-10-21'
    CRANpkgs:
    - ACSNMineR
    - RNaviCell
    - ggplot2
    BIOpkgs:
    - GOstats
    - clusterProfiler
    CTV_rev:
    - Graphics
    - Phylogenetics
  - slug: RJ-2016-048
    old_slug: na-charte-na-etal
    title: 'Subgroup Discovery with Evolutionary Fuzzy Systems in R: The SDEFSR Package'
    bibtitle: |-
      Subgroup Discovery with Evolutionary Fuzzy Systems in R: The
                SDEFSR Package
    author:
    - Ángel M. García
    - Francisco Charte
    - Pedro González
    - Cristóbal J. Carmona
    - María J. del Jesus
    bibauthor: |-
      Ángel M. García and Francisco Charte and Pedro González and
                Cristóbal J. Carmona and María J. del Jesus
    landing: '2016'
    abstract: '  Abstract Subgroup discovery is a data mining task halfway between
      descriptive and predictive data            mining. Nowadays it is very relevant
      for researchers due to the fact that the knowledge extracted            is simple
      and interesting. For this task, evolutionary fuzzy systems are well suited algorithms            because
      they can find a good trade-off between multiple objectives in large search spaces.
      In fact, this            paper presents the SDEFSR package, which contains all
      the evolutionary fuzzy systems for subgroup            discovery presented throughout
      the literature. It is a package without dependencies on other software,            providing
      functions with recommended default parameters. In addition, it brings a graphical
      user            interface to avoid the user having to know all the parameters
      of the algorithms.'
    pages:
    - 307
    - 323
    acknowledged: []
    online: '2016-09-09'
    CRANpkgs:
    - rsubgroup
    - SDEFSR
    - devtools
    - mldr
  - slug: RJ-2016-049
    old_slug: pitsillou-fokianos
    title: 'dCovTS: Distance Covariance/Correlation for Time Series'
    bibtitle: 'dCovTS: Distance Covariance/Correlation for Time Series'
    author:
    - Maria Pitsillou
    - Konstantinos Fokianos
    bibauthor: Maria Pitsillou and Konstantinos Fokianos
    landing: '2016'
    abstract: '  Abstract The distance covariance function is a new measure of dependence
      between random vectors.            We drop the assumption of iid data to introduce
      distance covariance for time series. The R package            dCovTS provides
      functions that compute and plot distance covariance and correlation functions            for
      both univariate and multivariate time series. Additionally it includes functions
      for testing serial            independence based on distance covariance. This
      paper describes the theoretical background of            distance covariance
      methodology in time series and discusses in detail the implementation of these            methods
      with the R package dCovTS.'
    pages:
    - 324
    - 340
    acknowledged: '2016-04-18'
    online: '2016-10-21'
    CRANpkgs:
    - energy
    - doParallel
    - portes
    - MTS
    CTV_rev:
    - TimeSeries
    - Multivariate
  - slug: RJ-2016-050
    old_slug: schweiker
    title: 'comf: An R Package for Thermal Comfort Studies'
    bibtitle: 'comf: An R Package for Thermal Comfort Studies'
    author: Marcel Schweiker
    bibauthor: Marcel Schweiker
    landing: '2016'
    abstract: '  Abstract The field of thermal comfort generated a number of thermal
      comfort indices. Their code            implementation needs to be done by individual
      researchers. This paper presents the R package, comf,            which includes
      functions for common and new thermal comfort indices. Additional functions allow            comparisons
      between the predictive performance of these indices. This paper reviews existing
      thermal            comfort indices and available code implementations. This
      is followed by the description of the R            package and an example how
      to use the R package for the comparison of different thermal comfort            indices
      on data from a thermal comfort study.'
    pages:
    - 341
    - 351
    acknowledged: '2016-04-18'
    online: '2016-10-21'
    CRANpkgs: comf
  - slug: RJ-2016-051
    old_slug: olmedo-ortegafarias-delafuentesaiz-etal
    title: 'water: Tools and Functions to Estimate Actual Evapotranspiration Using
      Land Surface Energy Balance Models in R'
    bibtitle: |-
      water: Tools and Functions to Estimate Actual
                Evapotranspiration Using Land Surface Energy Balance Models
                in R
    author:
    - Guillermo Federico Olmedo
    - Samuel Ortega-Farías
    - Daniel de la Fuente-Sáiz
    - David Fonseca-            Luego
    - Fernando Fuentes-Peñailillo
    bibauthor: |-
      Guillermo Federico Olmedo and Samuel Ortega-Farías and
                Daniel de la Fuente-Sáiz and David Fonseca- Luego and
                Fernando Fuentes-Peñailillo
    landing: '2016'
    abstract: '  Abstract The crop water requirement is a key factor in the agricultural
      process. It is usually estimated            throughout actual evapotranspiration
      (ETa ). This parameter is the key to develop irrigation strategies,            to
      improve water use efficiency and to understand hydrological, climatic, and ecosystem
      processes.            Currently, it is calculated with classical methods, which
      are difficult to extrapolate, or with land surface            energy balance
      models (LSEB), such as METRIC and SEBAL, which are based on remote sensing data.            This
      paper describes water, an open implementation of LSEB. The package provides
      several functions            to estimate the parameters of the LSEB equation
      from satellite data and proposes a new object class            to handle weather
      station data. One of the critical steps in METRIC is the selection of “cold”
      and           “hot” pixels, which water solves with an automatic method. The
      water package can process a batch            of satellite images and integrates
      most of the already published sub-models for METRIC. Although            water
      implements METRIC, it will be expandable to SEBAL and others in the near future.
      Finally, two            different procedures are demonstrated using data that
      is included in water package.'
    pages:
    - 352
    - 369
    acknowledged: '2016-04-30'
    online: '2016-12-12'
    CRANpkgs:
    - raster
    - raster
    CTV_rev:
    - Spatial
    - SpatioTemporal
  - slug: RJ-2016-052
    old_slug: lipsitz-belloni-chernozhukov-etal
    title: 'quantreg.nonpar: An R Package for Performing Nonparametric Series Quantile
      Regression'
    bibtitle: |-
      quantreg.nonpar: An R Package for Performing Nonparametric
                Series Quantile Regression
    author:
    - Michael Lipsitz
    - Alexandre Belloni
    - Victor Chernozhukov
    - Iván Fernández-Val
    bibauthor: |-
      Michael Lipsitz and Alexandre Belloni and Victor
                Chernozhukov and Iván Fernández-Val
    landing: '2016'
    abstract: '  Abstract The R package quantreg.nonpar implements nonparametric quantile
      regression methods            to estimate and make inference on partially linear
      quantile models. quantreg.nonpar obtains point            estimates of the conditional
      quantile function and its derivatives based on series approximations to            the
      nonparametric part of the model. It also provides pointwise and uniform confidence
      intervals            over a region of covariate values and/or quantile indices
      for the same functions using analytical            and resampling methods. This
      paper serves as an introduction to the package and displays basic            functionality
      of the functions contained within.'
    pages:
    - 370
    - 381
    acknowledged: '2016-04-30'
    online: '2016-11-21'
    CRANpkgs:
    - quantreg.nonpar
    - quantreg
    - QuantifQuantile
    - quantregGrowth
    - fda
    CTV_rev:
    - Environmetrics
    - Econometrics
    - Optimization
    - ReproducibleResearch
    - Robust
    - SocialSciences
    - Survival
  - slug: RJ-2016-053
    old_slug: koitka-friedrich
    title: 'nmfgpu4R: GPU-Accelerated Computation of the Non-Negative Matrix Factorization
      (NMF) Using CUDA Capable Hardware'
    bibtitle: |-
      nmfgpu4R: GPU-Accelerated Computation of the Non-Negative
                Matrix Factorization (NMF) Using CUDA Capable Hardware
    author:
    - Sven Koitka
    - Christoph M. Friedrich
    bibauthor: Sven Koitka and Christoph M. Friedrich
    landing: '2016'
    abstract: '  Abstract In this work, a novel package called nmfgpu4R is presented,
      which offers the computation            of Non-negative Matrix Factorization
      (NMF) on Compute Unified Device Architecture (CUDA) platforms            within
      the R environment. Benchmarks show a remarkable speed-up in terms of time per
      iteration            by utilizing the parallelization capabilities of modern
      graphics cards. Therefore the application of            NMF gets more attractive
      for real-world sized problems because the time to compute a factorization is            reduced
      by an order of magnitude.'
    pages:
    - 382
    - 392
    acknowledged: '2016-04-30'
    online: '2016-11-21'
    CRANpkgs:
    - NMF
    - NMFN
    - nmfgpu4R
    - Matrix
    - SparseM
    CTV_rev:
    - Econometrics
    - Multivariate
    - NumericalMathematics
  - slug: RJ-2016-054
    old_slug: roocks
    title: Computing Pareto Frontiers and Database Preferences with the rPref Package
    bibtitle: |-
      Computing Pareto Frontiers and Database Preferences with the
                rPref Package
    author: Patrick Roocks
    bibauthor: Patrick Roocks
    landing: '2016'
    abstract: ' Abstract The concept of Pareto frontiers is well-known in economics.
      Within the database community           there exist many different solutions
      for the specification and calculation of Pareto frontiers, also called           Skyline
      queries in the database context. Slight generalizations like the combination
      of the Pareto           operator with the lexicographical order have been established
      under the term database preferences. In           this paper we present the
      rPref package which allows to efficiently deal with these concepts within           R.
      With its help, database preferences can be specified in a very similar way as
      in a state-of-the-art           database management system. Our package provides
      algorithms for an efficient calculation of the           Pareto-optimal set
      and further functionalities for visualizing and analyzing the induced preference           order.'
    pages:
    - 393
    - 404
    acknowledged: '2016-05-10'
    online: '2017-01-03'
    CRANpkgs:
    - rPref
    - emoa
    - mco
    - TunePareto
    - dplyr
    - lazyeval
    - RcppParallel
    - igraph
    - ggplot2
    BIOpkgs: Rgraphviz
    CTV_rev:
    - Graphics
    - Optimization
    - gR
    - HighPerformanceComputing
    - Phylogenetics
    - Spatial
  - slug: RJ-2016-055
    old_slug: fachada-rodrigues-lopes-etal
    title: 'micompr: An R Package for Multivariate Independent Comparison of Observations'
    bibtitle: |-
      micompr: An R Package for Multivariate Independent
                Comparison of Observations
    author:
    - Nuno Fachada
    - João Rodrigues
    - Vitor V. Lopes
    - Rui C. Martins
    - Agostinho C. Rosa
    bibauthor: |-
      Nuno Fachada and João Rodrigues and Vitor V. Lopes and Rui
                C. Martins and Agostinho C. Rosa
    landing: '2016'
    abstract: '  Abstract The R package micompr implements a procedure for assessing
      if two or more multivariate            samples are drawn from the same distribution.
      The procedure uses principal component analysis to            convert multivariate
      observations into a set of linearly uncorrelated statistical measures, which
      are then            compared using a number of statistical methods. This technique
      is independent of the distributional            properties of samples and automatically
      selects features that best explain their differences. The            procedure
      is appropriate for comparing samples of time series, images, spectrometric measures
      or            similar high-dimension multivariate observations.'
    pages:
    - 405
    - 420
    acknowledged: '2016-05-10'
    online: '2016-11-21'
    CRANpkgs:
    - micompr
    - vegan
    - Blossom
    - energy
    - crossmatch
    - cramer
    - ks
    - ChemoSpec
    - biotools
    - MVN
    - testthat
    - knitr
    - roxygen2
    - deseasonalize
    CTV_rev:
    - Multivariate
    - ChemPhys
    - Environmetrics
    - Phylogenetics
    - Psychometrics
    - ReproducibleResearch
    - Spatial
    - TimeSeries
  - slug: RJ-2016-056
    old_slug: zhu-chen
    title: 'mixtox: An R Package for Mixture Toxicity Assessment'
    bibtitle: 'mixtox: An R Package for Mixture Toxicity Assessment'
    author:
    - Xiang-Wei Zhu
    - Jian-Yi Chen
    bibauthor: Xiang-Wei Zhu and Jian-Yi Chen
    landing: '2016'
    abstract: '  Abstract Mixture toxicity assessment is indeed necessary for humans
      and ecosystems that are contin           ually exposed to a variety of chemical
      mixtures. This paper describes an R package, called mixtox,            which
      offers a general framework of curve fitting, mixture experimental design, and
      mixture toxicity            prediction for practitioners in toxicology. The
      unique features of mixtox include: (1) constructing a            uniform table
      for mixture experimental design; and (2) predicting toxicity of a mixture with
      multiple            components based on reference models such as concentration
      addition, independent action, and            generalized concentration addition.
      We describe the various functions of the package and provide            examples
      to illustrate their use and show the collaboration of mixtox with other existing
      packages            (e.g., drc) in predicting toxicity of chemical mixtures.'
    pages:
    - 421
    - 433
    acknowledged: '2016-05-10'
    online: '2016-10-21'
  - slug: RJ-2016-057
    old_slug: sola-irigoien-mestres-etal
    title: 'Weighted Distance Based Discriminant Analysis: The R Package WeDiBaDis'
    bibtitle: |-
      Weighted Distance Based Discriminant Analysis: The R Package
                WeDiBaDis
    author:
    - Itziar Irigoien
    - Francesc Mestres
    - Concepcion Arenas
    bibauthor: Itziar Irigoien and Francesc Mestres and Concepcion Arenas
    landing: '2016'
    abstract: '  Abstract The WeDiBaDis package provides a user friendly environment
      to perform discriminant            analysis (supervised classification). WeDiBaDis
      is an easy to use package addressed to the biological            and medical
      communities, and in general, to researchers interested in applied studies. It
      can be            suitable when the user is interested in the problem of constructing
      a discriminant rule on the basis            of distances between a relatively
      small number of instances or units of known unbalanced-class            membership
      measured on many (possibly thousands) features of any type. This is a current
      situation            when analyzing genetic biomedical data. This discriminant
      rule can then be used both, as a means of            explaining differences
      among classes, but also in the important task of assigning the class membership            for
      new unlabeled units. Our package implements two discriminant analysis procedures
      in an R            environment: the well-known distance-based discriminant analysis
      (DB-discriminant) and a weighted           distance-based discriminant (WDB-discriminant),
      a novel classifier rule that we introduce. This new            procedure is
      based on an improvement of the DB rule taking into account the statistical depth
      of the            units. This article presents both classifying procedures and
      describes the implementation of each in            detail. We illustrate the
      use of the package using an ecological and a genetic experimental example.            Finally,
      we illustrate the effectiveness of the new proposed procedure (WDB), as compared
      with DB.            This comparison is carried out using thirty-eight, high-dimensional,
      class-unbalanced, cancer data            sets, three of which include clinical
      features.'
    pages:
    - 434
    - 450
    acknowledged: '2016-05-29'
    online: '2017-01-03'
    CRANpkgs:
    - cluster
    - ICGE
    - vegan
    CTV_rev:
    - Environmetrics
    - Multivariate
    - Cluster
    - Phylogenetics
    - Psychometrics
    - Spatial
  - slug: RJ-2016-058
    old_slug: mori-mori-mendiburu-etal
    title: 'Distance Measures for Time Series in R: The TSdist Package'
    bibtitle: 'Distance Measures for Time Series in R: The TSdist Package'
    author:
    - Usue Mori
    - Alexander Mendiburu
    - Jose A. Lozano
    bibauthor: Usue Mori and Alexander Mendiburu and Jose A. Lozano
    landing: '2016'
    abstract: '  Abstract The definition of a distance measure between time series
      is crucial for many time series data            mining tasks, such as clustering
      and classification. For this reason, a vast portfolio of time series            distance
      measures has been published in the past few years. In this paper, the TSdist
      package is            presented, a complete tool which provides a unified framework
      to calculate the largest variety of            time series dissimilarity measures
      available in R at the moment, to the best of our knowledge. The            package
      implements some popular distance measures which were not previously available
      in R, and            moreover, it also provides wrappers for measures already
      included in other R packages. Additionally,            the application of these
      distance measures to clustering and classification tasks is also supported            in
      TSdist, directly enabling the evaluation and comparison of their performance
      within these two            frameworks.'
    pages:
    - 451
    - 459
    acknowledged: '2016-05-29'
    online: '2016-09-09'
    CRANpkgs:
    - TSdist
    - dtw
    - pdc
    - proxy
    - longitudinalData
    - TSclust
    - zoo
    - xts
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Finance
    - Environmetrics
    - Multivariate
    - SpatioTemporal
  - slug: RJ-2016-059
    old_slug: meiramachado-sestelo
    title: 'condSURV: An R Package for the Estimation of the Conditional Survival
      Function for Ordered Multivariate Failure Time Data'
    bibtitle: |-
      condSURV: An R Package for the Estimation of the Conditional
                Survival Function for Ordered Multivariate Failure Time Data
    author:
    - Luis Meira-Machado
    - Marta Sestelo
    bibauthor: Luis Meira-Machado and Marta Sestelo
    landing: '2016'
    abstract: '  Abstract One major goal in clinical applications of time-to-event
      data is the estimation of survival            with censored data. The usual
      nonparametric estimator of the survival function is the time-honored            Kaplan-Meier
      product-limit estimator. Though this estimator has been implemented in several
      R            packages, the development of the condSURV R package has been motivated
      by recent contributions            that allow the estimation of the survival
      function for ordered multivariate failure time data. The            condSURV
      package provides three different approaches all based on the Kaplan-Meier estimator.            In
      one of these approaches these quantities are estimated conditionally on current
      or past covariate            measures. Illustration of the software usage is
      included using real data.'
    pages:
    - 460
    - 473
    acknowledged: '2016-05-29'
    online: '2017-01-03'
    CRANpkgs:
    - survival
    - prodlim
    - condSURV
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - SocialSciences
  - slug: RJ-2016-060
    old_slug: tang-horikoshi-li
    title: 'ggfortify: Unified Interface to Visualize Statistical Results of Popular
      R Packages'
    bibtitle: |-
      ggfortify: Unified Interface to Visualize Statistical
                Results of Popular R Packages
    author:
    - Yuan Tang
    - Masaaki Horikoshi
    - Wenxuan Li
    bibauthor: Yuan Tang and Masaaki Horikoshi and Wenxuan Li
    landing: '2016'
    abstract: '  Abstract The ggfortify package provides a unified interface that
      enables users to use one line of code            to visualize statistical results
      of many R packages using ggplot2 idioms. With the help of ggfortify,            statisticians,
      data scientists, and researchers can avoid the sometimes repetitive work of
      using the            ggplot2 syntax to achieve what they need.'
    pages:
    - 474
    - 485
    acknowledged: '2016-05-29'
    online: '2016-09-10'
    CRANpkgs:
    - lattice
    - ggplot2
    - ggfortify
    - cluster
    - lfda
    - zoo
    - xts
    - timeSeries
    - forecast
    - changepoint
    - strucchange
    - dlm
    - dplyr
    - tidyr
    - gridExtra
    - scales
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - Environmetrics
    - Graphics
    - Multivariate
    - Bayesian
    - Cluster
    - Pharmacokinetics
    - Phylogenetics
    - SpatioTemporal
  - slug: RJ-2016-061
    old_slug: pebesma-mailund-hiebert
    title: Measurement Units in R
    bibtitle: Measurement Units in R
    author:
    - Edzer Pebesma
    - Thomas Mailund
    - James Hiebert
    bibauthor: Edzer Pebesma and Thomas Mailund and James Hiebert
    landing: '2016'
    abstract: ' Abstract We briefly review SI units, and discuss R packages that deal
      with measurement units,           their compatibility and conversion. Built
      upon udunits2 and the UNIDATA udunits library, we           introduce the package
      units that provides a class for maintaining unit metadata. When used in           expression,
      it automatically converts units, and simplifies units of results when possible;
      in case of           incompatible units, errors are raised. The class flexibly
      allows expansion beyond predefined units.           Using units may eliminate
      a whole class of potential scientific programming mistakes. We discuss           the
      potential and limitations of computing with explicit units.'
    pages:
    - 486
    - 494
    acknowledged: '2016-07-12'
    online: '2016-12-12'
    CRANpkgs:
    - lubridate
    - sp
    - measurements
    - NISTunits
    - udunits2
    - units
    - ggplot2
    - spacetime
    - h5
    - RNetCDF
    - sos4R
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Graphics
    - Phylogenetics
    - ReproducibleResearch
    - TimeSeries
  - slug: RJ-2016-062
    old_slug: imdadullah-aslam-altaf
    title: 'mctest: An R Package for Detection of Collinearity among Regressors'
    bibtitle: |-
      mctest: An R Package for Detection of Collinearity among
                Regressors
    author:
    - Muhammad Imdadullah
    - Muhammad Aslam
    - Saima Altaf
    bibauthor: Muhammad Imdadullah and Muhammad Aslam and Saima Altaf
    landing: '2016'
    abstract: '  Abstract It is common for linear regression models to be plagued
      with the problem of multicollinearity            when two or more regressors
      are highly correlated. This problem results in unstable estimates of            regression
      coefficients and causes some serious problems in validation and interpretation
      of the model.            Different diagnostic measures are used to detect multicollinearity
      among regressors. Many statistical            software and R packages provide
      few diagnostic measures for the judgment of multicollinearity. Most            widely
      used diagnostic measures in these software are: coefficient of determination
      (R2 ), variance            inflation factor/tolerance limit (VIF/TOL), eigenvalues,
      condition number (CN) and condition index            (CI) etc. In this manuscript,
      we present an R package, mctest, that computes popular and widely used            multicollinearity
      diagnostic measures. The package also indicates which regressors may be the
      reason            of collinearity among regressors.'
    pages:
    - 495
    - 505
    acknowledged: '2016-07-12'
    online: '2016-12-12'
    CRANpkgs:
    - mctest
    - perturb
    - HH
    - car
    - fmsb
    - rms
    - faraway
    - usdm
    - VIF
    - leaps
    - bestglm
    - glmulti
    - meifly
    CTV_rev:
    - SocialSciences
    - Econometrics
    - ChemPhys
    - ClinicalTrials
    - Finance
    - Multivariate
    - ReproducibleResearch
    - Survival
  - heading: News and Notes
  - title: R Foundation News
    author: by Torsten Hothorn
    slug: foundation
    bibauthor: by Torsten Hothorn
    pages:
    - 506
    - 506
  - title: Changes on CRAN
    author: by Kurt Hornik and Achim Zeileis
    slug: cran
    bibtitle: Changes on {CRAN}
    bibauthor: by Kurt Hornik and Achim Zeileis
    pages:
    - 507
    - 509
  - title: News from the Bioconductor Project
    author: by Bioconductor Core Team
    slug: bioc
    bibauthor: by Bioconductor Core Team
    pages:
    - 510
    - 510
  - title: Changes in R
    author: by the R Core Team
    slug: ch
    bibtitle: Changes in {R}
    bibauthor: by the R Core Team
    pages:
    - 511
    - 514
- issue: 2017-1
  year: 2017
  volume: 9
  num: 1
  month: June
  bibmonth: jun
  articles:
  - slug: editorial
    author: Roger Bivand
    title: Editorial
    bibtitle: Editorial
    bibauthor: Roger Bivand
    pages:
    - 4
    - 5
  - heading: Contributed Research Articles
  - slug: RJ-2017-001
    title: 'iotools: High-Performance I/O Tools for R'
    bibtitle: 'iotools: High-Performance I/O Tools for R'
    author:
    - Taylor Arnold
    - Michael J. Kane
    - Simon Urbanek
    bibauthor: Taylor Arnold and Michael J. Kane and Simon Urbanek
    abstract: '  Abstract The iotools package provides a set of tools for input and
      output intensive data processing in            R. The functions chunk.apply
      and read.chunk are supplied to allow for iteratively loading contiguous            blocks
      of data into memory as raw vectors. These raw vectors can then be efficiently
      converted            into matrices and data frames with the iotools functions
      mstrsplit and dstrsplit. These functions            minimize copying of data
      and avoid the use of intermediate strings in order to drastically improve            performance.
      Finally, we also provide read.csv.raw to allow users to read an entire dataset
      into            memory with the same efficient parsing code. In this paper,
      we present these functions through a            set of examples with an emphasis
      on the flexibility provided by chunk-wise operations. We provide            benchmarks
      comparing the speed of read.csv.raw to data loading functions provided in base
      R and            other contributed packages.'
    acknowledged: '2015-03-20'
    online: '2017-05-10'
    CRANpkgs:
    - bigmemory
    - ff
    - readr
    - foreach
    - iterators
    - iotools
    - Matrix
    CTV_rev:
    - HighPerformanceComputing
    - Econometrics
    - Multivariate
    - NumericalMathematics
    landing: '2017'
    pages:
    - 6
    - 13
  - slug: RJ-2017-002
    title: 'IsoGeneGUI: Multiple Approaches for Dose-Response Analysis of Microarray
      Data Using R'
    bibtitle: |-
      IsoGeneGUI: Multiple Approaches for Dose-Response Analysis
                of Microarray Data Using R
    author:
    - Martin Otava
    - Rudradev Sengupta
    - Ziv Shkedy
    - Dan Lin
    - Setia Pramana
    - Tobias Verbeke
    - Philippe            Haldermans
    - Ludwig A. Hothorn
    - Daniel Gerhard
    - Rebecca M. Kuiper
    - Florian Klinglmueller
    - '           Adetayo Kasim'
    bibauthor: |-
      Martin Otava and Rudradev Sengupta and Ziv Shkedy and
                Dan Lin and Setia Pramana and Tobias Verbeke and Philippe
                Haldermans and Ludwig A. Hothorn and Daniel Gerhard and
                Rebecca M. Kuiper and Florian Klinglmueller and Adetayo
                Kasim
    abstract: '  Abstract The analysis of transcriptomic experiments with ordered
      covariates, such as dose-response            data, has become a central topic
      in bioinformatics, in particular in omics studies. Consequently,            multiple
      R packages on CRAN and Bioconductor are designed to analyse microarray data
      from various            perspectives under the assumption of order restriction.
      We introduce the new R package IsoGene            Graphical User Interface (IsoGeneGUI),
      an extension of the original IsoGene package that includes            methods
      from most of available R packages designed for the analysis of order restricted
      microarray            data, namely orQA, ORIClust, goric and ORCME. The methods
      included in the new IsoGeneGUI            range from inference and estimation
      to model selection and clustering tools. The IsoGeneGUI is not            only
      the most complete tool for the analysis of order restricted microarray experiments
      available in            R but also it can be used to analyse other types of
      dose-response data. The package provides all the            methods in a user
      friendly fashion, so analyses can be implemented by users with limited knowledge            of
      R programming.'
    acknowledged: '2015-07-22'
    online: '2017-05-10'
    CRANpkgs:
    - IsoGene
    - orQA
    - goric
    - ORCME
    - ORIClust
    - limma
    - mratios
    CTV_rev: Cluster
    landing: '2017'
    pages:
    - 14
    - 26
  - slug: RJ-2017-023
    title: Network Visualization with ggplot2
    bibtitle: Network Visualization with ggplot2
    author:
    - Sam Tyner
    - François Briatte
    - Heike Hofmann
    bibauthor: Sam Tyner and François Briatte and Heike Hofmann
    abstract: '  Abstract This paper explores three different approaches to visualize
      networks by building on the            grammar of graphics framework implemented
      in the ggplot2 package. The goal of each approach is            to provide the
      user with the ability to apply the flexibility of ggplot2 to the visualization
      of network            data, including through the mapping of network attributes
      to specific plot aesthetics. By incorporating            networks in the ggplot2
      framework, these approaches (1) allow users to enhance networks with            additional
      information on edges and nodes, (2) give access to the strengths of ggplot2,
      such as layers            and facets, and (3) convert network data objects to
      the more familiar data frames.'
    acknowledged: '2015-11-14'
    online: '2017-05-10'
    CRANpkgs:
    - igraph
    - sna
    - network
    - statnet
    - ggplot2
    - ggnetwork
    - geomnet
    - ggmap
    - ggfortify
    - GGally
    - gcookbook
    - intergraph
    - grid
    - ggrepel
    - ndtv
    - gridExtra
    - tnet
    - ggCompNet
    - tidyverse
    - plyr
    - dplyr
    BIOpkgs:
    - ggbio
    - ggtree
    CTV_rev:
    - gR
    - SocialSciences
    - Graphics
    - Optimization
    - Spatial
    - Bayesian
    - Phylogenetics
    - WebTechnologies
    landing: '2017'
    pages:
    - 27
    - 59
  - slug: RJ-2017-003
    title: 'OrthoPanels: An R Package for Estimating a Dynamic Panel Model with Fixed
      Effects Using the Orthogonal Reparameterization Approach'
    bibtitle: |-
      OrthoPanels: An R Package for Estimating a Dynamic
                Panel Model with Fixed Effects Using the Orthogonal
                Reparameterization Approach
    author:
    - Mark Pickup
    - Paul Gustafson
    - Davor Cubranic
    - Geoffrey Evans
    bibauthor: |-
      Mark Pickup and Paul Gustafson and Davor Cubranic and
                Geoffrey Evans
    abstract: '  Abstract This article describes the R package OrthoPanels, which
      includes the function opm(). This            function implements the orthogonal
      reparameterization approach recommended by Lancaster (2002) to            estimate
      dynamic panel models with fixed effects (and optionally: wave specific intercepts).
      This article            provides a statistical description of the orthogonal
      reparameterization approach, a demonstration of            the package using
      real-world data, and simulations comparing the estimator to the known-to-be-biased            OLS
      estimator and the commonly used GMM estimator.'
    acknowledged: '2015-11-15'
    online: '2017-05-10'
    CRANpkgs:
    - OrthoPanels
    - plm
    CTV_rev:
    - Econometrics
    - SpatioTemporal
    landing: '2017'
    pages:
    - 60
    - 76
  - slug: RJ-2017-024
    title: 'The mosaic Package: Helping Students to Think with Data Using R'
    bibtitle: |-
      The mosaic Package: Helping Students to `Think with Data'
                Using R
    author:
    - Randall Pruim
    - Daniel T Kaplan
    - Nicholas J Horton
    bibauthor: Randall Pruim and Daniel T Kaplan and Nicholas J Horton
    abstract: '  Abstract The mosaic package provides a simplified and systematic
      introduction to the core functional           ity related to descriptive statistics,
      visualization, modeling, and simulation-based inference required            in
      first and second courses in statistics. This introduction to the package describes
      some of the guiding            principles behind the design of the package and
      provides illustrative examples of several of the most            important functions
      it implements. These can be combined to help students “think with data" using
      R            in their early course work, starting with simple, yet powerful,
      declarative commands.'
    acknowledged: '2015-11-19'
    online: '2017-05-10'
    CRANpkgs:
    - mosaic
    - lattice
    - mosaic
    - mosaicData
    - ggplot2
    - ggplot2
    - dplyr
    - parallel
    - MASS
    CTV_rev:
    - Graphics
    - Multivariate
    - Phylogenetics
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Psychometrics
    - Robust
    - SocialSciences
    landing: '2017'
    pages:
    - 77
    - 102
  - slug: RJ-2017-004
    title: 'smoof: Single- and Multi-Objective Optimization Test Functions'
    bibtitle: |-
      smoof: Single- and Multi-Objective Optimization Test
                Functions
    author: Jakob Bossek
    bibauthor: Jakob Bossek
    abstract: '  Abstract Benchmarking algorithms for optimization problems usually
      is carried out by running the            algorithms under consideration on a
      diverse set of benchmark or test functions. A vast variety of            test
      functions was proposed by researchers and is being used for investigations in
      the literature. The            smoof package implements a large set of test
      functions and test function generators for both the single           and multi-objective
      case in continuous optimization and provides functions to easily create own
      test            functions. Moreover, the package offers some additional helper
      methods, which can be used in the            context of optimization.'
    acknowledged: '2016-02-28'
    online: '2017-05-10'
    CRANpkgs:
    - emoa
    - mco
    - ecr
    - cec2005benchmark
    - cec2013
    - globalOptTests
    - soobench
    - smoof
    - ParamHelpers
    - ggplot2
    CTVs: Optimization
    CTV_rev:
    - Optimization
    - Graphics
    - Phylogenetics
    landing: '2017'
    pages:
    - 103
    - 113
  - slug: RJ-2017-031
    title: 'minval: An R package for MINimal VALidation of Stoichiometric Reactions'
    bibtitle: |-
      minval: An R package for MINimal VALidation of
                Stoichiometric Reactions
    author:
    - Daniel Osorio
    - Janneth González
    - Andrés Pinzón
    bibauthor: Daniel Osorio and Janneth González and Andrés Pinzón
    abstract: '  Abstract A genome-scale metabolic reconstruction is a compilation
      of all stoichiometric reactions that            can describe the entire cellular
      metabolism of an organism, and they have become an indispensable            tool
      for our understanding of biological phenomena, covering fields that range from
      systems biology            to bioengineering. Interrogation of metabolic reconstructions
      are generally carried through Flux            Balance Analysis, an optimization
      method in which the biological sense of the optimal solution is            highly
      sensitive to thermodynamic unbalance caused by the presence of stoichiometric
      reactions            whose compounds are not produced or consumed in any other
      reaction (orphan metabolites) and            by mass unbalance. The minval package
      was designed as a tool to identify orphan metabolites and            evaluate
      the mass and charge balance of stoichiometric reactions. The package also includes
      functions            to characterize and write models in TSV and SBML formats,
      extract all reactants, products, metabolite            names and compartments
      from a metabolic reconstruction.'
    acknowledged: '2016-03-10'
    online: '2017-06-08'
    CRANpkgs:
    - sybil
    - abcdeFBA
    - minval
    - gdata
    - readxl
    - xlsx
    - sybilSBML
    - sybil
    landing: '2017'
    pages:
    - 114
    - 123
  - slug: RJ-2017-032
    title: Working with Daily Climate Model Output Data in R and the futureheatwaves
      Package
    bibtitle: |-
      Working with Daily Climate Model Output Data in R and the
                futureheatwaves Package
    author:
    - G. Brooke Anderson
    - Colin Eason
    - Elizabeth A. Barnes
    bibauthor: G. Brooke Anderson and Colin Eason and Elizabeth A. Barnes
    abstract: '  Abstract Research on climate change impacts can require extensive
      processing of climate model output,            especially when using ensemble
      techniques to incorporate output from multiple climate models and            multiple
      simulations of each model. This processing can be particularly extensive when
      identifying            and characterizing multi-day extreme events like heat
      waves and frost day spells, as these must be            processed from model
      output with daily time steps. Further, climate model output is in a format and            follows
      standards that may be unfamiliar to most R users. Here, we provide an overview
      of working            with daily climate model output data in R. We then present
      the futureheatwaves package, which we            developed to ease the process
      of identifying, characterizing, and exploring multi-day extreme events            in
      climate model output. This package can input a directory of climate model output
      files, identify all            extreme events using customizable event definitions,
      and summarize the output using user-specified            functions.'
    acknowledged: '2016-04-18'
    online: '2017-06-08'
    CRANpkgs:
    - futureheatwaves
    - ggplot2
    - ncdf4
    - RNetCDF
    - ncdf4.helpers
    - PCICt
    - ncdf4.helpers
    - RCMIP5
    - wux
    - ggplot2
    - Rcpp
    - leaflet
    BIOpkgs: ncdfFlow
    CTV_rev:
    - Graphics
    - Phylogenetics
    - Spatial
    - SpatioTemporal
    - HighPerformanceComputing
    - NumericalMathematics
    landing: '2017'
    pages:
    - 124
    - 137
  - slug: RJ-2017-005
    title: 'alineR: an R Package for Optimizing Feature-Weighted Alignments and Linguistic
      Distances'
    bibtitle: |-
      alineR: an R Package for Optimizing Feature-Weighted
                Alignments and Linguistic Distances
    author:
    - Sean S. Downey
    - Guowei Sun
    - Peter Norquest
    bibauthor: Sean S. Downey and Guowei Sun and Peter Norquest
    abstract: '  Abstract Linguistic distance measurements are commonly used in anthropology
      and biology when            quantitative and statistical comparisons between
      words are needed. This is common, for example,            when analyzing linguistic
      and genetic data. Such comparisons can provide insight into historical            population
      patterns and evolutionary processes. However, the most commonly used linguistic            distances
      are derived from edit distances, which do not weight phonetic features that
      may, for            example, represent smaller-scale patterns in linguistic
      evolution. Thus, computational methods for            calculating feature-weighted
      linguistic distances are needed for linguistic, biological, and evolutionary            applications;
      additionally, the linguistic distances presented here are generic and may have
      broader            applications in fields such as text mining and search, as
      well as applications in psycholinguistics            and morphology. To facilitate
      this research, we are making available an open-source R software            package
      that performs feature-weighted linguistic distance calculations. The package
      also includes a            supervised learning methodology that uses a genetic
      algorithm and manually determined alignments            to estimate 13 linguistic
      parameters including feature weights and a skip penalty. Here we present the            package
      and use it to demonstrate the supervised learning methodology by estimating
      the optimal            linguistic parameters for both simulated data and for
      a sample of Austronesian languages. Our results            show that the methodology
      can estimate these parameters for both simulated and real language            data,
      that optimizing feature weights improves alignment accuracy by approximately
      29%, and that            optimization significantly affects the resulting distance
      measurements. Availability: alineR is available            on CRAN.'
    acknowledged: '2016-04-18'
    online: '2017-05-10'
    CRANpkgs:
    - alineR
    - stringdist
    - RecordLinkage
    - doMC
    BIOpkgs: Biostrings
    CTV_rev:
    - OfficialStatistics
    - HighPerformanceComputing
    landing: '2017'
    pages:
    - 138
    - 152
  - slug: RJ-2017-006
    title: Implementing a Metapopulation Bass Diffusion Model using the R Package
      deSolve
    bibtitle: |-
      Implementing a Metapopulation Bass Diffusion Model using the
                R Package deSolve
    author: Jim Duggan
    bibauthor: Jim Duggan
    abstract: '  Abstract Diffusion is a fundamental process in physical, biological,
      social and economic settings.            Consumer products often go viral, with
      sales driven by the word of mouth effect, as their adoption            spreads
      through a population. The classic diffusion model used for product adoption
      is the Bass            diffusion model, and this divides a population into two
      groups of people: potential adopters who            are likely to adopt a product,
      and adopters who have purchased the product, and influence others            to
      adopt. The Bass diffusion model is normally captured in an aggregate form, where
      no significant            consumer differences are modeled. This paper extends
      the Bass model to capture a spatial perspective,            using metapopulation
      equations from the field of infectious disease modeling. The paper’s focus is
      on            simulation of deterministic models by solving ordinary differential
      equations, and does not encompass            parameter estimation. The metapopulation
      model in implemented in R using the deSolve package,            and shows the
      potential of using the R framework to implement large-scale integral equation
      models,            with applications in the field of marketing and consumer
      behaviour.'
    acknowledged: '2016-04-30'
    online: '2017-05-10'
    CRANpkgs:
    - deSolve
    - EpiModel
    - ggplot2
    - scales
    CTV_rev:
    - DifferentialEquations
    - Graphics
    - Phylogenetics
    landing: '2017'
    pages:
    - 153
    - 163
  - slug: RJ-2017-007
    title: 'MDplot: Visualise Molecular Dynamics'
    bibtitle: 'MDplot: Visualise Molecular Dynamics'
    author:
    - Christian Margreitter
    - Chris Oostenbrink
    bibauthor: Christian Margreitter and Chris Oostenbrink
    abstract: '  Abstract The MDplot package provides plotting functions to allow
      for automated visualisation of            molecular dynamics simulation output.
      It is especially useful in cases where the plot generation is            rather
      tedious due to complex file formats or when a large number of plots are generated.
      The graphs            that are supported range from those which are standard,
      such as RMSD/RMSF (root-mean-square            deviation and root-mean-square
      fluctuation, respectively) to less standard, such as thermodynamic            integration
      analysis and hydrogen bond monitoring over time. All told, they address many
      com           monly used analyses. In this article, we set out the MDplot package’s
      functions, give examples of the            function calls, and show the associated
      plots. Plotting and data parsing is separated in all cases, i.e.            the
      respective functions can be used independently. Thus, data manipulation and
      the integration of            additional file formats is fairly easy. Currently,
      the loading functions support GROMOS, GROMACS,            and AMBER file formats.
      Moreover, we also provide a Bash interface that allows simple embedding of            MDplot
      into Bash scripts as the final analysis step.            Availability: The package
      can be obtained in the latest major version from CRAN (https://cran.r           project.org/package=MDplot)
      or in the most recent version from the project’s GitHub page at            https://github.com/MDplot/MDplot,
      where feedback is also most welcome. MDplot is published            under the
      GPL-3 license.'
    acknowledged: '2016-04-30'
    online: '2017-05-10'
    CRANpkgs:
    - MDplot
    - bio3d
    - Rknots
    landing: '2017'
    pages:
    - 164
    - 186
  - slug: RJ-2017-008
    title: 'On Some Extensions to GA Package: Hybrid Optimisation, Parallelisation
      and Islands EvolutionOn some extensions to GA package: hybrid optimisation,
      parallelisation and islands evolution'
    bibtitle: |-
      On Some Extensions to GA Package: Hybrid Optimisation,
                Parallelisation and Islands Evolution
    author: Luca Scrucca
    bibauthor: Luca Scrucca
    abstract: '  Abstract Genetic algorithms are stochastic iterative algorithms in
      which a population of individuals            evolve by emulating the process
      of biological evolution and natural selection. The R package GA            provides
      a collection of general purpose functions for optimisation using genetic algorithms.
      This            paper describes some enhancements recently introduced in version
      3 of the package. In particular,            hybrid GAs have been implemented
      by including the option to perform local searches during the            evolution.
      This allows to combine the power of genetic algorithms with the speed of a local
      optimiser.            Another major improvement is the provision of facilities
      for parallel computing. Parallelisation has            been implemented using
      both the master-slave approach and the islands evolution model. Several            examples
      of usage are presented, with both real-world data examples and benchmark functions,            showing
      that often high-quality solutions can be obtained more efficiently.'
    acknowledged: '2016-05-29'
    online: '2017-05-10'
    CRANpkgs:
    - rgenoud
    - Rmalschains
    - DEoptim
    - GenSA
    - pso
    - cmaes
    - tabuSearch
    - GA
    - quantmod
    - doParallel
    - foreach
    - iterators
    - doRNG
    - forecast
    - astsa
    - globalOptTests
    - Rcpp
    - memoise
    CTVs:
    - Optimization
    - HighPerformanceComputing
    CTV_rev:
    - Optimization
    - HighPerformanceComputing
    - Finance
    - MachineLearning
    - TimeSeries
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    landing: '2017'
    pages:
    - 187
    - 206
  - slug: RJ-2017-009
    title: 'imputeTS: Time Series Missing Value Imputation in R'
    bibtitle: 'imputeTS: Time Series Missing Value Imputation in R'
    author:
    - Steffen Moritz
    - Thomas Bartz-Beielstein
    bibauthor: Steffen Moritz and Thomas Bartz-Beielstein
    abstract: '  Abstract The imputeTS package specializes on univariate time series
      imputation. It offers multiple            state-of-the-art imputation algorithm
      implementations along with plotting functions for time series            missing
      data statistics. While imputation in general is a well-known problem and widely
      covered by R            packages, finding packages able to fill missing values
      in univariate time series is more complicated. The            reason for this
      lies in the fact, that most imputation algorithms rely on inter-attribute correlations,
      while            univariate time series imputation instead needs to employ time
      dependencies. This paper provides an            introduction to the imputeTS
      package and its provided algorithms and tools. Furthermore, it gives a            short
      overview about univariate time series imputation in R.'
    acknowledged: '2016-07-12'
    online: '2017-05-10'
    CRANpkgs:
    - AMELIA
    - mice
    - VIM
    - missMDA
    - imputeTS
    - zoo
    - forecast
    - spacetime
    - timeSeries
    - xts
    CTV_rev:
    - TimeSeries
    - Finance
    - Econometrics
    - OfficialStatistics
    - Environmetrics
    - Multivariate
    - SocialSciences
    - SpatioTemporal
    - Psychometrics
    - Spatial
    landing: '2017'
    pages:
    - 207
    - 218
  - slug: RJ-2017-027
    title: 'The NoiseFiltersR Package: Label Noise Preprocessing in R'
    bibtitle: 'The NoiseFiltersR Package: Label Noise Preprocessing in R'
    author:
    - Pablo Morales
    - Julián Luengo
    - Luís P.F. Garcia
    - Ana C. Lorena
    - André C.P.L.F. de Carvalho
    - '           Francisco Herrera'
    bibauthor: |-
      Pablo Morales and Julián Luengo and Luís P.F. Garcia and
                Ana C. Lorena and André C.P.L.F. de Carvalho and Francisco
                Herrera
    abstract: '  Abstract In Data Mining, the value of extracted knowledge is directly
      related to the quality of the            used data. This makes data preprocessing
      one of the most important steps in the knowledge discovery            process.
      A common problem affecting data quality is the presence of noise. A training
      set with label            noise can reduce the predictive performance of classification
      learning techniques and increase the            overfitting of classification
      models. In this work we present the NoiseFiltersR package. It contains the            first
      extensive R implementation of classical and state-of-the-art label noise filters,
      which are the most            common techniques for preprocessing label noise.
      The algorithms used for the implementation of the            label noise filters
      are appropriately documented and referenced. They can be called in a R-user-friendly            manner,
      and their results are unified by means of the "filter" class, which also benefits
      from adapted            print and summary methods.'
    acknowledged: '2016-07-12'
    online: '2017-05-10'
    CRANpkgs:
    - MICE
    - Amelia
    - caret
    - FSelector
    - mvoutlier
    - robustDA
    - probFDA
    - NoiseFiltersR
    - unbalanced
    - RWeka
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Robust
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - OfficialStatistics
    - SocialSciences
    landing: '2017'
    pages:
    - 219
    - 228
  - slug: RJ-2017-018
    title: 'coxphMIC: An R Package for Sparse Estimation of Cox Proportional Hazards
      Models via Approximated Information Criteria'
    bibtitle: |-
      coxphMIC: An R Package for Sparse Estimation of Cox
                Proportional Hazards Models via Approximated Information
                Criteria
    author:
    - Razieh Nabi
    - Xiaogang Su
    bibauthor: Razieh Nabi and Xiaogang Su
    abstract: '  Abstract In this paper, we describe an R package named coxphMIC,
      which implements the sparse            estimation method for Cox proportional
      hazards models via approximated information criterion (Su            et al.,
      2016). The developed methodology is named MIC which stands for “Minimizing approximated            Information
      Criteria". A reparameterization step is introduced to enforce sparsity while
      at the same            time keeping the objective function smooth. As a result,
      MIC is computationally fast with a superior            performance in sparse
      estimation. Furthermore, the reparameterization tactic yields an additional            advantage
      in terms of circumventing post-selection inference (Leeb and Pötscher, 2005).
      The MIC            method and its R implementation are introduced and illustrated
      with the PBC data.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    landing: '2017'
    pages:
    - 229
    - 238
  - slug: RJ-2017-010
    title: Update of the nlme Package to Allow a Fixed Standard Deviation of the Residual
      Error
    bibtitle: |-
      Update of the nlme Package to Allow a Fixed Standard
                Deviation of the Residual Error
    author:
    - Simon H. Heisterkamp
    - Engelbertus van Willigen
    - Paul-Matthias Diderichsen
    - John Maringwa
    bibauthor: |-
      Simon H. Heisterkamp and Engelbertus van Willigen and Paul-
                Matthias Diderichsen and John Maringwa
    abstract: '  Abstract The use of linear and non-linear mixed models in the life
      sciences and pharmacometrics            is common practice. Estimation of the
      parameters of models not involving a system of differential            equations
      is often done by the R or S-Plus software with the nonlinear mixed effects nlme
      package.            The estimated residual error may be used for diagnosis of
      the fitted model, but not whether the            model correctly describes the
      relation between response and included variables including the true            covariance
      structure. The latter is only true if the residual error is known in advance.
      Therefore, it            may be necessary or more appropriate to fix the residual
      error a priori instead of estimate its value.            This can be the case
      if one wants to include evidence from past studies or a theoretical derivation;            e.g.,
      when using a binomial model. S-Plus has an option to fix this residual error
      to a constant, in            contrast to R. For convenience, the nlme package
      was customized to offer this option as well. In this            paper, we derived
      the log-likelihoods for the mixed models using a fixed residual error. By using
      some            well-known examples from mixed models, we demonstrated the equivalence
      of R and S-Plus with            respect to the estimates. The updated package
      has been accepted by the Comprehensive R Archive            Network (CRAN) team
      and will be available at the CRAN website.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs: nlme
    CTV_rev:
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - Spatial
    - SpatioTemporal
    landing: '2017'
    pages:
    - 239
    - 251
  - slug: RJ-2017-011
    title: 'EMSaov: An R Package for the Analysis of Variance with the Expected Mean
      Squares and its Shiny Application'
    bibtitle: |-
      EMSaov: An R Package for the Analysis of Variance with the
                Expected Mean Squares and its Shiny Application
    author:
    - Hye-Min Choe
    - Mijeong Kim
    - Eun-Kyung Lee
    bibauthor: Hye-Min Choe and Mijeong Kim and Eun-Kyung Lee
    abstract: '  Abstract EMSaov is a new R package that we developed to provide users
      with an analysis of variance            table including the expected mean squares
      (EMS) for various types of experimental design. It is not            easy to
      find the appropriate test, particularly the denominator for the F statistic
      that depends on the            EMS, when some variables exhibit random effects
      or when we use a special experimental design such            as nested design,
      repeated measures design, or split-plot design. With EMSaov, a user can easily            find
      the F statistic denominator and can determine how to analyze the data when using
      a special            experimental design. We also develop a web application
      with a GUI interface using the shiny package            in R . We expect that
      our application can contribute to the efficient and easy analysis of experimental            data.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - nlme
    - afex
    - EMSaov
    - shiny
    CTV_rev:
    - ChemPhys
    - Econometrics
    - Environmetrics
    - Finance
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - Spatial
    - SpatioTemporal
    - WebTechnologies
    landing: '2017'
    pages:
    - 252
    - 261
  - slug: RJ-2017-015
    title: 'GsymPoint: An R Package to Estimate the Generalized Symmetry Point, an
      Optimal Cut-off Point for Binary Classification in Continuous Diagnostic Tests'
    bibtitle: |-
      GsymPoint: An R Package to Estimate the Generalized Symmetry
                Point, an Optimal Cut-off Point for Binary Classification in
                Continuous Diagnostic Tests
    author:
    - Mónica López-Ratón
    - Elisa M. Molanes-López
    - Emilio Letón
    - Carmen Cadarso-Suárez
    bibauthor: |-
      Mónica López-Ratón and Elisa M. Molanes-López and Emilio
                Letón and Carmen Cadarso-Suárez
    abstract: '  Abstract In clinical practice, it is very useful to select an optimal
      cutpoint in the scale of a continuous            biomarker or diagnostic test
      for classifying individuals as healthy or diseased. Several methods for            choosing
      optimal cutpoints have been presented in the literature, depending on the ultimate
      goal. One            of these methods, the generalized symmetry point, recently
      introduced, generalizes the symmetry            point by incorporating the misclassification
      costs. Two statistical approaches have been proposed in the            literature
      for estimating this optimal cutpoint and its associated sensitivity and specificity
      measures,            a parametric method based on the generalized pivotal quantity
      and a nonparametric method based            on empirical likelihood. In this
      paper, we introduce GsymPoint, an R package that implements these            methods
      in a user-friendly environment, allowing the end-user to calculate the generalized
      symmetry            point depending on the levels of certain categorical covariates.
      The practical use of this package is            illustrated using three real
      biomedical datasets.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - GsymPoint
    - PresenceAbsence
    - DiagnosisMed
    - pROC
    - OptimalCutpoints
    - GsymPoint
    landing: '2017'
    pages:
    - 262
    - 283
  - slug: RJ-2017-025
    title: 'autoimage: Multiple Heat Maps for Projected Coordinates'
    bibtitle: 'autoimage: Multiple Heat Maps for Projected Coordinates'
    author: Joshua P. French
    bibauthor: Joshua P. French
    abstract: '  Abstract Heat maps are commonly used to display the spatial distribution
      of a response observed            on a two-dimensional grid. The autoimage package
      provides convenient functions for constructing            multiple heat maps
      in unified, seamless way, particularly when working with projected coordinates.            The
      autoimage package natively supports: 1. automatic inclusion of a color scale
      with the plotted            image, 2. construction of heat maps for responses
      observed on regular or irregular grids, as well as            non-gridded data,
      3. construction of a matrix of heat maps with a common color scale, 4. construction            of
      a matrix of heat maps with individual color scales, 5. projecting coordinates
      before plotting, 6.            easily adding geographic borders, points, and
      other features to the heat maps. After comparing the            autoimage package’s
      capabilities for constructing heat maps to those of existing tools, a carefully            selected
      set of examples is used to highlight the capabilities of the autoimage package.'
    acknowledged: '2016-08-25'
    online: '2017-05-10'
    CRANpkgs:
    - autoimage
    - fields
    - lattice
    - sp
    - ggplot2
    - spatstat
    - gridExtra
    - cowplot
    - akima
    - mapproj
    - gear
    - viridisLite
    - maps
    CTV_rev:
    - Spatial
    - Graphics
    - SpatioTemporal
    - Multivariate
    - NumericalMathematics
    - Phylogenetics
    - Survival
    landing: '2017'
    pages:
    - 284
    - 297
  - slug: RJ-2017-020
    title: Market Area Analysis for Retail and Service Locations with MCI
    bibtitle: |-
      Market Area Analysis for Retail and Service Locations with
                MCI
    author: Thomas Wieland
    bibauthor: Thomas Wieland
    abstract: '  Abstract In retail location analysis, marketing research and spatial
      planning, the market areas of            stores and/or locations are a frequent
      subject. Market area analyses consist of empirical observations            and
      modeling via theoretical and/or econometric models such as the Huff Model or
      the Multiplicative            Competitive Interaction Model. The authors’ package
      MCI implements the steps of market area            analysis into R with a focus
      on fitting the models and data preparation and processing.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - MCI
    - SpatialPosition
    - ggmap
    - osmar
    - osrm
    - car
    - spgwr
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Econometrics
    - Finance
    - Multivariate
    - SocialSciences
    landing: '2017'
    pages:
    - 298
    - 323
  - slug: RJ-2017-021
    title: 'PSF: Introduction to R Package for Pattern Sequence Based Forecasting
      Algorithm'
    bibtitle: |-
      PSF: Introduction to R Package for Pattern Sequence Based
                Forecasting Algorithm
    author:
    - Neeraj Bokde
    - Gualberto Asencio-Cortés
    - Francisco Martínez-Álvarez
    - Kishore Kulat
    bibauthor: |-
      Neeraj Bokde and Gualberto Asencio-Cortés and Francisco
                Martínez-Álvarez and Kishore Kulat
    abstract: '  Abstract This paper introduces the R package that implements the
      Pattern Sequence based Forecasting            (PSF) algorithm, which was developed
      for univariate time series forecasting. This algorithm has been            successfully
      applied to many different fields. The PSF algorithm consists of two major parts:
      clustering            and prediction. The clustering part includes selection
      of the optimum number of clusters. It labels            time series data with
      reference to such clusters. The prediction part includes functions like optimum            window
      size selection for specific patterns and prediction of future values with reference
      to past            pattern sequences. The PSF package consists of various functions
      to implement the PSF algorithm. It            also contains a function which
      automates all other functions to obtain optimized prediction results.            The
      aim of this package is to promote the PSF algorithm and to ease its usage with
      minimum efforts.            This paper describes all the functions in the PSF
      package with their syntax. It also provides a simple            example. Finally,
      the usefulness of this package is discussed by comparing it to auto.arima and
      ets,            well-known time series forecasting functions available on CRAN
      repository.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - PSF
    - cluster
    - data.table
    - forecast
    CTV_rev:
    - Environmetrics
    - Finance
    - Cluster
    - Econometrics
    - HighPerformanceComputing
    - Multivariate
    - TimeSeries
    landing: '2017'
    pages:
    - 324
    - 333
  - slug: RJ-2017-029
    title: 'flan: An R Package for Inference on Mutation Models.'
    bibtitle: 'flan: An R Package for Inference on Mutation Models.'
    author:
    - Adrien Mazoyer
    - Rémy Drouilhet
    - Stéphane Despréaux
    - Bernard Ycart
    bibauthor: |-
      Adrien Mazoyer and Rémy Drouilhet and Stéphane Despréaux and
                Bernard Ycart
    abstract: '  Abstract This paper describes flan, a package providing tools for
      fluctuation analysis of mutant cell            counts. It includes functions
      dedicated to the distribution of final numbers of mutant cells. Parametric            estimation
      and hypothesis testing are also implemented, enabling inference on different
      sorts of data            with several possible methods. An overview of the subject
      is proposed. The general form of mutation            models is described, including
      the classical models as particular cases. Estimating from a model,            when
      the data have been generated by another, induces different possible biases,
      which are identified            and discussed. The three estimation methods
      available in the package are described, and their mean            squared errors
      are compared. Finally, implementation is discussed, and a few examples of usage
      on            real data sets are given.'
    acknowledged: '2016-09-12'
    online: '2017-05-18'
    CRANpkgs:
    - flan
    - Rcpp
    - ggplot2
    - RcppGSL
    - polynom
    - RcppArmadillo
    - lbfgsb3
    CTV_rev:
    - NumericalMathematics
    - Graphics
    - HighPerformanceComputing
    - Optimization
    - Phylogenetics
    landing: '2017'
    pages:
    - 334
    - 351
  - slug: RJ-2017-012
    title: Multilabel Classification with R Package mlr
    bibtitle: Multilabel Classification with R Package mlr
    author:
    - Philipp Probst
    - Quay Au
    - Giuseppe Casalicchio
    - Clemens Stachl
    - Bernd Bischl
    bibauthor: |-
      Philipp Probst and Quay Au and Giuseppe Casalicchio and
                Clemens Stachl and Bernd Bischl
    abstract: '  Abstract We implemented several multilabel classification algorithms
      in the machine learning package            mlr. The implemented methods are
      binary relevance, classifier chains, nested stacking, dependent            binary
      relevance and stacking, which can be used with any base learner that is accessible
      in mlr.            Moreover, there is access to the multilabel classification
      versions of randomForestSRC and rFerns.            All these methods can be
      easily compared by different implemented multilabel performance measures            and
      resampling methods in the standardized mlr framework. In a benchmark experiment
      with several            multilabel datasets, the performance of the different
      methods is evaluated.'
    acknowledged: '2016-09-12'
    online: '2017-05-10'
    CRANpkgs:
    - mldr
    - rFerns
    - randomForestSRC
    - randomForestSRC
    - ada
    - batchtools
    CTV_rev:
    - HighPerformanceComputing
    - MachineLearning
    - Survival
    landing: '2017'
    pages:
    - 352
    - 369
  - slug: RJ-2017-033
    title: 'Counterfactual: An R Package for Counterfactual Analysis'
    bibtitle: 'Counterfactual: An R Package for Counterfactual Analysis'
    author:
    - Mingli Chen
    - Victor Chernozhukov
    - Iván Fernández-Val
    - Blaise Melly
    bibauthor: |-
      Mingli Chen and Victor Chernozhukov and Iván Fernández-Val
                and Blaise Melly
    abstract: '  Abstract The Counterfactual package implements the estimation and
      inference methods of Cher           nozhukov et al. (2013) for counterfactual
      analysis. The counterfactual distributions considered are            the result
      of changing either the marginal distribution of covariates related to the outcome
      variable of            interest, or the conditional distribution of the outcome
      given the covariates. They can be applied to            estimate quantile treatment
      effects and wage decompositions. This paper serves as an introduction to            the
      package and displays basic functionality of the commands contained within.'
    acknowledged: '2016-09-15'
    online: '2017-06-08'
    CRANpkgs:
    - Counterfactual
    - quantreg
    - survival
    CTV_rev:
    - Econometrics
    - SocialSciences
    - Survival
    - ClinicalTrials
    - Environmetrics
    - Optimization
    - ReproducibleResearch
    - Robust
    landing: '2017'
    pages:
    - 370
    - 384
  - slug: RJ-2017-019
    title: Retrieval and Analysis of Eurostat Open Data with the eurostat Package
    bibtitle: |-
      Retrieval and Analysis of Eurostat Open Data with the
                eurostat Package
    author:
    - Leo Lahti
    - Janne Huovari
    - Markus Kainu
    - Przemysław Biecek
    bibauthor: |-
      Leo Lahti and Janne Huovari and Markus Kainu and Przemysław
                Biecek
    abstract: '  Abstract The increasing availability of open statistical data resources
      is providing novel opportunities            for research and citizen science.
      Efficient algorithmic tools are needed to realize the full potential of the            new
      information resources. We introduce the eurostat R package that provides a collection
      of custom            tools for the Eurostat open data service, including functions
      to query, download, manipulate, and            visualize these data sets in
      a smooth, automated and reproducible manner. The online documentation            provides
      detailed examples on the analysis of these spatio-temporal data collections.
      This work            provides substantial improvements over the previously available
      tools, and has been extensively            tested by an active user community.
      The eurostat R package contributes to the growing open source            ecosystem
      dedicated to reproducible research in computational social science and digital
      humanities.'
    acknowledged: '2016-09-15'
    online: '2017-05-10'
    CRANpkgs:
    - FAOSTAT
    - WDI
    - pxweb
    - osmar
    - eurostat
    - smarterpoland
    - rsdmx
    - datamart
    - quandl
    - pdfetch
    - classInt
    - httr
    - jsonlite
    - readr
    - sp
    - stringi
    - tibble
    - plotrix
    - maptools
    - rgdal
    - rgeos
    - scales
    - stringr
    - countrycode
    CTVs:
    - ReproducibleResearch
    - SocialSciences
    - Spatial
    - SpatioTemporal
    - TimeSeries
    - WebTechnologies
    CTV_rev:
    - Spatial
    - WebTechnologies
    - Graphics
    - NaturalLanguageProcessing
    - SpatioTemporal
    - TimeSeries
    landing: '2017'
    pages:
    - 385
    - 392
  - slug: RJ-2017-030
    title: 'PGEE: An R Package for Analysis of Longitudinal Data with High-Dimensional
      Covariates'
    bibtitle: |-
      PGEE: An R Package for Analysis of Longitudinal Data with
                High-Dimensional Covariates
    author:
    - Gul Inan
    - Lan Wang
    bibauthor: Gul Inan and Lan Wang
    abstract: '  Abstract We introduce an R package PGEE that implements the penalized
      generalized estimating            equations (GEE) procedure proposed by Wang
      et al. (2012) to analyze longitudinal data with a large            number of
      covariates. The PGEE package includes three main functions: CVfit, PGEE, and
      MGEE. The            CVfit function computes the cross-validated tuning parameter
      for penalized generalized estimating            equations. The function PGEE
      performs simultaneous estimation and variable selection for longitudinal            data
      with high-dimensional covariates; whereas the function MGEE fits unpenalized
      GEE to the data for            comparison. The R package PGEE is illustrated
      using a yeast cell-cycle gene expression data set.'
    acknowledged: '2016-09-15'
    online: '2017-06-08'
    CRANpkgs:
    - gee
    - geepack
    - PGEE
    - MASS
    - mvtnorm
    - ncvreg
    - penalized
    - glmnet
    - rqPen
    CTV_rev:
    - MachineLearning
    - SocialSciences
    - Distributions
    - Econometrics
    - Multivariate
    - Survival
    - Environmetrics
    - Finance
    - NumericalMathematics
    - Psychometrics
    - Robust
    landing: '2017'
    pages:
    - 393
    - 402
  - slug: RJ-2017-022
    title: 'BayesBinMix: an R Package for Model Based Clustering of Multivariate Binary
      Data'
    bibtitle: |-
      BayesBinMix: an R Package for Model Based Clustering of
                Multivariate Binary Data
    author:
    - Panagiotis Papastamoulis
    - Magnus Rattray
    bibauthor: Panagiotis Papastamoulis and Magnus Rattray
    abstract: '  Abstract The BayesBinMix package offers a Bayesian framework for
      clustering binary data with or            without missing values by fitting
      mixtures of multivariate Bernoulli distributions with an unknown            number
      of components. It allows the joint estimation of the number of clusters and
      model parameters            using Markov chain Monte Carlo sampling. Heated
      chains are run in parallel and accelerate the            convergence to the
      target posterior distribution. Identifiability issues are addressed by implementing            label
      switching algorithms. The package is demonstrated and benchmarked against the
      Expectation           Maximization algorithm using a simulation study as well
      as a real dataset.'
    acknowledged: '2016-09-30'
    online: '2017-05-10'
    CRANpkgs:
    - BayesBinMix
    - label.switching
    - foreach
    - doParallel
    - coda
    - FlexMix
    - flexclust
    CTV_rev:
    - Bayesian
    - Cluster
    - gR
    - HighPerformanceComputing
    landing: '2017'
    pages:
    - 403
    - 420
  - slug: RJ-2017-016
    title: 'pdp: An R Package for Constructing Partial Dependence Plots'
    bibtitle: 'pdp: An R Package for Constructing Partial Dependence Plots'
    author: Brandon M. Greenwell
    bibauthor: Brandon M. Greenwell
    abstract: '  Abstract Complex nonparametric models—like neural networks, random
      forests, and support vector            machines—are more common than ever in
      predictive analytics, especially when dealing with large            observational
      databases that don’t adhere to the strict assumptions imposed by traditional
      statistical            techniques (e.g., multiple linear regression which assumes
      linearity, homoscedasticity, and normality).            Unfortunately, it can
      be challenging to understand the results of such models and explain them to            management.
      Partial dependence plots offer a simple solution. Partial dependence plots are
      low           dimensional graphical renderings of the prediction function so
      that the relationship between the            outcome and predictors of interest
      can be more easily understood. These plots are especially useful in            explaining
      the output from black box models. In this paper, we introduce pdp, a general
      R package            for constructing partial dependence plots.'
    acknowledged: '2016-09-30'
    online: '2017-05-10'
    CRANpkgs:
    - randomForest
    - gbm
    - party
    - partykit
    - pdp
    - plotmo
    - lattice
    - ICEbox
    - car
    - effects
    - ggplot2
    - grid
    - latticeExtra
    - gridExtra
    - nnet
    - C50
    - rpart
    - adabag
    - ipred
    - adabag
    - xgboost
    - Cubist
    - MASS
    - earth
    - mda
    - ranger
    - e1071
    - kernlab
    - caret
    - magrittr
    - foreach
    - viridis
    - plyr
    - doMC
    - doParallel
    - dplyr
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Environmetrics
    - Survival
    - Econometrics
    - SocialSciences
    - Graphics
    - HighPerformanceComputing
    - Cluster
    - Distributions
    - Psychometrics
    - Finance
    - NaturalLanguageProcessing
    - NumericalMathematics
    - Optimization
    - Phylogenetics
    - Robust
    - WebTechnologies
    landing: '2017'
    pages:
    - 421
    - 436
  - slug: RJ-2017-028
    title: 'checkmate: Fast Argument Checks for Defensive R Programming'
    bibtitle: 'checkmate: Fast Argument Checks for Defensive R Programming'
    author: Michel Lang
    bibauthor: Michel Lang
    abstract: '  Abstract Dynamically typed programming languages like R allow programmers
      to write generic,            flexible and concise code and to interact with
      the language using an interactive Read-eval-print-loop            (REPL). However,
      this flexibility has its price: As the R interpreter has no information about
      the            expected variable type, many base functions automatically convert
      the input instead of raising an            exception. Unfortunately, this frequently
      leads to runtime errors deeper down the call stack which            obfuscates
      the original problem and renders debugging challenging. Even worse, unwanted
      conver           sions can remain undetected and skew or invalidate the results
      of a statistical analysis. As a resort,            assertions can be employed
      to detect unexpected input during runtime and to signal understandable            and
      traceable errors. The package checkmate provides a plethora of functions to
      check the type and            related properties of the most frequently used
      R objects and variable types. The package is mostly            written in C
      to avoid any unnecessary performance overhead. Thus, the programmer can conveniently            write
      concise, well-tested assertions which outperforms custom R code for many applications.
      Fur           thermore, checkmate simplifies writing unit tests using the framework
      testthat (Wickham, 2011) by            extending it with plenty of additional
      expectation functions, and registered C routines are available            for
      package developers to perform assertions on arbitrary SEXPs (internal data structure
      for R objects            implemented as struct in C) in compiled code.'
    acknowledged: '2016-11-16'
    online: '2017-05-12'
    CRANpkgs:
    - checkmate
    - assertthat
    - assertive
    - assertive.numbers
    - assertive.sets
    - assertr
    - magrittr
    - dplyr
    - testthat
    - data.table
    - tibble
    - microbenchmark
    - mlr
    - BatchJobs
    - batchtools
    CTV_rev:
    - HighPerformanceComputing
    - Finance
    - MachineLearning
    - WebTechnologies
    landing: '2017'
    pages:
    - 437
    - 445
  - slug: RJ-2017-013
    title: 'milr: Multiple-Instance Logistic Regression with Lasso Penalty'
    bibtitle: |-
      milr: Multiple-Instance Logistic Regression with Lasso
                Penalty
    author:
    - Ping-Yang Chen
    - Ching-Chuan Chen
    - Chun-Hao Yang
    - Sheng-Mao Chang
    - Kuo-Jung Lee
    bibauthor: |-
      Ping-Yang Chen and Ching-Chuan Chen and Chun-Hao Yang and
                Sheng-Mao Chang and Kuo-Jung Lee
    abstract: '  Abstract The purpose of the milr package is to analyze multiple-instance
      data. Ordinary multiple           instance data consists of many independent
      bags, and each bag is composed of several instances.            The statuses
      of bags and instances are binary. Moreover, the statuses of instances are not
      observed,            whereas the statuses of bags are observed. The functions
      in this package are applicable for analyzing            multiple-instance data,
      simulating data via logistic regression, and selecting important covariates
      in            the regression model. To this end, maximum likelihood estimation
      with an expectation-maximization            algorithm is implemented for model
      estimation, and a lasso penalty added to the likelihood function is            applied
      for variable selection. Additionally, an "milr" object is applicable to generic
      functions fitted,            predict and summary. Simulated data and a real
      example are given to demonstrate the features of this            package.'
    acknowledged: '2016-11-16'
    online: '2017-05-10'
    CRANpkgs: milr
    landing: '2017'
    pages:
    - 446
    - 457
  - slug: RJ-2017-014
    title: 'spcadjust: An R Package for Adjusting for Estimation Error in Control
      Charts'
    bibtitle: |-
      spcadjust: An R Package for Adjusting for Estimation Error
                in Control Charts
    author:
    - Axel Gandy
    - Jan Terje Kvaløy
    bibauthor: Axel Gandy and Jan Terje Kvaløy
    abstract: '  Abstract In practical applications of control charts the in-control
      state and the corresponding chart            parameters are usually estimated
      based on some past in-control data. The estimation error then            needs
      to be accounted for. In this paper we present an R package, spcadjust, which
      implements a            bootstrap based method for adjusting monitoring schemes
      to take into account the estimation error.            By bootstrapping the past
      data this method guarantees, with a certain probability, a conditional            performance
      of the chart. In spcadjust the method is implement for various types of Shewhart,            CUSUM
      and EWMA charts, various performance criteria, and both parametric and non-parametric            bootstrap
      schemes. In addition to the basic charts, charts based on linear and logistic
      regression            models for risk adjusted monitoring are included, and
      it is easy for the user to add further charts. Use            of the package
      is demonstrated by examples.'
    acknowledged: '2016-11-16'
    online: '2017-05-10'
    CRANpkgs:
    - spcadjust
    - surveillance
    - spc
    - qcc
    - IQCC
    - qcr
    - edcc
    - MSQC
    CTV_rev:
    - Environmetrics
    - SpatioTemporal
    - TimeSeries
    landing: '2017'
    pages:
    - 458
    - 476
  - slug: RJ-2017-017
    title: Weighted Effect Coding for Observational Data with wec
    bibtitle: Weighted Effect Coding for Observational Data with wec
    author:
    - Rense Nieuwenhuis
    - Manfred te Grotenhuis
    - Ben Pelzer
    bibauthor: Rense Nieuwenhuis and Manfred te Grotenhuis and Ben Pelzer
    abstract: '  Abstract Weighted effect coding refers to a specific coding matrix
      to include factor variables in            generalised linear regression models.
      With weighted effect coding, the effect for each category            represents
      the deviation of that category from the weighted mean (which corresponds to
      the sample            mean). This technique has particularly attractive properties
      when analysing observational data, that            commonly are unbalanced.
      The wec package is introduced, that provides functions to apply weighted            effect
      coding to factor variables, and to interactions between (a.) a factor variable
      and a continuous            variable and between (b.) two factor variables.'
    acknowledged: '2016-12-23'
    online: '2017-05-10'
    CRANpkgs: wec
    landing: '2017'
    pages:
    - 477
    - 485
  - slug: RJ-2017-026
    title: 'Hosting Data Packages via drat: A Case Study with Hurricane Exposure Data'
    bibtitle: |-
      Hosting Data Packages via drat: A Case Study with Hurricane
                Exposure Data
    author:
    - G. Brooke Anderson
    - Dirk Eddelbuettel
    bibauthor: G. Brooke Anderson and Dirk Eddelbuettel
    abstract: '  Abstract Data-only packages offer a way to provide extended functionality
      for other R users. However,            such packages can be large enough to
      exceed the package size limit (5 megabytes) for the Comprehen           sive
      R Archive Network (CRAN). As an alternative, large data packages can be posted
      to additional            repostiories beyond CRAN itself in a way that allows
      smaller code packages on CRAN to access and            use the data. The drat
      package facilitates creation and use of such alternative repositories and makes            it
      particularly simple to host them via GitHub. CRAN packages can draw on packages
      posted to drat            repositories through the use of the ‘Additonal_repositories’
      field in the DESCRIPTION file. This paper            describes how R users can
      create a suite of coordinated packages, in which larger data packages are            hosted
      in an alternative repository created with drat, while a smaller code package
      that interacts with            this data is created that can be submitted to
      CRAN.'
    acknowledged: '2017-02-17'
    online: '2017-05-10'
    CRANpkgs:
    - NMMAPSlite
    - stashR
    - rnoaa
    - tigris
    - UScensus2000
    - drat
    - grattan
    - hurricaneexposure
    - devtools
    - rcmdcheck
    - git2r
    - littler
    - knitr
    - roxygen2
    CTV_rev:
    - ReproducibleResearch
    - WebTechnologies
    landing: '2017'
    pages:
    - 486
    - 497
  - heading: News and Notes
  - slug: foundation
    author: Torsten Hothorn
    title: R Foundation News
    bibtitle: R Foundation News
    bibauthor: Torsten Hothorn
    pages:
    - 498
    - 500
  - slug: erum
    author:
    - Maciej Beręsewicz
    - Adolfo Alvarez
    - Przemysław Biecek
    - Marcin K. Dyderski
    - Marcin Kosinski
    - '          Jakub Nowosad'
    - Kamil Rotter
    - Alicja Szabelska-Beręsewicz
    - Marcin Szymkowiak
    - Łukasz Wawrowski
    - '          Joanna Zyprych-Walczak'
    title: 'Conference Report: European R Users Meeting 2016'
    bibtitle: 'Conference Report: European R Users Meeting 2016'
    bibauthor: |-
      Maciej Beręsewicz and Adolfo Alvarez and Przemysław Biecek
                and Marcin K. Dyderski and Marcin Kosinski and Jakub Nowosad
                and Kamil Rotter and Alicja Szabelska-Beręsewicz and Marcin
                Szymkowiak and Łukasz Wawrowski and Joanna Zyprych-Walczak
    pages:
    - 501
    - 504
  - slug: cran
    author:
    - Kurt Hornik
    - Uwe Ligges
    - Achim Zeileis
    title: Changes on CRAN
    bibtitle: Changes on CRAN
    bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
    pages:
    - 505
    - 507
  - slug: bioc
    author: Bioconductor Core Team
    title: News from the Bioconductor Project
    bibtitle: News from the Bioconductor Project
    bibauthor: Bioconductor Core Team
    pages:
    - 508
    - 508
  - slug: ch
    author: R Core Team
    title: Changes in R
    bibtitle: Changes in R
    bibauthor: R Core Team
    pages:
    - 509
    - 521
- issue: 2017-2
  year: 2017
  volume: 9
  num: 2
  month: Dec.
  bibmonth: dec
  articles:
  - slug: editorial
    cat: Editorial
    author: Roger Bivand
    title: Editorial
    bibtitle: Editorial
    bibauthor: Roger Bivand
    pages:
    - 4
    - 5
  - heading: Contributed Research Articles
  - slug: RJ-2017-034
    title: 'anchoredDistr: a Package for the Bayesian Inversion of Geostatistical
      Parameters with Multi-type and Multi-scale Data'
    bibtitle: |-
      anchoredDistr: a Package for the Bayesian Inversion of
                Geostatistical Parameters with Multi-type and Multi-scale
                Data
    author:
    - Heather Savoy
    - Falk Heße
    - Yoram Rubin
    bibauthor: Heather Savoy and Falk Heße and Yoram Rubin
    abstract: '  Abstract The Method of Anchored Distributions (MAD) is a method for
      Bayesian inversion designed            for inferring both local (e.g. point
      values) and global properties (e.g. mean and variogram parameters)            of
      spatially heterogenous fields using multi-type and multi-scale data. Software
      implementations            of MAD exist in C++ and C# to import data, execute
      an ensemble of forward model simulations,            and perform basic post-processing
      of calculating likelihood and posterior distributions for a given            application.
      This article describes the R package anchoredDistr that has been built to provide
      an R           based environment for this method. In particular, anchoredDistr
      provides a range of post-processing            capabilities for MAD software
      by taking advantage of the statistical capabilities and wide use of the            R
      language. Two examples from stochastic hydrogeology are provided to highlight
      the features of            the package for MAD applications in inferring anchored
      distributions of local parameters (e.g. point            values of transmissivity)
      as well as global parameters (e.g. the mean of the spatial random function for            hydraulic
      conductivity).'
    acknowledged: '2016-08-25'
    online: '2017-06-28'
    CRANpkgs:
    - gstat
    - spBayes
    - spTimer
    - anchoredDistr
    - devtools
    - RSQLite
    - np
    - plyr
    - dplyr
    - ggplot2
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Bayesian
    - Econometrics
    - Graphics
    - Phylogenetics
    - SocialSciences
    - TimeSeries
    suppl: 489 bytes
    landing: '2017'
    pages:
    - 6
    - 17
  - slug: RJ-2017-040
    title: 'dGAselID: An R Package for Selecting a Variable Number of Features in
      High Dimensional Data'
    bibtitle: |-
      dGAselID: An R Package for Selecting a Variable Number of
                Features in High Dimensional Data
    author:
    - Nicolae Teodor Melita
    - Stefan Holban
    bibauthor: Nicolae Teodor Melita and Stefan Holban
    abstract: '  Abstract The dGAselID package proposes an original approach to feature
      selection in high dimen           sional data. The method is built upon a diploid
      genetic algorithm. The genotype to phenotype            mapping is modeled after
      the Incomplete Dominance Inheritance, overpassing the necessity to define            a
      dominance scheme. The fitness evaluation is done by user selectable supervised
      classifiers, from a            broad range of options. Cross validation options
      are also accessible. A new approach to crossover,            inspired from the
      random assortment of chromosomes during meiosis is included. Several mutation            operators,
      inspired from genetics, are also proposed. The package is fully compatible with
      the data            formats used in Bioconductor and MLInterfaces package, readily
      applicable to microarray studies,            but is flexible to other feature
      selection applications from high dimensional data. Several options for            the
      visualization of evolution and outcomes are implemented to facilitate the interpretation
      of results.            The package’s functionality is illustrated by examples.'
    acknowledged: '2016-08-25'
    online: '2017-08-25'
    CRANpkgs:
    - dGAselID
    - genalg
    - GA
    - nsga2R
    - gaoptim
    - STPGA
    - kofnGA
    - mogavs
    - gaselect
    - scales
    BIOpkgs:
    - MLInterfaces
    - MLInterfaces
    - ALL
    - genefilter
    - hgu95av2.db
    CTV_rev: Optimization
    landing: '2017'
    pages:
    - 18
    - 34
  - slug: RJ-2017-057
    title: Allele Imputation and Haplotype Determination from Databases Composed of
      Nuclear Families
    bibtitle: |-
      Allele Imputation and Haplotype Determination from Databases
                Composed of Nuclear Families
    author:
    - Nathan Medina-Rodríguez
    - Ángelo Santana
    bibauthor: Nathan Medina-Rodríguez and Ángelo Santana
    abstract: '  Abstract The alleHap package is designed for imputing genetic missing
      data and reconstruct non           recombinant haplotypes from pedigree databases
      in a deterministic way. When genotypes of related            individuals are
      available in a number of linked genetic markers, the program starts by identifying            haplotypes
      compatible with the observed genotypes in those markers without missing values.
      If            haplotypes are identified in parents or offspring, missing alleles
      can be imputed in subjects containing            missing values. Several scenarios
      are analyzed: family completely genotyped, children partially            genotyped
      and parents completely genotyped, children fully genotyped and parents containing            entirely
      or partially missing genotypes, and founders and their offspring both only partially
      genotyped.            The alleHap package also has a function to simulate pedigrees
      including all these scenarios. This            article describes in detail how
      our package works for the desired applications, including illustrated            explanations
      and easily reproducible examples.'
    acknowledged: '2016-08-25'
    online: '2017-11-16'
    CRANpkgs:
    - haplo.ccs
    - haplo.stats
    - hsphase
    - linkim
    - rrBLUP
    - synbreed
    - alleHap
    CTV_rev: Genetics
    landing: '2017'
    pages:
    - 35
    - 55
  - slug: RJ-2017-046
    title: Visualization of Regression Models Using visreg
    bibtitle: Visualization of Regression Models Using visreg
    author:
    - Patrick Breheny
    - Woodrow Burchett
    bibauthor: Patrick Breheny and Woodrow Burchett
    abstract: '  Abstract Regression models allow one to isolate the relationship
      between the outcome and an ex           planatory variable while the other variables
      are held constant. Here, we introduce an R package,            visreg, for the
      convenient visualization of this relationship via short, simple function calls.
      In addition            to estimates of this relationship, the package also provides
      pointwise confidence bands and partial            residuals to allow assessment
      of variability as well as outliers and other deviations from modeling            assumptions.
      The package provides several options for visualizing models with interactions,
      including            lattice plots, contour plots, and both static and interactive
      perspective plots. The implementation of            the package is designed
      to be fully object-oriented and interface seamlessly with R’s rich collection
      of            model classes, allowing a consistent interface for visualizing
      not only linear models, but generalized            linear models, proportional
      hazards models, generalized additive models, robust regression models,            and
      many more.'
    acknowledged: '2016-09-12'
    online: '2017-10-24'
    CRANpkgs:
    - visreg
    - rms
    - rockchalk
    - car
    - effects
    - plotmo
    - lattice
    - ggplot2
    - splines
    - rgl
    - MASS
    - mgcv
    - locfit
    - randomForest
    - e1071
    - gbm
    - lme4
    CTV_rev:
    - SocialSciences
    - Econometrics
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Graphics
    - Psychometrics
    - Survival
    - Bayesian
    - Distributions
    - SpatioTemporal
    - Cluster
    - Finance
    - NumericalMathematics
    - OfficialStatistics
    - Phylogenetics
    - ReproducibleResearch
    - Robust
    landing: '2017'
    pages:
    - 56
    - 71
  - slug: RJ-2017-044
    title: 'fourierin: An R package to compute Fourier integrals'
    bibtitle: 'fourierin: An R package to compute Fourier integrals'
    author:
    - Guillermo Basulto-Elias
    - Alicia Carriquiry
    - Kris De Brabanter
    - Daniel J. Nordman
    bibauthor: |-
      Guillermo Basulto-Elias and Alicia Carriquiry and Kris De
                Brabanter and Daniel J. Nordman
    abstract: '  Abstract We present the R package fourierin (Basulto-Elias, 2017)
      for evaluating functions defined as            Fourier-type integrals over a
      collection of argument values. The integrals are finitely supported with            integrands
      involving continuous functions of one or two variables. As an important application,
      such            Fourier integrals arise in so-called “inversion formulas”, where
      one seeks to evaluate a probability            density at a series of points
      from a given characteristic function (or vice versa) through Fourier            transforms.
      This paper intends to fill a gap in current R software, where tools for repeated
      evaluation            of functions as Fourier integrals are not directly available.
      We implement two approaches for such            computations with numerical
      integration. In particular, if the argument collection for evaluation            corresponds
      to a regular grid, then an algorithm from Inverarity (2002) may be employed
      based            on a fast Fourier transform, which creates significant improvements
      in the speed over a second            approach to numerical Fourier integration
      (where the latter also applies to cases where the points for            evaluation
      are not on a grid). We illustrate the package with the computation of probability
      densities            and characteristic functions through Fourier integrals/transforms,
      for both univariate and bivariate            examples.'
    acknowledged: '2016-11-16'
    online: '2017-10-12'
    CRANpkgs:
    - fourierin
    - RcppArmadillo
    CTV_rev: NumericalMathematics
    landing: '2017'
    pages:
    - 72
    - 83
  - slug: RJ-2017-036
    title: Discrete Time Markov Chains with R
    bibtitle: Discrete Time Markov Chains with R
    author: Giorgio Alfredo Spedicato
    bibauthor: Giorgio Alfredo Spedicato
    abstract: '  Abstract The markovchain package aims to provide S4 classes and methods
      to easily handle Discrete            Time Markov Chains (DTMCs), filling the
      gap with what is currently available in the CRAN repository.            In this
      work, I provide an exhaustive description of the main functions included in
      the package, as            well as hands-on examples.'
    acknowledged: '2016-11-16'
    online: '2017-07-24'
    CRANpkgs:
    - markovchain
    - clickstream
    - DTMCPack
    - MTCM
    - FuzzyStatProb
    - depmixS4
    - HMM
    - msm
    - heemod
    - TPmsm
    - Rcpp
    - igraph
    - matlab
    - Matrix
    - expm
    - method
    - expm
    - RcppParallel
    CTV_rev:
    - NumericalMathematics
    - HighPerformanceComputing
    - Survival
    - Cluster
    - Distributions
    - Econometrics
    - Finance
    - gR
    - Graphics
    - Multivariate
    - Optimization
    - Spatial
    - TimeSeries
    landing: '2017'
    pages:
    - 84
    - 104
  - slug: RJ-2017-041
    title: 'CRTgeeDR: an R Package for Doubly Robust Generalized Estimating Equations
      Estimations in Cluster Randomized Trials with Missing Data'
    bibtitle: |-
      CRTgeeDR: an R Package for Doubly Robust Generalized
                Estimating Equations Estimations in Cluster Randomized
                Trials with Missing Data
    author:
    - Melanie Prague
    - Rui Wang
    - Victor De Gruttola
    bibauthor: Melanie Prague and Rui Wang and Victor De Gruttola
    abstract: '  Abstract Semi-parametric approaches based on generalized estimating
      equations (GEE) are widely            used to analyze correlated outcomes in
      longitudinal settings. In this paper, we present a package            CRTgeeDR
      developed for cluster randomized trials with missing data (CRTs). For use of
      inverse            probability weighting to adjust for missing data in cluster
      randomized trials, we show that other            software lead to biased estimation
      for non-independence working correlation structure. CRTgeeDR            solves
      this problem. We also extend the ability of existing packages to allow augmented
      Doubly Robust            GEE estimation (DR). Simulation studies demonstrate
      the consistency of estimators implemented in            CRTgeeDR compared to
      packages such as geepack and the gains associated with the use of the DR            for
      analyzing a binary outcome using a logistic regression. Finally, we illustrate
      the method on data            from a sanitation CRT in developing countries.'
    acknowledged: '2016-11-16'
    online: '2017-08-25'
    CRANpkgs:
    - CRTgeeDR
    - gee
    - geepack
    - geeM
    - ipw
    - drgee
    - CausalGAM
    - tmle
    - tmlenet
    - numDeriv
    - geesmv
    CTV_rev:
    - SocialSciences
    - Econometrics
    - NumericalMathematics
    - Robust
    landing: '2017'
    pages:
    - 105
    - 115
  - slug: RJ-2017-051
    title: 'queueing: A Package For Analysis Of Queueing Networks and Models in R'
    bibtitle: |-
      queueing: A Package For Analysis Of Queueing Networks and
                Models in R
    author:
    - Pedro Cañadilla Jiménez
    - Yolanda Román Montoya
    bibauthor: Pedro Cañadilla Jiménez and Yolanda Román Montoya
    abstract: '  Abstract queueing is a package that solves and provides the main
      performance measures for both            basic Markovian queueing models and
      single and multiclass product-form queueing networks. It can            be used
      both in education and for professional purposes. It provides an intuitive, straightforward            way
      to build queueing models using S3 methods. The package solves Markovian models
      of the form            M/M/c/K/M/FCFS, open and closed single class Jackson
      networks, open and closed multiclass            networks and mixed networks.
      Markovian models are used when both the customer inter-arrival time            and
      the server processing time are exponentially distributed. Queueing network solvers
      are useful for            modelling situations in which more than one station
      must be visited.'
    acknowledged: '2016-11-16'
    online: '2017-10-24'
    CRANpkgs:
    - simmer
    - queuecomputer
    - queueing
    suppl: 1.8 Kb
    landing: '2017'
    pages:
    - 116
    - 126
  - slug: RJ-2017-038
    title: 'ctmcd: An R Package for Estimating the Parameters of a Continuous-Time
      Markov Chain from Discrete-Time Data'
    bibtitle: |-
      ctmcd: An R Package for Estimating the Parameters of a
                Continuous-Time Markov Chain from Discrete-Time Data
    author: Marius Pfeuffer
    bibauthor: Marius Pfeuffer
    abstract: '  Abstract This article introduces the R package ctmcd, which provides
      an implementation of methods            for the estimation of the parameters
      of a continuous-time Markov chain given that data are only            available
      on a discrete-time basis. This data consists of partial observations of the
      state of the chain,            which are made without error at discrete times,
      an issue also known as the embedding problem for            Markov chains. The
      functions provided comprise matrix logarithm based approximations as described            in
      Israel et al. (2001), as well as Kreinin and Sidelnikova (2001), an expectation-maximization
      algorithm            and a Gibbs sampling approach, both introduced by Bladt
      and Sørensen (2005). For the expectation           maximization algorithm Wald
      confidence intervals based on the Fisher information estimation method            of
      Oakes (1999) are provided. For the Gibbs sampling approach, equal-tailed credibility
      intervals            can be obtained. In order to visualize the parameter estimates,
      a matrix plot function is provided.            The methods described are illustrated
      by Standard and Poor’s discrete-time corporate credit rating            transition
      data.'
    acknowledged: '2016-12-12'
    online: '2017-07-28'
    CRANpkgs:
    - msm
    - ctmcd
    - coda
    - foreach
    - doParallel
    CTV_rev:
    - Bayesian
    - Distributions
    - gR
    - HighPerformanceComputing
    - Survival
    suppl: 1.6 Kb
    landing: '2017'
    pages:
    - 127
    - 141
  - slug: RJ-2017-037
    title: Furniture for Quantitative Scientists
    bibtitle: Furniture for Quantitative Scientists
    author:
    - Tyson S. Barrett
    - Emily Brignone
    bibauthor: Tyson S. Barrett and Emily Brignone
    abstract: '  Abstract A basic understanding of the distributions of study variables
      and the relationships among            them is essential to inform statistical
      modeling. This understanding is achieved through the com           putation
      of summary statistics and exploratory data analysis. Unfortunately, this step
      tends to be            under-emphasized in the research process, in part because
      of the often tedious nature of thorough            exploratory data analysis.
      The table1() function in the furniture package streamlines much of the            exploratory
      data analysis process, making the computation and communication of summary statistics            simple
      and beautiful while offering significant time-savings to the researcher.'
    acknowledged: '2016-12-23'
    online: '2017-07-24'
    CRANpkgs: furniture
    landing: '2017'
    pages:
    - 142
    - 148
  - slug: RJ-2017-052
    title: 'BayesBD: An R Package for Bayesian Inference on Image Boundaries'
    bibtitle: |-
      BayesBD: An R Package for Bayesian Inference on Image
                Boundaries
    author:
    - Nicholas Syring
    - Meng Li
    bibauthor: Nicholas Syring and Meng Li
    abstract: '  Abstract                 We present the BayesBD package providing
      Bayesian inference for boundaries of noisy images.            The BayesBD package
      implements flexible Gaussian process priors indexed by the circle to recover            the
      boundary in a binary or Gaussian noised image. The boundary recovered by BayesBD
      has the            practical advantages of guaranteed geometric restrictions
      and convenient joint inferences under certain            assumptions, in addition
      to its desirable theoretical property of achieving (nearly) minimax optimal            rate
      in a way that is adaptive to the unknown smoothness. The core sampling tasks
      for our model have            linear complexity, and are implemented in C++
      for computational efficiency using packages Rcpp and            RcppArmadillo.
      Users can access the full functionality of the package in both the command line
      and            the corresponding shiny application. Additionally, the package
      includes numerous utility functions            to aid users in data preparation
      and analysis of results. We compare BayesBD with selected existing            packages
      using both simulations and real data applications, demonstrating the excellent
      performance            and flexibility of BayesBD even when the observation
      contains complicated structural information            that may violate its
      assumptions.'
    acknowledged: '2016-12-23'
    online: '2017-10-25'
    CRANpkgs:
    - BayesBD
    - RcppArmadillo
    - shiny
    CTV_rev:
    - NumericalMathematics
    - WebTechnologies
    landing: '2017'
    pages:
    - 149
    - 162
  - slug: RJ-2017-047
    title: 'arulesViz: Interactive Visualization of Association Rules with R'
    bibtitle: |-
      arulesViz: Interactive Visualization of Association Rules
                with R
    author: Michael Hahsler
    bibauthor: Michael Hahsler
    abstract: '  Abstract Association rule mining is a popular data mining method
      to discover interesting relation           ships between variables in large
      databases. An extensive toolbox is available in the R-extension            package
      arules. However, mining association rules often results in a vast number of
      found rules,            leaving the analyst with the task to go through a large
      set of rules to identify interesting ones. Sifting            manually through
      extensive sets of rules is time-consuming and strenuous. Visualization and espe           cially
      interactive visualization has a long history of making large amounts of data
      better accessible.            The R-extension package arulesViz provides most
      popular visualization techniques for association            rules. In this paper,
      we discuss recently added interactive visualizations to explore association
      rules            and demonstrate how easily they can be used in arulesViz via
      a unified interface. With examples, we            help to guide the user in
      selecting appropriate visualizations and interpreting the results.'
    acknowledged: '2016-12-23'
    online: '2017-10-24'
    CRANpkgs:
    - arulesViz
    - arules
    - DT
    - plotly
    - grid
    - visNetwork
    CTV_rev:
    - MachineLearning
    - ReproducibleResearch
    landing: '2017'
    pages:
    - 163
    - 175
  - slug: RJ-2017-060
    title: 'ManlyMix: An R Package for Manly Mixture Modeling'
    bibtitle: 'ManlyMix: An R Package for Manly Mixture Modeling'
    author:
    - Xuwen Zhu
    - Volodymyr Melnykov
    bibauthor: Xuwen Zhu and Volodymyr Melnykov
    abstract: '  Abstract Model-based clustering is a popular technique for grouping
      objects based on a finite mixture            model. It has countless applications
      in different fields of study. The R package ManlyMix implements            the
      Manly mixture model that allows modeling skewness within data groups and performs
      cluster            analysis. ManlyMix is a powerful diagnostics tool that is
      capable of conducting investigation con           cerning the normality of variables
      upon fitting of a Manly forward or backward model. Theoretical            foundations
      as well as description of functions are provided. All features of the package
      are illus           trated with examples in great detail. The analysis of real-life
      datasets demonstrates the flexibility and            usefulness of the package.'
    acknowledged: '2017-02-17'
    online: '2017-11-22'
    CRANpkgs:
    - flowClust
    - mixsmsn
    - EMMIXskew
    - EMMIXuskew
    - mixsmsn
    - EMMIXskew
    - EMMIXuskew
    - flowClust
    - ManlyMix
    - ManlyMix
    CTV_rev: Cluster
    landing: '2017'
    pages:
    - 176
    - 197
  - slug: RJ-2017-042
    title: 'adegraphics: An S4 Lattice-Based Package for the Representation of Multivariate
      Data'
    bibtitle: |-
      adegraphics: An S4 Lattice-Based Package for the
                Representation of Multivariate Data
    author:
    - Aurélie Siberchicot
    - Alice Julien-Laferrière
    - Anne-Béatrice Dufour
    - Jean Thioulouse
    - Stéphane            Dray
    bibauthor: |-
      Aurélie Siberchicot and Alice Julien-Laferrière and Anne-
                Béatrice Dufour and Jean Thioulouse and Stéphane Dray
    abstract: '  Abstract The ade4 package provides tools for multivariate analyses.
      Whereas new statistical methods            have been added regularly in the
      package since its first release in 2002, the graphical functions, that            are
      used to display the main outputs of an analysis, have not benefited from such
      enhancements. In            this context, the adegraphics package, available
      on CRAN since 2015, is a complete reimplementation            of the ade4 graphical
      functionalities but with large improvements. The package uses the S4 object            system
      (each graph is an object) and is based on the graphical framework provided by
      lattice and            grid. We give a brief description of the package and
      illustrate some important functionalities to build            elegant graphs.'
    acknowledged: '2017-02-17'
    online: '2017-10-07'
    CRANpkgs:
    - vegan
    - MASS
    - FactoMineR
    - ade4
    - lattice
    - adegraphics
    - sp
    - spdep
    - RColorBrewer
    - ggplot2
    CTVs: Multivariate
    CTV_rev:
    - Multivariate
    - Spatial
    - Graphics
    - Psychometrics
    - Environmetrics
    - Econometrics
    - Phylogenetics
    - Distributions
    - NumericalMathematics
    - Robust
    - SocialSciences
    - SpatioTemporal
    suppl: 3.4 Kb
    landing: '2017'
    pages:
    - 198
    - 212
  - slug: RJ-2017-064
    title: 'carx: an R Package to Estimate Censored Autoregressive Time Series with
      Exogenous Covariates '
    bibtitle: |-
      carx: an R Package to Estimate Censored Autoregressive Time
                Series with Exogenous Covariates
    author:
    - Chao Wang
    - Kung-Sik Chan
    bibauthor: Chao Wang and Kung-Sik Chan
    abstract: '  Abstract We implement in the R package carx a novel and computationally
      efficient quasi-likelihood            method for estimating a censored autoregressive
      model with exogenous covariates. The proposed            quasi-likelihood method
      reduces to maximum likelihood estimation in absence of censoring. The carx            package
      contains many useful functions for practical data analysis with censored stochastic
      regression,            including functions for outlier detection, model diagnostics,
      and prediction with censored time series            data. We illustrate the
      capabilities of the carx package with simulations and an elaborate real data            analysis.'
    acknowledged: '2017-03-10'
    online: '2017-11-27'
    CRANpkgs:
    - censReg
    - AER
    - NADA
    - VGAM
    - MCMCpack
    - cents
    - ARCensReg
    - carx
    - xts
    - TSA
    CTV_rev:
    - Survival
    - TimeSeries
    - Econometrics
    - Distributions
    - Multivariate
    - Psychometrics
    - Bayesian
    - Environmetrics
    - ExtremeValue
    - Finance
    - SocialSciences
    - SpatioTemporal
    suppl: 2.3 Kb
    landing: '2017'
    pages:
    - 213
    - 231
  - slug: RJ-2017-048
    title: 'liureg: A Comprehensive R Package for the Liu Estimation of Linear Regression
      Model with Collinear Regressors'
    bibtitle: |-
      liureg: A Comprehensive R Package for the Liu Estimation of
                Linear Regression Model with Collinear Regressors
    author:
    - Muhammad Imdadullah
    - Muhammad Aslam
    - Saima Altaf
    bibauthor: Muhammad Imdadullah and Muhammad Aslam and Saima Altaf
    abstract: '  Abstract The Liu regression estimator is now a commonly used alternative
      to the conventional            ordinary least squares estimator that avoids
      the adverse effects in the situations when there exists a            considerable
      degree of multicollinearity among the regressors. There are only a few software
      packages            available for estimation of the Liu regression coefficients,
      though with limited methods to estimate            the Liu biasing parameter
      without addressing testing procedures. Our liureg package can be used            to
      estimate the Liu regression coefficients utilizing a range of different existing
      biasing parameters,            to test these coefficients with more than 15
      Liu related statistics, and to present different graphical            displays
      of these statistics.'
    acknowledged: '2017-03-14'
    online: '2017-10-24'
    CRANpkgs:
    - lrmest
    - ltsbase
    - liureg
    - lmridge
    - MASS
    - mctest
    CTV_rev:
    - Distributions
    - Econometrics
    - Environmetrics
    - Multivariate
    - NumericalMathematics
    - Psychometrics
    - Robust
    - SocialSciences
    suppl: 689 bytes
    landing: '2017'
    pages:
    - 232
    - 247
  - slug: RJ-2017-035
    title: A Tidy Data Model for Natural Language Processing using cleanNLP
    bibtitle: |-
      A Tidy Data Model for Natural Language Processing using
                cleanNLP
    author: Taylor Arnold
    bibauthor: Taylor Arnold
    abstract: '  Abstract Recent advances in natural language processing have produced
      libraries that extract low           level features from a collection of raw
      texts. These features, known as annotations, are usually stored            internally
      in hierarchical, tree-based data structures. This paper proposes a data model
      to represent            annotations as a collection of normalized relational
      data tables optimized for exploratory data analysis            and predictive
      modeling. The R package cleanNLP, which calls one of two state of the art NLP            libraries
      (CoreNLP or spaCy), is presented as an implementation of this data model. It
      takes raw text            as an input and returns a list of normalized tables.
      Specific annotations provided include tokenization,            part of speech
      tagging, named entity recognition, sentiment analysis, dependency parsing, coreference            resolution,
      and word embeddings. The package currently supports input text in English, German,            French,
      and Spanish.'
    acknowledged: '2017-03-27'
    online: '2017-06-28'
    CRANpkgs:
    - dplyr
    - ggplot2
    - magrittr
    - broom
    - janitor
    - tidyr
    - cleanNLP
    - tidytext
    - StanfordCoreNLP
    - coreNLP
    - XML
    - spacyr
    - NLP
    - cleanNLP
    - lda
    - lsa
    - topicmodels
    - sqliter
    - rJava
    - sotu
    - glmnet
    CTVs: NaturalLanguageProcessing
    CTV_rev:
    - NaturalLanguageProcessing
    - WebTechnologies
    - Graphics
    - HighPerformanceComputing
    - MachineLearning
    - Phylogenetics
    - Survival
    suppl: 3.4 Kb
    landing: '2017'
    pages:
    - 248
    - 267
  - slug: RJ-2017-055
    title: 'mle.tools: An R Package for Maximum Likelihood Bias Correction'
    bibtitle: |-
      mle.tools: An R Package for Maximum Likelihood Bias
                Correction
    author:
    - Josmar Mazucheli
    - André Felipe B. Menezes
    - Saralees Nadarajah
    bibauthor: |-
      Josmar Mazucheli and André Felipe B. Menezes and Saralees
                Nadarajah
    abstract: '  Abstract Recently, Mazucheli (2017) uploaded the package mle.tools
      to CRAN. It can be used for            bias corrections of maximum likelihood
      estimates through the methodology proposed by Cox and            Snell (1968).
      The main function of the package, coxsnell.bc(), computes the bias corrected
      maximum            likelihood estimates. Although in general, the bias corrected
      estimators may be expected to have            better sampling properties than
      the uncorrected estimators, analytical expressions from the formula            proposed
      by Cox and Snell (1968) are either tedious or impossible to obtain. The purpose
      of this paper            is twofolded: to introduce the mle.tools package, especially
      the coxsnell.bc() function; secondly, to            compare, for thirty one
      continuous distributions, the bias estimates from the coxsnell.bc() function            and
      the bias estimates from analytical expressions available in the literature.
      We also compare, for            five distributions, the observed and expected
      Fisher information. Our numerical experiments show            that the functions
      are efficient to estimate the biases by the Cox-Snell formula and for calculating
      the            observed and expected Fisher information.'
    acknowledged: '2017-04-04'
    online: '2017-11-01'
    CRANpkgs:
    - mle.tools
    - fitdistrplus
    CTV_rev:
    - Distributions
    - Survival
    suppl: 4.5 Kb
    landing: '2017'
    pages:
    - 268
    - 290
  - slug: RJ-2017-045
    title: 'afmToolkit: an R Package for Automated AFM Force-Distance Curves Analysis'
    bibtitle: |-
      afmToolkit: an R Package for Automated AFM Force-Distance
                Curves Analysis
    author:
    - Rafael Benítez
    - Vicente J. Bolós
    - José-Luis Toca-Herrera
    bibauthor: |-
      Rafael Benítez and Vicente J. Bolós and José-Luis Toca-
                Herrera
    abstract: '  Abstract Atomic force microscopy (AFM) is widely used to measure
      molecular and colloidal inter           actions as well as mechanical properties
      of biomaterials. In this paper the afmToolkit R package is            introduced.
      This package allows the user to automatically batch process AFM force-distance
      and            force-time curves. afmToolkit capabilities range from importing
      ASCII files and preprocessing the            curves (contact point detection,
      baseline correction. . . ) for finding relevant physical information,            such
      as Young’s modulus, adhesion energies and exponential decay for force relaxation
      and creep            experiments. This package also contains plotting, summary
      and feature extraction functions. The            package also comes with several
      data sets so the user can test the aforementioned features with ease.            The
      package afmToolkit eases the basic processing of large amount of AFM F-d/t curves
      at once. It            is also flexible enough to easily incorporate new functions
      as they are needed and can be seen as a            programming infrastructure
      for further algorithm development.'
    acknowledged: '2017-04-07'
    online: '2017-10-12'
    CRANpkgs:
    - afmToolkit
    - devtools
    - ggplot2
    - minpack.lm
    - gridExtra
    - scales
    - dplyr
    CTV_rev:
    - ChemPhys
    - Graphics
    - Optimization
    - Phylogenetics
    suppl: 1.5 Kb
    landing: '2017'
    pages:
    - 291
    - 308
  - slug: RJ-2017-049
    title: The welchADF Package for Robust Hypothesis Testing in Unbalanced Multivariate
      Mixed Models with Heteroscedastic and Non-normal Data
    bibtitle: |-
      The welchADF Package for Robust Hypothesis Testing in
                Unbalanced Multivariate Mixed Models with Heteroscedastic
                and Non-normal Data
    author: Pablo J. Villacorta
    bibauthor: Pablo J. Villacorta
    abstract: '  Abstract A new R package is presented for dealing with non-normality
      and variance heterogeneity of            sample data when conducting hypothesis
      tests of main effects and interactions in mixed models. The            proposal
      departs from an existing SAS program which implements Johansen’s general formulation
      of            Welch-James’s statistic with approximate degrees of freedom, which
      makes it suitable for testing any            linear hypothesis concerning cell
      means in univariate and multivariate mixed model designs when            the
      data pose non-normality and non-homogeneous variance. Improved type I error
      rate control is            obtained using bootstrapping for calculating an empirical
      critical value, whereas robustness against            non-normality is achieved
      through trimmed means and Winsorized variances. A wrapper function            eases
      the application of the test in common situations, such as performing omnibus
      tests on all effects            and interactions, pairwise contrasts, and tetrad
      contrasts of two-way interactions. The package is            demonstrated in
      several problems including unbalanced univariate and multivariate designs.'
    acknowledged: '2017-04-24'
    online: '2017-10-24'
    CRANpkgs:
    - ART
    - WRS2
    - robustbase
    - robust
    - robustlmm
    - nlme
    - lme4
    - welchADF
    - gamm4
    - mgcv
    CTV_rev:
    - Robust
    - Econometrics
    - Environmetrics
    - SocialSciences
    - Bayesian
    - OfficialStatistics
    - Psychometrics
    - SpatioTemporal
    - ChemPhys
    - Finance
    - Multivariate
    - Spatial
    suppl: 1.2 Kb
    landing: '2017'
    pages:
    - 309
    - 328
  - slug: RJ-2017-054
    title: 'ider: Intrinsic Dimension Estimation with R'
    bibtitle: 'ider: Intrinsic Dimension Estimation with R'
    author: Hideitsu Hino
    bibauthor: Hideitsu Hino
    abstract: '  Abstract In many data analyses, the dimensionality of the observed
      data is high while its intrinsic            dimension remains quite low. Estimating
      the intrinsic dimension of an observed dataset is an essential            preliminary
      step for dimensionality reduction, manifold learning, and visualization. This
      paper            introduces an R package, named ider, that implements eight
      intrinsic dimension estimation methods,            including a recently proposed
      method based on a second-order expansion of a probability mass            function
      and a generalized linear model. The usage of each function in the package is
      explained with            datasets generated using a function that is also included
      in the package.'
    acknowledged: '2017-04-27'
    online: '2017-10-31'
    CRANpkgs:
    - ider
    - ider
    - ider
    - fractal
    - nonlinearTseries
    - tseriesChaos
    - fractal
    - nonlinearTseries
    - tseriesChaos
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - ider
    - Rcpp
    CTV_rev:
    - TimeSeries
    - Finance
    - HighPerformanceComputing
    - NumericalMathematics
    suppl: 950 bytes
    landing: '2017'
    pages:
    - 329
    - 341
  - slug: RJ-2017-068
    title: 'rpsftm: An R Package for Rank Preserving Structural Failure Time Models'
    bibtitle: |-
      rpsftm: An R Package for Rank Preserving Structural Failure
                Time Models
    author:
    - Annabel Allison
    - Ian R White
    - Simon Bond
    bibauthor: Annabel Allison and Ian R White and Simon Bond
    abstract: '  Abstract                Treatment switching in a randomised controlled
      trial occurs when participants change from their            randomised treatment
      to the other trial treatment during the study. Failure to account for treatment            switching
      in the analysis (i.e. by performing a standard intention-to-treat analysis)
      can lead to biased            estimates of treatment efficacy. The rank preserving
      structural failure time model (RPSFTM) is a            method used to adjust
      for treatment switching in trials with survival outcomes. The RPSFTM is due
      to            Robins and Tsiatis (1991) and has been developed by White et al.
      (1997, 1999).                The method is randomisation based and uses only
      the randomised treatment group, observed            event times, and treatment
      history in order to estimate a causal treatment effect. The treatment effect,            ψ,
      is estimated by balancing counter-factual event times (that would be observed
      if no treatment            were received) between treatment groups. G-estimation
      is used to find the value of ψ such that a test            statistic Z (ψ) =
      0. This is usually the test statistic used in the intention-to-treat analysis,
      for example,            the log rank test statistic.                We present
      an R package, rpsftm, that implements the method.'
    acknowledged: '2017-04-27'
    online: '2017-12-04'
    CRANpkgs:
    - ipw
    - rpsftm
    - eha
    CTV_rev: Survival
    suppl: 678 bytes
    landing: '2017'
    pages:
    - 342
    - 353
  - slug: RJ-2017-039
    title: 'anomalyDetection: Implementation of Augmented Network Log Anomaly Detection
      Procedures'
    bibtitle: |-
      anomalyDetection: Implementation of Augmented Network Log
                Anomaly Detection Procedures
    author:
    - Robert J. Gutierrez
    - Bradley C. Boehmke
    - Kenneth W. Bauer
    - Cade M. Saie
    - Trevor J. Bihl
    bibauthor: |-
      Robert J. Gutierrez and Bradley C. Boehmke and Kenneth W.
                Bauer and Cade M. Saie and Trevor J. Bihl
    abstract: '  Abstract As the number of cyber-attacks continues to grow on a daily
      basis, so does the delay in threat            detection. For instance, in 2015,
      the Office of Personnel Management discovered that approximately            21.5
      million individual records of Federal employees and contractors had been stolen.
      On average,            the time between an attack and its discovery is more
      than 200 days. In the case of the OPM breach,            the attack had been
      going on for almost a year. Currently, cyber analysts inspect numerous potential            incidents
      on a daily basis, but have neither the time nor the resources available to perform
      such a task.            anomalyDetection aims to curtail the time frame in which
      anomalous cyber activities go unnoticed            and to aid in the efficient
      discovery of these anomalous transactions among the millions of daily logged            events
      by i) providing an efficient means for pre-processing and aggregating cyber
      data for analysis            by employing a tabular vector transformation and
      handling multicollinearity concerns; ii) offering            numerous built-in
      multivariate statistical functions such as Mahalanobis distance, factor analysis,            principal
      components analysis to identify anomalous activity, iii) incorporating the pipe
      operator            (%>%) to allow it to work well in the tidyverse workflow.
      Combined, anomalyDetection offers cyber            analysts an efficient and
      simplified approach to break up network events into time-segment blocks            and
      identify periods associated with suspected anomalies for further evaluation.'
    acknowledged: '2017-05-05'
    online: '2017-08-04'
    CRANpkgs:
    - anomalyDetection
    - magrittr
    - tidyverse
    CTV_rev: WebTechnologies
    suppl: 909 bytes
    landing: '2017'
    pages:
    - 354
    - 365
  - slug: RJ-2017-053
    title: Simulating Noisy, Nonparametric, and Multivariate Discrete Patterns
    bibtitle: |-
      Simulating Noisy, Nonparametric, and Multivariate Discrete
                Patterns
    author:
    - Ruby Sharma
    - Sajal Kumar
    - Hua Zhong
    - Mingzhou Song
    bibauthor: Ruby Sharma and Sajal Kumar and Hua Zhong and Mingzhou Song
    abstract: '  Abstract Requiring no analytical forms, nonparametric discrete patterns
      are flexible in representing            complex relationships among random variables.
      This makes them increasingly useful for data-driven            applications.
      However, there appears to be no software tools for simulating nonparametric
      discrete            patterns, which prevents objective evaluation of statistical
      methods that discover discrete relationships            from data. We present
      a simulator to generate nonparametric discrete functions as contingency tables.            User
      can request strictly many-to-one functional patterns. The simulator can also
      produce contingency            tables representing dependent non-functional
      and independent relationships. An option is provided            to apply random
      noise to contingency tables. We demonstrate the utility of the simulator by
      showing            the advantage of the FunChisq test over Pearson’s chi-square
      test in detecting functional patterns. This            simulator, implemented
      in the function simulate_tables in the R package FunChisq (version 2.4.0 or            greater),
      offers an important means to evaluate the performance of nonparametric statistical
      pattern            discovery methods.'
    acknowledged: '2017-05-09'
    online: '2017-10-25'
    CRANpkgs:
    - rTableICC
    - FunChisq
    suppl: 3.4 Kb
    landing: '2017'
    pages:
    - 366
    - 377
  - slug: RJ-2017-066
    title: glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated
      Generalized Linear Mixed Modeling
    bibtitle: |-
      glmmTMB Balances Speed and Flexibility Among Packages for
                Zero-inflated Generalized Linear Mixed Modeling
    author:
    - Mollie E. Brooks
    - Kasper Kristensen
    - Koen J. van Benthem
    - Arni Magnusson
    - Casper W. Berg
    - '           Anders Nielsen'
    - Hans J. Skaug
    - Martin Mächler
    - Benjamin M. Bolker
    bibauthor: |-
      Mollie E. Brooks and Kasper Kristensen and Koen J. van
                Benthem and Arni Magnusson and Casper W. Berg and Anders
                Nielsen and Hans J. Skaug and Martin Mächler and Benjamin M.
                Bolker
    abstract: '  Abstract Count data can be analyzed using generalized linear mixed
      models when observations            are correlated in ways that require random
      effects. However, count data are often zero-inflated,            containing
      more zeros than would be expected from the typical error distributions. We present
      a new            package, glmmTMB, and compare it to other R packages that fit
      zero-inflated mixed models. The            glmmTMB package fits many types of
      GLMMs and extensions, including models with continuously            distributed
      responses, but here we focus on count responses. glmmTMB is faster than glmmADMB,            MCMCglmm,
      and brms, and more flexible than INLA and mgcv for zero-inflated modeling. One            unique
      feature of glmmTMB (among packages that fit zero-inflated mixed models) is its
      ability to            estimate the Conway-Maxwell-Poisson distribution parameterized
      by the mean. Overall, its most            appealing features for new users may
      be the combination of speed, flexibility, and its interface’s            similarity
      to lme4.'
    acknowledged: '2017-05-29'
    online: '2017-12-01'
    CRANpkgs:
    - glmmTMB
    - pscl
    - MCMCglmm
    - mgcv
    - brms
    - gamlss
    - flexmix
    - MXM
    - VGAM
    - mgcv
    - TMB
    - devtools
    CTV_rev:
    - Econometrics
    - Environmetrics
    - SocialSciences
    - Bayesian
    - Psychometrics
    - Survival
    - Cluster
    - Distributions
    - ExtremeValue
    - gR
    - MachineLearning
    - Multivariate
    - Phylogenetics
    suppl: 5 Kb
    landing: '2017'
    pages:
    - 378
    - 400
  - slug: RJ-2017-059
    title: Simulating Probabilistic Long-Term Effects in Models with Temporal Dependence
    bibtitle: |-
      Simulating Probabilistic Long-Term Effects in Models with
                Temporal Dependence
    author:
    - Christopher Gandrud
    - Laron K. Williams
    bibauthor: Christopher Gandrud and Laron K. Williams
    abstract: '  Abstract The R package pltesim calculates and depicts probabilistic
      long-term effects in binary models            with temporal dependence variables.
      The package performs two tasks. First, it calculates the change in            the
      probability of the event occurring given a change in a theoretical variable.
      Second, it calculates the            rolling difference in the future probability
      of the event for two scenarios: one where the event occurred            at a
      given time and one where the event does not occur. The package is consistent
      with the recent            movement to depict meaningful and easy-to-interpret
      quantities of interest with the requisite measures            of uncertainty.
      It is the first to make it easy for researchers to interpret shortand long-term
      effects of            explanatory variables in binary autoregressive models,
      which can have important implications for the            correct interpretation
      of these models.'
    acknowledged: '2017-06-29'
    online: '2017-11-22'
    CRANpkgs:
    - pltesim
    - ggplot2
    - DAMisc
    CTV_rev:
    - Graphics
    - Phylogenetics
    suppl: 1.6 Kb
    landing: '2017'
    pages:
    - 401
    - 408
  - slug: RJ-2017-067
    title: 'RQGIS: Integrating R with QGIS for Statistical Geocomputing'
    bibtitle: 'RQGIS: Integrating R with QGIS for Statistical Geocomputing'
    author:
    - Jannes Muenchow
    - Patrick Schratz
    - Alexander Brenning
    bibauthor: Jannes Muenchow and Patrick Schratz and Alexander Brenning
    abstract: '  Abstract Integrating R with Geographic Information Systems (GIS)
      extends R’s statistical capabilities            with numerous geoprocessing
      and data handling tools available in a GIS. QGIS is one of the most            popular
      open-source GIS, and it furthermore integrates other GIS programs such as the
      System for            Automated Geoscientific Analyses (SAGA) GIS and the Geographic
      Resources Analysis Support            System (GRASS) GIS within a single software
      environment. This and its QGIS Python API makes            it a perfect candidate
      for console-based geoprocessing. By establishing an interface, the R package            RQGIS
      makes it possible to use QGIS as a geoprocessing workhorse from within R. Compared
      to            other packages building a bridge to GIS (e.g., rgrass7, RSAGA,
      RPyGeo), RQGIS offers a wider            range of geoalgorithms, and is often
      easier to use due to various convenience functions. Finally,            RQGIS
      supports the seamless integration of Python code using reticulate from within
      R for improved            extendability.'
    acknowledged: '2017-07-07'
    online: '2017-12-04'
    CRANpkgs:
    - maptools
    - raster
    - sp
    - sf
    - mapview
    - mapmisc
    - osmar
    - dodgr
    - RArcInfo
    - rgrass7
    - mapedit
    - rgdal
    - rgeos
    - RSAGA
    - RPyGeo
    - RQGIS
    - reticulate
    - rPython
    - sperrorest
    - nlme
    - mgcv
    - spgrass6
    - leaflet
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - SocialSciences
    - Bayesian
    - ChemPhys
    - Finance
    - HighPerformanceComputing
    - OfficialStatistics
    - Psychometrics
    - WebTechnologies
    suppl: 1.9 Kb
    landing: '2017'
    pages:
    - 409
    - 428
  - slug: RJ-2017-061
    title: 'Partial Rank Data with the hyper2 Package: Likelihood Functions for Generalized
      Bradley-Terry Models'
    bibtitle: |-
      Partial Rank Data with the hyper2 Package: Likelihood
                Functions for Generalized Bradley-Terry Models
    author: Robin K. S. Hankin
    bibauthor: Robin K. S. Hankin
    abstract: '  Abstract Here I present the hyper2 package for generalized Bradley-Terry
      models and give examples            from two competitive situations: single
      scull rowing, and the competitive cooking game show Mas           terChef Australia.
      A number of natural statistical hypotheses may be tested straightforwardly using            the
      software.'
    acknowledged: '2017-07-07'
    online: '2017-11-22'
    CRANpkgs:
    - hyper2
    - aylmer
    CTV_rev: Distributions
    suppl: 1 Kb
    landing: '2017'
    pages:
    - 429
    - 439
  - slug: RJ-2017-062
    title: 'riskRegression: Predicting the Risk of an Event using Cox Regression Models'
    bibtitle: |-
      riskRegression: Predicting the Risk of an Event using Cox
                Regression Models
    author:
    - Brice Ozenne
    - Anne Lyngholm Sørensen
    - Thomas Scheike
    - Christian Torp-Pedersen
    - Thomas            Alexander Gerds
    bibauthor: |-
      Brice Ozenne and Anne Lyngholm Sørensen and Thomas Scheike
                and Christian Torp-Pedersen and Thomas Alexander Gerds
    abstract: '  Abstract In the presence of competing risks a prediction of the time-dynamic
      absolute risk of an event            can be based on cause-specific Cox regression
      models for the event and the competing risks (Benichou            and Gail,
      1990). We present computationally fast and memory optimized C++ functions with
      an R inter           face for predicting the covariate specific absolute risks,
      their confidence intervals, and their confidence            bands based on right
      censored time to event data. We provide explicit formulas for our implementation            of
      the estimator of the (stratified) baseline hazard function in the presence of
      tied event times. As            a by-product we obtain fast access to the baseline
      hazards (compared to survival::basehaz()) and            predictions of survival
      probabilities, their confidence intervals and confidence bands. Confidence            intervals
      and confidence bands are based on point-wise asymptotic expansions of the corresponding            statistical
      functionals. The software presented here is implemented in the riskRegression
      package.'
    acknowledged: '2017-07-07'
    online: '2017-11-22'
    CRANpkgs:
    - survival
    - rms
    - riskRegression
    - mstate
    - rbenchmark
    - profvis
    - mets
    CTVs: Survival
    CTV_rev:
    - Survival
    - Econometrics
    - SocialSciences
    - ClinicalTrials
    - ReproducibleResearch
    suppl: 1.7 Kb
    landing: '2017'
    pages:
    - 440
    - 460
  - slug: RJ-2017-043
    title: 'LeArEst: Length and Area Estimation from Data Measured with Additive Error'
    bibtitle: |-
      LeArEst: Length and Area Estimation from Data Measured with
                Additive Error
    author:
    - Mirta Benšić
    - Petar Taler
    - Safet Hamedović
    - Emmanuel Karlo Nyarko
    - Kristian Sabo
    bibauthor: |-
      Mirta Benšić and Petar Taler and Safet Hamedović and
                Emmanuel Karlo Nyarko and Kristian Sabo
    abstract: '  Abstract This paper describes an R package LeArEst that can be used
      for estimating object dimensions            from a noisy image. The package
      is based on a simple parametric model for data that are drawn from            uniform
      distribution contaminated by an additive error. Our package is able to estimate
      the length            of the object of interest on a given straight line that
      intersects it, as well as to estimate the object area            when it is
      elliptically shaped. The input data may be a numerical vector or an image in
      JPEG format.            In this paper, background statistical models and methods
      for the package are summarized, and the            algorithms and key functions
      implemented are described. Also, examples that demonstrate its usage            are
      provided.            Availability: LeArEst is available on CRAN.'
    acknowledged: '2017-07-07'
    online: '2017-10-07'
    CRANpkgs:
    - LeArEst
    - decon
    - deamer
    - conicfit
    - jpeg
    - opencpu
    - shiny
    CTV_rev:
    - WebTechnologies
    - NumericalMathematics
    suppl: 570 bytes
    landing: '2017'
    pages:
    - 461
    - 473
  - slug: RJ-2017-056
    title: 'Splitting It Up: The spduration Split-Population Duration Regression Package
      for Time-Varying Covariates'
    bibtitle: |-
      Splitting It Up: The spduration Split-Population Duration
                Regression Package for Time-Varying Covariates
    author:
    - Andreas Beger
    - Daniel W. Hill
    - Jr.
    - Nils. W. Metternich
    - Shahryar Minhas
    - Michael D. Ward
    bibauthor: |-
      Andreas Beger and Daniel W. Hill and Jr. and Nils. W.
                Metternich and Shahryar Minhas and Michael D. Ward
    abstract: '  Abstract We present an implementation of split-population duration
      regression in the spduration            (Beger et al., 2017) package for R that
      allows for time-varying covariates. The statistical model accounts            for
      units that are immune to a certain outcome and are not part of the duration
      process the researcher            is primarily interested in. We provide insights
      for when immune units exist, that can significantly            increase the
      predictive performance compared to standard duration models. The package includes            estimation
      and several post-estimation methods for split-population Weibull and log-logistic
      models.            We provide an empirical application to data on military coups.'
    acknowledged: '2017-07-12'
    online: '2017-11-05'
    CRANpkgs:
    - spduration
    - survival
    - smcure
    CTV_rev:
    - Survival
    - ClinicalTrials
    - Econometrics
    - SocialSciences
    landing: '2017'
    pages:
    - 474
    - 486
  - slug: RJ-2017-050
    title: Bayesian Regression Models for Interval-censored Data in R
    bibtitle: Bayesian Regression Models for Interval-censored Data in R
    author: Clifford Anderson-Bergman
    bibauthor: Clifford Anderson-Bergman
    abstract: '  Abstract The package icenReg provides classic survival regression
      models for interval-censored data.            We present an update to the package
      that extends the parametric models into the Bayesian framework.            Core
      additions include functionality to define the regression model with the standard
      regression            syntax while providing a custom prior function. Several
      other utility functions are presented that            allow for simplified examination
      of the posterior distribution.'
    acknowledged: '2017-08-05'
    online: '2017-10-24'
    CRANpkgs:
    - icenReg
    - foreach
    - doParallel
    - coda
    - Rcpp
    - RcppEigen
    CTV_rev:
    - HighPerformanceComputing
    - NumericalMathematics
    - Bayesian
    - gR
    - Survival
    suppl: 1.2 Kb
    landing: '2017'
    pages:
    - 487
    - 498
  - slug: RJ-2017-063
    title: 'openEBGM: An R Implementation of the Gamma-Poisson Shrinker Data Mining
      Model'
    bibtitle: |-
      openEBGM: An R Implementation of the Gamma-Poisson Shrinker
                Data Mining Model
    author:
    - Travis Canida
    - John Ihrie
    bibauthor: Travis Canida and John Ihrie
    abstract: '  Abstract We introduce the R package openEBGM, an implementation of
      the Gamma-Poisson Shrinker            (GPS) model for identifying unexpected
      counts in large contingency tables using an empirical Bayes            approach.
      The Empirical Bayes Geometric Mean (EBGM) and quantile scores are obtained from            the
      GPS model estimates. openEBGM provides for the evaluation of counts using a
      number of            different methods, including the model-based disproportionality
      scores, the relative reporting ratio            (RR), and the proportional reporting
      ratio (PRR). Data squashing for computational efficiency and            stratification
      for confounding variable adjustment are included. Application to adverse event
      detection            is discussed.'
    acknowledged: '2017-08-11'
    online: '2017-11-22'
    CRANpkgs:
    - openEBGM
    - PhViD
    - mederrRank
    - tidyr
    - ggplot2
    - data.table
    CTV_rev:
    - Bayesian
    - Finance
    - Graphics
    - HighPerformanceComputing
    - Phylogenetics
    suppl: 5.1 Kb
    landing: '2017'
    pages:
    - 499
    - 519
  - slug: RJ-2017-058
    title: 'rentrez: An R package for the NCBI eUtils API'
    bibtitle: 'rentrez: An R package for the NCBI eUtils API'
    author: David J. Winter
    bibauthor: David J. Winter
    abstract: '  Abstract The USA National Center for Biotechnology Information (NCBI)
      is one of the world’s most            important sources of biological information.
      NCBI databases like PubMed and GenBank contain mil           lions of records
      describing bibliographic, genetic, genomic, and medical data. Here I present
      rentrez,            a package which provides an R interface to 50 NCBI databases.
      The package is well-documented,            contains an extensive suite of unit
      tests and has an active user base. The programmatic interface to the            NCBI
      provided by rentrez allows researchers to query databases and download or import
      particular            records into R sessions for subsequent analysis. The complete
      nature of the package, its extensive            test-suite and the fact the
      package implements the NCBI’s usage policies all make rentrez a powerful            aid
      to developers of new packages that perform more specific tasks.'
    acknowledged: '2017-09-01'
    online: '2017-11-16'
    CRANpkgs:
    - ape
    - RISmed
    - pubmed.mineR
    - rentrez
    - reutils
    - rotl
    - fulltext
    - treemap
    BIOpkgs:
    - genomes
    - RMassBank
    - MeSHSim
    - genbankr
    CTV_rev:
    - Phylogenetics
    - Environmetrics
    - Genetics
    - Graphics
    - OfficialStatistics
    - WebTechnologies
    suppl: 11.2 Kb
    landing: '2017'
    pages:
    - 520
    - 526
  - slug: RJ-2017-065
    title: 'An Introduction to Rocker: Docker Containers for R'
    bibtitle: 'An Introduction to Rocker: Docker Containers for R'
    author:
    - Carl Boettiger
    - Dirk Eddelbuettel
    bibauthor: Carl Boettiger and Dirk Eddelbuettel
    abstract: '  Abstract We describe the Rocker project, which provides a widely-used
      suite of Docker images with            customized R environments for particular
      tasks. We discuss how this suite is organized, and how these            tools
      can increase portability, scaling, reproducibility, and convenience of R users
      and developers.'
    acknowledged: '2017-10-12'
    online: '2017-11-27'
    CRANpkgs:
    - packrat
    - rhub
    - tidyverse
    CTV_rev: ReproducibleResearch
    landing: '2017'
    pages:
    - 527
    - 536
  - heading: News and Notes
  - slug: useR2017
    author: Tobias Verbeke
    title: 'Conference Report: useR!2017'
    bibtitle: 'Conference Report: useR!2017'
    bibauthor: Tobias Verbeke
    pages:
    - 537
    - 538
  - slug: insurance
    author:
    - Nicolas Baradel
    - Christophe Dutang
    - Caroline Hillairet
    title: 'Conference Report: R in Insurance 2017'
    bibtitle: 'Conference Report: R in Insurance 2017'
    bibauthor: Nicolas Baradel and Christophe Dutang and Caroline Hillairet
    pages:
    - 539
    - 540
  - slug: forwards
    author:
    - Stella Bollmann
    - Dianne Cook
    - Jasmine Dumas
    - John Fox
    - Julie Josse
    - Oliver Keyes
    - Carolin           Strobl
    - Heather Turner
    - Rudolf Debelak
    title: Forwards Column
    bibtitle: Forwards Column
    bibauthor: |-
      Stella Bollmann and Dianne Cook and Jasmine Dumas and John
                Fox and Julie Josse and Oliver Keyes and Carolin Strobl and
                Heather Turner and Rudolf Debelak
    pages:
    - 541
    - 552
  - slug: teaching
    author:
    - Matthias Gehrke
    - Reed Davis
    - Norman Matloff
    - Paul Thompson
    - Tiffany Chen
    - 'Emily Watkins          '
    - Laurel Beckett
    title: R Teaching Column
    bibtitle: R Teaching Column
    bibauthor: |-
      Matthias Gehrke and Reed Davis and Norman Matloff and Paul
                Thompson and Tiffany Chen and Emily Watkins and Laurel
                Beckett
    pages:
    - 553
    - 562
  - slug: foundation
    author: Torsten Hothorn
    title: R Foundation News
    bibtitle: R Foundation News
    bibauthor: Torsten Hothorn
    pages:
    - 563
    - 563
  - slug: cran
    author:
    - Kurt Hornik
    - Uwe Ligges
    - Achim Zeileis
    title: Changes on CRAN
    bibtitle: Changes on CRAN
    bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
    pages:
    - 564
    - 566
  - slug: bioc
    author: Bioconductor Core Team
    title: News from the Bioconductor Project
    bibtitle: News from the Bioconductor Project
    bibauthor: Bioconductor Core Team
    pages:
    - 567
    - 567
  - slug: ch
    author: R Core Team
    title: Changes in R
    bibtitle: Changes in R
    bibauthor: R Core Team
    pages:
    - 568
    - 570
- issue: 2018-1
  year: 2018
  volume: 10
  num: 1
  month: Jul
  bibmonth: july
  articles:
  - slug: editorial
    cat: Editorial
    author: John Verzani
    title: Editorial
    bibtitle: Editorial
    bibauthor: John Verzani
    pages:
    - 4
    - 4
  - heading: Contributed Research Articles
  - slug: RJ-2018-001
    title: A System for an Accountable Data Analysis Process in R
    bibtitle: A System for an Accountable Data Analysis Process in R
    author:
    - Jonathan Gelfond
    - Martin Goros
    - Brian Hernandez
    - Alex Bokov
    bibauthor: |-
      Jonathan Gelfond and Martin Goros and Brian Hernandez and
                Alex Bokov
    abstract: '  Abstract Efficiently producing transparent analyses may be difficult
      for beginners or tedious for the            experienced. This implies a need
      for computing systems and environments that can efficiently satisfy            reproducibility
      and accountability standards. To this end, we have developed a system, R package,            and
      R Shiny application called adapr (Accountable Data Analysis Process in R) that
      is built on the            principle of accountable units. An accountable unit
      is a data file (statistic, table or graphic) that            can be associated
      with a provenance, meaning how it was created, when it was created and who            created
      it, and this is similar to the ’verifiable computational results’ (VCR) concept
      proposed by            Gavish and Donoho. Both accountable units and VCRs are
      version controlled, sharable, and can            be incorporated into a collaborative
      project. However, accountable units use file hashes and do not            involve
      watermarking or public repositories like VCRs. Reproducing collaborative work
      may be highly            complex, requiring repeating computations on multiple
      systems from multiple authors; however,            determining the provenance
      of each unit is simpler, requiring only a search using file hashes and            version
      control systems.'
    acknowledged: '2016-09-30'
    online: '2018-05-15'
    CRANpkgs:
    - knitr
    - rmarkdown
    - cacher
    - archivist
    - adapr
    - packrat
    CTV_rev: ReproducibleResearch
    landing: '2018'
    pages:
    - 6
    - 21
  - slug: RJ-2018-033
    title: 'RealVAMS: An R Package for Fitting a Multivariate Value-added Model (VAM)'
    bibtitle: |-
      RealVAMS: An R Package for Fitting a Multivariate Value-
                added Model (VAM)
    author:
    - Jennifer Broatch
    - Jennifer Green
    - Andrew Karl
    bibauthor: Jennifer Broatch and Jennifer Green and Andrew Karl
    abstract: '  Abstract We present RealVAMS, an R package for fitting a generalized
      linear mixed model to            multimembership data with partially crossed
      and partially nested random effects. RealVAMS utilizes            a multivariate
      generalized linear mixed model with pseudo-likelihood approximation for fitting            normally
      distributed continuous response(s) jointly with a binary outcome. In an educational
      context,            the model is referred to as a multidimensional value-added
      model, which extends previous theory to            estimate the relationships
      between potential teacher contributions toward different student outcomes            and
      to allow the consideration of a binary, real-world outcome such as graduation.
      The simultaneous            joint modeling of continuous and binary outcomes
      was not available prior to RealVAMS due to            computational difficulties.
      In this paper, we discuss the multidimensional model, describe RealVAMS,            and
      demonstrate the use of this package and its modeling options with an educational
      data set.'
    acknowledged: '2017-03-03'
    online: '2018-05-22'
    CRANpkgs:
    - RealVAMS
    - lme4
    CTV_rev:
    - Bayesian
    - Econometrics
    - Environmetrics
    - OfficialStatistics
    - Psychometrics
    - SocialSciences
    - SpatioTemporal
    suppl: 1.4 Kb
    landing: '2018'
    pages:
    - 22
    - 30
  - slug: RJ-2018-013
    title: 'InfoTrad: An R package for estimating the probability of informed trading'
    bibtitle: |-
      InfoTrad: An R package for estimating the probability of
                informed trading
    author:
    - Duygu Çelik
    - Murat Tiniç
    bibauthor: Duygu Çelik and Murat Tiniç
    abstract: '  Abstract The purpose of this paper is to introduce the R package
      InfoTrad for estimating the proba           bility of informed trading (PIN)
      initially proposed by Easley et al. (1996). PIN is a popular information            asymmetry
      measure that proxies the proportion of informed traders in the market. This
      study provides            a short survey on alternative estimation techniques
      for the PIN. There are many problems documented            in the existing literature
      in estimating PIN. InfoTrad package aims to address two problems. First,            the
      sequential trading structure proposed by Easley et al. (1996) and later extended
      by Easley et al.            (2002) is prone to sample selection bias for stocks
      with large trading volumes, due to floating point            exception. This
      problem is solved by different factorizations provided by Easley et al. (2010)
      (EHO            factorization) and Lin and Ke (2011) (LK factorization). Second,
      the estimates are prone to bias due to            boundary solutions. A grid-search
      algorithm (YZ algorithm) is proposed by Yan and Zhang (2012) to            overcome
      the bias introduced due to boundary estimates. In recent years, clustering algorithms
      have            become popular due to their flexibility in quickly handling
      large data sets. Gan et al. (2015) propose            an algorithm (GAN algorithm)
      to estimate PIN using hierarchical agglomerative clustering which is            later
      extended by Ersan and Alici (2016) (EA algorithm). The package InfoTrad offers
      LK and EHO            factorizations given an input matrix and initial parameter
      vector. In addition, these factorizations can            be used to estimate
      PIN through YZ algorithm, GAN algorithm and EA algorithm.'
    acknowledged: '2017-03-05'
    online: '2018-05-16'
    CRANpkgs:
    - InfoTrad
    - FinAsym
    - PIN
    - nloptr
    CTV_rev:
    - Finance
    - Optimization
    suppl: 4.3 Kb
    landing: '2018'
    pages:
    - 31
    - 42
  - slug: RJ-2018-035
    title: 'RatingScaleReduction package: stepwise rating scale item reduction without
      predictability loss'
    bibtitle: |-
      RatingScaleReduction package: stepwise rating scale item
                reduction without predictability loss
    author:
    - Waldemar W. Koczkodaj
    - Feng Li
    - Alicja Wolny–Dominiak
    bibauthor: Waldemar W. Koczkodaj and Feng Li and Alicja Wolny–Dominiak
    abstract: '  Abstract This study presents an innovative method for reducing the
      number of rating scale items            without predictability loss. The “area
      under the receiver operator curve” method (AUC ROC) is used            for the
      stepwise method of reducing items of a rating scale. RatingScaleReduction R
      package contains            the presented implementation. Differential evolution
      (a metaheuristic for optimization) was applied            to one of the analyzed
      datasets to illustrate that the presented stepwise method can be used with other            classifiers
      to reduce the number of rating scale items (variables). The targeted areas of
      application are            decision making, data mining, machine learning, and
      psychometrics.            Keywords: rating scale, receiver operator characteristic,
      ROC, AUC, scale reduction.'
    acknowledged: '2017-03-20'
    online: '2018-06-01'
    CRANpkgs:
    - pROC
    - ROCR
    - RatingScaleReduction
    - DEoptim
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Optimization
    suppl: unknown
    landing: '2018'
    pages:
    - 43
    - 55
  - slug: RJ-2018-038
    title: 'mmpf: Monte-Carlo Methods for Prediction Functions'
    bibtitle: 'mmpf: Monte-Carlo Methods for Prediction Functions'
    author: Zachary M. Jones
    bibauthor: Zachary M. Jones
    abstract: '  Abstract Machine learning methods can often learn high-dimensional
      functions which generalize            well but are not human interpretable.
      The mmpf package marginalizes prediction functions using            Monte-Carlo
      methods, allowing users to investigate the behavior of these learned functions,
      as on a            lower dimensional subset of input features: partial dependence
      and variations thereof. This makes            machine learning methods more
      useful in situations where accurate prediction is not the only goal,            such
      as in the social sciences where linear models are commonly used because of their
      interpretability.                 Many methods for estimating prediction functions
      produce estimated functions which are not            directly human-interpretable
      because of their complexity: for example, they may include high           dimensional
      interactions and/or complex nonlinearities. While a learning method’s capacity
      to            automatically learn interactions and nonlinearities is attractive
      when the goal is prediction, there            are many cases where users want
      good predictions and the ability to understand how predictions            depend
      on the features. mmpf implements general methods for interpreting prediction
      functions            using Monte-Carlo methods. These methods allow any function
      which generates predictions to be be            interpreted. mmpf is currently
      used in other packages for machine learning like edarf and mlr (Jones            and
      Linder, 2016; Bischl et al., 2016).'
    acknowledged: '2017-04-17'
    online: '2018-06-29'
    CRANpkgs:
    - mmpf
    - edarf
    landing: '2018'
    pages:
    - 56
    - 60
  - slug: RJ-2018-014
    title: Generalized Additive Model Multiple Imputation by Chained Equations With
      Package ImputeRobust
    bibtitle: |-
      Generalized Additive Model Multiple Imputation by Chained
                Equations With Package ImputeRobust
    author:
    - Daniel Salfran
    - Martin Spiess
    bibauthor: Daniel Salfran and Martin Spiess
    abstract: '  Abstract Data analysis, common to all empirical sciences, often requires
      complete data sets. Unfortu           nately, real world data collection will
      usually result in data values not being observed. We present a            package
      for robust multiple imputation (the ImputeRobust package) that allows the use
      of generalized            additive models for location, scale, and shape in
      the context of chained equations. The paper describes            the basics
      of the imputation technique which builds on a semi-parametric regression model
      (GAMLSS)            and the algorithms and functions provided with the corresponding
      package. Furthermore, some            illustrative examples are provided.'
    acknowledged: '2017-05-02'
    online: '2018-05-16'
    CRANpkgs:
    - ImputeRobust
    - mice
    - gamlss
    CTV_rev:
    - Econometrics
    - Multivariate
    - OfficialStatistics
    - SocialSciences
    suppl: 1.2 Kb
    landing: '2018'
    pages:
    - 61
    - 72
  - slug: RJ-2018-015
    title: 'MGLM: An R Package for Multivariate Categorical Data Analysis'
    bibtitle: |-
      MGLM: An R Package for Multivariate Categorical Data
                Analysis
    author:
    - Juhyun Kim
    - Yiwen Zhang
    - Joshua Day
    - Hua Zhou
    bibauthor: Juhyun Kim and Yiwen Zhang and Joshua Day and Hua Zhou
    abstract: '  Abstract Data with multiple responses is ubiquitous in modern applications.
      However, few tools are            available for regression analysis of multivariate
      counts. The most popular multinomial-logit model            has a very restrictive
      mean-variance structure, limiting its applicability to many data sets. This
      article            introduces an R package MGLM, short for multivariate response
      generalized linear models, that            expands the current tools for regression
      analysis of polytomous data. Distribution fitting, random            number
      generation, regression, and sparse regression are treated in a unifying framework.
      The            algorithm, usage, and implementation details are discussed.'
    acknowledged: '2017-05-09'
    online: '2018-05-16'
    CRANpkgs:
    - MGLM
    - VGAM
    - glmnet
    - dirmult
    - parallel
    - isoform
    - glmc
    CTV_rev:
    - Distributions
    - Survival
    - Econometrics
    - Environmetrics
    - ExtremeValue
    - MachineLearning
    - Multivariate
    - Psychometrics
    - SocialSciences
    suppl: 1.7 Kb
    landing: '2018'
    pages:
    - 73
    - 90
  - slug: RJ-2018-016
    title: 'ArCo: An R package to Estimate Artificial Counterfactuals'
    bibtitle: 'ArCo: An R package to Estimate Artificial Counterfactuals'
    author:
    - Yuri R. Fonseca
    - Ricardo P. Masini
    - Marcelo C. Medeiros
    - Gabriel F. R. Vasconcelos
    bibauthor: |-
      Yuri R. Fonseca and Ricardo P. Masini and Marcelo C.
                Medeiros and Gabriel F. R. Vasconcelos
    abstract: '  Abstract In this paper we introduce the ArCo package for R which
      consists of a set of functions            to implement the the Artificial Counterfactual
      (ArCo) methodology to estimate causal effects of an            intervention
      (treatment) on aggregated data and when a control group is not necessarily available.            The
      ArCo method is a two-step procedure, where in the first stage a counterfactual
      is estimated from a            large panel of time series from a pool of untreated
      peers. In the second-stage, the average treatment            effect over the
      post-intervention sample is computed. Standard inferential procedures are available.            The
      package is illustrated with both simulated and real datasets.'
    acknowledged: '2017-05-09'
    online: '2018-05-16'
    CRANpkgs:
    - ArCo
    - boot
    - glmnet
    - Synth
    CTV_rev:
    - Survival
    - Econometrics
    - MachineLearning
    - Optimization
    - SocialSciences
    - TimeSeries
    suppl: 2.9 Kb
    landing: '2018'
    pages:
    - 91
    - 108
  - slug: RJ-2018-018
    title: 'PanJen: An R package for Ranking Transformations in a Linear Regression'
    bibtitle: |-
      PanJen: An R package for Ranking Transformations in a Linear
                Regression
    author:
    - Cathrine Ulla Jensen
    - Toke Emil Panduro
    bibauthor: Cathrine Ulla Jensen and Toke Emil Panduro
    abstract: '  Abstract PanJen is an R-package for ranking transformations in linear
      regressions. It provides users            with the ability to explore the relationship
      between a dependent variable and its independent variables.            The package
      offers an easy and data-driven way to choose a functional form in multiple linear            regression
      models by comparing a range of parametric transformations. The parametric functional            forms
      are benchmarked against each other and a non-parametric transformation. The
      package            allows users to generate plots that show the relation between
      a covariate and the dependent variable.            Furthermore, PanJen will
      enable users to specify specific functional transformations, driven by a            priori
      and theory-based hypotheses. The package supplies both model fits and plots
      that allow users            to make informed choices on the functional forms
      in their regression. We show that the ranking            in PanJen outperforms
      the Box-Tidwell transformation, especially in the presence of inefficiency,            heteroscedasticity
      or endogeneity.'
    acknowledged: '2017-05-12'
    online: '2018-05-21'
    CRANpkgs:
    - PanJen
    - mgcv
    CTV_rev:
    - Bayesian
    - Econometrics
    - Environmetrics
    - SocialSciences
    suppl: 1 Kb
    landing: '2018'
    pages:
    - 109
    - 121
  - slug: RJ-2018-019
    title: Tackling Uncertainties of Species Distribution Model Projections with Package
      mopa
    bibtitle: |-
      Tackling Uncertainties of Species Distribution Model
                Projections with Package mopa
    author:
    - M. Iturbide
    - J. Bedia
    - J.M. Gutiérrez
    bibauthor: M. Iturbide and J. Bedia and J.M. Gutiérrez
    abstract: '  Abstract Species Distribution Models (SDMs) constitute an important
      tool to assist decision-making            in environmental conservation and
      planning in the context of climate change. Nevertheless, SDM pro           jections
      are affected by a wide range of uncertainty factors (related to training data,
      climate projections            and SDM techniques), which limit their potential
      value and credibility. The new package mopa pro           vides tools for designing
      comprehensive multi-factor SDM ensemble experiments, combining multiple            sources
      of uncertainty (e.g. baseline climate, pseudo-absence realizations, SDM techniques,
      future            projections) and allowing to assess their contribution to
      the overall spread of the ensemble projection.            In addition, mopa
      is seamlessly integrated with the climate4R bundle and allows straightforward            retrieval
      and post-processing of state-of-the-art climate datasets (including observations
      and climate            change projections), thus facilitating the proper analysis
      of key uncertainty factors related to climate            data.'
    acknowledged: '2017-05-29'
    online: '2018-05-21'
    CRANpkgs:
    - mopa
    - sdm
    - biomod2
    - dismo
    - SDMTools
    - raster
    - sp
    - e1071
    - stats
    - ranger
    - earth
    - tree
    - rpart
    - caret
    CTV_rev:
    - MachineLearning
    - Multivariate
    - Environmetrics
    - Spatial
    - SpatioTemporal
    - Survival
    - Cluster
    - Distributions
    - HighPerformanceComputing
    - Psychometrics
    suppl: 2.2 Kb
    landing: '2018'
    pages:
    - 122
    - 139
  - slug: RJ-2018-020
    title: 'FHDI: An R Package for Fractional Hot Deck Imputation'
    bibtitle: 'FHDI: An R Package for Fractional Hot Deck Imputation'
    author:
    - Jongho Im
    - In Ho Cho
    - Jae Kwang Kim
    bibauthor: Jongho Im and In Ho Cho and Jae Kwang Kim
    abstract: '  Abstract Fractional hot deck imputation (FHDI), proposed by Kalton
      and Kish (1984) and investigated            by Kim and Fuller (2004), is a tool
      for handling item nonresponse in survey sampling. In FHDI,            each missing
      item is filled with multiple observed values yielding a single completed data
      set for            subsequent analyses. An R package FHDI is developed to perform
      FHDI and also the fully efficient            fractional imputation (FEFI) method
      of (Fuller and Kim, 2005) to impute multivariate missing data            with
      arbitrary missing patterns. FHDI substitutes missing items with a few observed
      values jointly            obtained from a set of donors whereas the FEFI uses
      all the possible donors. This paper introduces            FHDI as a tool for
      implementing the multivariate version of fractional hot deck imputation discussed            in
      Im et al. (2015) as well as FEFI. For variance estimation of FHDI and FEFI,
      the Jackknife method is            implemented, and replicated weights are provided
      as a part of the output.'
    acknowledged: '2017-06-02'
    online: '2018-05-21'
    CRANpkgs:
    - mice
    - mi
    - Amelia
    - VIM
    - FHDI
    CTV_rev:
    - OfficialStatistics
    - SocialSciences
    - Multivariate
    suppl: 984 bytes
    landing: '2018'
    pages:
    - 140
    - 154
  - slug: RJ-2018-021
    title: Bayesian Testing, Variable Selection and Model Averaging in Linear Models
      using R with BayesVarSel
    bibtitle: |-
      Bayesian Testing, Variable Selection and Model Averaging in
                Linear Models using R with BayesVarSel
    author:
    - Gonzalo Garcia-Donato
    - Anabel Forte
    bibauthor: Gonzalo Garcia-Donato and Anabel Forte
    abstract: '  Abstract In this paper, objective Bayesian methods for hypothesis
      testing and variable selection in            linear models are considered. The
      focus is on BayesVarSel, an R package that computes posterior            probabilities
      of hypotheses/models and provides a suite of tools to properly summarize the
      results. We            introduce the usage of specific functions to compute
      several types of model averaging estimations and            predictions weighted
      by posterior probabilities. BayesVarSel contains exact algorithms to perform            fast
      computations in problems of small to moderate size and heuristic sampling methods
      to solve            large problems. We illustrate the functionalities of the
      package with several data examples.'
    acknowledged: '2017-06-14'
    online: '2018-05-21'
    CRANpkgs:
    - BayesVarSel
    - faraway
    - BayesFactor
    - BMS
    - mombf
    - BAS
    - BMA
    CTV_rev:
    - Bayesian
    - Econometrics
    - SocialSciences
    - Survival
    suppl: 4.4 Kb
    landing: '2018'
    pages:
    - 155
    - 174
  - slug: RJ-2018-022
    title: 'onewaytests: An R Package for One-Way Tests in Independent Groups Designs'
    bibtitle: |-
      onewaytests: An R Package for One-Way Tests in Independent
                Groups Designs
    author:
    - Osman Dag
    - Anil Dolgun
    - Naime Meric Konar
    bibauthor: Osman Dag and Anil Dolgun and Naime Meric Konar
    abstract: '  Abstract One-way tests in independent groups designs are the most
      commonly utilized statistical            methods with applications on the experiments
      in medical sciences, pharmaceutical research, agri           culture, biology,
      engineering, social sciences and so on. In this paper, we present the onewaytests            package
      to investigate treatment effects on the dependent variable. The package offers
      the one-way            tests in independent groups designs, which include ANOVA,
      Welch’s heteroscedastic F test, Welch’s            heteroscedastic F test with
      trimmed means and Winsorized variances, Brown-Forsythe test, Alexander           Govern
      test, James second order test and Kruskal-Wallis test. The package also provides
      pairwise            comparisons, graphical approaches, and assesses variance
      homogeneity and normality of data in each            group via tests and plots.
      A simulation study is also conducted to give recommendations for applied            researchers
      on the selection of appropriate one-way tests under assumption violations. Furthermore,            especially
      for non-R users, a user-friendly web application of the package is provided.
      This application            is available at http://www.softmed.hacettepe.edu.tr/onewaytests.'
    acknowledged: '2017-06-14'
    online: '2018-05-21'
    CRANpkgs:
    - onewaytests
    - onewaytests
    - stats
    suppl: 1.1 Kb
    landing: '2018'
    pages:
    - 175
    - 199
  - slug: RJ-2018-023
    title: 'Inventorymodel: an R Package for Centralized Inventory Problems'
    bibtitle: |-
      Inventorymodel: an R Package for Centralized Inventory
                Problems
    author: Alejandro Saavedra-Nieves
    bibauthor: Alejandro Saavedra-Nieves
    abstract: '  Abstract Inventory management of goods is an integral part of logistics
      systems; common to various            economic sectors such as industry, agriculture
      and trade; and independent of production volume. In            general, as companies
      seek to minimize economic losses, studies on problems of multi-agent inventory            have
      increased in recent years. A multi-agent inventory problem is a situation in
      which several            agents face individual inventory problems and agree
      to coordinate their orders with the objective of            reducing their costs.
      The R package Inventorymodel allows the determination of both the optimal            policy
      for some inventory situations with deterministic demands and the allocation
      of costs from a            game-theoretic perspective. The required calculations
      may be computed for any number of agents            although the computational
      complexity of this class of problems when the involved agents enlarge is            not
      reduced. In this work, the different possibilities that the package offers are
      described and some            examples of usage are also demonstrated.'
    acknowledged: '2017-06-14'
    online: '2018-05-21'
    CRANpkgs:
    - Inventorymodel
    - e1071
    - GameTheoryAllocation
    CTV_rev:
    - Cluster
    - Distributions
    - Environmetrics
    - MachineLearning
    - Multivariate
    - Psychometrics
    suppl: 687 bytes
    landing: '2018'
    pages:
    - 200
    - 217
  - slug: RJ-2018-024
    title: R Package imputeTestbench to Compare Imputation Methods for Univariate
      Time Series
    bibtitle: |-
      R Package imputeTestbench to Compare Imputation Methods for
                Univariate Time Series
    author:
    - Marcus W Beck
    - Neeraj Bokde
    - Gualberto Asencio-Cortés
    - Kishore Kulat
    bibauthor: |-
      Marcus W Beck and Neeraj Bokde and Gualberto Asencio-Cortés
                and Kishore Kulat
    abstract: '  Abstract Missing observations are common in time series data and
      several methods are available to            impute these values prior to analysis.
      Variation in statistical characteristics of univariate time series            can
      have a profound effect on characteristics of missing observations and, therefore,
      the accuracy of            different imputation methods. The imputeTestbench
      package can be used to compare the prediction            accuracy of different
      methods as related to the amount and type of missing data for a user-supplied            dataset.
      Missing data are simulated by removing observations completely at random or
      in blocks of            different sizes depending on characteristics of the
      data. Several imputation algorithms are included            with the package
      that vary from simple replacement with means to more complex interpolation            methods.
      The testbench is not limited to the default functions and users can add or remove
      methods            as needed. Plotting functions also allow comparative visualization
      of the behavior and effectiveness of            different algorithms. We present
      example applications that demonstrate how the package can be used            to
      understand differences in prediction accuracy between methods as affected by
      characteristics of a            dataset and the nature of missing data.'
    acknowledged: '2017-06-29'
    online: '2018-05-21'
    CRANpkgs:
    - imputeTestbench
    - dplyr
    - reshape2
    - tidyr
    - ggplot2
    - forecast
    - imputeTS
    - zoo
    - stats
    - datasets
    - Rcpp
    - matlabr
    CTV_rev:
    - TimeSeries
    - Econometrics
    - Environmetrics
    - Finance
    - Graphics
    - HighPerformanceComputing
    - ModelDeployment
    - NumericalMathematics
    - Phylogenetics
    suppl: 3.8 Kb
    landing: '2018'
    pages:
    - 218
    - 233
  - slug: RJ-2018-034
    title: 'ICSOutlier: Unsupervised Outlier Detection for Low-Dimensional Contamination
      Structure'
    bibtitle: |-
      ICSOutlier: Unsupervised Outlier Detection for Low-
                Dimensional Contamination Structure
    author:
    - Aurore Archimbaud
    - Klaus Nordhausen
    - Anne Ruiz-Gazen
    bibauthor: Aurore Archimbaud and Klaus Nordhausen and Anne Ruiz-Gazen
    abstract: '  Abstract Detecting outliers in a multivariate and unsupervised context
      is an important and ongoing            problem notably for quality control.
      Many statistical methods are already implemented in R and            are briefly
      surveyed in the present paper. But only a few lead to the accurate identification
      of            potential outliers in the case of a small level of contamination.
      In this particular context, the Invariant            Coordinate Selection (ICS)
      method shows remarkable properties for identifying outliers that lie on            a
      low-dimensional subspace in its first invariant components. It is implemented
      in the ICSOutlier            package. The main function of the package, ics.outlier,
      offers the possibility of labelling potential            outliers in a completely
      automated way. Four examples, including two real examples in quality control,            illustrate
      the use of the function. Comparing with several other approaches, it appears
      that ICS is            generally as efficient as its competitors and shows an
      advantage in the context of a small proportion of            outliers lying
      in a low-dimensional subspace. In quality control, the method may help in properly            identifying
      some defective products while not detecting too many false positives.'
    acknowledged: '2017-06-29'
    online: '2018-05-30'
    CRANpkgs:
    - mvoutlier
    - CerioliOutlierDetection
    - rrcovHD
    - faoutlier
    - abodOutlier
    - HighDimOut
    - alphaOutlier
    - extremevalues
    - HDoutliers
    - outliers
    - DMwR2
    - ldbod
    - Rlof
    - depth
    - REPPlab
    - OutlierDC
    - pcadapt
    - rrcov
    - ICSOutlier
    - ICS
    - robustbase
    CTV_rev:
    - Robust
    - Multivariate
    - OfficialStatistics
    - Psychometrics
    - Survival
    suppl: 3.1 Kb
    landing: '2018'
    pages:
    - 234
    - 250
  - slug: RJ-2018-025
    title: 'rpostgis: Linking R with a PostGIS Spatial Database'
    bibtitle: 'rpostgis: Linking R with a PostGIS Spatial Database'
    author:
    - David Bucklin
    - Mathieu Basille
    bibauthor: David Bucklin and Mathieu Basille
    abstract: '  Abstract With the proliferation of sensors and the ease of data collection
      from online sources, large            datasets have become the norm in many
      scientific disciplines, and efficient data storage, management,            and
      retrival is imperative for large research projects. Relational databases provide
      a solution, but            in order to be useful, must be able to be linked
      to analysis and visualization tools, such as R. Here,            we present
      a package intended to facilitate integration of R with the open-source database
      software            PostgreSQL, with a focus on its spatial extension, PostGIS.
      The package rpostgis (version 1.4.1)            provides methods for spatial
      data handling (vector and raster) between PostGIS-enabled databases            and
      R, methods for R "data.frame"s storage in PostgreSQL, and a set of convenient
      wrappers for            common database procedures. We thus expect rpostgis
      to be useful for both (1) existing users of            spatial data in R and/or
      PostGIS, and (2) R users who have yet to adopt relational databases for their            projects.'
    acknowledged: '2017-07-07'
    online: '2018-05-21'
    CRANpkgs:
    - rgdal
    - maptools
    - raster
    - RPostgreSQL
    - DBI
    - rpostgis
    - sp
    - rgeos
    - wkb
    - sf
    - rpostgisLT
    - adehabitatLT
    CTVs: Spatial
    CTV_rev:
    - Spatial
    - SpatioTemporal
    suppl: 1.7 Kb
    landing: '2018'
    pages:
    - 251
    - 268
  - slug: RJ-2018-026
    title: 'lba: An R Package for Latent Budget Analysis'
    bibtitle: 'lba: An R Package for Latent Budget Analysis'
    author:
    - Enio G. Jelihovschi
    - Ivan Bezerra Allaman
    bibauthor: Enio G. Jelihovschi and Ivan Bezerra Allaman
    abstract: '  Abstract The latent budget model is a mixture model for compositional
      data sets in which the entries,            a contingency table, may be either
      realizations from a product multinomial distribution or distribution            free.
      Based on this model, the latent budget analysis considers the interactions of
      two variables; the ex           planatory (row) and the response (column) variables.
      The package lba uses expectation-maximization            and active constraints
      method (ACM) to carry out, respectively, the maximum likelihood and the least            squares
      estimation of the model parameters. It contains three main functions, lba which
      performs            the analysis, goodnessfit for model selection and goodness
      of fit and the plotting functions plotcorr            and plotlba used as a
      help in the interpretation of the results.'
    acknowledged: '2017-07-12'
    online: '2018-05-21'
    CRANpkgs:
    - lba
    - alabama
    - plotrix
    - scatterplot3d
    - rgl
    - MASS
    CTV_rev:
    - Graphics
    - Multivariate
    - Psychometrics
    - Distributions
    - Econometrics
    - Environmetrics
    - NumericalMathematics
    - Optimization
    - Robust
    - SocialSciences
    - SpatioTemporal
    suppl: 1.1 Kb
    landing: '2018'
    pages:
    - 269
    - 287
  - slug: RJ-2018-027
    title: Semiparametric Generalized Linear Models with the gldrm Package
    bibtitle: |-
      Semiparametric Generalized Linear Models with the gldrm
                Package
    author:
    - Michael J. Wurm
    - Paul J. Rathouz
    bibauthor: Michael J. Wurm and Paul J. Rathouz
    abstract: '  Abstract This paper introduces a new algorithm to estimate and perform
      inferences on a recently            proposed and developed semiparametric generalized
      linear model (glm). Rather than selecting a            particular parametric
      exponential family model, such as the Poisson distribution, this semiparametric            glm
      assumes that the response is drawn from the more general exponential tilt family.
      The regression            coefficients and unspecified reference distribution
      are estimated by maximizing a semiparametric like           lihood. The new
      algorithm incorporates several computational stability and efficiency improvements            over
      the algorithm originally proposed. In particular, the new algorithm performs
      well for either small            or large support for the nonparametric response
      distribution. The algorithm is implemented in a new            R package called
      gldrm.'
    acknowledged: '2017-07-23'
    online: '2018-05-21'
    CRANpkgs: gldrm
    landing: '2018'
    pages:
    - 288
    - 307
  - slug: RJ-2018-028
    title: 'LP Algorithms for Portfolio Optimization: The PortfolioOptim Package'
    bibtitle: |-
      LP Algorithms for Portfolio Optimization: The PortfolioOptim
                Package
    author: Andrzej Palczewski
    bibauthor: Andrzej Palczewski
    abstract: '  Abstract The paper describes two algorithms for financial portfolio
      optimization with the following            risk measures: CVaR, MAD, LSAD and
      dispersion CVaR. These algorithms can be applied to discrete            distributions
      of asset returns since then the optimization problems can be reduced to linear
      programs.            The first algorithm solves a simple recourse problem as
      described by Haneveld using Benders de           composition method. The second
      algorithm finds an optimal portfolio with the smallest distance            to
      a given benchmark portfolio and is an adaptation of the least norm solution
      (called also normal            solution) of linear programs due to Zhao and
      Li. The algorithms are implemented in R in the package            PortfolioOptim.'
    acknowledged: '2017-07-23'
    online: '2018-05-21'
    CRANpkgs:
    - fPortfolio
    - PortfolioAnalytics
    - Rglpk
    - quadprog
    - DEoptim
    - GenSA
    - psoptim
    - parma
    - nloptr
    - PortfolioOptim
    CTV_rev:
    - Optimization
    - Finance
    suppl: 1.4 Kb
    landing: '2018'
    pages:
    - 308
    - 327
  - slug: RJ-2018-029
    title: 'Welfare, Inequality and Poverty Analysis with rtip: An Approach Based
      on Stochastic Dominance'
    bibtitle: |-
      Welfare, Inequality and Poverty Analysis with rtip: An
                Approach Based on Stochastic Dominance
    author:
    - Angel Berihuete
    - Carmen D. Ramos
    - Miguel A. Sordo
    bibauthor: Angel Berihuete and Carmen D. Ramos and Miguel A. Sordo
    abstract: '  Abstract Disparities in economic welfare, inequality and poverty
      across and within countries are            of great interest to sociologists,
      economists, researchers, social organizations and political scientists.            Information
      about these topics is commonly based on surveys. We present a package called
      rtip that            implements techniques based on stochastic dominance to
      make unambiguous comparisons, in terms            of welfare, poverty and inequality,
      among income distributions. Besides providing point estimates            and
      confidence intervals for the most commonly used indicators of these characteristics,
      the package            rtip estimates the usual Lorenz curve, the generalized
      Lorenz curve, the TIP (Three I’s of Poverty)            curve and allows to
      test statistically whether one curve is dominated by another.'
    acknowledged: '2017-07-25'
    online: '2018-05-21'
    CRANpkgs:
    - rtip
    - IC2
    - ineq
    - laeken
    - boot
    CTV_rev:
    - OfficialStatistics
    - Econometrics
    - Optimization
    - SocialSciences
    - Survival
    - TimeSeries
    suppl: 2.2 Kb
    landing: '2018'
    pages:
    - 328
    - 341
  - slug: RJ-2018-039
    title: dimRed and coRanking - Unifying Dimensionality Reduction in R
    bibtitle: dimRed and coRanking---Unifying Dimensionality Reduction in R
    author:
    - Guido Kraemer
    - Markus Reichstein
    - Miguel D. Mahecha
    bibauthor: Guido Kraemer and Markus Reichstein and Miguel D. Mahecha
    abstract: '  Abstract “Dimensionality reduction” (DR) is a widely used approach
      to find low dimensional and            interpretable representations of data
      that are natively embedded in high-dimensional spaces. DR can be            realized
      by a plethora of methods with different properties, objectives, and, hence,
      (dis)advantages. The            resulting low-dimensional data embeddings are
      often difficult to compare with objective criteria. Here,            we introduce
      the dimRed and coRanking packages for the R language. These open source software            packages
      enable users to easily access multiple classical and advanced DR methods using
      a common            interface. The packages also provide quality indicators
      for the embeddings and easy visualization of            high dimensional data.
      The coRanking package provides the functionality for assessing DR methods            in
      the co-ranking matrix framework. In tandem, these packages allow for uncovering
      complex            structures high dimensional data. Currently 15 DR methods
      are available in the package, some of            which were not previously available
      to R users. Here, we outline the dimRed and coRanking packages            and
      make the implemented methods understandable to the interested reader.'
    acknowledged: '2017-08-14'
    online: '2018-06-29'
    CRANpkgs:
    - dimRed
    - coRanking
    - kernlab
    - vegan
    - RANN
    - igraph
    - lle
    - diffusionMap
    - MASS
    - igraph
    - Rtsne
    - fastICA
    - DRR
    BIOpkgs: pcaMethods
    CTV_rev:
    - Multivariate
    - Optimization
    - Psychometrics
    - Spatial
    - Environmetrics
    - gR
    - Graphics
    - ChemPhys
    - Cluster
    - Distributions
    - Econometrics
    - MachineLearning
    - NaturalLanguageProcessing
    - NumericalMathematics
    - Phylogenetics
    - Robust
    - SocialSciences
    landing: '2018'
    pages:
    - 342
    - 358
  - slug: RJ-2018-002
    title: 'GrpString: An R Package for Analysis of Groups of Strings'
    bibtitle: 'GrpString: An R Package for Analysis of Groups of Strings'
    author:
    - Hui Tang
    - Elizabeth L. Day
    - Molly B. Atkinson
    - Norbert J. Pienta
    bibauthor: |-
      Hui Tang and Elizabeth L. Day and Molly B. Atkinson and
                Norbert J. Pienta
    abstract: '  Abstract The R package GrpString was developed as a comprehensive
      toolkit for quantitatively            analyzing and comparing groups of strings.
      It offers functions for researchers and data analysts to            prepare
      strings from event sequences, extract common patterns from strings, and compare
      patterns be           tween string vectors. The package also finds transition
      matrices and complexity of strings, determines            clusters in a string
      vector, and examines the statistical difference between two groups of strings.'
    acknowledged: '2017-08-16'
    online: '2018-05-15'
    CRANpkgs:
    - stringr
    - stringb
    - stringi
    - gsubfn
    - uniqtag
    - stringdist
    - TraMineR
    - informR
    - GrpString
    - entropy
    CTV_rev:
    - NaturalLanguageProcessing
    - OfficialStatistics
    - Survival
    suppl: 984 bytes
    landing: '2018'
    pages:
    - 359
    - 369
  - slug: RJ-2018-003
    title: 'Epistemic Game Theory: Putting Algorithms to Work'
    bibtitle: 'Epistemic Game Theory: Putting Algorithms to Work'
    author:
    - Bilge Başer
    - Nalan Cinemre
    bibauthor: Bilge Başer and Nalan Cinemre
    abstract: '  Abstract The aim of this study is to construct an epistemic model
      in which each rational choice under            common belief in rationality
      is supplemented by a type which expresses such a belief. In practice, the            finding
      of type depends on manual solution approach with some mathematical operations
      in scope of            the theory. This approach becomes less convenient with
      the growth of the size of the game. To solve            this difficulty, a linear
      programming model is constructed for two-player, static and non-cooperative            games
      to find the type that is supporting that player’s rational choice is optimal
      under common            belief in rationality and maximizing the utility of
      the game. Since the optimal choice would only            be made from rational
      choices, it is first necessary to eliminate all strictly dominated choices.
      In            real life, the games are usually large sized. Therefore, the elimination
      process should be performed            in a computer environment. Since software
      related to game theory was mostly prepared with a            result-oriented
      approach for some types of games, it was necessary to develop software to execute            the
      iterated elimination method. With this regard, a program has been developed
      that determines            the choices that are strictly dominated by pure and
      randomized choices in two-player games. Two            functions named “esdc”
      and “type” are created by using R statistical programming language for the            operations
      performed in both parts, and these functions are added to the content of an
      R package after            its creation with the name EpistemicGameTheory.'
    acknowledged: '2017-09-13'
    online: '2018-05-15'
    CRANpkgs:
    - EpistemicGameTheory
    - roxygen2
    - lpSolve
    CTV_rev: Optimization
    suppl: 631 bytes
    landing: '2018'
    pages:
    - 370
    - 380
  - slug: RJ-2018-004
    title: 'Residuals and Diagnostics for Binary and Ordinal Regression Models: An
      Introduction to the sure Package'
    bibtitle: |-
      Residuals and Diagnostics for Binary and Ordinal Regression
                Models: An Introduction to the sure Package
    author:
    - Brandon M. Greenwell
    - Andrew J. McCarthy
    - Bradley C. Boehmke
    - Dungang Liu
    bibauthor: |-
      Brandon M. Greenwell and Andrew J. McCarthy and Bradley C.
                Boehmke and Dungang Liu
    abstract: '  Abstract Residual diagnostics is an important topic in the classroom,
      but it is less often used in practice            by Brandon M. Greenwell, Andrew
      J. McCarthy, Bradley C. Boehmke, and Dungang Liu            Introduction to
      the sure Package            Ordinal Regression Models: An'
    acknowledged: '2017-09-21'
    online: '2018-05-15'
    CRANpkgs:
    - MASS
    - VGAM
    - ordinal
    - rms
    - PResiduals
    - sure
    - ggplot2
    CTV_rev:
    - Econometrics
    - Psychometrics
    - SocialSciences
    - Distributions
    - Environmetrics
    - Multivariate
    - Survival
    - ExtremeValue
    - Graphics
    - NumericalMathematics
    - Phylogenetics
    - ReproducibleResearch
    - Robust
    suppl: 2 Kb
    landing: '2018'
    pages:
    - 381
    - 394
  - slug: RJ-2018-017
    title: Advanced Bayesian Multilevel Modeling with the R Package brms
    bibtitle: |-
      Advanced Bayesian Multilevel Modeling with the R Package
                brms
    author: Paul-Christian Bürkner
    bibauthor: Paul-Christian Bürkner
    abstract: '  Abstract The brms package allows R users to easily specify a wide
      range of Bayesian single-level            and multilevel models which are fit
      with the probabilistic programming language Stan behind the            scenes.
      Several response distributions are supported, of which all parameters (e.g.,
      location, scale, and            shape) can be predicted. Non-linear relationships
      may be specified using non-linear predictor terms            or semi-parametric
      approaches such as splines or Gaussian processes. Multivariate models can be
      fit            as well. To make all of these modeling options possible in a
      multilevel framework, brms provides an            intuitive and powerful formula
      syntax, which extends the well known formula syntax of lme4. The            purpose
      of the present paper is to introduce this syntax in detail and to demonstrate
      its usefulness            with four examples, each showing relevant aspects
      of the syntax.'
    acknowledged: '2017-10-01'
    online: '2018-05-18'
    CRANpkgs:
    - brms
    - lme4
    - rstanarm
    - MCMCglmm
    - mgcv
    - nlme
    - afex
    - loo
    - gamlss.data
    - bridgesampling
    CTV_rev:
    - Bayesian
    - SocialSciences
    - Econometrics
    - Environmetrics
    - Psychometrics
    - OfficialStatistics
    - SpatioTemporal
    - ChemPhys
    - Finance
    - Phylogenetics
    - Spatial
    - Survival
    landing: '2018'
    pages:
    - 395
    - 411
  - slug: RJ-2018-005
    title: Support Vector Machines for Survival Analysis with R
    bibtitle: Support Vector Machines for Survival Analysis with R
    author:
    - Césaire J. K. Fouodo
    - Inke R. König
    - Claus Weihs
    - Andreas Ziegler
    - Marvin N. Wright
    bibauthor: |-
      Césaire J. K. Fouodo and Inke R. König and Claus Weihs and
                Andreas Ziegler and Marvin N. Wright
    abstract: '  Abstract This article introduces the R package survivalsvm, implementing
      support vector machines            for survival analysis. Three approaches are
      available in the package: The regression approach takes            censoring
      into account when formulating the inequality constraints of the support vector
      problem.            In the ranking approach, the inequality constraints set
      the objective to maximize the concordance            index for comparable pairs
      of observations. The hybrid approach combines the regression and ranking            constraints
      in a single model. We describe survival support vector machines and their implementation,            provide
      examples and compare the prediction performance with the Cox proportional hazards
      model,            random survival forests and gradient boosting using several
      real datasets. On these datasets, survival            support vector machines
      perform on par with the reference methods.'
    acknowledged: '2017-10-01'
    online: '2018-05-16'
    CRANpkgs:
    - survivalsvm
    - kernlab
    - pracma
    - quadprog
    - Matrix
    - randomForestSRC
    - mboost
    - mlr
    - ggplot2
    - tikzDevice
    CTV_rev:
    - MachineLearning
    - Multivariate
    - NumericalMathematics
    - Optimization
    - Survival
    - Cluster
    - DifferentialEquations
    - Econometrics
    - Graphics
    - HighPerformanceComputing
    - NaturalLanguageProcessing
    - Phylogenetics
    - ReproducibleResearch
    suppl: 11.2 Kb
    landing: '2018'
    pages:
    - 412
    - 423
  - slug: RJ-2018-008
    title: Nonparametric Independence Tests and k-sample Tests for Large Sample Sizes
      Using Package HHG
    bibtitle: |-
      Nonparametric Independence Tests and k-sample Tests for
                Large Sample Sizes Using Package HHG
    author:
    - Barak Brill
    - Yair Heller
    - Ruth Heller
    bibauthor: Barak Brill and Yair Heller and Ruth Heller
    abstract: '  Abstract Nonparametric tests of independence and k-sample tests are
      ubiquitous in modern applica           tions, but they are typically computationally
      expensive. We present a family of nonparametric tests            that are computationally
      efficient and powerful for detecting any type of dependence between a pair            of
      univariate random variables. The computational complexity of the suggested tests
      is sub-quadratic            in sample size, allowing calculation of test statistics
      for millions of observations. We survey both            algorithms and the HHG
      package in which they are implemented, with usage examples showing            the
      implementation of the proposed tests for both the independence case and the
      k-sample problem.            The tests are compared to existing nonparametric
      tests via several simulation studies comparing both            runtime and power.
      Special focus is given to the design of data structures used in implementation
      of            the tests. These data structures can be useful for developers
      of nonparametric distribution-free tests.'
    acknowledged: '2017-10-23'
    online: '2018-05-16'
    CRANpkgs:
    - Hmisc
    - infotheo
    - entropy
    - minerva
    - dHSIC
    - energy
    - HHG
    - kernlab
    - dslice
    - rbenchmark
    - doRNG
    BIOpkgs: minet
    CTV_rev:
    - Multivariate
    - Bayesian
    - ClinicalTrials
    - Cluster
    - Econometrics
    - HighPerformanceComputing
    - MachineLearning
    - NaturalLanguageProcessing
    - OfficialStatistics
    - Optimization
    - ReproducibleResearch
    - SocialSciences
    suppl: 20.8 Kb
    landing: '2018'
    pages:
    - 424
    - 438
  - slug: RJ-2018-009
    title: 'Simple Features for R: Standardized Support for Spatial Vector Data'
    bibtitle: |-
      Simple Features for R: Standardized Support for Spatial
                Vector Data
    author: Edzer Pebesma
    bibauthor: Edzer Pebesma
    abstract: '  Abstract Simple features are a standardized way of encoding spatial
      vector data (points, lines,            polygons) in computers. The sf package
      implements simple features in R, and has roughly the same            capacity
      for spatial vector data as packages sp, rgeos, and rgdal. We describe the need
      for this package,            its place in the R package ecosystem, and its potential
      to connect R to other computer systems. We            illustrate this with examples
      of its use.'
    acknowledged: '2017-11-05'
    online: '2018-05-16'
    CRANpkgs:
    - sf
    - sp
    - rgdal
    - rgeos
    - tidyverse
    - dplyr
    - ggplot2
    - lwgeom
    - geosphere
    - s2
    - raster
    - Rcpp
    CTV_rev:
    - Spatial
    - SpatioTemporal
    - Graphics
    - HighPerformanceComputing
    - ModelDeployment
    - NumericalMathematics
    - Phylogenetics
    suppl: 775 bytes
    landing: '2018'
    pages:
    - 439
    - 446
  - slug: RJ-2018-010
    title: 'Pstat: An R Package to Assess Population Differentiation in Phenotypic
      Traits'
    bibtitle: |-
      Pstat: An R Package to Assess Population Differentiation in
                Phenotypic Traits
    author:
    - Stéphane Blondeau Da Silva
    - Anne Da Silva
    bibauthor: Stéphane Blondeau Da Silva and Anne Da Silva
    abstract: '  Abstract The package Pstat calculates PST values to assess differentiation
      among populations from            a set of quantitative traits and provides
      bootstrapped distributions and confidence intervals for PST .            Variations
      of PST as a function of the parameter c/h2 are studied as well. The package
      implements            different transformations of the measured phenotypic traits
      to eliminate variation resulting from            allometric growth, including
      calculation of residuals from linear regression, Reist standardization, and            the
      Aitchison transformation.'
    acknowledged: '2017-11-05'
    online: '2018-05-16'
    CRANpkgs:
    - Pstat
    - diveRsity
    - hierfstat
    CTV_rev: Genetics
    suppl: 4 Kb
    landing: '2018'
    pages:
    - 447
    - 454
  - slug: RJ-2018-037
    title: 'Collections in R: Review and Proposal'
    bibtitle: 'Collections in R: Review and Proposal'
    author: Timothy Barry
    bibauthor: Timothy Barry
    abstract: '  Abstract R is a powerful tool for data processing, visualization,
      and modeling. However, R is slower            than other languages used for
      similar purposes, such as Python. One reason for this is that R lacks            base
      support for collections, abstract data types that store, manipulate, and return
      data (e.g., sets,            maps, stacks). An exciting recent trend in the
      R extension ecosystem is the development of collection            packages,
      packages that provide classes that implement common collections. At least 12
      collection            packages are available across the two major R extension
      repositories, the Comprehensive R Archive            Network (CRAN) and Bioconductor.
      In this article, we compare collection packages in terms of their            features,
      design philosophy, ease of use, and performance on benchmark tests. We demonstrate
      that,            when used well, the data structures provided by collection
      packages are in many cases significantly            faster than the data structures
      provided by base R. We also highlight current deficiencies among            R
      collection packages and propose avenues of possible improvement. This article
      provides useful            recommendations to R programmers seeking to speed
      up their programs and aims to inform the            development of future collection-oriented
      software for R.'
    acknowledged: '2017-11-05'
    online: '2018-06-13'
    CRANpkgs:
    - Rcpp
    - hashr
    - hashFunction
    - filehashSQLite
    - tictoc
    - DSL
    - bit64
    - bit
    - Oarray
    - sets
    - filehash
    - hash
    - hashmap
    - rstackdeque
    - rstack
    - liqueueR
    - dequer
    - flifo
    - listenv
    - stdvectors
    - microbenchmark
    - neuroim
    - FindMinIC
    BIOpkgs: S4Vectors
    CTV_rev:
    - HighPerformanceComputing
    - MedicalImaging
    - NumericalMathematics
    landing: '2018'
    pages:
    - 455
    - 471
  - slug: RJ-2018-011
    title: Approximating the Sum of Independent Non-Identical Binomial Random Variables
    bibtitle: |-
      Approximating the Sum of Independent Non-Identical Binomial
                Random Variables
    author:
    - Boxiang Liu
    - Thomas Quertermous
    bibauthor: Boxiang Liu and Thomas Quertermous
    abstract: '  Abstract The distribution of the sum of independent non-identical
      binomial random variables is            frequently encountered in areas such
      as genomics, healthcare, and operations research. Analytical            solutions
      for the density and distribution are usually cumbersome to find and difficult
      to compute.            Several methods have been developed to approximate the
      distribution, among which is the saddlepoint            approximation. However,
      implementation of the saddlepoint approximation is non-trivial. In this            paper,
      we implement the saddlepoint approximation in the sinib package and provide
      two examples            to illustrate its usage. One example uses simulated
      data while the other uses real-world healthcare data.            The sinib package
      addresses the gap between the theory and the implementation of approximating            the
      sum of independent non-identical binomials.'
    acknowledged: '2017-12-05'
    online: '2018-05-16'
    CRANpkgs:
    - stats
    - EQL
    - sinib
    suppl: 1.9 Kb
    landing: '2018'
    pages:
    - 472
    - 483
  - slug: RJ-2018-012
    title: 'cchs: An R Package for Stratified Case-Cohort Studies'
    bibtitle: 'cchs: An R Package for Stratified Case-Cohort Studies'
    author: Edmund Jones
    bibauthor: Edmund Jones
    abstract: '  Abstract The cchs package contains a function, also called cchs,
      for analyzing data from a stratified            case-cohort study, as used in
      epidemiology. For data from this type of study, cchs calculates Estimator            III
      of Borgan et al. (2000), which is a score-unbiased estimator for the regression
      coefficients in the            Cox proportional hazards model. From the user’s
      point of view, the function is similar to coxph            (in the survival
      package) and other widely used model-fitting functions. Convenient software
      has            not previously been available for Estimator III since it is complicated
      to calculate. SAS and S-Plus            code-fragments for the calculation have
      been published, but cchs is easier to use and more efficient            in terms
      of time and memory, and can cope with much larger datasets. It also avoids several
      minor            approximations and simplifications.'
    acknowledged: '2017-12-28'
    online: '2018-05-16'
    CRANpkgs:
    - cchs
    - survival
    - cchs
    - survival
    - survey
    - NestedCohort
    CTV_rev:
    - Survival
    - SocialSciences
    - ClinicalTrials
    - Econometrics
    - OfficialStatistics
    suppl: 1.3 Kb
    landing: '2018'
    pages:
    - 484
    - 494
  - slug: RJ-2018-036
    title: Small Area Disease Risk Estimation and Visualization Using R
    bibtitle: Small Area Disease Risk Estimation and Visualization Using R
    author: Paula Moraga
    bibauthor: Paula Moraga
    abstract: '  Abstract Small area disease risk estimation is essential for disease
      prevention and control. In this            paper, we demonstrate how R can be
      used to obtain disease risk estimates and quantify risk factors            using
      areal data. We explain how to define disease risk models and how to perform
      Bayesian inference            using the INLA package. We also show how to make
      interactive maps of estimates using the leaflet            package to better
      understand the disease spatial patterns and communicate the results. We show
      an            example of lung cancer risk in Pennsylvania, United States, in
      year 2002, and demonstrate that R            represents an excellent tool for
      disease surveillance by enabling reproducible health data analysis.'
    acknowledged: '2018-02-03'
    online: '2018-06-07'
    CRANpkgs:
    - leaflet
    - SpatialEpi
    - spdep
    - ggplot2
    - flexdashboard
    - shiny
    - SpatialEpiApp
    - dygraphs
    - DT
    - rmarkdown
    CTV_rev:
    - ReproducibleResearch
    - Spatial
    - Econometrics
    - Graphics
    - Phylogenetics
    - TimeSeries
    - WebTechnologies
    suppl: 1.7 Kb
    landing: '2018'
    pages:
    - 495
    - 506
  - slug: RJ-2018-031
    title: 'SetMethods: an Add-on R Package for Advanced QCA'
    bibtitle: 'SetMethods: an Add-on R Package for Advanced QCA'
    author:
    - Ioana-Elena Oana
    - Carsten Q. Schneider
    bibauthor: Ioana-Elena Oana and Carsten Q. Schneider
    abstract: '  Abstract This article presents the functionalities of the R package
      SetMethods, aimed at performing            advanced set-theoretic analyses.
      This includes functions for performing set-theoretic multi-method            research,
      set-theoretic theory evaluation, Enhanced Standard Analysis, diagnosing the
      impact of            temporal, spatial, or substantive clusterings of the data
      on the results obtained via Qualitative Com           parative Analysis (QCA),
      indirect calibration, and visualising QCA results via XY plots or radar charts.            Each
      functionality is presented in turn, the conceptual idea and the logic behind
      the procedure being            first summarized, and afterwards illustrated
      with data from Schneider et al. (2010).'
    acknowledged: '2018-02-02'
    online: '2018-05-21'
    CRANpkgs:
    - QCA
    - SetMethods
    suppl: 5.5 Kb
    landing: '2018'
    pages:
    - 507
    - 533
  - slug: RJ-2018-032
    title: 'HRM: An R Package for Analysing High-dimensional Multi-factor Repeated
      Measures'
    bibtitle: |-
      HRM: An R Package for Analysing High-dimensional Multi-
                factor Repeated Measures
    author:
    - Martin Happ
    - Solomon W. Harrar
    - Arne C. Bathke
    bibauthor: Martin Happ and Solomon W. Harrar and Arne C. Bathke
    abstract: '  Abstract High-dimensional longitudinal data pose a serious challenge
      for statistical inference as many            test statistics cannot be computed
      for high-dimensional data, or they do not maintain the nominal            type-I
      error rate, or have very low power. Therefore, it is necessary to derive new
      inference methods            capable of dealing with high dimensionality, and
      to make them available to statistics practitioners.            One such method
      is implemented in the package HRM described in this article. This new method            uses
      a similar approach as the Welch-Satterthwaite t-test approximation and works
      very well for            high-dimensional data as long as the data distribution
      is not too skewed or heavy-tailed. The package            also provides a GUI
      to offer an easy way to apply the methods.'
    acknowledged: '2018-03-02'
    online: '2018-05-21'
    CRANpkgs:
    - HRM
    - ggplot2
    - data.table
    - RGtk2
    - RGtk2Extras
    - cairoDevice
    - xtable
    - longitudinal
    - MANOVA.RM
    CTV_rev:
    - Graphics
    - Finance
    - HighPerformanceComputing
    - Phylogenetics
    - ReproducibleResearch
    landing: '2018'
    pages:
    - 534
    - 548
  - heading: News and Notes
  - slug: erums
    author: Gergely Daróczi
    title: 'Conference Report: eRum 2018'
    bibtitle: 'Conference Report: eRum 2018'
    bibauthor: Gergely Daróczi
    pages:
    - 549
    - 550
  - slug: rday
    author:
    - Fernando P. Mayer
    - Walmes M. Zeviani
    - Wagner H. Bonat
    - Elias T. Krainski
    - Paulo J. Ribeiro Jr           About
    title: R Day report
    bibtitle: R Day report
    bibauthor: |-
      Fernando P. Mayer and Walmes M. Zeviani and Wagner H. Bonat
                and Elias T. Krainski and Paulo J. Ribeiro Jr About
    pages:
    - 551
    - 554
  - slug: foundation
    author: Torsten Hothorn
    title: R Foundation News
    bibtitle: R Foundation News
    bibauthor: Torsten Hothorn
    pages:
    - 555
    - 555
  - slug: cran
    author:
    - Kurt Hornik
    - Uwe Ligges
    - Achim Zeileis
    title: Changes on CRAN
    bibtitle: Changes on CRAN
    bibauthor: Kurt Hornik and Uwe Ligges and Achim Zeileis
    pages:
    - 556
    - 559
  - slug: bioc
    author: Bioconductor Core Team
    title: News from the Bioconductor Project
    bibtitle: News from the Bioconductor Project
    bibauthor: Bioconductor Core Team
    pages:
    - 560
    - 560
  - slug: ch
    author: R Core Team
    title: Changes in R
    bibtitle: Changes in R
    bibauthor: R Core Team
    pages:
    - 561
    - 570

